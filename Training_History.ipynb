{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lolikgiovi/ConvNeXt-Repro/blob/main/Training_History.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLDhghC4ZScc"
      },
      "source": [
        "## Installing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X1NHh8vo6HsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb8c96e-6c90-41d5-f161-5339b8968367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m880.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.0+cu111) (8.4.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0+cu111 torchvision-0.9.0+cu111\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.3.2\n",
            "  Downloading timm-0.3.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (1.15.0)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.8/dist-packages (from timm==0.3.2) (1.8.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm==0.3.2) (0.9.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0->timm==0.3.2) (4.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.3.2) (8.4.0)\n",
            "Installing collected packages: tensorboardX, timm\n",
            "Successfully installed tensorboardX-2.6 timm-0.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (8.1.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=47c353a521dc07d17a7c2263f16ef21d66ea46f0f5ebd751170193f8b9e0cbe2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.16.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.13.10\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install timm==0.3.2 tensorboardX six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zfHP00nmNvj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23d0c9d-b636-45ec-f3c1-bb31ff9bcada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ConvNeXt'...\n",
            "remote: Enumerating objects: 252, done.\u001b[K\n",
            "remote: Counting objects: 100% (249/249), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 252 (delta 129), reused 192 (delta 110), pack-reused 3\u001b[K\n",
            "Receiving objects: 100% (252/252), 69.63 KiB | 963.00 KiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/ConvNeXt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "znP2jlYfYPEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8fd8323-b5c1-49d4-9267-56c2b27d9d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional: Using Weights a& Biases Dashboard\n",
        "I found it convenient to monitor my model training performance via W&B Dashboard. You can log in to W&B using this command and follow the instruction through."
      ],
      "metadata": {
        "id": "NG1rusYIWIMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1178f6d81bafb6a3f9362a927de31ed685ab4c59\n",
        "!pip install wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shGZtSWkMe7z",
        "outputId": "c4eea47b-1c5a-4beb-fa43-76498d18a9ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT6CasRLZZKW"
      },
      "source": [
        "## Dataset\n",
        "I am using [Imagenette Dataset](https://github.com/fastai/imagenette). It is a **subset of Imagenet** dataset, the dataset being used in [the official ConvNeXt implementation](https://github.com/facebookresearch/ConvNeXt).\n",
        "\n",
        "Both of the dataset containing images with Fullsize, 320px and 160px size. I am using the 160px for training the ConvNeXt model.\n",
        "\n",
        "The dataset also comes with a CSV file with 1%, 5%, 25%, and 50% of the labels randomly changed to an incorrect label.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tCqILVtanjC"
      },
      "source": [
        "### Imagenette\n",
        "*Imagenette* is a subset of 10 easily classified classes from Imagenet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6fis649mas-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e043054a-24d3-40ae-93e7-e4e1b2977ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-05 15:38:18--  https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.165.160, 52.217.118.160, 52.217.101.110, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.165.160|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99003388 (94M) [application/x-tar]\n",
            "Saving to: ‘imagenette2-160.tgz’\n",
            "\n",
            "imagenette2-160.tgz 100%[===================>]  94.42M  26.8MB/s    in 3.5s    \n",
            "\n",
            "2023-03-05 15:38:22 (26.8 MB/s) - ‘imagenette2-160.tgz’ saved [99003388/99003388]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Getting data from Imagenette\n",
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
        "!tar -xzf imagenette2-160.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YneHUU_BaVwf"
      },
      "source": [
        "### Alternative: Imagewoof\n",
        "*Imagewoof* is a subset of 10 classes from Imagenet **that aren't so easy to classify**, since they're all dog breeds. The breeds are: Australian terrier, Border terrier, Samoyed, Beagle, Shih-Tzu, English foxhound, Rhodesian ridgeback, Dingo, Golden retriever, Old English sheepdog. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG6uNmu_6NnL"
      },
      "outputs": [],
      "source": [
        "# Getting data from Imagewoof\n",
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-160.tgz\n",
        "!tar -xvzf imagewoof2-160.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HmeCL0nPqIq"
      },
      "source": [
        "## Setting up Model Training in Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq763_bgYW6m"
      },
      "source": [
        "Original training command [from repo](https://github.com/facebookresearch/ConvNeXt/blob/main/TRAINING.md):\n",
        "\n",
        "\n",
        "```\n",
        "python -m torch.distributed.launch --nproc_per_node=8 main.py \\\n",
        "                                   --model convnext_tiny --drop_path 0.1 \\\n",
        "                                   --batch_size 128 --lr 4e-3 --update_freq 4 \\\n",
        "                                   --model_ema true --model_ema_eval true \\\n",
        "                                   --data_path /path/to/imagenet-1k \n",
        "                                   --output_dir /path/to/save_results\n",
        "```\n",
        "\n",
        "Using this command straight up in my Google Colab, it will resulting error like:\n",
        "```\n",
        "RuntimeError: CUDA error: invalid device ordinal  File \"main.py\", line 477, in <module>\n",
        "```\n",
        "\n",
        "So I specified the CUDA Device first and changed the nproc_per_node from 8 to 1, my training command become:\n",
        "```\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_tiny --drop_path 0.1 \\\n",
        "                                    --batch_size 128 --lr 4e-3 --update_freq 4 \\\n",
        "                                    --model_ema true --model_ema_eval true \\\n",
        "                                    --input_size 160 --drop_path 0.2 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --output_dir /content/res\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEeKMWF06X9x",
        "outputId": "e48ee53e-b9be-4182-a622-080626af11d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ConvNeXt\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ConvNeXt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am using ConvNeXt Tiny as the model architecture, since my task is requiring me to train the models using smallest dataset, then a smaller architecture will fit best since it have fewer parameters and require less data to train."
      ],
      "metadata": {
        "id": "ZPeuTOAALyGS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmUA0BePRAQm"
      },
      "source": [
        "### ConvNeXt-T -- Batch 32, Augmentation Default\n",
        "- Batch size: 32\n",
        "- Epochs: 100\n",
        "- Update Freq: 4\n",
        "- Input Size: 160 (Imagenette2-160)\n",
        "- Learning rate: 0.004\n",
        "- Drop: 0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my first trial on Training the model. I tried to train 100 epoch with 50-30-20 steps since I want to see the initial performance first before doing the whole 100 epochs. "
      ],
      "metadata": {
        "id": "QAAzsbiAXFWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZkrN_Cq7jI0",
        "outputId": "c8b3c188-5c9f-4b2b-f3c2-3191b98ace29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt\n",
            "| distributed init (rank 0): env://, gpu 0\n",
            "Namespace(aa='original', auto_resume=True, batch_size=32, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_backend='nccl', dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=True, drop_path=0.1, enable_wandb=True, epochs=50, eval=False, eval_data_path=None, finetune='', gpu=0, head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=0, log_dir='/content/result_tiny', lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=True, model_ema_decay=0.9999, model_ema_eval=True, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/content/result_tiny', pin_mem=True, project='convnext', rank=0, recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=4, use_amp=False, wandb_ckpt=True, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.AutoAugment object at 0x7fc2809ed7f0>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7fc280977430>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fc2809f4130>\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlolikgiovi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ConvNeXt/wandb/run-20230304_224509-lsmcg0yh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclean-frog-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/lsmcg0yh\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Using EMA with decay = 0.99990000\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 128\n",
            "Update frequent = 4\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 73\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 1460\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Auto resume checkpoint: \n",
            "Start training for 50 epochs\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [0]  [  0/295]  eta: 0:20:49  lr: 0.000000  min_lr: 0.000000  loss: 7.0436 (7.0436)  weight_decay: 0.0500 (0.0500)  time: 4.2372  data: 1.9341  max mem: 3500\n",
            "Epoch: [0]  [ 10/295]  eta: 0:02:57  lr: 0.000005  min_lr: 0.000005  loss: 7.0696 (7.0563)  weight_decay: 0.0500 (0.0500)  time: 0.6239  data: 0.1766  max mem: 3500\n",
            "Epoch: [0]  [ 20/295]  eta: 0:02:03  lr: 0.000014  min_lr: 0.000014  loss: 7.0460 (7.0483)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0013  max mem: 3500\n",
            "Epoch: [0]  [ 30/295]  eta: 0:01:42  lr: 0.000019  min_lr: 0.000019  loss: 6.9645 (6.9953)  weight_decay: 0.0500 (0.0500)  time: 0.2536  data: 0.0012  max mem: 3500\n",
            "Epoch: [0]  [ 40/295]  eta: 0:01:29  lr: 0.000027  min_lr: 0.000027  loss: 6.8312 (6.9475)  weight_decay: 0.0500 (0.0500)  time: 0.2488  data: 0.0007  max mem: 3500\n",
            "Epoch: [0]  [ 50/295]  eta: 0:01:21  lr: 0.000033  min_lr: 0.000033  loss: 6.7204 (6.8798)  weight_decay: 0.0500 (0.0500)  time: 0.2494  data: 0.0008  max mem: 3500\n",
            "Epoch: [0]  [ 60/295]  eta: 0:01:15  lr: 0.000041  min_lr: 0.000041  loss: 6.5038 (6.8008)  weight_decay: 0.0500 (0.0500)  time: 0.2522  data: 0.0011  max mem: 3500\n",
            "Epoch: [0]  [ 70/295]  eta: 0:01:10  lr: 0.000047  min_lr: 0.000047  loss: 6.1955 (6.6927)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0015  max mem: 3500\n",
            "Epoch: [0]  [ 80/295]  eta: 0:01:05  lr: 0.000055  min_lr: 0.000055  loss: 5.9260 (6.5971)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0022  max mem: 3500\n",
            "Epoch: [0]  [ 90/295]  eta: 0:01:01  lr: 0.000060  min_lr: 0.000060  loss: 5.6575 (6.4772)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0023  max mem: 3500\n",
            "Epoch: [0]  [100/295]  eta: 0:00:57  lr: 0.000069  min_lr: 0.000069  loss: 5.4776 (6.3696)  weight_decay: 0.0500 (0.0500)  time: 0.2571  data: 0.0014  max mem: 3500\n",
            "Epoch: [0]  [110/295]  eta: 0:00:54  lr: 0.000074  min_lr: 0.000074  loss: 5.1557 (6.2596)  weight_decay: 0.0500 (0.0500)  time: 0.2558  data: 0.0008  max mem: 3500\n",
            "Epoch: [0]  [120/295]  eta: 0:00:50  lr: 0.000082  min_lr: 0.000082  loss: 4.6330 (6.1278)  weight_decay: 0.0500 (0.0500)  time: 0.2562  data: 0.0005  max mem: 3500\n",
            "Epoch: [0]  [130/295]  eta: 0:00:47  lr: 0.000088  min_lr: 0.000088  loss: 4.5812 (6.0164)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0003  max mem: 3500\n",
            "Epoch: [0]  [140/295]  eta: 0:00:44  lr: 0.000096  min_lr: 0.000096  loss: 4.3811 (5.9103)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0017  max mem: 3500\n",
            "Epoch: [0]  [150/295]  eta: 0:00:41  lr: 0.000101  min_lr: 0.000101  loss: 4.3650 (5.8117)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0036  max mem: 3500\n",
            "Epoch: [0]  [160/295]  eta: 0:00:38  lr: 0.000110  min_lr: 0.000110  loss: 4.0304 (5.7010)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0027  max mem: 3500\n",
            "Epoch: [0]  [170/295]  eta: 0:00:35  lr: 0.000115  min_lr: 0.000115  loss: 3.9260 (5.6053)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0011  max mem: 3500\n",
            "Epoch: [0]  [180/295]  eta: 0:00:32  lr: 0.000123  min_lr: 0.000123  loss: 3.8931 (5.5101)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0017  max mem: 3500\n",
            "Epoch: [0]  [190/295]  eta: 0:00:29  lr: 0.000129  min_lr: 0.000129  loss: 3.9364 (5.4269)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0016  max mem: 3500\n",
            "Epoch: [0]  [200/295]  eta: 0:00:26  lr: 0.000137  min_lr: 0.000137  loss: 3.8883 (5.3447)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0008  max mem: 3500\n",
            "Epoch: [0]  [210/295]  eta: 0:00:23  lr: 0.000143  min_lr: 0.000143  loss: 3.8439 (5.2857)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0016  max mem: 3500\n",
            "Epoch: [0]  [220/295]  eta: 0:00:20  lr: 0.000151  min_lr: 0.000151  loss: 3.8337 (5.2300)  weight_decay: 0.0500 (0.0500)  time: 0.2772  data: 0.0022  max mem: 3500\n",
            "Epoch: [0]  [230/295]  eta: 0:00:18  lr: 0.000156  min_lr: 0.000156  loss: 3.6658 (5.1689)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0019  max mem: 3500\n",
            "Epoch: [0]  [240/295]  eta: 0:00:15  lr: 0.000164  min_lr: 0.000164  loss: 3.5741 (5.1016)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0014  max mem: 3500\n",
            "Epoch: [0]  [250/295]  eta: 0:00:12  lr: 0.000170  min_lr: 0.000170  loss: 3.3932 (5.0355)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0010  max mem: 3500\n",
            "Epoch: [0]  [260/295]  eta: 0:00:09  lr: 0.000178  min_lr: 0.000178  loss: 3.2954 (4.9671)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0009  max mem: 3500\n",
            "Epoch: [0]  [270/295]  eta: 0:00:06  lr: 0.000184  min_lr: 0.000184  loss: 3.1817 (4.9034)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0016  max mem: 3500\n",
            "Epoch: [0]  [280/295]  eta: 0:00:04  lr: 0.000192  min_lr: 0.000192  loss: 3.1443 (4.8398)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0017  max mem: 3500\n",
            "Epoch: [0]  [290/295]  eta: 0:00:01  lr: 0.000197  min_lr: 0.000197  loss: 3.1052 (4.7798)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0006  max mem: 3500\n",
            "Epoch: [0]  [294/295]  eta: 0:00:00  lr: 0.000197  min_lr: 0.000197  loss: 3.1030 (4.7741)  weight_decay: 0.0500 (0.0500)  time: 0.2228  data: 0.0001  max mem: 3500\n",
            "Epoch: [0] Total time: 0:01:21 (0.2751 s / it)\n",
            "Averaged stats: lr: 0.000197  min_lr: 0.000197  loss: 3.1030 (4.7741)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:00  loss: 2.1231 (2.1231)  acc1: 43.7500 (43.7500)  acc5: 91.6667 (91.6667)  time: 2.9278  data: 2.6080  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 2.0948 (2.1770)  acc1: 47.9167 (36.5530)  acc5: 91.6667 (86.9318)  time: 0.3747  data: 0.2378  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 2.3502 (2.2879)  acc1: 20.8333 (24.1071)  acc5: 66.6667 (75.1984)  time: 0.1191  data: 0.0016  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.3332 (2.2726)  acc1: 20.8333 (23.5215)  acc5: 64.5833 (78.2930)  time: 0.1191  data: 0.0025  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.3281 (2.3554)  acc1: 16.6667 (18.9024)  acc5: 60.4167 (65.8537)  time: 0.1348  data: 0.0028  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.4609 (2.3451)  acc1: 0.0000 (21.7729)  acc5: 20.8333 (66.1765)  time: 0.1395  data: 0.0017  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 2.2729 (2.3893)  acc1: 12.5000 (19.3648)  acc5: 68.7500 (60.5874)  time: 0.1303  data: 0.0010  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.2812 (2.3681)  acc1: 14.5833 (21.2148)  acc5: 68.7500 (62.2066)  time: 0.1374  data: 0.0025  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.2443 (2.3561)  acc1: 22.9167 (20.0874)  acc5: 77.0833 (64.6348)  time: 0.1292  data: 0.0017  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.2443 (2.3555)  acc1: 22.9167 (19.9236)  acc5: 79.1667 (64.8153)  time: 0.1255  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1681 s / it)\n",
            "* Acc@1 19.924 Acc@5 64.815 loss 2.356\n",
            "Accuracy of the model on the 3925 test images: 19.9%\n",
            "Max accuracy: 19.92%\n",
            "Test:  [ 0/82]  eta: 0:03:05  loss: 7.3245 (7.3245)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.2617  data: 2.0856  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 7.3245 (7.2405)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.3218  data: 0.1961  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 7.0337 (7.1242)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1244  data: 0.0045  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 7.0139 (7.1109)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1200  data: 0.0014  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 7.0134 (7.0810)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1214  data: 0.0037  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 6.9952 (7.0740)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1233  data: 0.0057  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.9529 (7.0456)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0683)  time: 0.1232  data: 0.0044  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.9691 (7.0425)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0880)  time: 0.1200  data: 0.0021  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 7.0683 (7.0491)  acc1: 0.0000 (0.0514)  acc5: 0.0000 (0.2572)  time: 0.1161  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 7.0863 (7.0507)  acc1: 0.0000 (0.0510)  acc5: 0.0000 (0.2803)  time: 0.1147  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1531 s / it)\n",
            "* Acc@1 0.051 Acc@5 0.280 loss 7.051\n",
            "Accuracy of the model EMA on 3925 test images: 0.1%\n",
            "Max EMA accuracy: 0.05%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [1]  [  0/295]  eta: 0:14:02  lr: 0.000200  min_lr: 0.000200  loss: 3.0387 (3.0387)  weight_decay: 0.0500 (0.0500)  time: 2.8549  data: 2.1739  max mem: 3500\n",
            "Epoch: [1]  [ 10/295]  eta: 0:02:32  lr: 0.000206  min_lr: 0.000206  loss: 3.1189 (3.0988)  weight_decay: 0.0500 (0.0500)  time: 0.5366  data: 0.1999  max mem: 3500\n",
            "Epoch: [1]  [ 20/295]  eta: 0:01:51  lr: 0.000214  min_lr: 0.000214  loss: 3.1084 (3.0922)  weight_decay: 0.0500 (0.0500)  time: 0.2828  data: 0.0019  max mem: 3500\n",
            "Epoch: [1]  [ 30/295]  eta: 0:01:34  lr: 0.000219  min_lr: 0.000219  loss: 3.1029 (3.0953)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0018  max mem: 3500\n",
            "Epoch: [1]  [ 40/295]  eta: 0:01:25  lr: 0.000228  min_lr: 0.000228  loss: 3.0860 (3.0889)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0015  max mem: 3500\n",
            "Epoch: [1]  [ 50/295]  eta: 0:01:18  lr: 0.000233  min_lr: 0.000233  loss: 3.0860 (3.0983)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0006  max mem: 3500\n",
            "Epoch: [1]  [ 60/295]  eta: 0:01:13  lr: 0.000241  min_lr: 0.000241  loss: 3.1194 (3.0984)  weight_decay: 0.0500 (0.0500)  time: 0.2745  data: 0.0012  max mem: 3500\n",
            "Epoch: [1]  [ 70/295]  eta: 0:01:09  lr: 0.000247  min_lr: 0.000247  loss: 3.0948 (3.0961)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0011  max mem: 3500\n",
            "Epoch: [1]  [ 80/295]  eta: 0:01:05  lr: 0.000255  min_lr: 0.000255  loss: 3.0948 (3.0975)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0005  max mem: 3500\n",
            "Epoch: [1]  [ 90/295]  eta: 0:01:01  lr: 0.000260  min_lr: 0.000260  loss: 3.0822 (3.0950)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0009  max mem: 3500\n",
            "Epoch: [1]  [100/295]  eta: 0:00:57  lr: 0.000269  min_lr: 0.000269  loss: 3.0699 (3.0926)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0012  max mem: 3500\n",
            "Epoch: [1]  [110/295]  eta: 0:00:54  lr: 0.000274  min_lr: 0.000274  loss: 3.0480 (3.0881)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0013  max mem: 3500\n",
            "Epoch: [1]  [120/295]  eta: 0:00:50  lr: 0.000282  min_lr: 0.000282  loss: 3.0699 (3.0881)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0022  max mem: 3500\n",
            "Epoch: [1]  [130/295]  eta: 0:00:47  lr: 0.000288  min_lr: 0.000288  loss: 3.0836 (3.0883)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0025  max mem: 3500\n",
            "Epoch: [1]  [140/295]  eta: 0:00:44  lr: 0.000296  min_lr: 0.000296  loss: 3.0836 (3.0883)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0023  max mem: 3500\n",
            "Epoch: [1]  [150/295]  eta: 0:00:41  lr: 0.000302  min_lr: 0.000302  loss: 3.0626 (3.0856)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0020  max mem: 3500\n",
            "Epoch: [1]  [160/295]  eta: 0:00:38  lr: 0.000310  min_lr: 0.000310  loss: 3.0508 (3.0835)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0009  max mem: 3500\n",
            "Epoch: [1]  [170/295]  eta: 0:00:35  lr: 0.000315  min_lr: 0.000315  loss: 3.0508 (3.0823)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0008  max mem: 3500\n",
            "Epoch: [1]  [180/295]  eta: 0:00:32  lr: 0.000324  min_lr: 0.000324  loss: 3.0474 (3.0795)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0015  max mem: 3500\n",
            "Epoch: [1]  [190/295]  eta: 0:00:29  lr: 0.000329  min_lr: 0.000329  loss: 3.0514 (3.0802)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0021  max mem: 3500\n",
            "Epoch: [1]  [200/295]  eta: 0:00:26  lr: 0.000337  min_lr: 0.000337  loss: 3.0624 (3.0784)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0029  max mem: 3500\n",
            "Epoch: [1]  [210/295]  eta: 0:00:23  lr: 0.000343  min_lr: 0.000343  loss: 3.0580 (3.0788)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0031  max mem: 3500\n",
            "Epoch: [1]  [220/295]  eta: 0:00:20  lr: 0.000351  min_lr: 0.000351  loss: 3.0722 (3.0785)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0028  max mem: 3500\n",
            "Epoch: [1]  [230/295]  eta: 0:00:18  lr: 0.000356  min_lr: 0.000356  loss: 3.0838 (3.0790)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0026  max mem: 3500\n",
            "Epoch: [1]  [240/295]  eta: 0:00:15  lr: 0.000365  min_lr: 0.000365  loss: 3.0795 (3.0779)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0022  max mem: 3500\n",
            "Epoch: [1]  [250/295]  eta: 0:00:12  lr: 0.000370  min_lr: 0.000370  loss: 3.0633 (3.0769)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0019  max mem: 3500\n",
            "Epoch: [1]  [260/295]  eta: 0:00:09  lr: 0.000378  min_lr: 0.000378  loss: 3.0799 (3.0780)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0015  max mem: 3500\n",
            "Epoch: [1]  [270/295]  eta: 0:00:06  lr: 0.000384  min_lr: 0.000384  loss: 3.0799 (3.0782)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0014  max mem: 3500\n",
            "Epoch: [1]  [280/295]  eta: 0:00:04  lr: 0.000392  min_lr: 0.000392  loss: 3.0751 (3.0786)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0008  max mem: 3500\n",
            "Epoch: [1]  [290/295]  eta: 0:00:01  lr: 0.000398  min_lr: 0.000398  loss: 3.0707 (3.0794)  weight_decay: 0.0500 (0.0500)  time: 0.2552  data: 0.0002  max mem: 3500\n",
            "Epoch: [1]  [294/295]  eta: 0:00:00  lr: 0.000398  min_lr: 0.000398  loss: 3.0751 (3.0797)  weight_decay: 0.0500 (0.0500)  time: 0.2177  data: 0.0002  max mem: 3500\n",
            "Epoch: [1] Total time: 0:01:20 (0.2738 s / it)\n",
            "Averaged stats: lr: 0.000398  min_lr: 0.000398  loss: 3.0751 (3.0797)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:28  loss: 2.2013 (2.2013)  acc1: 25.0000 (25.0000)  acc5: 79.1667 (79.1667)  time: 1.8114  data: 1.6305  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.1839 (2.3151)  acc1: 27.0833 (22.9167)  acc5: 83.3333 (65.7197)  time: 0.2804  data: 0.1511  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.1766 (2.2956)  acc1: 27.0833 (29.2659)  acc5: 81.2500 (59.8214)  time: 0.1448  data: 0.0102  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.5627 (2.3140)  acc1: 0.0000 (26.8145)  acc5: 27.0833 (54.7715)  time: 0.1782  data: 0.0357  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.3248 (2.3143)  acc1: 0.0000 (21.4431)  acc5: 91.6667 (63.4146)  time: 0.1832  data: 0.0462  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 2.1519 (2.2659)  acc1: 2.0833 (24.6732)  acc5: 93.7500 (69.4036)  time: 0.1694  data: 0.0373  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 2.1629 (2.2729)  acc1: 6.2500 (21.1407)  acc5: 89.5833 (70.9358)  time: 0.1598  data: 0.0202  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.4174 (2.3056)  acc1: 2.0833 (19.6303)  acc5: 66.6667 (68.3099)  time: 0.1407  data: 0.0073  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.4174 (2.2631)  acc1: 20.8333 (23.0195)  acc5: 60.4167 (68.7243)  time: 0.1221  data: 0.0054  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.3791 (2.2575)  acc1: 20.8333 (23.3121)  acc5: 60.4167 (68.8917)  time: 0.1158  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1762 s / it)\n",
            "* Acc@1 23.312 Acc@5 68.892 loss 2.258\n",
            "Accuracy of the model on the 3925 test images: 23.3%\n",
            "Max accuracy: 23.31%\n",
            "Test:  [ 0/82]  eta: 0:02:17  loss: 7.3007 (7.3007)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 1.6795  data: 1.5047  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 7.3007 (7.2213)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.2784  data: 0.1512  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 7.0005 (7.1022)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1316  data: 0.0118  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.9932 (7.0917)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1233  data: 0.0065  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 6.9932 (7.0612)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1370  data: 0.0041  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 6.9884 (7.0543)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1455  data: 0.0039  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.9250 (7.0230)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0683)  time: 0.1394  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.9437 (7.0203)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0880)  time: 0.1559  data: 0.0163  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 7.0410 (7.0242)  acc1: 0.0000 (0.0257)  acc5: 0.0000 (0.2058)  time: 0.1458  data: 0.0156  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 7.0416 (7.0255)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.2293)  time: 0.1283  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1624 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.229 loss 7.025\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [2]  [  0/295]  eta: 0:08:58  lr: 0.000400  min_lr: 0.000400  loss: 3.1166 (3.1166)  weight_decay: 0.0500 (0.0500)  time: 1.8250  data: 1.4235  max mem: 3500\n",
            "Epoch: [2]  [ 10/295]  eta: 0:01:57  lr: 0.000406  min_lr: 0.000406  loss: 3.0979 (3.0812)  weight_decay: 0.0500 (0.0500)  time: 0.4115  data: 0.1323  max mem: 3500\n",
            "Epoch: [2]  [ 20/295]  eta: 0:01:33  lr: 0.000414  min_lr: 0.000414  loss: 3.0865 (3.0918)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0020  max mem: 3500\n",
            "Epoch: [2]  [ 30/295]  eta: 0:01:23  lr: 0.000419  min_lr: 0.000419  loss: 3.0865 (3.0888)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0014  max mem: 3500\n",
            "Epoch: [2]  [ 40/295]  eta: 0:01:17  lr: 0.000428  min_lr: 0.000428  loss: 3.0890 (3.0885)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0025  max mem: 3500\n",
            "Epoch: [2]  [ 50/295]  eta: 0:01:13  lr: 0.000433  min_lr: 0.000433  loss: 3.0932 (3.0893)  weight_decay: 0.0500 (0.0500)  time: 0.2745  data: 0.0034  max mem: 3500\n",
            "Epoch: [2]  [ 60/295]  eta: 0:01:09  lr: 0.000441  min_lr: 0.000441  loss: 3.0825 (3.0887)  weight_decay: 0.0500 (0.0500)  time: 0.2751  data: 0.0042  max mem: 3500\n",
            "Epoch: [2]  [ 70/295]  eta: 0:01:05  lr: 0.000447  min_lr: 0.000447  loss: 3.0595 (3.0856)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0031  max mem: 3500\n",
            "Epoch: [2]  [ 80/295]  eta: 0:01:01  lr: 0.000455  min_lr: 0.000455  loss: 3.0595 (3.0817)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0011  max mem: 3500\n",
            "Epoch: [2]  [ 90/295]  eta: 0:00:58  lr: 0.000461  min_lr: 0.000461  loss: 3.0639 (3.0798)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0015  max mem: 3500\n",
            "Epoch: [2]  [100/295]  eta: 0:00:55  lr: 0.000469  min_lr: 0.000469  loss: 3.0544 (3.0771)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0019  max mem: 3500\n",
            "Epoch: [2]  [110/295]  eta: 0:00:52  lr: 0.000474  min_lr: 0.000474  loss: 3.0481 (3.0740)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0029  max mem: 3500\n",
            "Epoch: [2]  [120/295]  eta: 0:00:49  lr: 0.000483  min_lr: 0.000483  loss: 3.0287 (3.0746)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0044  max mem: 3500\n",
            "Epoch: [2]  [130/295]  eta: 0:00:46  lr: 0.000488  min_lr: 0.000488  loss: 3.0626 (3.0742)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0027  max mem: 3500\n",
            "Epoch: [2]  [140/295]  eta: 0:00:43  lr: 0.000496  min_lr: 0.000496  loss: 3.0554 (3.0725)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0012  max mem: 3500\n",
            "Epoch: [2]  [150/295]  eta: 0:00:40  lr: 0.000502  min_lr: 0.000502  loss: 3.0543 (3.0727)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0019  max mem: 3500\n",
            "Epoch: [2]  [160/295]  eta: 0:00:37  lr: 0.000510  min_lr: 0.000510  loss: 3.0689 (3.0724)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0028  max mem: 3500\n",
            "Epoch: [2]  [170/295]  eta: 0:00:34  lr: 0.000515  min_lr: 0.000515  loss: 3.0664 (3.0720)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0034  max mem: 3500\n",
            "Epoch: [2]  [180/295]  eta: 0:00:31  lr: 0.000524  min_lr: 0.000524  loss: 3.0732 (3.0738)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0042  max mem: 3500\n",
            "Epoch: [2]  [190/295]  eta: 0:00:28  lr: 0.000529  min_lr: 0.000529  loss: 3.0884 (3.0730)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0041  max mem: 3500\n",
            "Epoch: [2]  [200/295]  eta: 0:00:25  lr: 0.000537  min_lr: 0.000537  loss: 3.0850 (3.0746)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0024  max mem: 3500\n",
            "Epoch: [2]  [210/295]  eta: 0:00:23  lr: 0.000543  min_lr: 0.000543  loss: 3.0706 (3.0741)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0017  max mem: 3500\n",
            "Epoch: [2]  [220/295]  eta: 0:00:20  lr: 0.000551  min_lr: 0.000551  loss: 3.0627 (3.0734)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0017  max mem: 3500\n",
            "Epoch: [2]  [230/295]  eta: 0:00:17  lr: 0.000557  min_lr: 0.000557  loss: 3.0646 (3.0739)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0016  max mem: 3500\n",
            "Epoch: [2]  [240/295]  eta: 0:00:14  lr: 0.000565  min_lr: 0.000565  loss: 3.0620 (3.0723)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0025  max mem: 3500\n",
            "Epoch: [2]  [250/295]  eta: 0:00:12  lr: 0.000570  min_lr: 0.000570  loss: 3.0412 (3.0712)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0050  max mem: 3500\n",
            "Epoch: [2]  [260/295]  eta: 0:00:09  lr: 0.000578  min_lr: 0.000578  loss: 3.0636 (3.0707)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0043  max mem: 3500\n",
            "Epoch: [2]  [270/295]  eta: 0:00:06  lr: 0.000584  min_lr: 0.000584  loss: 3.0560 (3.0702)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0013  max mem: 3500\n",
            "Epoch: [2]  [280/295]  eta: 0:00:04  lr: 0.000592  min_lr: 0.000592  loss: 3.0649 (3.0707)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0006  max mem: 3500\n",
            "Epoch: [2]  [290/295]  eta: 0:00:01  lr: 0.000598  min_lr: 0.000598  loss: 3.0340 (3.0686)  weight_decay: 0.0500 (0.0500)  time: 0.2565  data: 0.0005  max mem: 3500\n",
            "Epoch: [2]  [294/295]  eta: 0:00:00  lr: 0.000598  min_lr: 0.000598  loss: 3.0340 (3.0685)  weight_decay: 0.0500 (0.0500)  time: 0.2182  data: 0.0003  max mem: 3500\n",
            "Epoch: [2] Total time: 0:01:19 (0.2683 s / it)\n",
            "Averaged stats: lr: 0.000598  min_lr: 0.000598  loss: 3.0340 (3.0685)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:01  loss: 2.1702 (2.1702)  acc1: 18.7500 (18.7500)  acc5: 75.0000 (75.0000)  time: 2.9449  data: 2.7187  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 2.1407 (2.1244)  acc1: 16.6667 (21.7803)  acc5: 85.4167 (85.6061)  time: 0.4270  data: 0.2879  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 2.1201 (2.1175)  acc1: 29.1667 (27.8770)  acc5: 87.5000 (88.2937)  time: 0.1828  data: 0.0293  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 2.1472 (2.2229)  acc1: 25.0000 (21.2366)  acc5: 85.4167 (73.8575)  time: 0.1683  data: 0.0123  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 2.1097 (2.1919)  acc1: 14.5833 (21.0366)  acc5: 83.3333 (77.6423)  time: 0.1338  data: 0.0069  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 2.0767 (2.2010)  acc1: 20.8333 (24.2647)  acc5: 79.1667 (74.0605)  time: 0.1235  data: 0.0038  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 2.3552 (2.2621)  acc1: 0.0000 (20.3210)  acc5: 66.6667 (68.6817)  time: 0.1230  data: 0.0041  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.4389 (2.2885)  acc1: 0.0000 (18.5739)  acc5: 52.0833 (67.6937)  time: 0.1197  data: 0.0019  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.3627 (2.2040)  acc1: 14.5833 (23.9969)  acc5: 72.9167 (69.0844)  time: 0.1179  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.3385 (2.1944)  acc1: 16.6667 (24.4586)  acc5: 72.9167 (69.2739)  time: 0.1158  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1774 s / it)\n",
            "* Acc@1 24.459 Acc@5 69.274 loss 2.194\n",
            "Accuracy of the model on the 3925 test images: 24.5%\n",
            "Max accuracy: 24.46%\n",
            "Test:  [ 0/82]  eta: 0:02:48  loss: 7.2694 (7.2694)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.0501  data: 1.8578  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 7.2747 (7.1960)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.3556  data: 0.1953  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 6.9684 (7.0750)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1717  data: 0.0281  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 6.9684 (7.0685)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0672)  time: 0.1759  data: 0.0381  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 6.9800 (7.0373)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0508)  time: 0.1723  data: 0.0337  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 6.9800 (7.0306)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0408)  time: 0.1566  data: 0.0191  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 6.8918 (6.9963)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.1025)  time: 0.1442  data: 0.0120  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 6.9156 (6.9941)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.1174)  time: 0.1234  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.9782 (6.9942)  acc1: 0.0000 (0.0257)  acc5: 0.0000 (0.2315)  time: 0.1201  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 7.0002 (6.9950)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.2548)  time: 0.1184  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1795 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.255 loss 6.995\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [3]  [  0/295]  eta: 0:09:16  lr: 0.000600  min_lr: 0.000600  loss: 2.8726 (2.8726)  weight_decay: 0.0500 (0.0500)  time: 1.8877  data: 1.4953  max mem: 3500\n",
            "Epoch: [3]  [ 10/295]  eta: 0:01:59  lr: 0.000606  min_lr: 0.000606  loss: 3.0757 (3.0667)  weight_decay: 0.0500 (0.0500)  time: 0.4208  data: 0.1393  max mem: 3500\n",
            "Epoch: [3]  [ 20/295]  eta: 0:01:36  lr: 0.000614  min_lr: 0.000614  loss: 3.0544 (3.0544)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0024  max mem: 3500\n",
            "Epoch: [3]  [ 30/295]  eta: 0:01:26  lr: 0.000620  min_lr: 0.000620  loss: 3.0302 (3.0499)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0020  max mem: 3500\n",
            "Epoch: [3]  [ 40/295]  eta: 0:01:19  lr: 0.000628  min_lr: 0.000628  loss: 3.0345 (3.0447)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0015  max mem: 3500\n",
            "Epoch: [3]  [ 50/295]  eta: 0:01:13  lr: 0.000633  min_lr: 0.000633  loss: 3.0424 (3.0450)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0004  max mem: 3500\n",
            "Epoch: [3]  [ 60/295]  eta: 0:01:09  lr: 0.000642  min_lr: 0.000642  loss: 3.0580 (3.0504)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0015  max mem: 3500\n",
            "Epoch: [3]  [ 70/295]  eta: 0:01:05  lr: 0.000647  min_lr: 0.000647  loss: 3.0580 (3.0499)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0025  max mem: 3500\n",
            "Epoch: [3]  [ 80/295]  eta: 0:01:01  lr: 0.000655  min_lr: 0.000655  loss: 3.0710 (3.0558)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0022  max mem: 3500\n",
            "Epoch: [3]  [ 90/295]  eta: 0:00:58  lr: 0.000661  min_lr: 0.000661  loss: 3.0710 (3.0578)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0025  max mem: 3500\n",
            "Epoch: [3]  [100/295]  eta: 0:00:55  lr: 0.000669  min_lr: 0.000669  loss: 3.0626 (3.0557)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0027  max mem: 3500\n",
            "Epoch: [3]  [110/295]  eta: 0:00:52  lr: 0.000674  min_lr: 0.000674  loss: 3.0626 (3.0577)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0042  max mem: 3500\n",
            "Epoch: [3]  [120/295]  eta: 0:00:49  lr: 0.000683  min_lr: 0.000683  loss: 3.0572 (3.0567)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0039  max mem: 3500\n",
            "Epoch: [3]  [130/295]  eta: 0:00:46  lr: 0.000688  min_lr: 0.000688  loss: 3.0673 (3.0584)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0016  max mem: 3500\n",
            "Epoch: [3]  [140/295]  eta: 0:00:43  lr: 0.000696  min_lr: 0.000696  loss: 3.0826 (3.0596)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0018  max mem: 3500\n",
            "Epoch: [3]  [150/295]  eta: 0:00:40  lr: 0.000702  min_lr: 0.000702  loss: 3.0572 (3.0589)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0022  max mem: 3500\n",
            "Epoch: [3]  [160/295]  eta: 0:00:37  lr: 0.000710  min_lr: 0.000710  loss: 3.0599 (3.0598)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0034  max mem: 3500\n",
            "Epoch: [3]  [170/295]  eta: 0:00:34  lr: 0.000716  min_lr: 0.000716  loss: 3.0563 (3.0563)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0053  max mem: 3500\n",
            "Epoch: [3]  [180/295]  eta: 0:00:31  lr: 0.000724  min_lr: 0.000724  loss: 3.0062 (3.0557)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0041  max mem: 3500\n",
            "Epoch: [3]  [190/295]  eta: 0:00:28  lr: 0.000729  min_lr: 0.000729  loss: 3.0249 (3.0539)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0017  max mem: 3500\n",
            "Epoch: [3]  [200/295]  eta: 0:00:25  lr: 0.000737  min_lr: 0.000737  loss: 3.0014 (3.0516)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0009  max mem: 3500\n",
            "Epoch: [3]  [210/295]  eta: 0:00:23  lr: 0.000743  min_lr: 0.000743  loss: 2.9886 (3.0494)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0008  max mem: 3500\n",
            "Epoch: [3]  [220/295]  eta: 0:00:20  lr: 0.000751  min_lr: 0.000751  loss: 3.0253 (3.0496)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0017  max mem: 3500\n",
            "Epoch: [3]  [230/295]  eta: 0:00:17  lr: 0.000757  min_lr: 0.000757  loss: 3.0526 (3.0501)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0020  max mem: 3500\n",
            "Epoch: [3]  [240/295]  eta: 0:00:14  lr: 0.000765  min_lr: 0.000765  loss: 3.0107 (3.0474)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0032  max mem: 3500\n",
            "Epoch: [3]  [250/295]  eta: 0:00:12  lr: 0.000770  min_lr: 0.000770  loss: 3.0123 (3.0490)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0035  max mem: 3500\n",
            "Epoch: [3]  [260/295]  eta: 0:00:09  lr: 0.000779  min_lr: 0.000779  loss: 3.0505 (3.0487)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0017  max mem: 3500\n",
            "Epoch: [3]  [270/295]  eta: 0:00:06  lr: 0.000784  min_lr: 0.000784  loss: 3.0274 (3.0478)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0014  max mem: 3500\n",
            "Epoch: [3]  [280/295]  eta: 0:00:04  lr: 0.000792  min_lr: 0.000792  loss: 3.0471 (3.0490)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0011  max mem: 3500\n",
            "Epoch: [3]  [290/295]  eta: 0:00:01  lr: 0.000798  min_lr: 0.000798  loss: 3.0612 (3.0495)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0002  max mem: 3500\n",
            "Epoch: [3]  [294/295]  eta: 0:00:00  lr: 0.000798  min_lr: 0.000798  loss: 3.0664 (3.0496)  weight_decay: 0.0500 (0.0500)  time: 0.2202  data: 0.0002  max mem: 3500\n",
            "Epoch: [3] Total time: 0:01:19 (0.2690 s / it)\n",
            "Averaged stats: lr: 0.000798  min_lr: 0.000798  loss: 3.0664 (3.0496)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:27  loss: 2.5243 (2.5243)  acc1: 12.5000 (12.5000)  acc5: 39.5833 (39.5833)  time: 2.5297  data: 2.3406  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 2.4277 (2.3600)  acc1: 12.5000 (21.0227)  acc5: 56.2500 (63.4470)  time: 0.3423  data: 0.2143  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 2.1353 (2.2416)  acc1: 25.0000 (28.9683)  acc5: 89.5833 (77.0833)  time: 0.1240  data: 0.0016  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.1353 (2.3043)  acc1: 16.6667 (20.6989)  acc5: 87.5000 (69.2204)  time: 0.1240  data: 0.0026  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.1267 (2.2538)  acc1: 10.4167 (23.3740)  acc5: 75.0000 (71.9512)  time: 0.1234  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.1490 (2.2487)  acc1: 14.5833 (20.0980)  acc5: 87.5000 (74.9183)  time: 0.1235  data: 0.0046  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 2.2261 (2.2658)  acc1: 2.0833 (17.9986)  acc5: 87.5000 (72.8825)  time: 0.1232  data: 0.0056  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.4195 (2.2954)  acc1: 8.3333 (16.8427)  acc5: 50.0000 (68.1338)  time: 0.1199  data: 0.0033  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.3631 (2.2362)  acc1: 18.7500 (21.0905)  acc5: 54.1667 (69.0072)  time: 0.1169  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.3325 (2.2303)  acc1: 18.7500 (21.4777)  acc5: 54.1667 (69.0955)  time: 0.1155  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1575 s / it)\n",
            "* Acc@1 21.478 Acc@5 69.096 loss 2.230\n",
            "Accuracy of the model on the 3925 test images: 21.5%\n",
            "Max accuracy: 24.46%\n",
            "Test:  [ 0/82]  eta: 0:04:25  loss: 7.2311 (7.2311)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.2418  data: 3.0692  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 7.2415 (7.1638)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.4296  data: 0.2925  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 6.9391 (7.0424)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1439  data: 0.0092  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 6.9391 (7.0410)  acc1: 0.0000 (0.0672)  acc5: 0.0000 (0.0672)  time: 0.1346  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.9637 (7.0090)  acc1: 0.0000 (0.0508)  acc5: 0.0000 (0.0508)  time: 0.1280  data: 0.0028  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 6.9637 (7.0019)  acc1: 0.0000 (0.0408)  acc5: 0.0000 (0.0408)  time: 0.1249  data: 0.0037  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 6.8511 (6.9645)  acc1: 0.0000 (0.0342)  acc5: 0.0000 (0.1025)  time: 0.1234  data: 0.0048  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 6.8834 (6.9629)  acc1: 0.0000 (0.0293)  acc5: 0.0000 (0.1174)  time: 0.1222  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.9349 (6.9578)  acc1: 0.0000 (0.0257)  acc5: 0.0000 (0.2315)  time: 0.1196  data: 0.0013  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.9358 (6.9580)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.2293)  time: 0.1174  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1713 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.229 loss 6.958\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [4]  [  0/295]  eta: 0:07:46  lr: 0.000801  min_lr: 0.000801  loss: 3.0339 (3.0339)  weight_decay: 0.0500 (0.0500)  time: 1.5823  data: 1.2353  max mem: 3500\n",
            "Epoch: [4]  [ 10/295]  eta: 0:01:54  lr: 0.000806  min_lr: 0.000806  loss: 3.0339 (3.0296)  weight_decay: 0.0500 (0.0500)  time: 0.4008  data: 0.1143  max mem: 3500\n",
            "Epoch: [4]  [ 20/295]  eta: 0:01:33  lr: 0.000814  min_lr: 0.000814  loss: 3.0449 (3.0377)  weight_decay: 0.0500 (0.0500)  time: 0.2772  data: 0.0021  max mem: 3500\n",
            "Epoch: [4]  [ 30/295]  eta: 0:01:24  lr: 0.000820  min_lr: 0.000820  loss: 3.0968 (3.0532)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0027  max mem: 3500\n",
            "Epoch: [4]  [ 40/295]  eta: 0:01:17  lr: 0.000828  min_lr: 0.000828  loss: 3.0843 (3.0587)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0023  max mem: 3500\n",
            "Epoch: [4]  [ 50/295]  eta: 0:01:12  lr: 0.000833  min_lr: 0.000833  loss: 3.0715 (3.0586)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0021  max mem: 3500\n",
            "Epoch: [4]  [ 60/295]  eta: 0:01:08  lr: 0.000842  min_lr: 0.000842  loss: 3.0783 (3.0632)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0017  max mem: 3500\n",
            "Epoch: [4]  [ 70/295]  eta: 0:01:04  lr: 0.000847  min_lr: 0.000847  loss: 3.0750 (3.0641)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0013  max mem: 3500\n",
            "Epoch: [4]  [ 80/295]  eta: 0:01:01  lr: 0.000855  min_lr: 0.000855  loss: 3.0750 (3.0613)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0025  max mem: 3500\n",
            "Epoch: [4]  [ 90/295]  eta: 0:00:58  lr: 0.000861  min_lr: 0.000861  loss: 3.0718 (3.0616)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0027  max mem: 3500\n",
            "Epoch: [4]  [100/295]  eta: 0:00:54  lr: 0.000869  min_lr: 0.000869  loss: 3.0504 (3.0593)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0029  max mem: 3500\n",
            "Epoch: [4]  [110/295]  eta: 0:00:51  lr: 0.000875  min_lr: 0.000875  loss: 3.0504 (3.0604)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0025  max mem: 3500\n",
            "Epoch: [4]  [120/295]  eta: 0:00:48  lr: 0.000883  min_lr: 0.000883  loss: 3.0261 (3.0560)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0018  max mem: 3500\n",
            "Epoch: [4]  [130/295]  eta: 0:00:45  lr: 0.000888  min_lr: 0.000888  loss: 3.0261 (3.0560)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0028  max mem: 3500\n",
            "Epoch: [4]  [140/295]  eta: 0:00:42  lr: 0.000897  min_lr: 0.000897  loss: 3.0692 (3.0569)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0033  max mem: 3500\n",
            "Epoch: [4]  [150/295]  eta: 0:00:39  lr: 0.000902  min_lr: 0.000902  loss: 3.0765 (3.0560)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0038  max mem: 3500\n",
            "Epoch: [4]  [160/295]  eta: 0:00:37  lr: 0.000910  min_lr: 0.000910  loss: 3.0505 (3.0556)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0059  max mem: 3500\n",
            "Epoch: [4]  [170/295]  eta: 0:00:34  lr: 0.000916  min_lr: 0.000916  loss: 3.0269 (3.0529)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0048  max mem: 3500\n",
            "Epoch: [4]  [180/295]  eta: 0:00:31  lr: 0.000924  min_lr: 0.000924  loss: 2.9889 (3.0492)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0021  max mem: 3500\n",
            "Epoch: [4]  [190/295]  eta: 0:00:28  lr: 0.000929  min_lr: 0.000929  loss: 3.0125 (3.0482)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0010  max mem: 3500\n",
            "Epoch: [4]  [200/295]  eta: 0:00:25  lr: 0.000938  min_lr: 0.000938  loss: 3.0157 (3.0474)  weight_decay: 0.0500 (0.0500)  time: 0.2573  data: 0.0008  max mem: 3500\n",
            "Epoch: [4]  [210/295]  eta: 0:00:23  lr: 0.000943  min_lr: 0.000943  loss: 3.0344 (3.0459)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0012  max mem: 3500\n",
            "Epoch: [4]  [220/295]  eta: 0:00:20  lr: 0.000951  min_lr: 0.000951  loss: 3.0431 (3.0461)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0024  max mem: 3500\n",
            "Epoch: [4]  [230/295]  eta: 0:00:17  lr: 0.000957  min_lr: 0.000957  loss: 3.0252 (3.0459)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0040  max mem: 3500\n",
            "Epoch: [4]  [240/295]  eta: 0:00:14  lr: 0.000965  min_lr: 0.000965  loss: 3.0331 (3.0464)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0033  max mem: 3500\n",
            "Epoch: [4]  [250/295]  eta: 0:00:12  lr: 0.000971  min_lr: 0.000971  loss: 3.0366 (3.0467)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0025  max mem: 3500\n",
            "Epoch: [4]  [260/295]  eta: 0:00:09  lr: 0.000979  min_lr: 0.000979  loss: 3.0366 (3.0470)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0026  max mem: 3500\n",
            "Epoch: [4]  [270/295]  eta: 0:00:06  lr: 0.000984  min_lr: 0.000984  loss: 3.0272 (3.0458)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0032  max mem: 3500\n",
            "Epoch: [4]  [280/295]  eta: 0:00:04  lr: 0.000992  min_lr: 0.000992  loss: 2.9906 (3.0430)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0025  max mem: 3500\n",
            "Epoch: [4]  [290/295]  eta: 0:00:01  lr: 0.000998  min_lr: 0.000998  loss: 2.9880 (3.0421)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0006  max mem: 3500\n",
            "Epoch: [4]  [294/295]  eta: 0:00:00  lr: 0.000998  min_lr: 0.000998  loss: 2.9880 (3.0423)  weight_decay: 0.0500 (0.0500)  time: 0.2216  data: 0.0001  max mem: 3500\n",
            "Epoch: [4] Total time: 0:01:19 (0.2682 s / it)\n",
            "Averaged stats: lr: 0.000998  min_lr: 0.000998  loss: 2.9880 (3.0423)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:01:59  loss: 2.2149 (2.2149)  acc1: 4.1667 (4.1667)  acc5: 77.0833 (77.0833)  time: 1.4629  data: 1.2956  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 2.2124 (2.2888)  acc1: 6.2500 (5.8712)  acc5: 81.2500 (75.1894)  time: 0.2730  data: 0.1483  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.2088 (2.2874)  acc1: 6.2500 (17.4603)  acc5: 81.2500 (71.4286)  time: 0.1377  data: 0.0177  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.1333 (2.2254)  acc1: 10.4167 (20.0941)  acc5: 89.5833 (78.6962)  time: 0.1210  data: 0.0024  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 2.1306 (2.2090)  acc1: 16.6667 (20.7317)  acc5: 83.3333 (78.2012)  time: 0.1220  data: 0.0032  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 2.0840 (2.1833)  acc1: 29.1667 (24.4281)  acc5: 79.1667 (79.9837)  time: 0.1226  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 2.2855 (2.2129)  acc1: 8.3333 (21.1407)  acc5: 81.2500 (78.6885)  time: 0.1223  data: 0.0056  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.3112 (2.2058)  acc1: 4.1667 (21.4495)  acc5: 72.9167 (77.7289)  time: 0.1203  data: 0.0028  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.9002 (2.1287)  acc1: 43.7500 (26.0545)  acc5: 75.0000 (77.7778)  time: 0.1175  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8941 (2.1239)  acc1: 43.7500 (26.3694)  acc5: 75.0000 (77.7070)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1472 s / it)\n",
            "* Acc@1 26.369 Acc@5 77.707 loss 2.124\n",
            "Accuracy of the model on the 3925 test images: 26.4%\n",
            "Max accuracy: 26.37%\n",
            "Test:  [ 0/82]  eta: 0:03:37  loss: 7.1903 (7.1903)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.6584  data: 2.5073  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 7.2050 (7.1286)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.3566  data: 0.2333  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 6.9123 (7.0059)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.1247  data: 0.0040  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 6.9123 (7.0100)  acc1: 0.0000 (0.0672)  acc5: 0.0000 (0.0672)  time: 0.1235  data: 0.0044  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 6.9298 (6.9766)  acc1: 0.0000 (0.0508)  acc5: 0.0000 (0.0508)  time: 0.1237  data: 0.0055  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 6.9298 (6.9684)  acc1: 0.0000 (0.0408)  acc5: 0.0000 (0.0817)  time: 0.1234  data: 0.0037  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.8020 (6.9281)  acc1: 0.0000 (0.0342)  acc5: 0.0000 (0.2049)  time: 0.1227  data: 0.0039  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.8500 (6.9272)  acc1: 0.0000 (0.0293)  acc5: 0.0000 (0.2054)  time: 0.1198  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.8441 (6.9147)  acc1: 0.0000 (0.0257)  acc5: 0.0000 (0.3086)  time: 0.1180  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.8441 (6.9141)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.3057)  time: 0.1166  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1595 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.306 loss 6.914\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [5]  [  0/295]  eta: 0:14:29  lr: 0.001001  min_lr: 0.001001  loss: 3.0329 (3.0329)  weight_decay: 0.0500 (0.0500)  time: 2.9466  data: 2.3778  max mem: 3500\n",
            "Epoch: [5]  [ 10/295]  eta: 0:02:37  lr: 0.001006  min_lr: 0.001006  loss: 3.0576 (3.0360)  weight_decay: 0.0500 (0.0500)  time: 0.5523  data: 0.2184  max mem: 3500\n",
            "Epoch: [5]  [ 20/295]  eta: 0:01:53  lr: 0.001014  min_lr: 0.001014  loss: 3.0356 (3.0362)  weight_decay: 0.0500 (0.0500)  time: 0.2869  data: 0.0017  max mem: 3500\n",
            "Epoch: [5]  [ 30/295]  eta: 0:01:36  lr: 0.001020  min_lr: 0.001020  loss: 3.0356 (3.0374)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0016  max mem: 3500\n",
            "Epoch: [5]  [ 40/295]  eta: 0:01:26  lr: 0.001028  min_lr: 0.001028  loss: 3.0373 (3.0359)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0018  max mem: 3500\n",
            "Epoch: [5]  [ 50/295]  eta: 0:01:19  lr: 0.001034  min_lr: 0.001034  loss: 3.0305 (3.0313)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0019  max mem: 3500\n",
            "Epoch: [5]  [ 60/295]  eta: 0:01:14  lr: 0.001042  min_lr: 0.001042  loss: 3.0273 (3.0344)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0019  max mem: 3500\n",
            "Epoch: [5]  [ 70/295]  eta: 0:01:09  lr: 0.001047  min_lr: 0.001047  loss: 3.0432 (3.0348)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0017  max mem: 3500\n",
            "Epoch: [5]  [ 80/295]  eta: 0:01:05  lr: 0.001056  min_lr: 0.001056  loss: 3.0496 (3.0362)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0020  max mem: 3500\n",
            "Epoch: [5]  [ 90/295]  eta: 0:01:01  lr: 0.001061  min_lr: 0.001061  loss: 3.0338 (3.0371)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0012  max mem: 3500\n",
            "Epoch: [5]  [100/295]  eta: 0:00:57  lr: 0.001069  min_lr: 0.001069  loss: 3.0329 (3.0358)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0009  max mem: 3500\n",
            "Epoch: [5]  [110/295]  eta: 0:00:54  lr: 0.001075  min_lr: 0.001075  loss: 3.0326 (3.0338)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0019  max mem: 3500\n",
            "Epoch: [5]  [120/295]  eta: 0:00:50  lr: 0.001083  min_lr: 0.001083  loss: 3.0157 (3.0311)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0027  max mem: 3500\n",
            "Epoch: [5]  [130/295]  eta: 0:00:47  lr: 0.001088  min_lr: 0.001088  loss: 3.0018 (3.0278)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0031  max mem: 3500\n",
            "Epoch: [5]  [140/295]  eta: 0:00:44  lr: 0.001097  min_lr: 0.001097  loss: 3.0018 (3.0254)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0027  max mem: 3500\n",
            "Epoch: [5]  [150/295]  eta: 0:00:41  lr: 0.001102  min_lr: 0.001102  loss: 3.0032 (3.0252)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0023  max mem: 3500\n",
            "Epoch: [5]  [160/295]  eta: 0:00:38  lr: 0.001110  min_lr: 0.001110  loss: 3.0032 (3.0243)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0018  max mem: 3500\n",
            "Epoch: [5]  [170/295]  eta: 0:00:35  lr: 0.001116  min_lr: 0.001116  loss: 3.0052 (3.0233)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0019  max mem: 3500\n",
            "Epoch: [5]  [180/295]  eta: 0:00:32  lr: 0.001124  min_lr: 0.001124  loss: 3.0116 (3.0218)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0027  max mem: 3500\n",
            "Epoch: [5]  [190/295]  eta: 0:00:29  lr: 0.001130  min_lr: 0.001130  loss: 2.9605 (3.0178)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0026  max mem: 3500\n",
            "Epoch: [5]  [200/295]  eta: 0:00:26  lr: 0.001138  min_lr: 0.001138  loss: 2.9791 (3.0167)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0036  max mem: 3500\n",
            "Epoch: [5]  [210/295]  eta: 0:00:23  lr: 0.001143  min_lr: 0.001143  loss: 2.9844 (3.0152)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0033  max mem: 3500\n",
            "Epoch: [5]  [220/295]  eta: 0:00:20  lr: 0.001151  min_lr: 0.001151  loss: 2.9786 (3.0143)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0016  max mem: 3500\n",
            "Epoch: [5]  [230/295]  eta: 0:00:18  lr: 0.001157  min_lr: 0.001157  loss: 2.9855 (3.0138)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0012  max mem: 3500\n",
            "Epoch: [5]  [240/295]  eta: 0:00:15  lr: 0.001165  min_lr: 0.001165  loss: 3.0067 (3.0144)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0011  max mem: 3500\n",
            "Epoch: [5]  [250/295]  eta: 0:00:12  lr: 0.001171  min_lr: 0.001171  loss: 3.0122 (3.0146)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0009  max mem: 3500\n",
            "Epoch: [5]  [260/295]  eta: 0:00:09  lr: 0.001179  min_lr: 0.001179  loss: 3.0263 (3.0140)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0012  max mem: 3500\n",
            "Epoch: [5]  [270/295]  eta: 0:00:06  lr: 0.001184  min_lr: 0.001184  loss: 3.0255 (3.0131)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0027  max mem: 3500\n",
            "Epoch: [5]  [280/295]  eta: 0:00:04  lr: 0.001193  min_lr: 0.001193  loss: 2.9943 (3.0132)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0028  max mem: 3500\n",
            "Epoch: [5]  [290/295]  eta: 0:00:01  lr: 0.001198  min_lr: 0.001198  loss: 3.0060 (3.0131)  weight_decay: 0.0500 (0.0500)  time: 0.2570  data: 0.0011  max mem: 3500\n",
            "Epoch: [5]  [294/295]  eta: 0:00:00  lr: 0.001198  min_lr: 0.001198  loss: 3.0060 (3.0131)  weight_decay: 0.0500 (0.0500)  time: 0.2173  data: 0.0002  max mem: 3500\n",
            "Epoch: [5] Total time: 0:01:20 (0.2724 s / it)\n",
            "Averaged stats: lr: 0.001198  min_lr: 0.001198  loss: 3.0060 (3.0131)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:23  loss: 2.1211 (2.1211)  acc1: 35.4167 (35.4167)  acc5: 81.2500 (81.2500)  time: 1.7510  data: 1.5801  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 2.1396 (2.1374)  acc1: 41.6667 (36.9318)  acc5: 87.5000 (87.3106)  time: 0.2776  data: 0.1453  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.1292 (2.1131)  acc1: 33.3333 (35.1190)  acc5: 89.5833 (89.2857)  time: 0.1347  data: 0.0049  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.1292 (2.1386)  acc1: 22.9167 (28.9651)  acc5: 89.5833 (88.4409)  time: 0.1443  data: 0.0063  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.1618 (2.1324)  acc1: 20.8333 (27.7439)  acc5: 79.1667 (85.4167)  time: 0.1488  data: 0.0029  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.1465 (2.1599)  acc1: 25.0000 (28.6356)  acc5: 72.9167 (81.7402)  time: 0.1493  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 2.2140 (2.1742)  acc1: 25.0000 (27.3907)  acc5: 66.6667 (81.0109)  time: 0.1555  data: 0.0177  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.3138 (2.2059)  acc1: 4.1667 (24.2371)  acc5: 66.6667 (78.7559)  time: 0.1577  data: 0.0224  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.2557 (2.1307)  acc1: 10.4167 (27.8292)  acc5: 68.7500 (78.8323)  time: 0.1358  data: 0.0075  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.2351 (2.1241)  acc1: 10.4167 (28.1529)  acc5: 70.8333 (78.8026)  time: 0.1298  data: 0.0075  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1667 s / it)\n",
            "* Acc@1 28.153 Acc@5 78.803 loss 2.124\n",
            "Accuracy of the model on the 3925 test images: 28.2%\n",
            "Max accuracy: 28.15%\n",
            "Test:  [ 0/82]  eta: 0:02:02  loss: 7.1426 (7.1426)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 1.4885  data: 1.3168  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 7.1602 (7.0864)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.2676  data: 0.1444  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 6.8812 (6.9635)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.5952)  time: 0.1349  data: 0.0151  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.8812 (6.9741)  acc1: 0.0000 (0.0672)  acc5: 0.0000 (0.6048)  time: 0.1229  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 6.8948 (6.9402)  acc1: 0.0000 (0.0508)  acc5: 0.0000 (0.4573)  time: 0.1214  data: 0.0030  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 6.8948 (6.9308)  acc1: 0.0000 (0.0408)  acc5: 0.0000 (0.4085)  time: 0.1261  data: 0.0043  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.7454 (6.8877)  acc1: 0.0000 (0.0342)  acc5: 0.0000 (0.5806)  time: 0.1352  data: 0.0031  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.8154 (6.8876)  acc1: 0.0000 (0.0293)  acc5: 0.0000 (0.5282)  time: 0.1352  data: 0.0005  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.7792 (6.8663)  acc1: 0.0000 (0.0257)  acc5: 0.0000 (0.5916)  time: 0.1252  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.7341 (6.8647)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.5860)  time: 0.1225  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1512 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.586 loss 6.865\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [6]  [  0/295]  eta: 0:11:48  lr: 0.001201  min_lr: 0.001201  loss: 2.9994 (2.9994)  weight_decay: 0.0500 (0.0500)  time: 2.4012  data: 1.8761  max mem: 3500\n",
            "Epoch: [6]  [ 10/295]  eta: 0:02:12  lr: 0.001206  min_lr: 0.001206  loss: 2.9994 (3.0215)  weight_decay: 0.0500 (0.0500)  time: 0.4652  data: 0.1713  max mem: 3500\n",
            "Epoch: [6]  [ 20/295]  eta: 0:01:41  lr: 0.001215  min_lr: 0.001215  loss: 3.0140 (3.0087)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0012  max mem: 3500\n",
            "Epoch: [6]  [ 30/295]  eta: 0:01:28  lr: 0.001220  min_lr: 0.001220  loss: 3.0197 (3.0084)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0016  max mem: 3500\n",
            "Epoch: [6]  [ 40/295]  eta: 0:01:21  lr: 0.001228  min_lr: 0.001228  loss: 3.0134 (3.0084)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0022  max mem: 3500\n",
            "Epoch: [6]  [ 50/295]  eta: 0:01:15  lr: 0.001234  min_lr: 0.001234  loss: 2.9867 (3.0031)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0030  max mem: 3500\n",
            "Epoch: [6]  [ 60/295]  eta: 0:01:11  lr: 0.001242  min_lr: 0.001242  loss: 2.9719 (3.0027)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0029  max mem: 3500\n",
            "Epoch: [6]  [ 70/295]  eta: 0:01:07  lr: 0.001247  min_lr: 0.001247  loss: 3.0086 (3.0054)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0025  max mem: 3500\n",
            "Epoch: [6]  [ 80/295]  eta: 0:01:03  lr: 0.001256  min_lr: 0.001256  loss: 3.0215 (3.0059)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0018  max mem: 3500\n",
            "Epoch: [6]  [ 90/295]  eta: 0:00:59  lr: 0.001261  min_lr: 0.001261  loss: 3.0215 (3.0054)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0019  max mem: 3500\n",
            "Epoch: [6]  [100/295]  eta: 0:00:55  lr: 0.001269  min_lr: 0.001269  loss: 3.0038 (3.0053)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0019  max mem: 3500\n",
            "Epoch: [6]  [110/295]  eta: 0:00:52  lr: 0.001275  min_lr: 0.001275  loss: 2.9888 (3.0027)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0028  max mem: 3500\n",
            "Epoch: [6]  [120/295]  eta: 0:00:49  lr: 0.001283  min_lr: 0.001283  loss: 2.9725 (3.0012)  weight_decay: 0.0500 (0.0500)  time: 0.2751  data: 0.0043  max mem: 3500\n",
            "Epoch: [6]  [130/295]  eta: 0:00:46  lr: 0.001289  min_lr: 0.001289  loss: 3.0155 (3.0031)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0036  max mem: 3500\n",
            "Epoch: [6]  [140/295]  eta: 0:00:43  lr: 0.001297  min_lr: 0.001297  loss: 2.9884 (3.0003)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0021  max mem: 3500\n",
            "Epoch: [6]  [150/295]  eta: 0:00:40  lr: 0.001302  min_lr: 0.001302  loss: 2.9805 (3.0010)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0011  max mem: 3500\n",
            "Epoch: [6]  [160/295]  eta: 0:00:37  lr: 0.001310  min_lr: 0.001310  loss: 2.9924 (3.0014)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0012  max mem: 3500\n",
            "Epoch: [6]  [170/295]  eta: 0:00:34  lr: 0.001316  min_lr: 0.001316  loss: 2.9841 (3.0009)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0014  max mem: 3500\n",
            "Epoch: [6]  [180/295]  eta: 0:00:31  lr: 0.001324  min_lr: 0.001324  loss: 2.9841 (2.9992)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0024  max mem: 3500\n",
            "Epoch: [6]  [190/295]  eta: 0:00:29  lr: 0.001330  min_lr: 0.001330  loss: 2.9674 (2.9964)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0033  max mem: 3500\n",
            "Epoch: [6]  [200/295]  eta: 0:00:26  lr: 0.001338  min_lr: 0.001338  loss: 2.9712 (2.9977)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0027  max mem: 3500\n",
            "Epoch: [6]  [210/295]  eta: 0:00:23  lr: 0.001343  min_lr: 0.001343  loss: 2.9850 (2.9973)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0017  max mem: 3500\n",
            "Epoch: [6]  [220/295]  eta: 0:00:20  lr: 0.001352  min_lr: 0.001352  loss: 2.9695 (2.9966)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0010  max mem: 3500\n",
            "Epoch: [6]  [230/295]  eta: 0:00:17  lr: 0.001357  min_lr: 0.001357  loss: 2.9712 (2.9962)  weight_decay: 0.0500 (0.0500)  time: 0.2568  data: 0.0007  max mem: 3500\n",
            "Epoch: [6]  [240/295]  eta: 0:00:15  lr: 0.001365  min_lr: 0.001365  loss: 2.9803 (2.9953)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0010  max mem: 3500\n",
            "Epoch: [6]  [250/295]  eta: 0:00:12  lr: 0.001371  min_lr: 0.001371  loss: 2.9983 (2.9944)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0020  max mem: 3500\n",
            "Epoch: [6]  [260/295]  eta: 0:00:09  lr: 0.001379  min_lr: 0.001379  loss: 2.9927 (2.9946)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0040  max mem: 3500\n",
            "Epoch: [6]  [270/295]  eta: 0:00:06  lr: 0.001385  min_lr: 0.001385  loss: 2.9880 (2.9936)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0040  max mem: 3500\n",
            "Epoch: [6]  [280/295]  eta: 0:00:04  lr: 0.001393  min_lr: 0.001393  loss: 2.9975 (2.9942)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0018  max mem: 3500\n",
            "Epoch: [6]  [290/295]  eta: 0:00:01  lr: 0.001398  min_lr: 0.001398  loss: 3.0120 (2.9947)  weight_decay: 0.0500 (0.0500)  time: 0.2562  data: 0.0006  max mem: 3500\n",
            "Epoch: [6]  [294/295]  eta: 0:00:00  lr: 0.001398  min_lr: 0.001398  loss: 3.0120 (2.9942)  weight_decay: 0.0500 (0.0500)  time: 0.2183  data: 0.0002  max mem: 3500\n",
            "Epoch: [6] Total time: 0:01:19 (0.2696 s / it)\n",
            "Averaged stats: lr: 0.001398  min_lr: 0.001398  loss: 3.0120 (2.9942)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:51  loss: 1.6917 (1.6917)  acc1: 75.0000 (75.0000)  acc5: 95.8333 (95.8333)  time: 2.8252  data: 2.6329  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 1.6917 (1.7857)  acc1: 75.0000 (60.2273)  acc5: 95.8333 (94.5076)  time: 0.3922  data: 0.2492  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 1.8510 (1.8879)  acc1: 64.5833 (51.0913)  acc5: 93.7500 (94.0476)  time: 0.1600  data: 0.0259  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 2.0987 (2.0664)  acc1: 10.4167 (41.0618)  acc5: 89.5833 (75.9409)  time: 0.1738  data: 0.0422  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 2.0174 (2.0597)  acc1: 43.7500 (41.6667)  acc5: 70.8333 (76.2195)  time: 0.1610  data: 0.0225  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 2.2346 (2.1287)  acc1: 10.4167 (34.4771)  acc5: 75.0000 (73.0392)  time: 0.1340  data: 0.0023  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 2.3095 (2.1575)  acc1: 4.1667 (29.4740)  acc5: 64.5833 (74.4536)  time: 0.1245  data: 0.0021  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.2275 (2.1689)  acc1: 4.1667 (25.9683)  acc5: 83.3333 (74.7653)  time: 0.1220  data: 0.0006  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.0323 (2.0865)  acc1: 8.3333 (29.8868)  acc5: 87.5000 (76.6204)  time: 0.1175  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.9901 (2.0794)  acc1: 10.4167 (30.2930)  acc5: 87.5000 (76.6879)  time: 0.1166  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1776 s / it)\n",
            "* Acc@1 30.293 Acc@5 76.688 loss 2.079\n",
            "Accuracy of the model on the 3925 test images: 30.3%\n",
            "Max accuracy: 30.29%\n",
            "Test:  [ 0/82]  eta: 0:02:37  loss: 7.0883 (7.0883)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 1.9152  data: 1.7449  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 7.1052 (7.0362)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.2888  data: 0.1615  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 6.8462 (6.9144)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.9921)  time: 0.1364  data: 0.0021  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 6.8462 (6.9327)  acc1: 0.0000 (0.1344)  acc5: 0.0000 (1.1425)  time: 0.1561  data: 0.0101  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.8557 (6.8987)  acc1: 0.0000 (0.1016)  acc5: 0.0000 (0.8638)  time: 0.1675  data: 0.0258  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 6.8526 (6.8872)  acc1: 0.0000 (0.0817)  acc5: 0.0000 (0.8987)  time: 0.1633  data: 0.0228  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 6.7024 (6.8420)  acc1: 0.0000 (0.1366)  acc5: 0.0000 (1.1954)  time: 0.1598  data: 0.0141  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 6.7796 (6.8429)  acc1: 0.0000 (0.1174)  acc5: 0.0000 (1.1150)  time: 0.1477  data: 0.0084  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.6838 (6.8121)  acc1: 0.0000 (0.1029)  acc5: 0.0000 (1.0802)  time: 0.1262  data: 0.0009  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.6241 (6.8095)  acc1: 0.0000 (0.1019)  acc5: 0.0000 (1.0701)  time: 0.1230  data: 0.0009  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1732 s / it)\n",
            "* Acc@1 0.102 Acc@5 1.070 loss 6.809\n",
            "Accuracy of the model EMA on 3925 test images: 0.1%\n",
            "Max EMA accuracy: 0.10%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [7]  [  0/295]  eta: 0:08:37  lr: 0.001401  min_lr: 0.001401  loss: 3.0033 (3.0033)  weight_decay: 0.0500 (0.0500)  time: 1.7559  data: 1.3736  max mem: 3500\n",
            "Epoch: [7]  [ 10/295]  eta: 0:01:56  lr: 0.001406  min_lr: 0.001406  loss: 3.0033 (2.9937)  weight_decay: 0.0500 (0.0500)  time: 0.4081  data: 0.1260  max mem: 3500\n",
            "Epoch: [7]  [ 20/295]  eta: 0:01:34  lr: 0.001415  min_lr: 0.001415  loss: 2.9959 (2.9925)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0018  max mem: 3500\n",
            "Epoch: [7]  [ 30/295]  eta: 0:01:24  lr: 0.001420  min_lr: 0.001420  loss: 2.9838 (2.9887)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0028  max mem: 3500\n",
            "Epoch: [7]  [ 40/295]  eta: 0:01:18  lr: 0.001428  min_lr: 0.001428  loss: 2.9749 (2.9867)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0033  max mem: 3500\n",
            "Epoch: [7]  [ 50/295]  eta: 0:01:13  lr: 0.001434  min_lr: 0.001434  loss: 2.9840 (2.9905)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0023  max mem: 3500\n",
            "Epoch: [7]  [ 60/295]  eta: 0:01:08  lr: 0.001442  min_lr: 0.001442  loss: 2.9962 (2.9883)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0018  max mem: 3500\n",
            "Epoch: [7]  [ 70/295]  eta: 0:01:04  lr: 0.001448  min_lr: 0.001448  loss: 2.9978 (2.9889)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0019  max mem: 3500\n",
            "Epoch: [7]  [ 80/295]  eta: 0:01:01  lr: 0.001456  min_lr: 0.001456  loss: 2.9692 (2.9870)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0014  max mem: 3500\n",
            "Epoch: [7]  [ 90/295]  eta: 0:00:58  lr: 0.001461  min_lr: 0.001461  loss: 2.9604 (2.9875)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0018  max mem: 3500\n",
            "Epoch: [7]  [100/295]  eta: 0:00:55  lr: 0.001469  min_lr: 0.001469  loss: 2.9640 (2.9868)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0030  max mem: 3500\n",
            "Epoch: [7]  [110/295]  eta: 0:00:51  lr: 0.001475  min_lr: 0.001475  loss: 2.9639 (2.9832)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0044  max mem: 3500\n",
            "Epoch: [7]  [120/295]  eta: 0:00:48  lr: 0.001483  min_lr: 0.001483  loss: 2.9199 (2.9794)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0036  max mem: 3500\n",
            "Epoch: [7]  [130/295]  eta: 0:00:45  lr: 0.001489  min_lr: 0.001489  loss: 2.9426 (2.9767)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0015  max mem: 3500\n",
            "Epoch: [7]  [140/295]  eta: 0:00:42  lr: 0.001497  min_lr: 0.001497  loss: 2.9813 (2.9777)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0010  max mem: 3500\n",
            "Epoch: [7]  [150/295]  eta: 0:00:39  lr: 0.001502  min_lr: 0.001502  loss: 2.9857 (2.9785)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0019  max mem: 3500\n",
            "Epoch: [7]  [160/295]  eta: 0:00:37  lr: 0.001511  min_lr: 0.001511  loss: 2.9737 (2.9785)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0032  max mem: 3500\n",
            "Epoch: [7]  [170/295]  eta: 0:00:34  lr: 0.001516  min_lr: 0.001516  loss: 2.9712 (2.9785)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0050  max mem: 3500\n",
            "Epoch: [7]  [180/295]  eta: 0:00:31  lr: 0.001524  min_lr: 0.001524  loss: 2.9407 (2.9770)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0041  max mem: 3500\n",
            "Epoch: [7]  [190/295]  eta: 0:00:28  lr: 0.001530  min_lr: 0.001530  loss: 2.9940 (2.9798)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0021  max mem: 3500\n",
            "Epoch: [7]  [200/295]  eta: 0:00:25  lr: 0.001538  min_lr: 0.001538  loss: 2.9940 (2.9796)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0014  max mem: 3500\n",
            "Epoch: [7]  [210/295]  eta: 0:00:23  lr: 0.001544  min_lr: 0.001544  loss: 2.9545 (2.9760)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0017  max mem: 3500\n",
            "Epoch: [7]  [220/295]  eta: 0:00:20  lr: 0.001552  min_lr: 0.001552  loss: 2.9331 (2.9775)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0019  max mem: 3500\n",
            "Epoch: [7]  [230/295]  eta: 0:00:17  lr: 0.001557  min_lr: 0.001557  loss: 2.9776 (2.9763)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0025  max mem: 3500\n",
            "Epoch: [7]  [240/295]  eta: 0:00:14  lr: 0.001565  min_lr: 0.001565  loss: 2.9776 (2.9772)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0035  max mem: 3500\n",
            "Epoch: [7]  [250/295]  eta: 0:00:12  lr: 0.001571  min_lr: 0.001571  loss: 2.9481 (2.9777)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0039  max mem: 3500\n",
            "Epoch: [7]  [260/295]  eta: 0:00:09  lr: 0.001579  min_lr: 0.001579  loss: 2.9500 (2.9771)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0031  max mem: 3500\n",
            "Epoch: [7]  [270/295]  eta: 0:00:06  lr: 0.001585  min_lr: 0.001585  loss: 2.9204 (2.9749)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0019  max mem: 3500\n",
            "Epoch: [7]  [280/295]  eta: 0:00:04  lr: 0.001593  min_lr: 0.001593  loss: 2.9331 (2.9745)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0013  max mem: 3500\n",
            "Epoch: [7]  [290/295]  eta: 0:00:01  lr: 0.001598  min_lr: 0.001598  loss: 2.9455 (2.9731)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0004  max mem: 3500\n",
            "Epoch: [7]  [294/295]  eta: 0:00:00  lr: 0.001598  min_lr: 0.001598  loss: 2.9482 (2.9734)  weight_decay: 0.0500 (0.0500)  time: 0.2205  data: 0.0002  max mem: 3500\n",
            "Epoch: [7] Total time: 0:01:19 (0.2685 s / it)\n",
            "Averaged stats: lr: 0.001598  min_lr: 0.001598  loss: 2.9482 (2.9734)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:14  loss: 1.7582 (1.7582)  acc1: 58.3333 (58.3333)  acc5: 91.6667 (91.6667)  time: 2.3667  data: 2.2032  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 1.9180 (1.9111)  acc1: 45.8333 (45.2652)  acc5: 89.5833 (88.0682)  time: 0.3458  data: 0.2146  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 1.9797 (1.9436)  acc1: 43.7500 (43.1548)  acc5: 85.4167 (87.2024)  time: 0.1333  data: 0.0092  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.0235 (2.0076)  acc1: 25.0000 (34.0054)  acc5: 91.6667 (89.1129)  time: 0.1225  data: 0.0020  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.0946 (2.0215)  acc1: 14.5833 (31.4533)  acc5: 89.5833 (88.1606)  time: 0.1235  data: 0.0030  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.9739 (2.0015)  acc1: 29.1667 (35.7843)  acc5: 85.4167 (87.0915)  time: 0.1226  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 2.1017 (2.0582)  acc1: 8.3333 (31.1134)  acc5: 79.1667 (83.9481)  time: 0.1219  data: 0.0044  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.1849 (2.0734)  acc1: 8.3333 (28.3157)  acc5: 75.0000 (82.8932)  time: 0.1208  data: 0.0019  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.1206 (1.9639)  acc1: 14.5833 (33.1533)  acc5: 79.1667 (83.6934)  time: 0.1177  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.0514 (1.9527)  acc1: 16.6667 (33.6051)  acc5: 79.1667 (83.7452)  time: 0.1167  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1558 s / it)\n",
            "* Acc@1 33.605 Acc@5 83.745 loss 1.953\n",
            "Accuracy of the model on the 3925 test images: 33.6%\n",
            "Max accuracy: 33.61%\n",
            "Test:  [ 0/82]  eta: 0:04:30  loss: 7.0296 (7.0296)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.3026  data: 3.1499  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 7.0436 (6.9801)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.1894)  time: 0.4274  data: 0.2930  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 6.8071 (6.8598)  acc1: 0.0000 (0.2976)  acc5: 0.0000 (1.6865)  time: 0.1418  data: 0.0083  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 6.8071 (6.8869)  acc1: 0.0000 (0.3360)  acc5: 0.0000 (1.8817)  time: 0.1333  data: 0.0060  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.8127 (6.8528)  acc1: 0.0000 (0.2541)  acc5: 0.0000 (1.6260)  time: 0.1235  data: 0.0025  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 6.8040 (6.8390)  acc1: 0.0000 (0.2451)  acc5: 0.0000 (1.5523)  time: 0.1248  data: 0.0020  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 6.6693 (6.7918)  acc1: 0.0000 (0.3757)  acc5: 0.0000 (2.1175)  time: 0.1246  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 6.7265 (6.7937)  acc1: 0.0000 (0.3228)  acc5: 0.0000 (1.8779)  time: 0.1215  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.6420 (6.7526)  acc1: 0.0000 (0.2829)  acc5: 0.0000 (1.9805)  time: 0.1188  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.5566 (6.7489)  acc1: 0.0000 (0.2803)  acc5: 0.0000 (1.9873)  time: 0.1170  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1701 s / it)\n",
            "* Acc@1 0.280 Acc@5 1.987 loss 6.749\n",
            "Accuracy of the model EMA on 3925 test images: 0.3%\n",
            "Max EMA accuracy: 0.28%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [8]  [  0/295]  eta: 0:13:08  lr: 0.001601  min_lr: 0.001601  loss: 3.1410 (3.1410)  weight_decay: 0.0500 (0.0500)  time: 2.6723  data: 2.1282  max mem: 3500\n",
            "Epoch: [8]  [ 10/295]  eta: 0:02:31  lr: 0.001607  min_lr: 0.001607  loss: 2.9889 (3.0023)  weight_decay: 0.0500 (0.0500)  time: 0.5302  data: 0.1968  max mem: 3500\n",
            "Epoch: [8]  [ 20/295]  eta: 0:01:51  lr: 0.001615  min_lr: 0.001615  loss: 2.9947 (3.0129)  weight_decay: 0.0500 (0.0500)  time: 0.2938  data: 0.0033  max mem: 3500\n",
            "Epoch: [8]  [ 30/295]  eta: 0:01:35  lr: 0.001620  min_lr: 0.001620  loss: 2.9763 (2.9878)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0032  max mem: 3500\n",
            "Epoch: [8]  [ 40/295]  eta: 0:01:26  lr: 0.001629  min_lr: 0.001629  loss: 2.9489 (2.9847)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0021  max mem: 3500\n",
            "Epoch: [8]  [ 50/295]  eta: 0:01:19  lr: 0.001634  min_lr: 0.001634  loss: 2.9656 (2.9798)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0013  max mem: 3500\n",
            "Epoch: [8]  [ 60/295]  eta: 0:01:13  lr: 0.001642  min_lr: 0.001642  loss: 2.9901 (2.9846)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0022  max mem: 3500\n",
            "Epoch: [8]  [ 70/295]  eta: 0:01:09  lr: 0.001648  min_lr: 0.001648  loss: 2.9852 (2.9800)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0032  max mem: 3500\n",
            "Epoch: [8]  [ 80/295]  eta: 0:01:05  lr: 0.001656  min_lr: 0.001656  loss: 2.9667 (2.9803)  weight_decay: 0.0500 (0.0500)  time: 0.2747  data: 0.0035  max mem: 3500\n",
            "Epoch: [8]  [ 90/295]  eta: 0:01:01  lr: 0.001661  min_lr: 0.001661  loss: 3.0139 (2.9808)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0032  max mem: 3500\n",
            "Epoch: [8]  [100/295]  eta: 0:00:57  lr: 0.001670  min_lr: 0.001670  loss: 3.0139 (2.9798)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0021  max mem: 3500\n",
            "Epoch: [8]  [110/295]  eta: 0:00:54  lr: 0.001675  min_lr: 0.001675  loss: 2.9914 (2.9800)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0010  max mem: 3500\n",
            "Epoch: [8]  [120/295]  eta: 0:00:50  lr: 0.001683  min_lr: 0.001683  loss: 2.9614 (2.9796)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0013  max mem: 3500\n",
            "Epoch: [8]  [130/295]  eta: 0:00:47  lr: 0.001689  min_lr: 0.001689  loss: 2.9614 (2.9781)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0027  max mem: 3500\n",
            "Epoch: [8]  [140/295]  eta: 0:00:44  lr: 0.001697  min_lr: 0.001697  loss: 2.9759 (2.9791)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0032  max mem: 3500\n",
            "Epoch: [8]  [150/295]  eta: 0:00:41  lr: 0.001703  min_lr: 0.001703  loss: 2.9759 (2.9773)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0025  max mem: 3500\n",
            "Epoch: [8]  [160/295]  eta: 0:00:38  lr: 0.001711  min_lr: 0.001711  loss: 2.9220 (2.9744)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0021  max mem: 3500\n",
            "Epoch: [8]  [170/295]  eta: 0:00:35  lr: 0.001716  min_lr: 0.001716  loss: 2.9265 (2.9734)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0011  max mem: 3500\n",
            "Epoch: [8]  [180/295]  eta: 0:00:32  lr: 0.001724  min_lr: 0.001724  loss: 2.9397 (2.9733)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0015  max mem: 3500\n",
            "Epoch: [8]  [190/295]  eta: 0:00:29  lr: 0.001730  min_lr: 0.001730  loss: 2.9239 (2.9731)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0029  max mem: 3500\n",
            "Epoch: [8]  [200/295]  eta: 0:00:26  lr: 0.001738  min_lr: 0.001738  loss: 2.9432 (2.9734)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0050  max mem: 3500\n",
            "Epoch: [8]  [210/295]  eta: 0:00:23  lr: 0.001744  min_lr: 0.001744  loss: 2.9940 (2.9768)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0051  max mem: 3500\n",
            "Epoch: [8]  [220/295]  eta: 0:00:20  lr: 0.001752  min_lr: 0.001752  loss: 2.9727 (2.9755)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0028  max mem: 3500\n",
            "Epoch: [8]  [230/295]  eta: 0:00:18  lr: 0.001757  min_lr: 0.001757  loss: 2.9681 (2.9767)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0018  max mem: 3500\n",
            "Epoch: [8]  [240/295]  eta: 0:00:15  lr: 0.001766  min_lr: 0.001766  loss: 3.0077 (2.9777)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0016  max mem: 3500\n",
            "Epoch: [8]  [250/295]  eta: 0:00:12  lr: 0.001771  min_lr: 0.001771  loss: 2.9896 (2.9779)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0022  max mem: 3500\n",
            "Epoch: [8]  [260/295]  eta: 0:00:09  lr: 0.001779  min_lr: 0.001779  loss: 2.9674 (2.9784)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0015  max mem: 3500\n",
            "Epoch: [8]  [270/295]  eta: 0:00:06  lr: 0.001785  min_lr: 0.001785  loss: 3.0125 (2.9795)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0010  max mem: 3500\n",
            "Epoch: [8]  [280/295]  eta: 0:00:04  lr: 0.001793  min_lr: 0.001793  loss: 2.9706 (2.9785)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0014  max mem: 3500\n",
            "Epoch: [8]  [290/295]  eta: 0:00:01  lr: 0.001798  min_lr: 0.001798  loss: 2.9610 (2.9785)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0007  max mem: 3500\n",
            "Epoch: [8]  [294/295]  eta: 0:00:00  lr: 0.001798  min_lr: 0.001798  loss: 2.9610 (2.9785)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0001  max mem: 3500\n",
            "Epoch: [8] Total time: 0:01:20 (0.2729 s / it)\n",
            "Averaged stats: lr: 0.001798  min_lr: 0.001798  loss: 2.9610 (2.9785)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:32  loss: 1.8965 (1.8965)  acc1: 56.2500 (56.2500)  acc5: 83.3333 (83.3333)  time: 1.8588  data: 1.6814  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.9953 (2.0407)  acc1: 45.8333 (36.1742)  acc5: 79.1667 (78.4091)  time: 0.2852  data: 0.1550  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.9953 (2.0482)  acc1: 41.6667 (34.6230)  acc5: 77.0833 (78.9683)  time: 0.1275  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.1945 (2.0565)  acc1: 8.3333 (31.3844)  acc5: 91.6667 (83.8038)  time: 0.1246  data: 0.0025  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.1712 (2.0753)  acc1: 20.8333 (29.9289)  acc5: 89.5833 (83.3333)  time: 0.1334  data: 0.0019  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.1260 (2.0740)  acc1: 29.1667 (32.1895)  acc5: 81.2500 (83.9052)  time: 0.1487  data: 0.0010  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 2.0735 (2.0530)  acc1: 37.5000 (34.4262)  acc5: 87.5000 (84.8019)  time: 0.1503  data: 0.0004  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.9138 (2.0494)  acc1: 37.5000 (34.4190)  acc5: 87.5000 (84.7418)  time: 0.1429  data: 0.0003  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.8698 (1.9511)  acc1: 39.5833 (38.7603)  acc5: 87.5000 (85.4681)  time: 0.1339  data: 0.0038  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8684 (1.9421)  acc1: 39.5833 (39.1083)  acc5: 87.5000 (85.4268)  time: 0.1308  data: 0.0038  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1632 s / it)\n",
            "* Acc@1 39.108 Acc@5 85.427 loss 1.942\n",
            "Accuracy of the model on the 3925 test images: 39.1%\n",
            "Max accuracy: 39.11%\n",
            "Test:  [ 0/82]  eta: 0:02:28  loss: 6.9653 (6.9653)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 1.8058  data: 1.6473  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 6.9746 (6.9173)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.3788)  time: 0.2771  data: 0.1527  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 6.7630 (6.7983)  acc1: 0.0000 (0.7937)  acc5: 0.0000 (3.1746)  time: 0.1232  data: 0.0023  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.7630 (6.8349)  acc1: 0.0000 (0.8737)  acc5: 2.0833 (3.1586)  time: 0.1220  data: 0.0020  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 6.7669 (6.8019)  acc1: 0.0000 (0.6606)  acc5: 0.0000 (2.6931)  time: 0.1228  data: 0.0039  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 6.7509 (6.7854)  acc1: 0.0000 (0.6944)  acc5: 0.0000 (2.6552)  time: 0.1237  data: 0.0056  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.6304 (6.7353)  acc1: 0.0000 (0.9221)  acc5: 2.0833 (3.5178)  time: 0.1236  data: 0.0045  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.6661 (6.7384)  acc1: 0.0000 (0.8216)  acc5: 0.0000 (3.1690)  time: 0.1232  data: 0.0033  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.5904 (6.6861)  acc1: 0.0000 (0.7716)  acc5: 0.0000 (4.8097)  time: 0.1208  data: 0.0018  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.5104 (6.6811)  acc1: 0.0000 (0.7643)  acc5: 2.0833 (5.0446)  time: 0.1182  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1490 s / it)\n",
            "* Acc@1 0.764 Acc@5 5.045 loss 6.681\n",
            "Accuracy of the model EMA on 3925 test images: 0.8%\n",
            "Max EMA accuracy: 0.76%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [9]  [  0/295]  eta: 0:12:45  lr: 0.001801  min_lr: 0.001801  loss: 2.9326 (2.9326)  weight_decay: 0.0500 (0.0500)  time: 2.5950  data: 2.1998  max mem: 3500\n",
            "Epoch: [9]  [ 10/295]  eta: 0:02:16  lr: 0.001807  min_lr: 0.001807  loss: 2.9326 (2.9056)  weight_decay: 0.0500 (0.0500)  time: 0.4805  data: 0.2026  max mem: 3500\n",
            "Epoch: [9]  [ 20/295]  eta: 0:01:43  lr: 0.001815  min_lr: 0.001815  loss: 2.9367 (2.9263)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0023  max mem: 3500\n",
            "Epoch: [9]  [ 30/295]  eta: 0:01:30  lr: 0.001820  min_lr: 0.001820  loss: 2.9616 (2.9469)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0010  max mem: 3500\n",
            "Epoch: [9]  [ 40/295]  eta: 0:01:22  lr: 0.001829  min_lr: 0.001829  loss: 2.9751 (2.9486)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0014  max mem: 3500\n",
            "Epoch: [9]  [ 50/295]  eta: 0:01:16  lr: 0.001834  min_lr: 0.001834  loss: 2.9331 (2.9401)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0030  max mem: 3500\n",
            "Epoch: [9]  [ 60/295]  eta: 0:01:11  lr: 0.001842  min_lr: 0.001842  loss: 2.8922 (2.9321)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0038  max mem: 3500\n",
            "Epoch: [9]  [ 70/295]  eta: 0:01:07  lr: 0.001848  min_lr: 0.001848  loss: 2.8893 (2.9246)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0032  max mem: 3500\n",
            "Epoch: [9]  [ 80/295]  eta: 0:01:03  lr: 0.001856  min_lr: 0.001856  loss: 2.9066 (2.9328)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0021  max mem: 3500\n",
            "Epoch: [9]  [ 90/295]  eta: 0:00:59  lr: 0.001862  min_lr: 0.001862  loss: 3.0124 (2.9353)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0020  max mem: 3500\n",
            "Epoch: [9]  [100/295]  eta: 0:00:56  lr: 0.001870  min_lr: 0.001870  loss: 2.9521 (2.9376)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0019  max mem: 3500\n",
            "Epoch: [9]  [110/295]  eta: 0:00:53  lr: 0.001875  min_lr: 0.001875  loss: 2.9248 (2.9392)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0022  max mem: 3500\n",
            "Epoch: [9]  [120/295]  eta: 0:00:49  lr: 0.001883  min_lr: 0.001883  loss: 2.9071 (2.9365)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0029  max mem: 3500\n",
            "Epoch: [9]  [130/295]  eta: 0:00:46  lr: 0.001889  min_lr: 0.001889  loss: 2.9040 (2.9342)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0032  max mem: 3500\n",
            "Epoch: [9]  [140/295]  eta: 0:00:43  lr: 0.001897  min_lr: 0.001897  loss: 2.9151 (2.9340)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0019  max mem: 3500\n",
            "Epoch: [9]  [150/295]  eta: 0:00:40  lr: 0.001903  min_lr: 0.001903  loss: 2.9159 (2.9358)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0005  max mem: 3500\n",
            "Epoch: [9]  [160/295]  eta: 0:00:37  lr: 0.001911  min_lr: 0.001911  loss: 2.9570 (2.9345)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0007  max mem: 3500\n",
            "Epoch: [9]  [170/295]  eta: 0:00:34  lr: 0.001916  min_lr: 0.001916  loss: 2.8549 (2.9299)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0008  max mem: 3500\n",
            "Epoch: [9]  [180/295]  eta: 0:00:31  lr: 0.001925  min_lr: 0.001925  loss: 2.8771 (2.9288)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0011  max mem: 3500\n",
            "Epoch: [9]  [190/295]  eta: 0:00:29  lr: 0.001930  min_lr: 0.001930  loss: 2.9238 (2.9286)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0029  max mem: 3500\n",
            "Epoch: [9]  [200/295]  eta: 0:00:26  lr: 0.001938  min_lr: 0.001938  loss: 2.9178 (2.9268)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0030  max mem: 3500\n",
            "Epoch: [9]  [210/295]  eta: 0:00:23  lr: 0.001944  min_lr: 0.001944  loss: 2.9178 (2.9250)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0012  max mem: 3500\n",
            "Epoch: [9]  [220/295]  eta: 0:00:20  lr: 0.001952  min_lr: 0.001952  loss: 2.9281 (2.9250)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0009  max mem: 3500\n",
            "Epoch: [9]  [230/295]  eta: 0:00:17  lr: 0.001958  min_lr: 0.001958  loss: 2.9516 (2.9258)  weight_decay: 0.0500 (0.0500)  time: 0.2572  data: 0.0009  max mem: 3500\n",
            "Epoch: [9]  [240/295]  eta: 0:00:15  lr: 0.001966  min_lr: 0.001966  loss: 2.9516 (2.9256)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0022  max mem: 3500\n",
            "Epoch: [9]  [250/295]  eta: 0:00:12  lr: 0.001971  min_lr: 0.001971  loss: 2.9326 (2.9253)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0044  max mem: 3500\n",
            "Epoch: [9]  [260/295]  eta: 0:00:09  lr: 0.001979  min_lr: 0.001979  loss: 2.9136 (2.9239)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0043  max mem: 3500\n",
            "Epoch: [9]  [270/295]  eta: 0:00:06  lr: 0.001985  min_lr: 0.001985  loss: 2.9136 (2.9251)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0022  max mem: 3500\n",
            "Epoch: [9]  [280/295]  eta: 0:00:04  lr: 0.001993  min_lr: 0.001993  loss: 2.9421 (2.9259)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0006  max mem: 3500\n",
            "Epoch: [9]  [290/295]  eta: 0:00:01  lr: 0.001999  min_lr: 0.001999  loss: 2.9045 (2.9241)  weight_decay: 0.0500 (0.0500)  time: 0.2565  data: 0.0002  max mem: 3500\n",
            "Epoch: [9]  [294/295]  eta: 0:00:00  lr: 0.001999  min_lr: 0.001999  loss: 2.9045 (2.9243)  weight_decay: 0.0500 (0.0500)  time: 0.2185  data: 0.0002  max mem: 3500\n",
            "Epoch: [9] Total time: 0:01:19 (0.2706 s / it)\n",
            "Averaged stats: lr: 0.001999  min_lr: 0.001999  loss: 2.9045 (2.9243)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:35  loss: 1.5905 (1.5905)  acc1: 66.6667 (66.6667)  acc5: 93.7500 (93.7500)  time: 2.6291  data: 2.4673  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 1.6526 (1.6933)  acc1: 60.4167 (58.3333)  acc5: 95.8333 (94.6970)  time: 0.3965  data: 0.2553  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 1.6756 (1.7407)  acc1: 54.1667 (54.8611)  acc5: 91.6667 (91.4683)  time: 0.1728  data: 0.0285  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 1.8851 (1.8275)  acc1: 39.5833 (44.3548)  acc5: 89.5833 (91.4651)  time: 0.1974  data: 0.0482  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 2.0619 (1.8770)  acc1: 27.0833 (41.5650)  acc5: 83.3333 (88.2114)  time: 0.2092  data: 0.0547  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 2.0171 (1.8961)  acc1: 35.4167 (41.0948)  acc5: 83.3333 (88.3170)  time: 0.1963  data: 0.0456  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:05  loss: 2.0416 (1.9319)  acc1: 33.3333 (38.9344)  acc5: 85.4167 (87.0219)  time: 0.1865  data: 0.0399  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.0562 (1.9254)  acc1: 29.1667 (39.5246)  acc5: 85.4167 (86.2676)  time: 0.1612  data: 0.0220  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.5468 (1.8517)  acc1: 60.4167 (42.8498)  acc5: 91.6667 (87.1656)  time: 0.1320  data: 0.0100  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4948 (1.8471)  acc1: 62.1622 (43.0318)  acc5: 91.6667 (87.1338)  time: 0.1287  data: 0.0099  max mem: 3500\n",
            "Test: Total time: 0:00:17 (0.2091 s / it)\n",
            "* Acc@1 43.032 Acc@5 87.134 loss 1.847\n",
            "Accuracy of the model on the 3925 test images: 43.0%\n",
            "Max accuracy: 43.03%\n",
            "Test:  [ 0/82]  eta: 0:02:43  loss: 6.8926 (6.8926)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 1.9987  data: 1.8306  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 6.8950 (6.8467)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.9470)  time: 0.2980  data: 0.1682  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 6.7174 (6.7307)  acc1: 0.0000 (1.3889)  acc5: 2.0833 (4.8611)  time: 0.1253  data: 0.0030  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.7174 (6.7778)  acc1: 0.0000 (1.5457)  acc5: 2.0833 (4.8387)  time: 0.1274  data: 0.0048  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 6.7180 (6.7461)  acc1: 0.0000 (1.3211)  acc5: 0.0000 (4.1159)  time: 0.1337  data: 0.0028  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 6.7015 (6.7260)  acc1: 0.0000 (1.2663)  acc5: 0.0000 (4.0033)  time: 0.1371  data: 0.0002  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.5904 (6.6738)  acc1: 0.0000 (1.5027)  acc5: 4.1667 (5.4645)  time: 0.1424  data: 0.0004  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.6003 (6.6782)  acc1: 0.0000 (1.3204)  acc5: 2.0833 (4.9589)  time: 0.1425  data: 0.0029  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.5373 (6.6138)  acc1: 0.0000 (1.2346)  acc5: 2.0833 (8.5134)  time: 0.1305  data: 0.0027  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.4644 (6.6075)  acc1: 0.0000 (1.2229)  acc5: 2.0833 (8.7643)  time: 0.1289  data: 0.0027  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1600 s / it)\n",
            "* Acc@1 1.223 Acc@5 8.764 loss 6.607\n",
            "Accuracy of the model EMA on 3925 test images: 1.2%\n",
            "Max EMA accuracy: 1.22%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [10]  [  0/295]  eta: 0:05:41  lr: 0.002001  min_lr: 0.002001  loss: 2.9154 (2.9154)  weight_decay: 0.0500 (0.0500)  time: 1.1564  data: 0.7486  max mem: 3500\n",
            "Epoch: [10]  [ 10/295]  eta: 0:01:51  lr: 0.002007  min_lr: 0.002007  loss: 2.8875 (2.8624)  weight_decay: 0.0500 (0.0500)  time: 0.3918  data: 0.1016  max mem: 3500\n",
            "Epoch: [10]  [ 20/295]  eta: 0:01:31  lr: 0.002015  min_lr: 0.002015  loss: 2.8854 (2.8789)  weight_decay: 0.0500 (0.0500)  time: 0.2902  data: 0.0193  max mem: 3500\n",
            "Epoch: [10]  [ 30/295]  eta: 0:01:22  lr: 0.002021  min_lr: 0.002021  loss: 2.8854 (2.8880)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0032  max mem: 3500\n",
            "Epoch: [10]  [ 40/295]  eta: 0:01:16  lr: 0.002029  min_lr: 0.002029  loss: 2.9233 (2.9006)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0030  max mem: 3500\n",
            "Epoch: [10]  [ 50/295]  eta: 0:01:12  lr: 0.002034  min_lr: 0.002034  loss: 2.9345 (2.9016)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0024  max mem: 3500\n",
            "Epoch: [10]  [ 60/295]  eta: 0:01:08  lr: 0.002042  min_lr: 0.002042  loss: 2.9100 (2.9035)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0021  max mem: 3500\n",
            "Epoch: [10]  [ 70/295]  eta: 0:01:04  lr: 0.002048  min_lr: 0.002048  loss: 2.9100 (2.9043)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0016  max mem: 3500\n",
            "Epoch: [10]  [ 80/295]  eta: 0:01:00  lr: 0.002056  min_lr: 0.002056  loss: 2.8979 (2.8989)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0026  max mem: 3500\n",
            "Epoch: [10]  [ 90/295]  eta: 0:00:57  lr: 0.002062  min_lr: 0.002062  loss: 2.8979 (2.8995)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0019  max mem: 3500\n",
            "Epoch: [10]  [100/295]  eta: 0:00:54  lr: 0.002070  min_lr: 0.002070  loss: 2.8504 (2.8947)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0032  max mem: 3500\n",
            "Epoch: [10]  [110/295]  eta: 0:00:51  lr: 0.002075  min_lr: 0.002075  loss: 2.8504 (2.8919)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0050  max mem: 3500\n",
            "Epoch: [10]  [120/295]  eta: 0:00:48  lr: 0.002084  min_lr: 0.002084  loss: 2.8445 (2.8902)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0033  max mem: 3500\n",
            "Epoch: [10]  [130/295]  eta: 0:00:45  lr: 0.002089  min_lr: 0.002089  loss: 2.8446 (2.8891)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0016  max mem: 3500\n",
            "Epoch: [10]  [140/295]  eta: 0:00:42  lr: 0.002097  min_lr: 0.002097  loss: 2.8862 (2.8909)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0010  max mem: 3500\n",
            "Epoch: [10]  [150/295]  eta: 0:00:39  lr: 0.002103  min_lr: 0.002103  loss: 2.9406 (2.8952)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0009  max mem: 3500\n",
            "Epoch: [10]  [160/295]  eta: 0:00:36  lr: 0.002111  min_lr: 0.002111  loss: 2.9734 (2.8986)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0007  max mem: 3500\n",
            "Epoch: [10]  [170/295]  eta: 0:00:34  lr: 0.002117  min_lr: 0.002117  loss: 2.9165 (2.8988)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0013  max mem: 3500\n",
            "Epoch: [10]  [180/295]  eta: 0:00:31  lr: 0.002125  min_lr: 0.002125  loss: 2.9091 (2.9012)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0031  max mem: 3500\n",
            "Epoch: [10]  [190/295]  eta: 0:00:28  lr: 0.002130  min_lr: 0.002130  loss: 2.9474 (2.9028)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0037  max mem: 3500\n",
            "Epoch: [10]  [200/295]  eta: 0:00:25  lr: 0.002138  min_lr: 0.002138  loss: 2.9258 (2.9036)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0024  max mem: 3500\n",
            "Epoch: [10]  [210/295]  eta: 0:00:23  lr: 0.002144  min_lr: 0.002144  loss: 2.9258 (2.9062)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0016  max mem: 3500\n",
            "Epoch: [10]  [220/295]  eta: 0:00:20  lr: 0.002152  min_lr: 0.002152  loss: 2.9431 (2.9082)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0017  max mem: 3500\n",
            "Epoch: [10]  [230/295]  eta: 0:00:17  lr: 0.002158  min_lr: 0.002158  loss: 2.9041 (2.9080)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0011  max mem: 3500\n",
            "Epoch: [10]  [240/295]  eta: 0:00:14  lr: 0.002166  min_lr: 0.002166  loss: 2.8616 (2.9045)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0013  max mem: 3500\n",
            "Epoch: [10]  [250/295]  eta: 0:00:12  lr: 0.002171  min_lr: 0.002171  loss: 2.8818 (2.9072)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0024  max mem: 3500\n",
            "Epoch: [10]  [260/295]  eta: 0:00:09  lr: 0.002180  min_lr: 0.002180  loss: 2.9651 (2.9088)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0019  max mem: 3500\n",
            "Epoch: [10]  [270/295]  eta: 0:00:06  lr: 0.002185  min_lr: 0.002185  loss: 2.9232 (2.9081)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0014  max mem: 3500\n",
            "Epoch: [10]  [280/295]  eta: 0:00:04  lr: 0.002193  min_lr: 0.002193  loss: 2.8720 (2.9064)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0013  max mem: 3500\n",
            "Epoch: [10]  [290/295]  eta: 0:00:01  lr: 0.002199  min_lr: 0.002199  loss: 2.8675 (2.9050)  weight_decay: 0.0500 (0.0500)  time: 0.2566  data: 0.0008  max mem: 3500\n",
            "Epoch: [10]  [294/295]  eta: 0:00:00  lr: 0.002199  min_lr: 0.002199  loss: 2.8611 (2.9047)  weight_decay: 0.0500 (0.0500)  time: 0.2192  data: 0.0003  max mem: 3500\n",
            "Epoch: [10] Total time: 0:01:19 (0.2680 s / it)\n",
            "Averaged stats: lr: 0.002199  min_lr: 0.002199  loss: 2.8611 (2.9047)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:28  loss: 0.9511 (0.9511)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.5462  data: 2.3821  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 1.1656 (1.2644)  acc1: 79.1667 (73.2955)  acc5: 95.8333 (97.3485)  time: 0.3649  data: 0.2269  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 1.6489 (1.4830)  acc1: 56.2500 (62.8968)  acc5: 95.8333 (93.9484)  time: 0.1517  data: 0.0212  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 1.7653 (1.7682)  acc1: 43.7500 (47.8495)  acc5: 81.2500 (82.2581)  time: 0.1377  data: 0.0162  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.9536 (1.8091)  acc1: 25.0000 (44.4106)  acc5: 75.0000 (82.6220)  time: 0.1214  data: 0.0029  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.9245 (1.8278)  acc1: 33.3333 (42.6879)  acc5: 89.5833 (84.6405)  time: 0.1246  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.8295 (1.8296)  acc1: 29.1667 (43.9891)  acc5: 91.6667 (84.7336)  time: 0.1242  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.7441 (1.8506)  acc1: 31.2500 (41.9014)  acc5: 89.5833 (84.5364)  time: 0.1204  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.6652 (1.7757)  acc1: 35.4167 (44.8302)  acc5: 93.7500 (85.6996)  time: 0.1173  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.6379 (1.7696)  acc1: 43.7500 (45.0701)  acc5: 93.7500 (85.7070)  time: 0.1156  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1622 s / it)\n",
            "* Acc@1 45.070 Acc@5 85.707 loss 1.770\n",
            "Accuracy of the model on the 3925 test images: 45.1%\n",
            "Max accuracy: 45.07%\n",
            "Test:  [ 0/82]  eta: 0:04:00  loss: 6.8155 (6.8155)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.9377  data: 2.7503  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 6.8155 (6.7701)  acc1: 0.0000 (0.1894)  acc5: 0.0000 (1.7045)  time: 0.4246  data: 0.2880  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 6.6569 (6.6555)  acc1: 0.0000 (2.0833)  acc5: 4.1667 (7.8373)  time: 0.1621  data: 0.0348  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 6.6651 (6.7141)  acc1: 0.0000 (2.5538)  acc5: 6.2500 (7.5269)  time: 0.1562  data: 0.0267  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 6.6695 (6.6855)  acc1: 0.0000 (2.1850)  acc5: 2.0833 (6.5549)  time: 0.1455  data: 0.0146  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 6.6268 (6.6615)  acc1: 0.0000 (1.9608)  acc5: 2.0833 (6.4951)  time: 0.1272  data: 0.0030  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 6.5494 (6.6072)  acc1: 0.0000 (2.2199)  acc5: 4.1667 (8.3675)  time: 0.1251  data: 0.0036  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 6.5494 (6.6129)  acc1: 0.0000 (1.9366)  acc5: 6.2500 (7.8932)  time: 0.1221  data: 0.0025  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.4698 (6.5353)  acc1: 0.0000 (1.8519)  acc5: 6.2500 (12.1399)  time: 0.1190  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.4180 (6.5277)  acc1: 0.0000 (1.8344)  acc5: 6.2500 (12.6115)  time: 0.1176  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1759 s / it)\n",
            "* Acc@1 1.834 Acc@5 12.611 loss 6.528\n",
            "Accuracy of the model EMA on 3925 test images: 1.8%\n",
            "Max EMA accuracy: 1.83%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [11]  [  0/295]  eta: 0:09:25  lr: 0.002202  min_lr: 0.002202  loss: 2.9449 (2.9449)  weight_decay: 0.0500 (0.0500)  time: 1.9176  data: 1.5617  max mem: 3500\n",
            "Epoch: [11]  [ 10/295]  eta: 0:02:01  lr: 0.002207  min_lr: 0.002207  loss: 2.7598 (2.7747)  weight_decay: 0.0500 (0.0500)  time: 0.4265  data: 0.1461  max mem: 3500\n",
            "Epoch: [11]  [ 20/295]  eta: 0:01:37  lr: 0.002215  min_lr: 0.002215  loss: 2.8310 (2.8230)  weight_decay: 0.0500 (0.0500)  time: 0.2761  data: 0.0047  max mem: 3500\n",
            "Epoch: [11]  [ 30/295]  eta: 0:01:26  lr: 0.002221  min_lr: 0.002221  loss: 2.8965 (2.8462)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0045  max mem: 3500\n",
            "Epoch: [11]  [ 40/295]  eta: 0:01:19  lr: 0.002229  min_lr: 0.002229  loss: 2.9071 (2.8648)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0025  max mem: 3500\n",
            "Epoch: [11]  [ 50/295]  eta: 0:01:14  lr: 0.002234  min_lr: 0.002234  loss: 2.8998 (2.8708)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0012  max mem: 3500\n",
            "Epoch: [11]  [ 60/295]  eta: 0:01:09  lr: 0.002243  min_lr: 0.002243  loss: 2.8682 (2.8684)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0008  max mem: 3500\n",
            "Epoch: [11]  [ 70/295]  eta: 0:01:05  lr: 0.002248  min_lr: 0.002248  loss: 2.8682 (2.8643)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0002  max mem: 3500\n",
            "Epoch: [11]  [ 80/295]  eta: 0:01:02  lr: 0.002256  min_lr: 0.002256  loss: 2.8570 (2.8674)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0042  max mem: 3500\n",
            "Epoch: [11]  [ 90/295]  eta: 0:00:59  lr: 0.002262  min_lr: 0.002262  loss: 2.8602 (2.8638)  weight_decay: 0.0500 (0.0500)  time: 0.2794  data: 0.0077  max mem: 3500\n",
            "Epoch: [11]  [100/295]  eta: 0:00:56  lr: 0.002270  min_lr: 0.002270  loss: 2.8570 (2.8627)  weight_decay: 0.0500 (0.0500)  time: 0.2757  data: 0.0050  max mem: 3500\n",
            "Epoch: [11]  [110/295]  eta: 0:00:52  lr: 0.002276  min_lr: 0.002276  loss: 2.8488 (2.8609)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0028  max mem: 3500\n",
            "Epoch: [11]  [120/295]  eta: 0:00:49  lr: 0.002284  min_lr: 0.002284  loss: 2.8243 (2.8589)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0024  max mem: 3500\n",
            "Epoch: [11]  [130/295]  eta: 0:00:46  lr: 0.002289  min_lr: 0.002289  loss: 2.8822 (2.8626)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0015  max mem: 3500\n",
            "Epoch: [11]  [140/295]  eta: 0:00:43  lr: 0.002297  min_lr: 0.002297  loss: 2.9046 (2.8601)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0011  max mem: 3500\n",
            "Epoch: [11]  [150/295]  eta: 0:00:40  lr: 0.002303  min_lr: 0.002303  loss: 2.9046 (2.8628)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0030  max mem: 3500\n",
            "Epoch: [11]  [160/295]  eta: 0:00:37  lr: 0.002311  min_lr: 0.002311  loss: 2.9128 (2.8648)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0056  max mem: 3500\n",
            "Epoch: [11]  [170/295]  eta: 0:00:34  lr: 0.002317  min_lr: 0.002317  loss: 2.9040 (2.8637)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0046  max mem: 3500\n",
            "Epoch: [11]  [180/295]  eta: 0:00:31  lr: 0.002325  min_lr: 0.002325  loss: 2.8925 (2.8692)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0027  max mem: 3500\n",
            "Epoch: [11]  [190/295]  eta: 0:00:29  lr: 0.002330  min_lr: 0.002330  loss: 2.9391 (2.8692)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0024  max mem: 3500\n",
            "Epoch: [11]  [200/295]  eta: 0:00:26  lr: 0.002339  min_lr: 0.002339  loss: 2.9373 (2.8724)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0024  max mem: 3500\n",
            "Epoch: [11]  [210/295]  eta: 0:00:23  lr: 0.002344  min_lr: 0.002344  loss: 2.9276 (2.8733)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0018  max mem: 3500\n",
            "Epoch: [11]  [220/295]  eta: 0:00:20  lr: 0.002352  min_lr: 0.002352  loss: 2.8583 (2.8735)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0033  max mem: 3500\n",
            "Epoch: [11]  [230/295]  eta: 0:00:17  lr: 0.002358  min_lr: 0.002358  loss: 2.9126 (2.8770)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0047  max mem: 3500\n",
            "Epoch: [11]  [240/295]  eta: 0:00:15  lr: 0.002366  min_lr: 0.002366  loss: 2.8996 (2.8770)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0040  max mem: 3500\n",
            "Epoch: [11]  [250/295]  eta: 0:00:12  lr: 0.002371  min_lr: 0.002371  loss: 2.9028 (2.8800)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0033  max mem: 3500\n",
            "Epoch: [11]  [260/295]  eta: 0:00:09  lr: 0.002380  min_lr: 0.002380  loss: 2.9420 (2.8799)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0019  max mem: 3500\n",
            "Epoch: [11]  [270/295]  eta: 0:00:06  lr: 0.002385  min_lr: 0.002385  loss: 2.8828 (2.8803)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0011  max mem: 3500\n",
            "Epoch: [11]  [280/295]  eta: 0:00:04  lr: 0.002393  min_lr: 0.002393  loss: 2.8486 (2.8786)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0013  max mem: 3500\n",
            "Epoch: [11]  [290/295]  eta: 0:00:01  lr: 0.002399  min_lr: 0.002399  loss: 2.8426 (2.8773)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0007  max mem: 3500\n",
            "Epoch: [11]  [294/295]  eta: 0:00:00  lr: 0.002399  min_lr: 0.002399  loss: 2.8471 (2.8774)  weight_decay: 0.0500 (0.0500)  time: 0.2210  data: 0.0004  max mem: 3500\n",
            "Epoch: [11] Total time: 0:01:19 (0.2707 s / it)\n",
            "Averaged stats: lr: 0.002399  min_lr: 0.002399  loss: 2.8471 (2.8774)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:49  loss: 0.8992 (0.8992)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 2.0731  data: 1.9113  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.9973 (1.2455)  acc1: 87.5000 (69.1288)  acc5: 100.0000 (96.2121)  time: 0.3002  data: 0.1776  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.7258 (1.5476)  acc1: 52.0833 (54.3651)  acc5: 89.5833 (91.3690)  time: 0.1220  data: 0.0034  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.0114 (1.8033)  acc1: 18.7500 (41.6667)  acc5: 81.2500 (84.6774)  time: 0.1220  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.8799 (1.7991)  acc1: 35.4167 (41.6159)  acc5: 81.2500 (85.6707)  time: 0.1236  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.7741 (1.8340)  acc1: 39.5833 (39.1748)  acc5: 89.5833 (86.3154)  time: 0.1234  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.7806 (1.8147)  acc1: 45.8333 (41.3934)  acc5: 89.5833 (86.2705)  time: 0.1214  data: 0.0035  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.8051 (1.8263)  acc1: 43.7500 (40.6103)  acc5: 89.5833 (86.3556)  time: 0.1191  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.7859 (1.7474)  acc1: 41.6667 (43.8786)  acc5: 91.6667 (87.5257)  time: 0.1178  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.7806 (1.7404)  acc1: 47.9167 (44.1529)  acc5: 91.8919 (87.5669)  time: 0.1159  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1518 s / it)\n",
            "* Acc@1 44.153 Acc@5 87.567 loss 1.740\n",
            "Accuracy of the model on the 3925 test images: 44.2%\n",
            "Max accuracy: 45.07%\n",
            "Test:  [ 0/82]  eta: 0:03:55  loss: 6.7268 (6.7268)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.8676  data: 2.7028  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 6.7268 (6.6817)  acc1: 0.0000 (0.9470)  acc5: 0.0000 (5.6818)  time: 0.3970  data: 0.2570  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 6.5870 (6.5714)  acc1: 0.0000 (3.2738)  acc5: 16.6667 (13.7897)  time: 0.1391  data: 0.0071  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 6.6081 (6.6432)  acc1: 0.0000 (3.4946)  acc5: 16.6667 (12.1640)  time: 0.1271  data: 0.0049  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.6181 (6.6185)  acc1: 0.0000 (2.9472)  acc5: 4.1667 (10.7215)  time: 0.1243  data: 0.0060  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 6.5722 (6.5897)  acc1: 0.0000 (2.7369)  acc5: 4.1667 (10.6209)  time: 0.1229  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.5034 (6.5331)  acc1: 2.0833 (3.0396)  acc5: 6.2500 (12.7391)  time: 0.1248  data: 0.0054  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.5034 (6.5403)  acc1: 2.0833 (2.7289)  acc5: 8.3333 (12.1479)  time: 0.1231  data: 0.0044  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.3777 (6.4497)  acc1: 0.0000 (2.8035)  acc5: 14.5833 (16.7953)  time: 0.1193  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.3659 (6.4406)  acc1: 2.0833 (2.8025)  acc5: 16.6667 (17.2484)  time: 0.1175  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1648 s / it)\n",
            "* Acc@1 2.803 Acc@5 17.248 loss 6.441\n",
            "Accuracy of the model EMA on 3925 test images: 2.8%\n",
            "Max EMA accuracy: 2.80%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [12]  [  0/295]  eta: 0:11:47  lr: 0.002402  min_lr: 0.002402  loss: 3.0390 (3.0390)  weight_decay: 0.0500 (0.0500)  time: 2.3967  data: 1.8004  max mem: 3500\n",
            "Epoch: [12]  [ 10/295]  eta: 0:02:26  lr: 0.002407  min_lr: 0.002407  loss: 2.8979 (2.8930)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.1671  max mem: 3500\n",
            "Epoch: [12]  [ 20/295]  eta: 0:01:49  lr: 0.002415  min_lr: 0.002415  loss: 2.8511 (2.8753)  weight_decay: 0.0500 (0.0500)  time: 0.2995  data: 0.0039  max mem: 3500\n",
            "Epoch: [12]  [ 30/295]  eta: 0:01:33  lr: 0.002421  min_lr: 0.002421  loss: 2.8596 (2.8856)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0023  max mem: 3500\n",
            "Epoch: [12]  [ 40/295]  eta: 0:01:24  lr: 0.002429  min_lr: 0.002429  loss: 2.9357 (2.8880)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0012  max mem: 3500\n",
            "Epoch: [12]  [ 50/295]  eta: 0:01:18  lr: 0.002435  min_lr: 0.002435  loss: 2.8257 (2.8723)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0018  max mem: 3500\n",
            "Epoch: [12]  [ 60/295]  eta: 0:01:12  lr: 0.002443  min_lr: 0.002443  loss: 2.8068 (2.8726)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0014  max mem: 3500\n",
            "Epoch: [12]  [ 70/295]  eta: 0:01:08  lr: 0.002448  min_lr: 0.002448  loss: 2.8877 (2.8775)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0012  max mem: 3500\n",
            "Epoch: [12]  [ 80/295]  eta: 0:01:04  lr: 0.002456  min_lr: 0.002456  loss: 2.8455 (2.8716)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0025  max mem: 3500\n",
            "Epoch: [12]  [ 90/295]  eta: 0:01:00  lr: 0.002462  min_lr: 0.002462  loss: 2.9083 (2.8828)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0032  max mem: 3500\n",
            "Epoch: [12]  [100/295]  eta: 0:00:57  lr: 0.002470  min_lr: 0.002470  loss: 2.9355 (2.8874)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0024  max mem: 3500\n",
            "Epoch: [12]  [110/295]  eta: 0:00:53  lr: 0.002476  min_lr: 0.002476  loss: 2.9108 (2.8861)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0022  max mem: 3500\n",
            "Epoch: [12]  [120/295]  eta: 0:00:50  lr: 0.002484  min_lr: 0.002484  loss: 2.8818 (2.8869)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0017  max mem: 3500\n",
            "Epoch: [12]  [130/295]  eta: 0:00:47  lr: 0.002489  min_lr: 0.002489  loss: 2.8763 (2.8883)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0017  max mem: 3500\n",
            "Epoch: [12]  [140/295]  eta: 0:00:44  lr: 0.002498  min_lr: 0.002498  loss: 2.8635 (2.8852)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0034  max mem: 3500\n",
            "Epoch: [12]  [150/295]  eta: 0:00:41  lr: 0.002503  min_lr: 0.002503  loss: 2.8550 (2.8865)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0036  max mem: 3500\n",
            "Epoch: [12]  [160/295]  eta: 0:00:38  lr: 0.002511  min_lr: 0.002511  loss: 2.9154 (2.8891)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0028  max mem: 3500\n",
            "Epoch: [12]  [170/295]  eta: 0:00:35  lr: 0.002517  min_lr: 0.002517  loss: 2.8571 (2.8861)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0018  max mem: 3500\n",
            "Epoch: [12]  [180/295]  eta: 0:00:32  lr: 0.002525  min_lr: 0.002525  loss: 2.8280 (2.8844)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0016  max mem: 3500\n",
            "Epoch: [12]  [190/295]  eta: 0:00:29  lr: 0.002531  min_lr: 0.002531  loss: 2.8907 (2.8864)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0028  max mem: 3500\n",
            "Epoch: [12]  [200/295]  eta: 0:00:26  lr: 0.002539  min_lr: 0.002539  loss: 2.8724 (2.8826)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0036  max mem: 3500\n",
            "Epoch: [12]  [210/295]  eta: 0:00:23  lr: 0.002544  min_lr: 0.002544  loss: 2.8478 (2.8816)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0041  max mem: 3500\n",
            "Epoch: [12]  [220/295]  eta: 0:00:20  lr: 0.002552  min_lr: 0.002552  loss: 2.8407 (2.8793)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0044  max mem: 3500\n",
            "Epoch: [12]  [230/295]  eta: 0:00:17  lr: 0.002558  min_lr: 0.002558  loss: 2.8781 (2.8793)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0036  max mem: 3500\n",
            "Epoch: [12]  [240/295]  eta: 0:00:15  lr: 0.002566  min_lr: 0.002566  loss: 2.8781 (2.8778)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0029  max mem: 3500\n",
            "Epoch: [12]  [250/295]  eta: 0:00:12  lr: 0.002572  min_lr: 0.002572  loss: 2.8750 (2.8778)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0019  max mem: 3500\n",
            "Epoch: [12]  [260/295]  eta: 0:00:09  lr: 0.002580  min_lr: 0.002580  loss: 2.8615 (2.8758)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0017  max mem: 3500\n",
            "Epoch: [12]  [270/295]  eta: 0:00:06  lr: 0.002585  min_lr: 0.002585  loss: 2.8176 (2.8732)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0034  max mem: 3500\n",
            "Epoch: [12]  [280/295]  eta: 0:00:04  lr: 0.002594  min_lr: 0.002594  loss: 2.8155 (2.8716)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0026  max mem: 3500\n",
            "Epoch: [12]  [290/295]  eta: 0:00:01  lr: 0.002599  min_lr: 0.002599  loss: 2.8223 (2.8693)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0005  max mem: 3500\n",
            "Epoch: [12]  [294/295]  eta: 0:00:00  lr: 0.002599  min_lr: 0.002599  loss: 2.8223 (2.8685)  weight_decay: 0.0500 (0.0500)  time: 0.2214  data: 0.0003  max mem: 3500\n",
            "Epoch: [12] Total time: 0:01:20 (0.2725 s / it)\n",
            "Averaged stats: lr: 0.002599  min_lr: 0.002599  loss: 2.8223 (2.8685)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:36  loss: 1.5181 (1.5181)  acc1: 54.1667 (54.1667)  acc5: 93.7500 (93.7500)  time: 2.6388  data: 2.4863  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 1.6181 (1.6186)  acc1: 50.0000 (49.4318)  acc5: 91.6667 (92.0455)  time: 0.3495  data: 0.2280  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 1.5424 (1.5553)  acc1: 54.1667 (56.0516)  acc5: 93.7500 (93.2540)  time: 0.1235  data: 0.0036  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 1.5424 (1.7459)  acc1: 52.0833 (43.9516)  acc5: 91.6667 (90.6586)  time: 0.1272  data: 0.0045  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.8092 (1.7624)  acc1: 31.2500 (42.7337)  acc5: 87.5000 (89.8374)  time: 0.1316  data: 0.0045  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.7973 (1.7946)  acc1: 41.6667 (40.8905)  acc5: 89.5833 (90.2369)  time: 0.1391  data: 0.0027  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.7973 (1.7799)  acc1: 43.7500 (42.8962)  acc5: 91.6667 (90.0615)  time: 0.1427  data: 0.0007  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.6767 (1.7555)  acc1: 54.1667 (44.4836)  acc5: 89.5833 (90.1408)  time: 0.1430  data: 0.0047  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3649 (1.6595)  acc1: 60.4167 (48.4054)  acc5: 95.8333 (90.8179)  time: 0.1317  data: 0.0044  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3577 (1.6531)  acc1: 62.5000 (48.6115)  acc5: 95.8333 (90.8025)  time: 0.1284  data: 0.0044  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1684 s / it)\n",
            "* Acc@1 48.611 Acc@5 90.803 loss 1.653\n",
            "Accuracy of the model on the 3925 test images: 48.6%\n",
            "Max accuracy: 48.61%\n",
            "Test:  [ 0/82]  eta: 0:02:24  loss: 6.6339 (6.6339)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 1.7591  data: 1.5809  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 6.6227 (6.5861)  acc1: 0.0000 (3.0303)  acc5: 0.0000 (9.0909)  time: 0.2724  data: 0.1457  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 6.5119 (6.4794)  acc1: 8.3333 (6.3492)  acc5: 25.0000 (18.7500)  time: 0.1228  data: 0.0024  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.5468 (6.5647)  acc1: 6.2500 (5.7796)  acc5: 22.9167 (15.8602)  time: 0.1226  data: 0.0024  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 6.5657 (6.5449)  acc1: 0.0000 (5.0813)  acc5: 6.2500 (14.3801)  time: 0.1233  data: 0.0025  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 6.5136 (6.5092)  acc1: 2.0833 (4.8611)  acc5: 8.3333 (14.7467)  time: 0.1235  data: 0.0044  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.4097 (6.4504)  acc1: 4.1667 (5.2254)  acc5: 8.3333 (17.0424)  time: 0.1240  data: 0.0055  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.4534 (6.4594)  acc1: 2.0833 (4.7535)  acc5: 12.5000 (16.4319)  time: 0.1231  data: 0.0027  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.3105 (6.3544)  acc1: 2.0833 (5.4527)  acc5: 18.7500 (21.4249)  time: 0.1203  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.2803 (6.3438)  acc1: 4.1667 (5.4777)  acc5: 18.7500 (21.9108)  time: 0.1188  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1483 s / it)\n",
            "* Acc@1 5.478 Acc@5 21.911 loss 6.344\n",
            "Accuracy of the model EMA on 3925 test images: 5.5%\n",
            "Max EMA accuracy: 5.48%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [13]  [  0/295]  eta: 0:10:38  lr: 0.002602  min_lr: 0.002602  loss: 2.7491 (2.7491)  weight_decay: 0.0500 (0.0500)  time: 2.1653  data: 1.8147  max mem: 3500\n",
            "Epoch: [13]  [ 10/295]  eta: 0:02:06  lr: 0.002607  min_lr: 0.002607  loss: 2.7881 (2.7639)  weight_decay: 0.0500 (0.0500)  time: 0.4439  data: 0.1677  max mem: 3500\n",
            "Epoch: [13]  [ 20/295]  eta: 0:01:38  lr: 0.002615  min_lr: 0.002615  loss: 2.8543 (2.8636)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0020  max mem: 3500\n",
            "Epoch: [13]  [ 30/295]  eta: 0:01:26  lr: 0.002621  min_lr: 0.002621  loss: 2.9154 (2.8582)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0009  max mem: 3500\n",
            "Epoch: [13]  [ 40/295]  eta: 0:01:19  lr: 0.002629  min_lr: 0.002629  loss: 2.8957 (2.8778)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0020  max mem: 3500\n",
            "Epoch: [13]  [ 50/295]  eta: 0:01:14  lr: 0.002635  min_lr: 0.002635  loss: 2.9088 (2.8762)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0026  max mem: 3500\n",
            "Epoch: [13]  [ 60/295]  eta: 0:01:10  lr: 0.002643  min_lr: 0.002643  loss: 2.8957 (2.8778)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0021  max mem: 3500\n",
            "Epoch: [13]  [ 70/295]  eta: 0:01:06  lr: 0.002648  min_lr: 0.002648  loss: 2.8622 (2.8653)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0027  max mem: 3500\n",
            "Epoch: [13]  [ 80/295]  eta: 0:01:02  lr: 0.002657  min_lr: 0.002657  loss: 2.8622 (2.8664)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0029  max mem: 3500\n",
            "Epoch: [13]  [ 90/295]  eta: 0:00:58  lr: 0.002662  min_lr: 0.002662  loss: 2.8469 (2.8611)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0022  max mem: 3500\n",
            "Epoch: [13]  [100/295]  eta: 0:00:55  lr: 0.002670  min_lr: 0.002670  loss: 2.8046 (2.8654)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0017  max mem: 3500\n",
            "Epoch: [13]  [110/295]  eta: 0:00:52  lr: 0.002676  min_lr: 0.002676  loss: 2.9338 (2.8671)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0017  max mem: 3500\n",
            "Epoch: [13]  [120/295]  eta: 0:00:49  lr: 0.002684  min_lr: 0.002684  loss: 2.9110 (2.8674)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0025  max mem: 3500\n",
            "Epoch: [13]  [130/295]  eta: 0:00:46  lr: 0.002690  min_lr: 0.002690  loss: 2.8713 (2.8676)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0028  max mem: 3500\n",
            "Epoch: [13]  [140/295]  eta: 0:00:43  lr: 0.002698  min_lr: 0.002698  loss: 2.8713 (2.8693)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0024  max mem: 3500\n",
            "Epoch: [13]  [150/295]  eta: 0:00:40  lr: 0.002703  min_lr: 0.002703  loss: 2.8604 (2.8636)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0022  max mem: 3500\n",
            "Epoch: [13]  [160/295]  eta: 0:00:37  lr: 0.002711  min_lr: 0.002711  loss: 2.8044 (2.8589)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0022  max mem: 3500\n",
            "Epoch: [13]  [170/295]  eta: 0:00:34  lr: 0.002717  min_lr: 0.002717  loss: 2.8253 (2.8603)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0025  max mem: 3500\n",
            "Epoch: [13]  [180/295]  eta: 0:00:31  lr: 0.002725  min_lr: 0.002725  loss: 2.8789 (2.8599)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0032  max mem: 3500\n",
            "Epoch: [13]  [190/295]  eta: 0:00:28  lr: 0.002731  min_lr: 0.002731  loss: 2.7708 (2.8571)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0032  max mem: 3500\n",
            "Epoch: [13]  [200/295]  eta: 0:00:26  lr: 0.002739  min_lr: 0.002739  loss: 2.7708 (2.8514)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0020  max mem: 3500\n",
            "Epoch: [13]  [210/295]  eta: 0:00:23  lr: 0.002744  min_lr: 0.002744  loss: 2.7810 (2.8532)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0013  max mem: 3500\n",
            "Epoch: [13]  [220/295]  eta: 0:00:20  lr: 0.002753  min_lr: 0.002753  loss: 2.8409 (2.8520)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0014  max mem: 3500\n",
            "Epoch: [13]  [230/295]  eta: 0:00:17  lr: 0.002758  min_lr: 0.002758  loss: 2.8185 (2.8518)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0017  max mem: 3500\n",
            "Epoch: [13]  [240/295]  eta: 0:00:14  lr: 0.002766  min_lr: 0.002766  loss: 2.8225 (2.8487)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0014  max mem: 3500\n",
            "Epoch: [13]  [250/295]  eta: 0:00:12  lr: 0.002772  min_lr: 0.002772  loss: 2.8070 (2.8469)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0022  max mem: 3500\n",
            "Epoch: [13]  [260/295]  eta: 0:00:09  lr: 0.002780  min_lr: 0.002780  loss: 2.7786 (2.8455)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0041  max mem: 3500\n",
            "Epoch: [13]  [270/295]  eta: 0:00:06  lr: 0.002785  min_lr: 0.002785  loss: 2.8015 (2.8444)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0040  max mem: 3500\n",
            "Epoch: [13]  [280/295]  eta: 0:00:04  lr: 0.002794  min_lr: 0.002794  loss: 2.8825 (2.8445)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0018  max mem: 3500\n",
            "Epoch: [13]  [290/295]  eta: 0:00:01  lr: 0.002799  min_lr: 0.002799  loss: 2.8464 (2.8424)  weight_decay: 0.0500 (0.0500)  time: 0.2567  data: 0.0002  max mem: 3500\n",
            "Epoch: [13]  [294/295]  eta: 0:00:00  lr: 0.002799  min_lr: 0.002799  loss: 2.8464 (2.8431)  weight_decay: 0.0500 (0.0500)  time: 0.2186  data: 0.0001  max mem: 3500\n",
            "Epoch: [13] Total time: 0:01:19 (0.2690 s / it)\n",
            "Averaged stats: lr: 0.002799  min_lr: 0.002799  loss: 2.8464 (2.8431)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:03  loss: 0.7361 (0.7361)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.2413  data: 2.0653  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.8292 (1.0327)  acc1: 85.4167 (77.6515)  acc5: 97.9167 (97.3485)  time: 0.3776  data: 0.2382  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 1.2190 (1.2550)  acc1: 72.9167 (69.4444)  acc5: 97.9167 (96.7262)  time: 0.1887  data: 0.0490  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 1.6708 (1.6289)  acc1: 47.9167 (53.5618)  acc5: 91.6667 (85.1479)  time: 0.1659  data: 0.0262  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.7883 (1.6810)  acc1: 41.6667 (50.6098)  acc5: 83.3333 (85.1118)  time: 0.1565  data: 0.0163  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.7883 (1.7443)  acc1: 41.6667 (45.5474)  acc5: 87.5000 (86.0294)  time: 0.1462  data: 0.0124  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.7413 (1.7265)  acc1: 45.8333 (46.6872)  acc5: 89.5833 (86.6803)  time: 0.1233  data: 0.0019  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.8744 (1.7580)  acc1: 41.6667 (43.6913)  acc5: 89.5833 (86.7664)  time: 0.1206  data: 0.0010  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.8744 (1.7223)  acc1: 39.5833 (44.9331)  acc5: 89.5833 (87.6800)  time: 0.1187  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8615 (1.7200)  acc1: 39.5833 (45.0446)  acc5: 89.5833 (87.6943)  time: 0.1169  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1763 s / it)\n",
            "* Acc@1 45.045 Acc@5 87.694 loss 1.720\n",
            "Accuracy of the model on the 3925 test images: 45.0%\n",
            "Max accuracy: 48.61%\n",
            "Test:  [ 0/82]  eta: 0:02:40  loss: 6.5318 (6.5318)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 1.9548  data: 1.7927  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 6.5063 (6.4803)  acc1: 0.0000 (5.3030)  acc5: 0.0000 (10.6061)  time: 0.2872  data: 0.1656  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 6.4168 (6.3787)  acc1: 12.5000 (9.4246)  acc5: 27.0833 (21.5278)  time: 0.1213  data: 0.0033  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.4809 (6.4787)  acc1: 12.5000 (7.8629)  acc5: 27.0833 (18.2124)  time: 0.1252  data: 0.0048  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 6.5084 (6.4653)  acc1: 0.0000 (6.8598)  acc5: 12.5000 (17.4289)  time: 0.1311  data: 0.0047  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 6.4279 (6.4220)  acc1: 4.1667 (6.9036)  acc5: 12.5000 (18.7500)  time: 0.1370  data: 0.0020  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.2804 (6.3614)  acc1: 6.2500 (7.0355)  acc5: 14.5833 (21.1749)  time: 0.1447  data: 0.0044  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.3752 (6.3722)  acc1: 4.1667 (6.4847)  acc5: 18.7500 (20.5106)  time: 0.1445  data: 0.0075  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.2556 (6.2516)  acc1: 6.2500 (8.8992)  acc5: 22.9167 (25.5144)  time: 0.1299  data: 0.0033  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.1742 (6.2395)  acc1: 8.3333 (9.1720)  acc5: 25.0000 (25.9873)  time: 0.1257  data: 0.0033  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1589 s / it)\n",
            "* Acc@1 9.172 Acc@5 25.987 loss 6.239\n",
            "Accuracy of the model EMA on 3925 test images: 9.2%\n",
            "Max EMA accuracy: 9.17%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [14]  [  0/295]  eta: 0:09:12  lr: 0.002802  min_lr: 0.002802  loss: 3.0240 (3.0240)  weight_decay: 0.0500 (0.0500)  time: 1.8734  data: 1.5142  max mem: 3500\n",
            "Epoch: [14]  [ 10/295]  eta: 0:01:58  lr: 0.002807  min_lr: 0.002807  loss: 2.9292 (2.9211)  weight_decay: 0.0500 (0.0500)  time: 0.4166  data: 0.1402  max mem: 3500\n",
            "Epoch: [14]  [ 20/295]  eta: 0:01:34  lr: 0.002816  min_lr: 0.002816  loss: 2.8478 (2.8628)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0017  max mem: 3500\n",
            "Epoch: [14]  [ 30/295]  eta: 0:01:24  lr: 0.002821  min_lr: 0.002821  loss: 2.8013 (2.8501)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0008  max mem: 3500\n",
            "Epoch: [14]  [ 40/295]  eta: 0:01:18  lr: 0.002829  min_lr: 0.002829  loss: 2.7819 (2.8417)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0010  max mem: 3500\n",
            "Epoch: [14]  [ 50/295]  eta: 0:01:13  lr: 0.002835  min_lr: 0.002835  loss: 2.8088 (2.8437)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0020  max mem: 3500\n",
            "Epoch: [14]  [ 60/295]  eta: 0:01:09  lr: 0.002843  min_lr: 0.002843  loss: 2.8137 (2.8393)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0029  max mem: 3500\n",
            "Epoch: [14]  [ 70/295]  eta: 0:01:05  lr: 0.002849  min_lr: 0.002849  loss: 2.8370 (2.8396)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0032  max mem: 3500\n",
            "Epoch: [14]  [ 80/295]  eta: 0:01:01  lr: 0.002857  min_lr: 0.002857  loss: 2.8500 (2.8358)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0039  max mem: 3500\n",
            "Epoch: [14]  [ 90/295]  eta: 0:00:58  lr: 0.002862  min_lr: 0.002862  loss: 2.8523 (2.8382)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0040  max mem: 3500\n",
            "Epoch: [14]  [100/295]  eta: 0:00:55  lr: 0.002870  min_lr: 0.002870  loss: 2.8452 (2.8337)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0046  max mem: 3500\n",
            "Epoch: [14]  [110/295]  eta: 0:00:52  lr: 0.002876  min_lr: 0.002876  loss: 2.8204 (2.8328)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0065  max mem: 3500\n",
            "Epoch: [14]  [120/295]  eta: 0:00:49  lr: 0.002884  min_lr: 0.002884  loss: 2.8139 (2.8258)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0060  max mem: 3500\n",
            "Epoch: [14]  [130/295]  eta: 0:00:46  lr: 0.002890  min_lr: 0.002890  loss: 2.8139 (2.8256)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0039  max mem: 3500\n",
            "Epoch: [14]  [140/295]  eta: 0:00:43  lr: 0.002898  min_lr: 0.002898  loss: 2.8619 (2.8279)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0031  max mem: 3500\n",
            "Epoch: [14]  [150/295]  eta: 0:00:40  lr: 0.002903  min_lr: 0.002903  loss: 2.8319 (2.8255)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0025  max mem: 3500\n",
            "Epoch: [14]  [160/295]  eta: 0:00:37  lr: 0.002912  min_lr: 0.002912  loss: 2.8343 (2.8267)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0021  max mem: 3500\n",
            "Epoch: [14]  [170/295]  eta: 0:00:34  lr: 0.002917  min_lr: 0.002917  loss: 2.8084 (2.8246)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0039  max mem: 3500\n",
            "Epoch: [14]  [180/295]  eta: 0:00:31  lr: 0.002925  min_lr: 0.002925  loss: 2.8044 (2.8272)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0055  max mem: 3500\n",
            "Epoch: [14]  [190/295]  eta: 0:00:28  lr: 0.002931  min_lr: 0.002931  loss: 2.8187 (2.8262)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0036  max mem: 3500\n",
            "Epoch: [14]  [200/295]  eta: 0:00:26  lr: 0.002939  min_lr: 0.002939  loss: 2.8187 (2.8267)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0014  max mem: 3500\n",
            "Epoch: [14]  [210/295]  eta: 0:00:23  lr: 0.002944  min_lr: 0.002944  loss: 2.8432 (2.8277)  weight_decay: 0.0500 (0.0500)  time: 0.2573  data: 0.0012  max mem: 3500\n",
            "Epoch: [14]  [220/295]  eta: 0:00:20  lr: 0.002953  min_lr: 0.002953  loss: 2.8538 (2.8288)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0022  max mem: 3500\n",
            "Epoch: [14]  [230/295]  eta: 0:00:17  lr: 0.002958  min_lr: 0.002958  loss: 2.8538 (2.8279)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0035  max mem: 3500\n",
            "Epoch: [14]  [240/295]  eta: 0:00:14  lr: 0.002966  min_lr: 0.002966  loss: 2.7991 (2.8282)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0051  max mem: 3500\n",
            "Epoch: [14]  [250/295]  eta: 0:00:12  lr: 0.002972  min_lr: 0.002972  loss: 2.7739 (2.8263)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0035  max mem: 3500\n",
            "Epoch: [14]  [260/295]  eta: 0:00:09  lr: 0.002980  min_lr: 0.002980  loss: 2.7901 (2.8267)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0005  max mem: 3500\n",
            "Epoch: [14]  [270/295]  eta: 0:00:06  lr: 0.002986  min_lr: 0.002986  loss: 2.7780 (2.8242)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0006  max mem: 3500\n",
            "Epoch: [14]  [280/295]  eta: 0:00:04  lr: 0.002994  min_lr: 0.002994  loss: 2.7780 (2.8238)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0010  max mem: 3500\n",
            "Epoch: [14]  [290/295]  eta: 0:00:01  lr: 0.002999  min_lr: 0.002999  loss: 2.8186 (2.8240)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0006  max mem: 3500\n",
            "Epoch: [14]  [294/295]  eta: 0:00:00  lr: 0.002999  min_lr: 0.002999  loss: 2.8186 (2.8238)  weight_decay: 0.0500 (0.0500)  time: 0.2198  data: 0.0001  max mem: 3500\n",
            "Epoch: [14] Total time: 0:01:19 (0.2693 s / it)\n",
            "Averaged stats: lr: 0.002999  min_lr: 0.002999  loss: 2.8186 (2.8238)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:25  loss: 1.2369 (1.2369)  acc1: 79.1667 (79.1667)  acc5: 91.6667 (91.6667)  time: 3.2420  data: 3.0803  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 1.3776 (1.4003)  acc1: 68.7500 (67.8030)  acc5: 95.8333 (93.9394)  time: 0.4035  data: 0.2829  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 1.4065 (1.4479)  acc1: 64.5833 (64.8810)  acc5: 93.7500 (92.2619)  time: 0.1244  data: 0.0086  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 1.5804 (1.6689)  acc1: 56.2500 (50.0000)  acc5: 87.5000 (90.2554)  time: 0.1258  data: 0.0089  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.5187 (1.5950)  acc1: 50.0000 (52.4898)  acc5: 89.5833 (91.7175)  time: 0.1221  data: 0.0036  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.7051 (1.6806)  acc1: 37.5000 (45.8742)  acc5: 93.7500 (91.0131)  time: 0.1231  data: 0.0052  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.7051 (1.6613)  acc1: 43.7500 (47.3361)  acc5: 89.5833 (90.8470)  time: 0.1231  data: 0.0055  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.6896 (1.6729)  acc1: 45.8333 (46.5669)  acc5: 89.5833 (90.6397)  time: 0.1201  data: 0.0021  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.6896 (1.6002)  acc1: 47.9167 (49.7171)  acc5: 91.6667 (91.1265)  time: 0.1180  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.5292 (1.5932)  acc1: 47.9167 (50.0127)  acc5: 91.6667 (91.1083)  time: 0.1164  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1642 s / it)\n",
            "* Acc@1 50.013 Acc@5 91.108 loss 1.593\n",
            "Accuracy of the model on the 3925 test images: 50.0%\n",
            "Max accuracy: 50.01%\n",
            "Test:  [ 0/82]  eta: 0:04:10  loss: 6.4297 (6.4297)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.0530  data: 2.8376  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 6.3898 (6.3721)  acc1: 0.0000 (6.8182)  acc5: 4.1667 (14.2045)  time: 0.4094  data: 0.2593  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 6.3278 (6.2729)  acc1: 14.5833 (11.5079)  acc5: 31.2500 (25.7937)  time: 0.1482  data: 0.0159  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 6.4106 (6.3874)  acc1: 14.5833 (9.4758)  acc5: 29.1667 (21.7070)  time: 0.1384  data: 0.0165  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.4514 (6.3811)  acc1: 2.0833 (8.2317)  acc5: 16.6667 (21.4431)  time: 0.1242  data: 0.0021  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 6.3044 (6.3294)  acc1: 6.2500 (8.5376)  acc5: 20.8333 (23.5294)  time: 0.1236  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 6.1400 (6.2676)  acc1: 8.3333 (8.5383)  acc5: 22.9167 (26.0929)  time: 0.1242  data: 0.0042  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 6.2531 (6.2801)  acc1: 4.1667 (8.0692)  acc5: 25.0000 (25.5282)  time: 0.1214  data: 0.0021  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.1712 (6.1431)  acc1: 10.4167 (11.9342)  acc5: 33.3333 (30.4784)  time: 0.1189  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 6.0582 (6.1292)  acc1: 12.5000 (12.3057)  acc5: 33.3333 (30.9045)  time: 0.1175  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1686 s / it)\n",
            "* Acc@1 12.306 Acc@5 30.904 loss 6.129\n",
            "Accuracy of the model EMA on 3925 test images: 12.3%\n",
            "Max EMA accuracy: 12.31%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [15]  [  0/295]  eta: 0:12:49  lr: 0.003002  min_lr: 0.003002  loss: 3.0348 (3.0348)  weight_decay: 0.0500 (0.0500)  time: 2.6085  data: 2.1219  max mem: 3500\n",
            "Epoch: [15]  [ 10/295]  eta: 0:02:29  lr: 0.003008  min_lr: 0.003008  loss: 2.9113 (2.8639)  weight_decay: 0.0500 (0.0500)  time: 0.5243  data: 0.1986  max mem: 3500\n",
            "Epoch: [15]  [ 20/295]  eta: 0:01:50  lr: 0.003016  min_lr: 0.003016  loss: 2.8602 (2.8653)  weight_decay: 0.0500 (0.0500)  time: 0.2926  data: 0.0039  max mem: 3500\n",
            "Epoch: [15]  [ 30/295]  eta: 0:01:34  lr: 0.003021  min_lr: 0.003021  loss: 2.8602 (2.8700)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0017  max mem: 3500\n",
            "Epoch: [15]  [ 40/295]  eta: 0:01:25  lr: 0.003029  min_lr: 0.003029  loss: 2.8767 (2.8742)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0014  max mem: 3500\n",
            "Epoch: [15]  [ 50/295]  eta: 0:01:18  lr: 0.003035  min_lr: 0.003035  loss: 2.8558 (2.8581)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0020  max mem: 3500\n",
            "Epoch: [15]  [ 60/295]  eta: 0:01:13  lr: 0.003043  min_lr: 0.003043  loss: 2.8430 (2.8596)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0024  max mem: 3500\n",
            "Epoch: [15]  [ 70/295]  eta: 0:01:08  lr: 0.003049  min_lr: 0.003049  loss: 2.8091 (2.8483)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0021  max mem: 3500\n",
            "Epoch: [15]  [ 80/295]  eta: 0:01:04  lr: 0.003057  min_lr: 0.003057  loss: 2.7599 (2.8399)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0030  max mem: 3500\n",
            "Epoch: [15]  [ 90/295]  eta: 0:01:01  lr: 0.003062  min_lr: 0.003062  loss: 2.7599 (2.8391)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0024  max mem: 3500\n",
            "Epoch: [15]  [100/295]  eta: 0:00:57  lr: 0.003071  min_lr: 0.003071  loss: 2.7692 (2.8351)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0015  max mem: 3500\n",
            "Epoch: [15]  [110/295]  eta: 0:00:53  lr: 0.003076  min_lr: 0.003076  loss: 2.8308 (2.8359)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0017  max mem: 3500\n",
            "Epoch: [15]  [120/295]  eta: 0:00:50  lr: 0.003084  min_lr: 0.003084  loss: 2.8454 (2.8370)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0010  max mem: 3500\n",
            "Epoch: [15]  [130/295]  eta: 0:00:47  lr: 0.003090  min_lr: 0.003090  loss: 2.8186 (2.8363)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0013  max mem: 3500\n",
            "Epoch: [15]  [140/295]  eta: 0:00:44  lr: 0.003098  min_lr: 0.003098  loss: 2.8186 (2.8352)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0032  max mem: 3500\n",
            "Epoch: [15]  [150/295]  eta: 0:00:41  lr: 0.003103  min_lr: 0.003103  loss: 2.8385 (2.8364)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0049  max mem: 3500\n",
            "Epoch: [15]  [160/295]  eta: 0:00:38  lr: 0.003112  min_lr: 0.003112  loss: 2.8209 (2.8365)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0037  max mem: 3500\n",
            "Epoch: [15]  [170/295]  eta: 0:00:35  lr: 0.003117  min_lr: 0.003117  loss: 2.8210 (2.8385)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0022  max mem: 3500\n",
            "Epoch: [15]  [180/295]  eta: 0:00:32  lr: 0.003125  min_lr: 0.003125  loss: 2.8301 (2.8385)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0024  max mem: 3500\n",
            "Epoch: [15]  [190/295]  eta: 0:00:29  lr: 0.003131  min_lr: 0.003131  loss: 2.8356 (2.8380)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0023  max mem: 3500\n",
            "Epoch: [15]  [200/295]  eta: 0:00:26  lr: 0.003139  min_lr: 0.003139  loss: 2.8317 (2.8332)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0045  max mem: 3500\n",
            "Epoch: [15]  [210/295]  eta: 0:00:23  lr: 0.003145  min_lr: 0.003145  loss: 2.8477 (2.8350)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0059  max mem: 3500\n",
            "Epoch: [15]  [220/295]  eta: 0:00:20  lr: 0.003153  min_lr: 0.003153  loss: 2.8866 (2.8323)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0038  max mem: 3500\n",
            "Epoch: [15]  [230/295]  eta: 0:00:18  lr: 0.003158  min_lr: 0.003158  loss: 2.8029 (2.8324)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0016  max mem: 3500\n",
            "Epoch: [15]  [240/295]  eta: 0:00:15  lr: 0.003167  min_lr: 0.003167  loss: 2.8047 (2.8306)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0012  max mem: 3500\n",
            "Epoch: [15]  [250/295]  eta: 0:00:12  lr: 0.003172  min_lr: 0.003172  loss: 2.6796 (2.8261)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0027  max mem: 3500\n",
            "Epoch: [15]  [260/295]  eta: 0:00:09  lr: 0.003180  min_lr: 0.003180  loss: 2.6986 (2.8263)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0034  max mem: 3500\n",
            "Epoch: [15]  [270/295]  eta: 0:00:06  lr: 0.003186  min_lr: 0.003186  loss: 2.8285 (2.8238)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0023  max mem: 3500\n",
            "Epoch: [15]  [280/295]  eta: 0:00:04  lr: 0.003194  min_lr: 0.003194  loss: 2.7436 (2.8210)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0012  max mem: 3500\n",
            "Epoch: [15]  [290/295]  eta: 0:00:01  lr: 0.003199  min_lr: 0.003199  loss: 2.7321 (2.8205)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0006  max mem: 3500\n",
            "Epoch: [15]  [294/295]  eta: 0:00:00  lr: 0.003199  min_lr: 0.003199  loss: 2.7488 (2.8208)  weight_decay: 0.0500 (0.0500)  time: 0.2201  data: 0.0002  max mem: 3500\n",
            "Epoch: [15] Total time: 0:01:20 (0.2732 s / it)\n",
            "Averaged stats: lr: 0.003199  min_lr: 0.003199  loss: 2.7488 (2.8208)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:49  loss: 1.1926 (1.1926)  acc1: 75.0000 (75.0000)  acc5: 91.6667 (91.6667)  time: 2.0640  data: 1.8970  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 1.4894 (1.4487)  acc1: 60.4167 (63.6364)  acc5: 91.6667 (91.2879)  time: 0.2994  data: 0.1747  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.4894 (1.4015)  acc1: 60.4167 (64.1865)  acc5: 93.7500 (93.0556)  time: 0.1229  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.6036 (1.6452)  acc1: 54.1667 (50.0000)  acc5: 91.6667 (89.0457)  time: 0.1217  data: 0.0038  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.4515 (1.5986)  acc1: 54.1667 (51.2195)  acc5: 93.7500 (90.3963)  time: 0.1220  data: 0.0051  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.4476 (1.5724)  acc1: 62.5000 (53.6356)  acc5: 95.8333 (91.6258)  time: 0.1255  data: 0.0057  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.4669 (1.5515)  acc1: 62.5000 (54.4740)  acc5: 95.8333 (91.7008)  time: 0.1359  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.8554 (1.6099)  acc1: 37.5000 (51.2324)  acc5: 87.5000 (90.9038)  time: 0.1352  data: 0.0002  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.8580 (1.5647)  acc1: 33.3333 (53.2150)  acc5: 87.5000 (90.8693)  time: 0.1219  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8554 (1.5602)  acc1: 37.5000 (53.4013)  acc5: 87.5000 (90.8280)  time: 0.1194  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1544 s / it)\n",
            "* Acc@1 53.401 Acc@5 90.828 loss 1.560\n",
            "Accuracy of the model on the 3925 test images: 53.4%\n",
            "Max accuracy: 53.40%\n",
            "Test:  [ 0/82]  eta: 0:02:40  loss: 6.3248 (6.3248)  acc1: 0.0000 (0.0000)  acc5: 8.3333 (8.3333)  time: 1.9608  data: 1.7934  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 6.2705 (6.2589)  acc1: 0.0000 (8.3333)  acc5: 12.5000 (20.2652)  time: 0.2897  data: 0.1648  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 6.2427 (6.1620)  acc1: 14.5833 (12.6984)  acc5: 33.3333 (31.1508)  time: 0.1222  data: 0.0023  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.3336 (6.2913)  acc1: 14.5833 (10.2823)  acc5: 31.2500 (25.5376)  time: 0.1231  data: 0.0034  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 6.3924 (6.2925)  acc1: 4.1667 (8.9939)  acc5: 22.9167 (26.1179)  time: 0.1232  data: 0.0035  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 6.2093 (6.2317)  acc1: 10.4167 (9.8448)  acc5: 27.0833 (28.5131)  time: 0.1234  data: 0.0061  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 5.9915 (6.1690)  acc1: 12.5000 (9.7336)  acc5: 33.3333 (30.9426)  time: 0.1236  data: 0.0067  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.1569 (6.1833)  acc1: 4.1667 (9.3016)  acc5: 29.1667 (30.5164)  time: 0.1210  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 6.0663 (6.0286)  acc1: 16.6667 (13.7603)  acc5: 37.5000 (35.1595)  time: 0.1188  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 5.9373 (6.0129)  acc1: 16.6667 (14.1656)  acc5: 39.5833 (35.5924)  time: 0.1172  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1504 s / it)\n",
            "* Acc@1 14.166 Acc@5 35.592 loss 6.013\n",
            "Accuracy of the model EMA on 3925 test images: 14.2%\n",
            "Max EMA accuracy: 14.17%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [16]  [  0/295]  eta: 0:12:15  lr: 0.003202  min_lr: 0.003202  loss: 2.8641 (2.8641)  weight_decay: 0.0500 (0.0500)  time: 2.4940  data: 1.9300  max mem: 3500\n",
            "Epoch: [16]  [ 10/295]  eta: 0:02:22  lr: 0.003208  min_lr: 0.003208  loss: 2.8282 (2.7464)  weight_decay: 0.0500 (0.0500)  time: 0.5009  data: 0.1770  max mem: 3500\n",
            "Epoch: [16]  [ 20/295]  eta: 0:01:46  lr: 0.003216  min_lr: 0.003216  loss: 2.6456 (2.7117)  weight_decay: 0.0500 (0.0500)  time: 0.2812  data: 0.0010  max mem: 3500\n",
            "Epoch: [16]  [ 30/295]  eta: 0:01:31  lr: 0.003221  min_lr: 0.003221  loss: 2.7319 (2.7438)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0007  max mem: 3500\n",
            "Epoch: [16]  [ 40/295]  eta: 0:01:23  lr: 0.003230  min_lr: 0.003230  loss: 2.8326 (2.7522)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0010  max mem: 3500\n",
            "Epoch: [16]  [ 50/295]  eta: 0:01:17  lr: 0.003235  min_lr: 0.003235  loss: 2.7914 (2.7623)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0024  max mem: 3500\n",
            "Epoch: [16]  [ 60/295]  eta: 0:01:12  lr: 0.003243  min_lr: 0.003243  loss: 2.7914 (2.7686)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0025  max mem: 3500\n",
            "Epoch: [16]  [ 70/295]  eta: 0:01:07  lr: 0.003249  min_lr: 0.003249  loss: 2.8342 (2.7687)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0020  max mem: 3500\n",
            "Epoch: [16]  [ 80/295]  eta: 0:01:03  lr: 0.003257  min_lr: 0.003257  loss: 2.8502 (2.7833)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0026  max mem: 3500\n",
            "Epoch: [16]  [ 90/295]  eta: 0:01:00  lr: 0.003263  min_lr: 0.003263  loss: 2.8502 (2.7883)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0013  max mem: 3500\n",
            "Epoch: [16]  [100/295]  eta: 0:00:56  lr: 0.003271  min_lr: 0.003271  loss: 2.8423 (2.7942)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0012  max mem: 3500\n",
            "Epoch: [16]  [110/295]  eta: 0:00:53  lr: 0.003276  min_lr: 0.003276  loss: 2.8030 (2.7928)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0021  max mem: 3500\n",
            "Epoch: [16]  [120/295]  eta: 0:00:50  lr: 0.003284  min_lr: 0.003284  loss: 2.7532 (2.7929)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0031  max mem: 3500\n",
            "Epoch: [16]  [130/295]  eta: 0:00:47  lr: 0.003290  min_lr: 0.003290  loss: 2.8233 (2.7951)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0037  max mem: 3500\n",
            "Epoch: [16]  [140/295]  eta: 0:00:43  lr: 0.003298  min_lr: 0.003298  loss: 2.8568 (2.7985)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0027  max mem: 3500\n",
            "Epoch: [16]  [150/295]  eta: 0:00:40  lr: 0.003304  min_lr: 0.003304  loss: 2.8046 (2.7931)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0015  max mem: 3500\n",
            "Epoch: [16]  [160/295]  eta: 0:00:37  lr: 0.003312  min_lr: 0.003312  loss: 2.7908 (2.7943)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0013  max mem: 3500\n",
            "Epoch: [16]  [170/295]  eta: 0:00:34  lr: 0.003317  min_lr: 0.003317  loss: 2.7993 (2.7942)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0016  max mem: 3500\n",
            "Epoch: [16]  [180/295]  eta: 0:00:32  lr: 0.003326  min_lr: 0.003326  loss: 2.8209 (2.7955)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0017  max mem: 3500\n",
            "Epoch: [16]  [190/295]  eta: 0:00:29  lr: 0.003331  min_lr: 0.003331  loss: 2.7908 (2.7941)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0032  max mem: 3500\n",
            "Epoch: [16]  [200/295]  eta: 0:00:26  lr: 0.003339  min_lr: 0.003339  loss: 2.8088 (2.7943)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0037  max mem: 3500\n",
            "Epoch: [16]  [210/295]  eta: 0:00:23  lr: 0.003345  min_lr: 0.003345  loss: 2.8521 (2.7956)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0018  max mem: 3500\n",
            "Epoch: [16]  [220/295]  eta: 0:00:20  lr: 0.003353  min_lr: 0.003353  loss: 2.8520 (2.7975)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0012  max mem: 3500\n",
            "Epoch: [16]  [230/295]  eta: 0:00:17  lr: 0.003358  min_lr: 0.003358  loss: 2.8494 (2.7997)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0014  max mem: 3500\n",
            "Epoch: [16]  [240/295]  eta: 0:00:15  lr: 0.003367  min_lr: 0.003367  loss: 2.8494 (2.8011)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0013  max mem: 3500\n",
            "Epoch: [16]  [250/295]  eta: 0:00:12  lr: 0.003372  min_lr: 0.003372  loss: 2.8552 (2.8054)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0014  max mem: 3500\n",
            "Epoch: [16]  [260/295]  eta: 0:00:09  lr: 0.003380  min_lr: 0.003380  loss: 2.8530 (2.8046)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0028  max mem: 3500\n",
            "Epoch: [16]  [270/295]  eta: 0:00:06  lr: 0.003386  min_lr: 0.003386  loss: 2.7955 (2.8057)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0038  max mem: 3500\n",
            "Epoch: [16]  [280/295]  eta: 0:00:04  lr: 0.003394  min_lr: 0.003394  loss: 2.7955 (2.8053)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0019  max mem: 3500\n",
            "Epoch: [16]  [290/295]  eta: 0:00:01  lr: 0.003400  min_lr: 0.003400  loss: 2.8094 (2.8061)  weight_decay: 0.0500 (0.0500)  time: 0.2566  data: 0.0001  max mem: 3500\n",
            "Epoch: [16]  [294/295]  eta: 0:00:00  lr: 0.003400  min_lr: 0.003400  loss: 2.8137 (2.8063)  weight_decay: 0.0500 (0.0500)  time: 0.2184  data: 0.0001  max mem: 3500\n",
            "Epoch: [16] Total time: 0:01:19 (0.2711 s / it)\n",
            "Averaged stats: lr: 0.003400  min_lr: 0.003400  loss: 2.8137 (2.8063)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:18  loss: 1.0914 (1.0914)  acc1: 79.1667 (79.1667)  acc5: 93.7500 (93.7500)  time: 1.6920  data: 1.5239  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.3210 (1.4167)  acc1: 70.8333 (59.6591)  acc5: 95.8333 (95.0758)  time: 0.2880  data: 0.1401  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.3210 (1.4605)  acc1: 64.5833 (53.9683)  acc5: 95.8333 (94.7421)  time: 0.1440  data: 0.0014  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 1.9625 (1.6087)  acc1: 20.8333 (44.4220)  acc5: 91.6667 (92.3387)  time: 0.1663  data: 0.0343  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.6180 (1.6198)  acc1: 45.8333 (45.3252)  acc5: 87.5000 (91.6159)  time: 0.1691  data: 0.0407  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.5228 (1.5869)  acc1: 54.1667 (50.0000)  acc5: 91.6667 (92.0752)  time: 0.1506  data: 0.0125  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.5281 (1.5988)  acc1: 56.2500 (49.6926)  acc5: 91.6667 (91.3934)  time: 0.1591  data: 0.0230  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.7724 (1.6315)  acc1: 39.5833 (47.8286)  acc5: 87.5000 (90.7570)  time: 0.1447  data: 0.0203  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.7555 (1.5708)  acc1: 39.5833 (50.5144)  acc5: 91.6667 (91.3323)  time: 0.1218  data: 0.0029  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.7190 (1.5656)  acc1: 41.6667 (50.7771)  acc5: 91.6667 (91.2866)  time: 0.1203  data: 0.0028  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1723 s / it)\n",
            "* Acc@1 50.777 Acc@5 91.287 loss 1.566\n",
            "Accuracy of the model on the 3925 test images: 50.8%\n",
            "Max accuracy: 53.40%\n",
            "Test:  [ 0/82]  eta: 0:02:07  loss: 6.2123 (6.2123)  acc1: 0.0000 (0.0000)  acc5: 25.0000 (25.0000)  time: 1.5545  data: 1.4462  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:18  loss: 6.1471 (6.1396)  acc1: 2.0833 (8.9015)  acc5: 27.0833 (31.4394)  time: 0.2517  data: 0.1332  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:11  loss: 6.1175 (6.0451)  acc1: 14.5833 (13.3929)  acc5: 39.5833 (38.6905)  time: 0.1216  data: 0.0029  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:08  loss: 6.2465 (6.1894)  acc1: 14.5833 (10.6855)  acc5: 33.3333 (31.3172)  time: 0.1229  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 6.3341 (6.1992)  acc1: 4.1667 (9.5528)  acc5: 27.0833 (31.9106)  time: 0.1245  data: 0.0033  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 6.0596 (6.1278)  acc1: 12.5000 (11.1520)  acc5: 35.4167 (35.0490)  time: 0.1281  data: 0.0035  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 5.8264 (6.0648)  acc1: 12.5000 (10.9290)  acc5: 45.8333 (37.1585)  time: 0.1317  data: 0.0012  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.0953 (6.0807)  acc1: 8.3333 (10.8568)  acc5: 33.3333 (36.3850)  time: 0.1348  data: 0.0019  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 5.9463 (5.9085)  acc1: 18.7500 (15.4321)  acc5: 41.6667 (40.6893)  time: 0.1280  data: 0.0018  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 5.8042 (5.8910)  acc1: 20.8333 (15.8471)  acc5: 41.6667 (41.0955)  time: 0.1248  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1496 s / it)\n",
            "* Acc@1 15.847 Acc@5 41.096 loss 5.891\n",
            "Accuracy of the model EMA on 3925 test images: 15.8%\n",
            "Max EMA accuracy: 15.85%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [17]  [  0/295]  eta: 0:09:37  lr: 0.003402  min_lr: 0.003402  loss: 2.9470 (2.9470)  weight_decay: 0.0500 (0.0500)  time: 1.9563  data: 1.5791  max mem: 3500\n",
            "Epoch: [17]  [ 10/295]  eta: 0:01:59  lr: 0.003408  min_lr: 0.003408  loss: 2.8304 (2.8076)  weight_decay: 0.0500 (0.0500)  time: 0.4200  data: 0.1460  max mem: 3500\n",
            "Epoch: [17]  [ 20/295]  eta: 0:01:34  lr: 0.003416  min_lr: 0.003416  loss: 2.7093 (2.7799)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0019  max mem: 3500\n",
            "Epoch: [17]  [ 30/295]  eta: 0:01:24  lr: 0.003422  min_lr: 0.003422  loss: 2.7930 (2.8011)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0016  max mem: 3500\n",
            "Epoch: [17]  [ 40/295]  eta: 0:01:18  lr: 0.003430  min_lr: 0.003430  loss: 2.8099 (2.7905)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0037  max mem: 3500\n",
            "Epoch: [17]  [ 50/295]  eta: 0:01:13  lr: 0.003435  min_lr: 0.003435  loss: 2.7620 (2.7853)  weight_decay: 0.0500 (0.0500)  time: 0.2763  data: 0.0044  max mem: 3500\n",
            "Epoch: [17]  [ 60/295]  eta: 0:01:09  lr: 0.003443  min_lr: 0.003443  loss: 2.8076 (2.7923)  weight_decay: 0.0500 (0.0500)  time: 0.2759  data: 0.0040  max mem: 3500\n",
            "Epoch: [17]  [ 70/295]  eta: 0:01:06  lr: 0.003449  min_lr: 0.003449  loss: 2.8432 (2.7960)  weight_decay: 0.0500 (0.0500)  time: 0.2765  data: 0.0045  max mem: 3500\n",
            "Epoch: [17]  [ 80/295]  eta: 0:01:02  lr: 0.003457  min_lr: 0.003457  loss: 2.8104 (2.7982)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0037  max mem: 3500\n",
            "Epoch: [17]  [ 90/295]  eta: 0:00:59  lr: 0.003463  min_lr: 0.003463  loss: 2.8494 (2.8085)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0019  max mem: 3500\n",
            "Epoch: [17]  [100/295]  eta: 0:00:55  lr: 0.003471  min_lr: 0.003471  loss: 2.8513 (2.8118)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0010  max mem: 3500\n",
            "Epoch: [17]  [110/295]  eta: 0:00:52  lr: 0.003476  min_lr: 0.003476  loss: 2.7854 (2.8062)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0013  max mem: 3500\n",
            "Epoch: [17]  [120/295]  eta: 0:00:49  lr: 0.003485  min_lr: 0.003485  loss: 2.7413 (2.7936)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0017  max mem: 3500\n",
            "Epoch: [17]  [130/295]  eta: 0:00:46  lr: 0.003490  min_lr: 0.003490  loss: 2.6789 (2.7919)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0030  max mem: 3500\n",
            "Epoch: [17]  [140/295]  eta: 0:00:43  lr: 0.003498  min_lr: 0.003498  loss: 2.7738 (2.7939)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0029  max mem: 3500\n",
            "Epoch: [17]  [150/295]  eta: 0:00:40  lr: 0.003504  min_lr: 0.003504  loss: 2.7901 (2.7975)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0019  max mem: 3500\n",
            "Epoch: [17]  [160/295]  eta: 0:00:37  lr: 0.003512  min_lr: 0.003512  loss: 2.7764 (2.7970)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0031  max mem: 3500\n",
            "Epoch: [17]  [170/295]  eta: 0:00:34  lr: 0.003517  min_lr: 0.003517  loss: 2.8595 (2.8034)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0041  max mem: 3500\n",
            "Epoch: [17]  [180/295]  eta: 0:00:31  lr: 0.003526  min_lr: 0.003526  loss: 2.8517 (2.8003)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0029  max mem: 3500\n",
            "Epoch: [17]  [190/295]  eta: 0:00:28  lr: 0.003531  min_lr: 0.003531  loss: 2.7393 (2.7973)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0027  max mem: 3500\n",
            "Epoch: [17]  [200/295]  eta: 0:00:26  lr: 0.003539  min_lr: 0.003539  loss: 2.7544 (2.7951)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0038  max mem: 3500\n",
            "Epoch: [17]  [210/295]  eta: 0:00:23  lr: 0.003545  min_lr: 0.003545  loss: 2.7870 (2.7940)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0036  max mem: 3500\n",
            "Epoch: [17]  [220/295]  eta: 0:00:20  lr: 0.003553  min_lr: 0.003553  loss: 2.7829 (2.7961)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0021  max mem: 3500\n",
            "Epoch: [17]  [230/295]  eta: 0:00:17  lr: 0.003559  min_lr: 0.003559  loss: 2.7829 (2.7962)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0011  max mem: 3500\n",
            "Epoch: [17]  [240/295]  eta: 0:00:14  lr: 0.003567  min_lr: 0.003567  loss: 2.7563 (2.7948)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0015  max mem: 3500\n",
            "Epoch: [17]  [250/295]  eta: 0:00:12  lr: 0.003572  min_lr: 0.003572  loss: 2.8133 (2.7960)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0022  max mem: 3500\n",
            "Epoch: [17]  [260/295]  eta: 0:00:09  lr: 0.003581  min_lr: 0.003581  loss: 2.8186 (2.8003)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0030  max mem: 3500\n",
            "Epoch: [17]  [270/295]  eta: 0:00:06  lr: 0.003586  min_lr: 0.003586  loss: 2.8114 (2.7985)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0038  max mem: 3500\n",
            "Epoch: [17]  [280/295]  eta: 0:00:04  lr: 0.003594  min_lr: 0.003594  loss: 2.7729 (2.7991)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0027  max mem: 3500\n",
            "Epoch: [17]  [290/295]  eta: 0:00:01  lr: 0.003600  min_lr: 0.003600  loss: 2.8400 (2.8017)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0005  max mem: 3500\n",
            "Epoch: [17]  [294/295]  eta: 0:00:00  lr: 0.003600  min_lr: 0.003600  loss: 2.8290 (2.8013)  weight_decay: 0.0500 (0.0500)  time: 0.2188  data: 0.0001  max mem: 3500\n",
            "Epoch: [17] Total time: 0:01:19 (0.2693 s / it)\n",
            "Averaged stats: lr: 0.003600  min_lr: 0.003600  loss: 2.8290 (2.8013)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:34  loss: 1.4033 (1.4033)  acc1: 72.9167 (72.9167)  acc5: 89.5833 (89.5833)  time: 1.8864  data: 1.7099  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.6767 (1.6301)  acc1: 54.1667 (54.9242)  acc5: 89.5833 (88.6364)  time: 0.2848  data: 0.1578  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.6375 (1.5947)  acc1: 54.1667 (54.6627)  acc5: 91.6667 (91.4683)  time: 0.1270  data: 0.0025  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 1.7350 (1.6516)  acc1: 41.6667 (48.9247)  acc5: 95.8333 (92.6075)  time: 0.1417  data: 0.0034  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.8098 (1.6756)  acc1: 39.5833 (47.2561)  acc5: 91.6667 (91.7175)  time: 0.1425  data: 0.0023  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.6554 (1.6411)  acc1: 50.0000 (51.0621)  acc5: 91.6667 (92.2794)  time: 0.1347  data: 0.0010  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.3510 (1.5824)  acc1: 70.8333 (54.1325)  acc5: 93.7500 (92.5205)  time: 0.1420  data: 0.0029  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.3771 (1.5743)  acc1: 62.5000 (54.7829)  acc5: 93.7500 (92.6643)  time: 0.1558  data: 0.0120  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3492 (1.5126)  acc1: 62.5000 (56.9187)  acc5: 93.7500 (92.6698)  time: 0.1426  data: 0.0101  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3161 (1.5080)  acc1: 64.5833 (57.0701)  acc5: 93.7500 (92.6115)  time: 0.1391  data: 0.0100  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1639 s / it)\n",
            "* Acc@1 57.070 Acc@5 92.611 loss 1.508\n",
            "Accuracy of the model on the 3925 test images: 57.1%\n",
            "Max accuracy: 57.07%\n",
            "Test:  [ 0/82]  eta: 0:02:30  loss: 6.0922 (6.0922)  acc1: 0.0000 (0.0000)  acc5: 41.6667 (41.6667)  time: 1.8349  data: 1.6565  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 6.0120 (6.0115)  acc1: 2.0833 (9.4697)  acc5: 39.5833 (40.3409)  time: 0.2774  data: 0.1532  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 6.0076 (5.9213)  acc1: 16.6667 (14.0873)  acc5: 43.7500 (44.9405)  time: 0.1205  data: 0.0031  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 6.1505 (6.0816)  acc1: 16.6667 (11.0215)  acc5: 41.6667 (36.1559)  time: 0.1221  data: 0.0033  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 6.2820 (6.1028)  acc1: 4.1667 (9.7053)  acc5: 29.1667 (36.0772)  time: 0.1230  data: 0.0030  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 5.9790 (6.0202)  acc1: 10.4167 (11.8873)  acc5: 43.7500 (39.7059)  time: 0.1231  data: 0.0041  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 5.6547 (5.9580)  acc1: 14.5833 (11.6803)  acc5: 52.0833 (41.5984)  time: 0.1280  data: 0.0037  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 6.0372 (5.9754)  acc1: 8.3333 (11.7664)  acc5: 39.5833 (40.8157)  time: 0.1304  data: 0.0009  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 5.8130 (5.7843)  acc1: 20.8333 (16.6152)  acc5: 45.8333 (44.9331)  time: 0.1236  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 5.6625 (5.7649)  acc1: 25.0000 (17.0446)  acc5: 47.9167 (45.2994)  time: 0.1210  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1513 s / it)\n",
            "* Acc@1 17.045 Acc@5 45.299 loss 5.765\n",
            "Accuracy of the model EMA on 3925 test images: 17.0%\n",
            "Max EMA accuracy: 17.04%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [18]  [  0/295]  eta: 0:09:26  lr: 0.003602  min_lr: 0.003602  loss: 2.8311 (2.8311)  weight_decay: 0.0500 (0.0500)  time: 1.9190  data: 1.5486  max mem: 3500\n",
            "Epoch: [18]  [ 10/295]  eta: 0:01:59  lr: 0.003608  min_lr: 0.003608  loss: 2.7203 (2.7588)  weight_decay: 0.0500 (0.0500)  time: 0.4190  data: 0.1414  max mem: 3500\n",
            "Epoch: [18]  [ 20/295]  eta: 0:01:34  lr: 0.003616  min_lr: 0.003616  loss: 2.7469 (2.7521)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0013  max mem: 3500\n",
            "Epoch: [18]  [ 30/295]  eta: 0:01:24  lr: 0.003622  min_lr: 0.003622  loss: 2.7699 (2.7594)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0012  max mem: 3500\n",
            "Epoch: [18]  [ 40/295]  eta: 0:01:18  lr: 0.003630  min_lr: 0.003630  loss: 2.7408 (2.7644)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0004  max mem: 3500\n",
            "Epoch: [18]  [ 50/295]  eta: 0:01:13  lr: 0.003635  min_lr: 0.003635  loss: 2.7408 (2.7701)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0006  max mem: 3500\n",
            "Epoch: [18]  [ 60/295]  eta: 0:01:09  lr: 0.003644  min_lr: 0.003644  loss: 2.7667 (2.7728)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0012  max mem: 3500\n",
            "Epoch: [18]  [ 70/295]  eta: 0:01:05  lr: 0.003649  min_lr: 0.003649  loss: 2.7734 (2.7728)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0014  max mem: 3500\n",
            "Epoch: [18]  [ 80/295]  eta: 0:01:01  lr: 0.003657  min_lr: 0.003657  loss: 2.7863 (2.7776)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0010  max mem: 3500\n",
            "Epoch: [18]  [ 90/295]  eta: 0:00:58  lr: 0.003663  min_lr: 0.003663  loss: 2.8229 (2.7778)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0016  max mem: 3500\n",
            "Epoch: [18]  [100/295]  eta: 0:00:55  lr: 0.003671  min_lr: 0.003671  loss: 2.7893 (2.7802)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0015  max mem: 3500\n",
            "Epoch: [18]  [110/295]  eta: 0:00:52  lr: 0.003676  min_lr: 0.003676  loss: 2.7789 (2.7804)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0027  max mem: 3500\n",
            "Epoch: [18]  [120/295]  eta: 0:00:49  lr: 0.003685  min_lr: 0.003685  loss: 2.7966 (2.7875)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0046  max mem: 3500\n",
            "Epoch: [18]  [130/295]  eta: 0:00:46  lr: 0.003690  min_lr: 0.003690  loss: 2.7966 (2.7851)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0038  max mem: 3500\n",
            "Epoch: [18]  [140/295]  eta: 0:00:43  lr: 0.003698  min_lr: 0.003698  loss: 2.8237 (2.7858)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0026  max mem: 3500\n",
            "Epoch: [18]  [150/295]  eta: 0:00:40  lr: 0.003704  min_lr: 0.003704  loss: 2.8529 (2.7857)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0017  max mem: 3500\n",
            "Epoch: [18]  [160/295]  eta: 0:00:37  lr: 0.003712  min_lr: 0.003712  loss: 2.7966 (2.7862)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0017  max mem: 3500\n",
            "Epoch: [18]  [170/295]  eta: 0:00:34  lr: 0.003718  min_lr: 0.003718  loss: 2.7966 (2.7868)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0027  max mem: 3500\n",
            "Epoch: [18]  [180/295]  eta: 0:00:31  lr: 0.003726  min_lr: 0.003726  loss: 2.7617 (2.7821)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0057  max mem: 3500\n",
            "Epoch: [18]  [190/295]  eta: 0:00:28  lr: 0.003731  min_lr: 0.003731  loss: 2.7514 (2.7820)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0048  max mem: 3500\n",
            "Epoch: [18]  [200/295]  eta: 0:00:26  lr: 0.003740  min_lr: 0.003740  loss: 2.7514 (2.7810)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0020  max mem: 3500\n",
            "Epoch: [18]  [210/295]  eta: 0:00:23  lr: 0.003745  min_lr: 0.003745  loss: 2.7586 (2.7820)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0016  max mem: 3500\n",
            "Epoch: [18]  [220/295]  eta: 0:00:20  lr: 0.003753  min_lr: 0.003753  loss: 2.7586 (2.7833)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0014  max mem: 3500\n",
            "Epoch: [18]  [230/295]  eta: 0:00:17  lr: 0.003759  min_lr: 0.003759  loss: 2.7701 (2.7829)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0036  max mem: 3500\n",
            "Epoch: [18]  [240/295]  eta: 0:00:15  lr: 0.003767  min_lr: 0.003767  loss: 2.7947 (2.7846)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0064  max mem: 3500\n",
            "Epoch: [18]  [250/295]  eta: 0:00:12  lr: 0.003772  min_lr: 0.003772  loss: 2.7974 (2.7858)  weight_decay: 0.0500 (0.0500)  time: 0.2767  data: 0.0058  max mem: 3500\n",
            "Epoch: [18]  [260/295]  eta: 0:00:09  lr: 0.003781  min_lr: 0.003781  loss: 2.7936 (2.7867)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0046  max mem: 3500\n",
            "Epoch: [18]  [270/295]  eta: 0:00:06  lr: 0.003786  min_lr: 0.003786  loss: 2.7685 (2.7836)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0046  max mem: 3500\n",
            "Epoch: [18]  [280/295]  eta: 0:00:04  lr: 0.003794  min_lr: 0.003794  loss: 2.7134 (2.7833)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0022  max mem: 3500\n",
            "Epoch: [18]  [290/295]  eta: 0:00:01  lr: 0.003800  min_lr: 0.003800  loss: 2.7964 (2.7871)  weight_decay: 0.0500 (0.0500)  time: 0.2564  data: 0.0002  max mem: 3500\n",
            "Epoch: [18]  [294/295]  eta: 0:00:00  lr: 0.003800  min_lr: 0.003800  loss: 2.7964 (2.7871)  weight_decay: 0.0500 (0.0500)  time: 0.2182  data: 0.0001  max mem: 3500\n",
            "Epoch: [18] Total time: 0:01:19 (0.2701 s / it)\n",
            "Averaged stats: lr: 0.003800  min_lr: 0.003800  loss: 2.7964 (2.7871)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:23  loss: 0.9821 (0.9821)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 1.7496  data: 1.5452  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.1346 (1.3158)  acc1: 72.9167 (67.6136)  acc5: 93.7500 (92.6136)  time: 0.2828  data: 0.1421  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.2540 (1.4306)  acc1: 66.6667 (61.2103)  acc5: 91.6667 (91.6667)  time: 0.1408  data: 0.0018  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 1.7769 (1.6366)  acc1: 41.6667 (49.3952)  acc5: 89.5833 (88.8441)  time: 0.1577  data: 0.0179  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.4522 (1.5995)  acc1: 58.3333 (51.5244)  acc5: 91.6667 (90.2947)  time: 0.1714  data: 0.0337  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.4522 (1.5837)  acc1: 60.4167 (52.6961)  acc5: 95.8333 (91.1765)  time: 0.1665  data: 0.0338  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.4754 (1.5624)  acc1: 58.3333 (53.5519)  acc5: 95.8333 (91.6325)  time: 0.1637  data: 0.0300  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.4871 (1.5561)  acc1: 58.3333 (53.7852)  acc5: 95.8333 (91.9308)  time: 0.1466  data: 0.0162  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3777 (1.5148)  acc1: 58.3333 (55.8899)  acc5: 95.8333 (92.3611)  time: 0.1218  data: 0.0035  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3425 (1.5127)  acc1: 60.4167 (56.0000)  acc5: 95.8333 (92.3057)  time: 0.1176  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1726 s / it)\n",
            "* Acc@1 56.000 Acc@5 92.306 loss 1.513\n",
            "Accuracy of the model on the 3925 test images: 56.0%\n",
            "Max accuracy: 57.07%\n",
            "Test:  [ 0/82]  eta: 0:02:12  loss: 5.9652 (5.9652)  acc1: 2.0833 (2.0833)  acc5: 43.7500 (43.7500)  time: 1.6145  data: 1.5026  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 5.8691 (5.8747)  acc1: 4.1667 (9.8485)  acc5: 50.0000 (49.2424)  time: 0.2660  data: 0.1439  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 5.8564 (5.7885)  acc1: 16.6667 (14.2857)  acc5: 50.0000 (50.8929)  time: 0.1260  data: 0.0049  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:08  loss: 6.0465 (5.9662)  acc1: 14.5833 (11.1559)  acc5: 43.7500 (40.2554)  time: 0.1207  data: 0.0024  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 6.2286 (5.9999)  acc1: 2.0833 (9.8069)  acc5: 31.2500 (39.7866)  time: 0.1210  data: 0.0029  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 5.8301 (5.9078)  acc1: 10.4167 (12.5409)  acc5: 47.9167 (43.4641)  time: 0.1231  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 5.5229 (5.8486)  acc1: 16.6667 (12.2951)  acc5: 56.2500 (45.2186)  time: 0.1312  data: 0.0067  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 5.9422 (5.8674)  acc1: 12.5000 (12.3826)  acc5: 41.6667 (44.3955)  time: 0.1335  data: 0.0036  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 5.6670 (5.6578)  acc1: 20.8333 (17.5926)  acc5: 47.9167 (48.3025)  time: 0.1238  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 5.5129 (5.6366)  acc1: 27.0833 (18.0127)  acc5: 52.0833 (48.6369)  time: 0.1223  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1499 s / it)\n",
            "* Acc@1 18.013 Acc@5 48.637 loss 5.637\n",
            "Accuracy of the model EMA on 3925 test images: 18.0%\n",
            "Max EMA accuracy: 18.01%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [19]  [  0/295]  eta: 0:09:08  lr: 0.003803  min_lr: 0.003803  loss: 2.6915 (2.6915)  weight_decay: 0.0500 (0.0500)  time: 1.8589  data: 1.5200  max mem: 3500\n",
            "Epoch: [19]  [ 10/295]  eta: 0:01:58  lr: 0.003808  min_lr: 0.003808  loss: 2.7907 (2.7716)  weight_decay: 0.0500 (0.0500)  time: 0.4148  data: 0.1399  max mem: 3500\n",
            "Epoch: [19]  [ 20/295]  eta: 0:01:34  lr: 0.003816  min_lr: 0.003816  loss: 2.8049 (2.7929)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0012  max mem: 3500\n",
            "Epoch: [19]  [ 30/295]  eta: 0:01:24  lr: 0.003822  min_lr: 0.003822  loss: 2.8234 (2.7991)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0014  max mem: 3500\n",
            "Epoch: [19]  [ 40/295]  eta: 0:01:18  lr: 0.003830  min_lr: 0.003830  loss: 2.8234 (2.7974)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0018  max mem: 3500\n",
            "Epoch: [19]  [ 50/295]  eta: 0:01:13  lr: 0.003836  min_lr: 0.003836  loss: 2.8194 (2.7995)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0020  max mem: 3500\n",
            "Epoch: [19]  [ 60/295]  eta: 0:01:09  lr: 0.003844  min_lr: 0.003844  loss: 2.8261 (2.7945)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0035  max mem: 3500\n",
            "Epoch: [19]  [ 70/295]  eta: 0:01:05  lr: 0.003849  min_lr: 0.003849  loss: 2.8565 (2.8017)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0036  max mem: 3500\n",
            "Epoch: [19]  [ 80/295]  eta: 0:01:01  lr: 0.003857  min_lr: 0.003857  loss: 2.8221 (2.7999)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0025  max mem: 3500\n",
            "Epoch: [19]  [ 90/295]  eta: 0:00:58  lr: 0.003863  min_lr: 0.003863  loss: 2.7822 (2.7983)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0020  max mem: 3500\n",
            "Epoch: [19]  [100/295]  eta: 0:00:54  lr: 0.003871  min_lr: 0.003871  loss: 2.7527 (2.7920)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0018  max mem: 3500\n",
            "Epoch: [19]  [110/295]  eta: 0:00:51  lr: 0.003877  min_lr: 0.003877  loss: 2.7503 (2.7889)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0026  max mem: 3500\n",
            "Epoch: [19]  [120/295]  eta: 0:00:48  lr: 0.003885  min_lr: 0.003885  loss: 2.7552 (2.7858)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0033  max mem: 3500\n",
            "Epoch: [19]  [130/295]  eta: 0:00:45  lr: 0.003890  min_lr: 0.003890  loss: 2.7372 (2.7828)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0030  max mem: 3500\n",
            "Epoch: [19]  [140/295]  eta: 0:00:42  lr: 0.003899  min_lr: 0.003899  loss: 2.7781 (2.7841)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0029  max mem: 3500\n",
            "Epoch: [19]  [150/295]  eta: 0:00:39  lr: 0.003904  min_lr: 0.003904  loss: 2.7677 (2.7812)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0025  max mem: 3500\n",
            "Epoch: [19]  [160/295]  eta: 0:00:37  lr: 0.003912  min_lr: 0.003912  loss: 2.7652 (2.7828)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0017  max mem: 3500\n",
            "Epoch: [19]  [170/295]  eta: 0:00:34  lr: 0.003918  min_lr: 0.003918  loss: 2.7397 (2.7756)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0014  max mem: 3500\n",
            "Epoch: [19]  [180/295]  eta: 0:00:31  lr: 0.003926  min_lr: 0.003926  loss: 2.7397 (2.7802)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0029  max mem: 3500\n",
            "Epoch: [19]  [190/295]  eta: 0:00:28  lr: 0.003931  min_lr: 0.003931  loss: 2.7819 (2.7793)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0032  max mem: 3500\n",
            "Epoch: [19]  [200/295]  eta: 0:00:25  lr: 0.003940  min_lr: 0.003940  loss: 2.7769 (2.7776)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0030  max mem: 3500\n",
            "Epoch: [19]  [210/295]  eta: 0:00:23  lr: 0.003945  min_lr: 0.003945  loss: 2.8342 (2.7806)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0031  max mem: 3500\n",
            "Epoch: [19]  [220/295]  eta: 0:00:20  lr: 0.003953  min_lr: 0.003953  loss: 2.8564 (2.7820)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0025  max mem: 3500\n",
            "Epoch: [19]  [230/295]  eta: 0:00:17  lr: 0.003959  min_lr: 0.003959  loss: 2.8564 (2.7820)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0018  max mem: 3500\n",
            "Epoch: [19]  [240/295]  eta: 0:00:14  lr: 0.003967  min_lr: 0.003967  loss: 2.7286 (2.7800)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0029  max mem: 3500\n",
            "Epoch: [19]  [250/295]  eta: 0:00:12  lr: 0.003973  min_lr: 0.003973  loss: 2.7168 (2.7811)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0033  max mem: 3500\n",
            "Epoch: [19]  [260/295]  eta: 0:00:09  lr: 0.003981  min_lr: 0.003981  loss: 2.7679 (2.7810)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0038  max mem: 3500\n",
            "Epoch: [19]  [270/295]  eta: 0:00:06  lr: 0.003986  min_lr: 0.003986  loss: 2.8183 (2.7820)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0038  max mem: 3500\n",
            "Epoch: [19]  [280/295]  eta: 0:00:04  lr: 0.003995  min_lr: 0.003995  loss: 2.8247 (2.7824)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0018  max mem: 3500\n",
            "Epoch: [19]  [290/295]  eta: 0:00:01  lr: 0.004000  min_lr: 0.004000  loss: 2.7701 (2.7809)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0008  max mem: 3500\n",
            "Epoch: [19]  [294/295]  eta: 0:00:00  lr: 0.004000  min_lr: 0.004000  loss: 2.7701 (2.7808)  weight_decay: 0.0500 (0.0500)  time: 0.2190  data: 0.0002  max mem: 3500\n",
            "Epoch: [19] Total time: 0:01:19 (0.2680 s / it)\n",
            "Averaged stats: lr: 0.004000  min_lr: 0.004000  loss: 2.7701 (2.7808)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:07  loss: 0.8292 (0.8292)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 3.0228  data: 2.8363  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.9963 (1.1526)  acc1: 79.1667 (72.5379)  acc5: 95.8333 (96.2121)  time: 0.4318  data: 0.3000  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 1.1319 (1.3011)  acc1: 68.7500 (66.5675)  acc5: 95.8333 (94.7421)  time: 0.1582  data: 0.0248  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 1.6799 (1.5372)  acc1: 43.7500 (52.9570)  acc5: 91.6667 (92.3387)  time: 0.1435  data: 0.0086  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.8562 (1.6063)  acc1: 37.5000 (50.2033)  acc5: 85.4167 (90.8028)  time: 0.1331  data: 0.0082  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.7118 (1.6096)  acc1: 47.9167 (51.5931)  acc5: 87.5000 (90.6046)  time: 0.1236  data: 0.0031  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.5782 (1.5953)  acc1: 58.3333 (53.0055)  acc5: 89.5833 (90.4713)  time: 0.1239  data: 0.0044  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.4826 (1.5731)  acc1: 60.4167 (54.1373)  acc5: 93.7500 (90.5223)  time: 0.1206  data: 0.0029  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1285 (1.4927)  acc1: 70.8333 (56.9187)  acc5: 97.9167 (91.3323)  time: 0.1177  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1182 (1.4875)  acc1: 70.8333 (57.0701)  acc5: 97.9167 (91.2866)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1723 s / it)\n",
            "* Acc@1 57.070 Acc@5 91.287 loss 1.487\n",
            "Accuracy of the model on the 3925 test images: 57.1%\n",
            "Max accuracy: 57.07%\n",
            "Test:  [ 0/82]  eta: 0:02:23  loss: 5.8248 (5.8248)  acc1: 2.0833 (2.0833)  acc5: 47.9167 (47.9167)  time: 1.7494  data: 1.5869  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 5.7379 (5.7279)  acc1: 4.1667 (10.0379)  acc5: 54.1667 (53.9773)  time: 0.3107  data: 0.1736  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 5.7126 (5.6486)  acc1: 16.6667 (14.5833)  acc5: 54.1667 (54.9603)  time: 0.1682  data: 0.0340  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 5.9340 (5.8452)  acc1: 14.5833 (11.2231)  acc5: 45.8333 (43.1452)  time: 0.1721  data: 0.0419  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.1858 (5.8953)  acc1: 2.0833 (9.8577)  acc5: 33.3333 (42.2764)  time: 0.1718  data: 0.0402  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.6737 (5.7940)  acc1: 10.4167 (12.9085)  acc5: 52.0833 (46.0784)  time: 0.1579  data: 0.0203  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 5.3899 (5.7375)  acc1: 18.7500 (12.7049)  acc5: 60.4167 (47.6776)  time: 0.1439  data: 0.0133  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 5.7946 (5.7581)  acc1: 10.4167 (12.8521)  acc5: 43.7500 (47.0951)  time: 0.1305  data: 0.0093  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 5.5031 (5.5308)  acc1: 22.9167 (18.1070)  acc5: 52.0833 (50.8488)  time: 0.1195  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 5.3613 (5.5078)  acc1: 29.1667 (18.5478)  acc5: 54.1667 (51.1592)  time: 0.1181  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1757 s / it)\n",
            "* Acc@1 18.548 Acc@5 51.159 loss 5.508\n",
            "Accuracy of the model EMA on 3925 test images: 18.5%\n",
            "Max EMA accuracy: 18.55%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [20]  [  0/295]  eta: 0:09:38  lr: 0.004000  min_lr: 0.004000  loss: 2.6928 (2.6928)  weight_decay: 0.0500 (0.0500)  time: 1.9624  data: 1.6132  max mem: 3500\n",
            "Epoch: [20]  [ 10/295]  eta: 0:02:04  lr: 0.004000  min_lr: 0.004000  loss: 2.7432 (2.7869)  weight_decay: 0.0500 (0.0500)  time: 0.4374  data: 0.1516  max mem: 3500\n",
            "Epoch: [20]  [ 20/295]  eta: 0:01:39  lr: 0.004000  min_lr: 0.004000  loss: 2.8181 (2.7811)  weight_decay: 0.0500 (0.0500)  time: 0.2814  data: 0.0032  max mem: 3500\n",
            "Epoch: [20]  [ 30/295]  eta: 0:01:28  lr: 0.004000  min_lr: 0.004000  loss: 2.8135 (2.7575)  weight_decay: 0.0500 (0.0500)  time: 0.2765  data: 0.0017  max mem: 3500\n",
            "Epoch: [20]  [ 40/295]  eta: 0:01:21  lr: 0.004000  min_lr: 0.004000  loss: 2.7635 (2.7596)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0027  max mem: 3500\n",
            "Epoch: [20]  [ 50/295]  eta: 0:01:15  lr: 0.004000  min_lr: 0.004000  loss: 2.6859 (2.7514)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0016  max mem: 3500\n",
            "Epoch: [20]  [ 60/295]  eta: 0:01:11  lr: 0.004000  min_lr: 0.004000  loss: 2.6859 (2.7397)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0006  max mem: 3500\n",
            "Epoch: [20]  [ 70/295]  eta: 0:01:06  lr: 0.003999  min_lr: 0.003999  loss: 2.6896 (2.7329)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0021  max mem: 3500\n",
            "Epoch: [20]  [ 80/295]  eta: 0:01:02  lr: 0.003999  min_lr: 0.003999  loss: 2.7156 (2.7376)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0028  max mem: 3500\n",
            "Epoch: [20]  [ 90/295]  eta: 0:00:59  lr: 0.003999  min_lr: 0.003999  loss: 2.7823 (2.7498)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0024  max mem: 3500\n",
            "Epoch: [20]  [100/295]  eta: 0:00:56  lr: 0.003999  min_lr: 0.003999  loss: 2.7943 (2.7519)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0036  max mem: 3500\n",
            "Epoch: [20]  [110/295]  eta: 0:00:52  lr: 0.003999  min_lr: 0.003999  loss: 2.8024 (2.7601)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0040  max mem: 3500\n",
            "Epoch: [20]  [120/295]  eta: 0:00:49  lr: 0.003998  min_lr: 0.003998  loss: 2.8346 (2.7660)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0028  max mem: 3500\n",
            "Epoch: [20]  [130/295]  eta: 0:00:46  lr: 0.003998  min_lr: 0.003998  loss: 2.8427 (2.7701)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0018  max mem: 3500\n",
            "Epoch: [20]  [140/295]  eta: 0:00:43  lr: 0.003997  min_lr: 0.003997  loss: 2.8511 (2.7721)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0017  max mem: 3500\n",
            "Epoch: [20]  [150/295]  eta: 0:00:40  lr: 0.003997  min_lr: 0.003997  loss: 2.8577 (2.7769)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0024  max mem: 3500\n",
            "Epoch: [20]  [160/295]  eta: 0:00:37  lr: 0.003997  min_lr: 0.003997  loss: 2.8248 (2.7813)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0037  max mem: 3500\n",
            "Epoch: [20]  [170/295]  eta: 0:00:34  lr: 0.003996  min_lr: 0.003996  loss: 2.8119 (2.7843)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0033  max mem: 3500\n",
            "Epoch: [20]  [180/295]  eta: 0:00:31  lr: 0.003996  min_lr: 0.003996  loss: 2.8001 (2.7863)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0035  max mem: 3500\n",
            "Epoch: [20]  [190/295]  eta: 0:00:29  lr: 0.003995  min_lr: 0.003995  loss: 2.7930 (2.7886)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0034  max mem: 3500\n",
            "Epoch: [20]  [200/295]  eta: 0:00:26  lr: 0.003995  min_lr: 0.003995  loss: 2.8170 (2.7909)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0021  max mem: 3500\n",
            "Epoch: [20]  [210/295]  eta: 0:00:23  lr: 0.003994  min_lr: 0.003994  loss: 2.8321 (2.7884)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0028  max mem: 3500\n",
            "Epoch: [20]  [220/295]  eta: 0:00:20  lr: 0.003994  min_lr: 0.003994  loss: 2.7782 (2.7859)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0023  max mem: 3500\n",
            "Epoch: [20]  [230/295]  eta: 0:00:17  lr: 0.003993  min_lr: 0.003993  loss: 2.7730 (2.7861)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0019  max mem: 3500\n",
            "Epoch: [20]  [240/295]  eta: 0:00:15  lr: 0.003993  min_lr: 0.003993  loss: 2.7630 (2.7848)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0021  max mem: 3500\n",
            "Epoch: [20]  [250/295]  eta: 0:00:12  lr: 0.003992  min_lr: 0.003992  loss: 2.7354 (2.7844)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0034  max mem: 3500\n",
            "Epoch: [20]  [260/295]  eta: 0:00:09  lr: 0.003991  min_lr: 0.003991  loss: 2.7027 (2.7795)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0036  max mem: 3500\n",
            "Epoch: [20]  [270/295]  eta: 0:00:06  lr: 0.003991  min_lr: 0.003991  loss: 2.7115 (2.7787)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0018  max mem: 3500\n",
            "Epoch: [20]  [280/295]  eta: 0:00:04  lr: 0.003990  min_lr: 0.003990  loss: 2.7215 (2.7770)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0007  max mem: 3500\n",
            "Epoch: [20]  [290/295]  eta: 0:00:01  lr: 0.003989  min_lr: 0.003989  loss: 2.6717 (2.7749)  weight_decay: 0.0500 (0.0500)  time: 0.2569  data: 0.0002  max mem: 3500\n",
            "Epoch: [20]  [294/295]  eta: 0:00:00  lr: 0.003989  min_lr: 0.003989  loss: 2.7215 (2.7751)  weight_decay: 0.0500 (0.0500)  time: 0.2197  data: 0.0001  max mem: 3500\n",
            "Epoch: [20] Total time: 0:01:19 (0.2706 s / it)\n",
            "Averaged stats: lr: 0.003989  min_lr: 0.003989  loss: 2.7215 (2.7751)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:52  loss: 0.8713 (0.8713)  acc1: 79.1667 (79.1667)  acc5: 93.7500 (93.7500)  time: 2.8403  data: 2.6771  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 1.0167 (1.1337)  acc1: 77.0833 (71.2121)  acc5: 95.8333 (94.8864)  time: 0.3824  data: 0.2455  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 1.0190 (1.1888)  acc1: 75.0000 (69.4444)  acc5: 95.8333 (94.6429)  time: 0.1289  data: 0.0019  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 1.5794 (1.4992)  acc1: 56.2500 (54.6371)  acc5: 89.5833 (91.3306)  time: 0.1210  data: 0.0014  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.6106 (1.5194)  acc1: 50.0000 (53.9126)  acc5: 89.5833 (91.5142)  time: 0.1209  data: 0.0032  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.3600 (1.4808)  acc1: 58.3333 (56.0866)  acc5: 93.7500 (92.1569)  time: 0.1208  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.3226 (1.4769)  acc1: 58.3333 (55.9085)  acc5: 95.8333 (92.3839)  time: 0.1214  data: 0.0047  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.5102 (1.4848)  acc1: 52.0833 (55.3404)  acc5: 95.8333 (92.5763)  time: 0.1198  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4589 (1.4341)  acc1: 58.3333 (57.3302)  acc5: 95.8333 (93.0041)  time: 0.1175  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4185 (1.4305)  acc1: 60.4167 (57.4522)  acc5: 95.8333 (92.9682)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1596 s / it)\n",
            "* Acc@1 57.452 Acc@5 92.968 loss 1.431\n",
            "Accuracy of the model on the 3925 test images: 57.5%\n",
            "Max accuracy: 57.45%\n",
            "Test:  [ 0/82]  eta: 0:03:43  loss: 5.6843 (5.6843)  acc1: 2.0833 (2.0833)  acc5: 47.9167 (47.9167)  time: 2.7312  data: 2.5415  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 5.6152 (5.5808)  acc1: 4.1667 (10.7955)  acc5: 58.3333 (58.5227)  time: 0.3910  data: 0.2521  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 5.5571 (5.5106)  acc1: 18.7500 (14.8810)  acc5: 58.3333 (59.0278)  time: 0.1464  data: 0.0122  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 5.8233 (5.7262)  acc1: 14.5833 (11.4919)  acc5: 50.0000 (46.5726)  time: 0.1329  data: 0.0023  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.1499 (5.7931)  acc1: 2.0833 (10.0102)  acc5: 33.3333 (45.1220)  time: 0.1391  data: 0.0136  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.6120 (5.6803)  acc1: 10.4167 (13.4395)  acc5: 52.0833 (48.9788)  time: 0.1354  data: 0.0127  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 5.1733 (5.6268)  acc1: 18.7500 (13.1831)  acc5: 62.5000 (50.3415)  time: 0.1246  data: 0.0025  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 5.6598 (5.6501)  acc1: 10.4167 (13.2923)  acc5: 47.9167 (49.6479)  time: 0.1229  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 5.3491 (5.4088)  acc1: 25.0000 (18.6214)  acc5: 56.2500 (53.2665)  time: 0.1191  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 5.2272 (5.3845)  acc1: 29.1667 (19.0573)  acc5: 58.3333 (53.5541)  time: 0.1181  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1684 s / it)\n",
            "* Acc@1 19.057 Acc@5 53.554 loss 5.385\n",
            "Accuracy of the model EMA on 3925 test images: 19.1%\n",
            "Max EMA accuracy: 19.06%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [21]  [  0/295]  eta: 0:07:26  lr: 0.003989  min_lr: 0.003989  loss: 2.9277 (2.9277)  weight_decay: 0.0500 (0.0500)  time: 1.5127  data: 1.1448  max mem: 3500\n",
            "Epoch: [21]  [ 10/295]  eta: 0:02:02  lr: 0.003988  min_lr: 0.003988  loss: 2.7194 (2.7080)  weight_decay: 0.0500 (0.0500)  time: 0.4281  data: 0.1115  max mem: 3500\n",
            "Epoch: [21]  [ 20/295]  eta: 0:01:37  lr: 0.003987  min_lr: 0.003987  loss: 2.7221 (2.7439)  weight_decay: 0.0500 (0.0500)  time: 0.2966  data: 0.0064  max mem: 3500\n",
            "Epoch: [21]  [ 30/295]  eta: 0:01:26  lr: 0.003987  min_lr: 0.003987  loss: 2.8006 (2.7337)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0041  max mem: 3500\n",
            "Epoch: [21]  [ 40/295]  eta: 0:01:19  lr: 0.003986  min_lr: 0.003986  loss: 2.8170 (2.7782)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0021  max mem: 3500\n",
            "Epoch: [21]  [ 50/295]  eta: 0:01:13  lr: 0.003985  min_lr: 0.003985  loss: 2.8170 (2.7790)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0005  max mem: 3500\n",
            "Epoch: [21]  [ 60/295]  eta: 0:01:09  lr: 0.003984  min_lr: 0.003984  loss: 2.7792 (2.7733)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0008  max mem: 3500\n",
            "Epoch: [21]  [ 70/295]  eta: 0:01:05  lr: 0.003983  min_lr: 0.003983  loss: 2.8111 (2.7843)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0021  max mem: 3500\n",
            "Epoch: [21]  [ 80/295]  eta: 0:01:02  lr: 0.003982  min_lr: 0.003982  loss: 2.7622 (2.7753)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0040  max mem: 3500\n",
            "Epoch: [21]  [ 90/295]  eta: 0:00:58  lr: 0.003981  min_lr: 0.003981  loss: 2.6853 (2.7716)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0043  max mem: 3500\n",
            "Epoch: [21]  [100/295]  eta: 0:00:55  lr: 0.003980  min_lr: 0.003980  loss: 2.7652 (2.7718)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0032  max mem: 3500\n",
            "Epoch: [21]  [110/295]  eta: 0:00:52  lr: 0.003979  min_lr: 0.003979  loss: 2.7652 (2.7688)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0017  max mem: 3500\n",
            "Epoch: [21]  [120/295]  eta: 0:00:49  lr: 0.003978  min_lr: 0.003978  loss: 2.8261 (2.7734)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0009  max mem: 3500\n",
            "Epoch: [21]  [130/295]  eta: 0:00:46  lr: 0.003977  min_lr: 0.003977  loss: 2.8734 (2.7743)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0013  max mem: 3500\n",
            "Epoch: [21]  [140/295]  eta: 0:00:43  lr: 0.003976  min_lr: 0.003976  loss: 2.8437 (2.7827)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0034  max mem: 3500\n",
            "Epoch: [21]  [150/295]  eta: 0:00:40  lr: 0.003975  min_lr: 0.003975  loss: 2.8437 (2.7834)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0038  max mem: 3500\n",
            "Epoch: [21]  [160/295]  eta: 0:00:37  lr: 0.003974  min_lr: 0.003974  loss: 2.7187 (2.7800)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0018  max mem: 3500\n",
            "Epoch: [21]  [170/295]  eta: 0:00:34  lr: 0.003973  min_lr: 0.003973  loss: 2.7032 (2.7783)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0011  max mem: 3500\n",
            "Epoch: [21]  [180/295]  eta: 0:00:31  lr: 0.003971  min_lr: 0.003971  loss: 2.7734 (2.7764)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0016  max mem: 3500\n",
            "Epoch: [21]  [190/295]  eta: 0:00:28  lr: 0.003970  min_lr: 0.003970  loss: 2.7987 (2.7765)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0024  max mem: 3500\n",
            "Epoch: [21]  [200/295]  eta: 0:00:26  lr: 0.003969  min_lr: 0.003969  loss: 2.7643 (2.7720)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0023  max mem: 3500\n",
            "Epoch: [21]  [210/295]  eta: 0:00:23  lr: 0.003968  min_lr: 0.003968  loss: 2.7292 (2.7687)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0028  max mem: 3500\n",
            "Epoch: [21]  [220/295]  eta: 0:00:20  lr: 0.003966  min_lr: 0.003966  loss: 2.8208 (2.7739)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0037  max mem: 3500\n",
            "Epoch: [21]  [230/295]  eta: 0:00:17  lr: 0.003965  min_lr: 0.003965  loss: 2.8464 (2.7767)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0045  max mem: 3500\n",
            "Epoch: [21]  [240/295]  eta: 0:00:15  lr: 0.003964  min_lr: 0.003964  loss: 2.8705 (2.7791)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0034  max mem: 3500\n",
            "Epoch: [21]  [250/295]  eta: 0:00:12  lr: 0.003963  min_lr: 0.003963  loss: 2.8374 (2.7806)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0011  max mem: 3500\n",
            "Epoch: [21]  [260/295]  eta: 0:00:09  lr: 0.003961  min_lr: 0.003961  loss: 2.7810 (2.7796)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0009  max mem: 3500\n",
            "Epoch: [21]  [270/295]  eta: 0:00:06  lr: 0.003960  min_lr: 0.003960  loss: 2.8045 (2.7794)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0015  max mem: 3500\n",
            "Epoch: [21]  [280/295]  eta: 0:00:04  lr: 0.003958  min_lr: 0.003958  loss: 2.7401 (2.7783)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0014  max mem: 3500\n",
            "Epoch: [21]  [290/295]  eta: 0:00:01  lr: 0.003957  min_lr: 0.003957  loss: 2.7306 (2.7743)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0005  max mem: 3500\n",
            "Epoch: [21]  [294/295]  eta: 0:00:00  lr: 0.003957  min_lr: 0.003957  loss: 2.7306 (2.7733)  weight_decay: 0.0500 (0.0500)  time: 0.2210  data: 0.0001  max mem: 3500\n",
            "Epoch: [21] Total time: 0:01:19 (0.2697 s / it)\n",
            "Averaged stats: lr: 0.003957  min_lr: 0.003957  loss: 2.7306 (2.7733)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:55  loss: 1.0688 (1.0688)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 2.1430  data: 1.9840  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 1.3111 (1.3188)  acc1: 66.6667 (65.1515)  acc5: 91.6667 (90.5303)  time: 0.3063  data: 0.1843  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.3111 (1.2920)  acc1: 66.6667 (64.3849)  acc5: 91.6667 (92.1627)  time: 0.1235  data: 0.0046  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.6621 (1.4723)  acc1: 39.5833 (53.8979)  acc5: 93.7500 (92.0027)  time: 0.1250  data: 0.0043  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.4100 (1.4535)  acc1: 60.4167 (55.9959)  acc5: 91.6667 (92.1748)  time: 0.1247  data: 0.0051  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.3666 (1.4318)  acc1: 64.5833 (57.6797)  acc5: 95.8333 (92.8105)  time: 0.1220  data: 0.0050  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.2817 (1.4049)  acc1: 64.5833 (58.2650)  acc5: 95.8333 (93.2036)  time: 0.1222  data: 0.0046  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.5954 (1.4424)  acc1: 47.9167 (56.5434)  acc5: 91.6667 (92.8404)  time: 0.1223  data: 0.0029  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.5954 (1.3970)  acc1: 52.0833 (58.5391)  acc5: 91.6667 (93.1070)  time: 0.1191  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.5557 (1.3939)  acc1: 52.0833 (58.6242)  acc5: 91.6667 (93.0446)  time: 0.1178  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1536 s / it)\n",
            "* Acc@1 58.624 Acc@5 93.045 loss 1.394\n",
            "Accuracy of the model on the 3925 test images: 58.6%\n",
            "Max accuracy: 58.62%\n",
            "Test:  [ 0/82]  eta: 0:03:42  loss: 5.5452 (5.5452)  acc1: 2.0833 (2.0833)  acc5: 50.0000 (50.0000)  time: 2.7134  data: 2.5518  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 5.4637 (5.4373)  acc1: 6.2500 (11.1742)  acc5: 60.4167 (60.4167)  time: 0.3570  data: 0.2345  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 5.4081 (5.3781)  acc1: 18.7500 (14.7817)  acc5: 60.4167 (60.9127)  time: 0.1226  data: 0.0029  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 5.7219 (5.6121)  acc1: 16.6667 (11.4919)  acc5: 52.0833 (48.3199)  time: 0.1246  data: 0.0042  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 6.1166 (5.6946)  acc1: 2.0833 (10.0102)  acc5: 33.3333 (46.9004)  time: 0.1242  data: 0.0045  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 5.5301 (5.5721)  acc1: 10.4167 (13.5621)  acc5: 56.2500 (50.6536)  time: 0.1229  data: 0.0041  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.9839 (5.5231)  acc1: 20.8333 (13.3538)  acc5: 62.5000 (51.9467)  time: 0.1214  data: 0.0033  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 5.5163 (5.5479)  acc1: 12.5000 (13.4683)  acc5: 52.0833 (51.5552)  time: 0.1193  data: 0.0011  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 5.1851 (5.2927)  acc1: 25.0000 (19.1101)  acc5: 60.4167 (55.0669)  time: 0.1184  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 5.0855 (5.2672)  acc1: 29.1667 (19.5924)  acc5: 60.4167 (55.3376)  time: 0.1168  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1595 s / it)\n",
            "* Acc@1 19.592 Acc@5 55.338 loss 5.267\n",
            "Accuracy of the model EMA on 3925 test images: 19.6%\n",
            "Max EMA accuracy: 19.59%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [22]  [  0/295]  eta: 0:12:22  lr: 0.003956  min_lr: 0.003956  loss: 2.3944 (2.3944)  weight_decay: 0.0500 (0.0500)  time: 2.5177  data: 2.0568  max mem: 3500\n",
            "Epoch: [22]  [ 10/295]  eta: 0:02:22  lr: 0.003955  min_lr: 0.003955  loss: 2.7918 (2.7455)  weight_decay: 0.0500 (0.0500)  time: 0.4995  data: 0.1878  max mem: 3500\n",
            "Epoch: [22]  [ 20/295]  eta: 0:01:46  lr: 0.003953  min_lr: 0.003953  loss: 2.7955 (2.7997)  weight_decay: 0.0500 (0.0500)  time: 0.2793  data: 0.0006  max mem: 3500\n",
            "Epoch: [22]  [ 30/295]  eta: 0:01:31  lr: 0.003952  min_lr: 0.003952  loss: 2.7955 (2.8009)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0009  max mem: 3500\n",
            "Epoch: [22]  [ 40/295]  eta: 0:01:22  lr: 0.003950  min_lr: 0.003950  loss: 2.7428 (2.7913)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0013  max mem: 3500\n",
            "Epoch: [22]  [ 50/295]  eta: 0:01:16  lr: 0.003949  min_lr: 0.003949  loss: 2.7709 (2.7941)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0018  max mem: 3500\n",
            "Epoch: [22]  [ 60/295]  eta: 0:01:12  lr: 0.003947  min_lr: 0.003947  loss: 2.6881 (2.7652)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0029  max mem: 3500\n",
            "Epoch: [22]  [ 70/295]  eta: 0:01:07  lr: 0.003946  min_lr: 0.003946  loss: 2.6671 (2.7551)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0023  max mem: 3500\n",
            "Epoch: [22]  [ 80/295]  eta: 0:01:03  lr: 0.003944  min_lr: 0.003944  loss: 2.6902 (2.7474)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0010  max mem: 3500\n",
            "Epoch: [22]  [ 90/295]  eta: 0:01:00  lr: 0.003942  min_lr: 0.003942  loss: 2.7075 (2.7514)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0017  max mem: 3500\n",
            "Epoch: [22]  [100/295]  eta: 0:00:56  lr: 0.003940  min_lr: 0.003940  loss: 2.7806 (2.7557)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0018  max mem: 3500\n",
            "Epoch: [22]  [110/295]  eta: 0:00:53  lr: 0.003939  min_lr: 0.003939  loss: 2.7764 (2.7577)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0011  max mem: 3500\n",
            "Epoch: [22]  [120/295]  eta: 0:00:50  lr: 0.003937  min_lr: 0.003937  loss: 2.7446 (2.7541)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0023  max mem: 3500\n",
            "Epoch: [22]  [130/295]  eta: 0:00:47  lr: 0.003935  min_lr: 0.003935  loss: 2.6716 (2.7504)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0048  max mem: 3500\n",
            "Epoch: [22]  [140/295]  eta: 0:00:44  lr: 0.003933  min_lr: 0.003933  loss: 2.7185 (2.7559)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0046  max mem: 3500\n",
            "Epoch: [22]  [150/295]  eta: 0:00:41  lr: 0.003931  min_lr: 0.003931  loss: 2.7967 (2.7493)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0020  max mem: 3500\n",
            "Epoch: [22]  [160/295]  eta: 0:00:37  lr: 0.003929  min_lr: 0.003929  loss: 2.6542 (2.7482)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0008  max mem: 3500\n",
            "Epoch: [22]  [170/295]  eta: 0:00:35  lr: 0.003928  min_lr: 0.003928  loss: 2.6385 (2.7428)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0013  max mem: 3500\n",
            "Epoch: [22]  [180/295]  eta: 0:00:32  lr: 0.003925  min_lr: 0.003925  loss: 2.6975 (2.7399)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0022  max mem: 3500\n",
            "Epoch: [22]  [190/295]  eta: 0:00:29  lr: 0.003924  min_lr: 0.003924  loss: 2.7114 (2.7367)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0032  max mem: 3500\n",
            "Epoch: [22]  [200/295]  eta: 0:00:26  lr: 0.003921  min_lr: 0.003921  loss: 2.7386 (2.7390)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0044  max mem: 3500\n",
            "Epoch: [22]  [210/295]  eta: 0:00:23  lr: 0.003920  min_lr: 0.003920  loss: 2.7679 (2.7375)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0031  max mem: 3500\n",
            "Epoch: [22]  [220/295]  eta: 0:00:20  lr: 0.003917  min_lr: 0.003917  loss: 2.7656 (2.7386)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0012  max mem: 3500\n",
            "Epoch: [22]  [230/295]  eta: 0:00:17  lr: 0.003916  min_lr: 0.003916  loss: 2.7566 (2.7372)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0019  max mem: 3500\n",
            "Epoch: [22]  [240/295]  eta: 0:00:15  lr: 0.003913  min_lr: 0.003913  loss: 2.7610 (2.7382)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0021  max mem: 3500\n",
            "Epoch: [22]  [250/295]  eta: 0:00:12  lr: 0.003912  min_lr: 0.003912  loss: 2.8132 (2.7416)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0028  max mem: 3500\n",
            "Epoch: [22]  [260/295]  eta: 0:00:09  lr: 0.003909  min_lr: 0.003909  loss: 2.7569 (2.7436)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0031  max mem: 3500\n",
            "Epoch: [22]  [270/295]  eta: 0:00:06  lr: 0.003907  min_lr: 0.003907  loss: 2.7453 (2.7424)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0020  max mem: 3500\n",
            "Epoch: [22]  [280/295]  eta: 0:00:04  lr: 0.003905  min_lr: 0.003905  loss: 2.7458 (2.7436)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0010  max mem: 3500\n",
            "Epoch: [22]  [290/295]  eta: 0:00:01  lr: 0.003903  min_lr: 0.003903  loss: 2.7349 (2.7423)  weight_decay: 0.0500 (0.0500)  time: 0.2572  data: 0.0002  max mem: 3500\n",
            "Epoch: [22]  [294/295]  eta: 0:00:00  lr: 0.003903  min_lr: 0.003903  loss: 2.7851 (2.7424)  weight_decay: 0.0500 (0.0500)  time: 0.2187  data: 0.0001  max mem: 3500\n",
            "Epoch: [22] Total time: 0:01:20 (0.2712 s / it)\n",
            "Averaged stats: lr: 0.003903  min_lr: 0.003903  loss: 2.7851 (2.7424)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:18  loss: 0.8604 (0.8604)  acc1: 89.5833 (89.5833)  acc5: 93.7500 (93.7500)  time: 1.6950  data: 1.5250  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 1.0755 (1.1398)  acc1: 72.9167 (75.0000)  acc5: 95.8333 (94.5076)  time: 0.2735  data: 0.1398  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.3540 (1.3414)  acc1: 60.4167 (64.9802)  acc5: 93.7500 (92.7579)  time: 0.1383  data: 0.0015  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 1.6924 (1.5928)  acc1: 41.6667 (50.6720)  acc5: 85.4167 (90.0538)  time: 0.1520  data: 0.0082  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.6580 (1.4465)  acc1: 41.6667 (56.8089)  acc5: 89.5833 (92.0224)  time: 0.1748  data: 0.0320  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.3158 (1.4706)  acc1: 62.5000 (55.2696)  acc5: 95.8333 (92.5245)  time: 0.1881  data: 0.0464  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.3901 (1.4435)  acc1: 60.4167 (57.2404)  acc5: 95.8333 (92.5546)  time: 0.1667  data: 0.0237  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.4921 (1.4720)  acc1: 54.1667 (55.9859)  acc5: 91.6667 (92.2829)  time: 0.1337  data: 0.0021  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4921 (1.4251)  acc1: 54.1667 (57.6646)  acc5: 91.6667 (92.5154)  time: 0.1186  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4052 (1.4214)  acc1: 54.1667 (57.8344)  acc5: 91.6667 (92.4331)  time: 0.1173  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1725 s / it)\n",
            "* Acc@1 57.834 Acc@5 92.433 loss 1.421\n",
            "Accuracy of the model on the 3925 test images: 57.8%\n",
            "Max accuracy: 58.62%\n",
            "Test:  [ 0/82]  eta: 0:03:54  loss: 5.4082 (5.4082)  acc1: 2.0833 (2.0833)  acc5: 60.4167 (60.4167)  time: 2.8610  data: 2.6656  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 5.2962 (5.2938)  acc1: 6.2500 (11.5530)  acc5: 64.5833 (64.3939)  time: 0.4131  data: 0.2744  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 5.2558 (5.2458)  acc1: 18.7500 (15.1786)  acc5: 64.5833 (64.1865)  time: 0.1611  data: 0.0263  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 5.6229 (5.4995)  acc1: 16.6667 (11.8280)  acc5: 54.1667 (51.3441)  time: 0.1450  data: 0.0135  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 6.0886 (5.5987)  acc1: 2.0833 (10.2642)  acc5: 37.5000 (49.6951)  time: 0.1575  data: 0.0215  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.4390 (5.4691)  acc1: 10.4167 (14.0523)  acc5: 56.2500 (53.1454)  time: 0.1783  data: 0.0363  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.8410 (5.4255)  acc1: 20.8333 (13.7295)  acc5: 64.5833 (54.2350)  time: 0.1695  data: 0.0370  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 5.3571 (5.4499)  acc1: 10.4167 (13.8498)  acc5: 54.1667 (53.9319)  time: 0.1678  data: 0.0373  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 5.0029 (5.1834)  acc1: 27.0833 (19.5988)  acc5: 64.5833 (57.2788)  time: 0.1470  data: 0.0201  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 4.9316 (5.1571)  acc1: 29.1667 (20.1019)  acc5: 66.6667 (57.5287)  time: 0.1435  data: 0.0201  max mem: 3500\n",
            "Test: Total time: 0:00:16 (0.1961 s / it)\n",
            "* Acc@1 20.102 Acc@5 57.529 loss 5.157\n",
            "Accuracy of the model EMA on 3925 test images: 20.1%\n",
            "Max EMA accuracy: 20.10%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [23]  [  0/295]  eta: 0:08:47  lr: 0.003902  min_lr: 0.003902  loss: 2.6290 (2.6290)  weight_decay: 0.0500 (0.0500)  time: 1.7876  data: 1.4339  max mem: 3500\n",
            "Epoch: [23]  [ 10/295]  eta: 0:01:56  lr: 0.003900  min_lr: 0.003900  loss: 2.6290 (2.6245)  weight_decay: 0.0500 (0.0500)  time: 0.4081  data: 0.1320  max mem: 3500\n",
            "Epoch: [23]  [ 20/295]  eta: 0:01:33  lr: 0.003898  min_lr: 0.003898  loss: 2.6971 (2.6847)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0012  max mem: 3500\n",
            "Epoch: [23]  [ 30/295]  eta: 0:01:23  lr: 0.003896  min_lr: 0.003896  loss: 2.7791 (2.7264)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0015  max mem: 3500\n",
            "Epoch: [23]  [ 40/295]  eta: 0:01:17  lr: 0.003893  min_lr: 0.003893  loss: 2.8380 (2.7444)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0031  max mem: 3500\n",
            "Epoch: [23]  [ 50/295]  eta: 0:01:13  lr: 0.003891  min_lr: 0.003891  loss: 2.8354 (2.7640)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0040  max mem: 3500\n",
            "Epoch: [23]  [ 60/295]  eta: 0:01:08  lr: 0.003888  min_lr: 0.003888  loss: 2.8665 (2.7639)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0041  max mem: 3500\n",
            "Epoch: [23]  [ 70/295]  eta: 0:01:04  lr: 0.003887  min_lr: 0.003887  loss: 2.8352 (2.7755)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0026  max mem: 3500\n",
            "Epoch: [23]  [ 80/295]  eta: 0:01:01  lr: 0.003884  min_lr: 0.003884  loss: 2.7705 (2.7658)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0010  max mem: 3500\n",
            "Epoch: [23]  [ 90/295]  eta: 0:00:57  lr: 0.003882  min_lr: 0.003882  loss: 2.7058 (2.7667)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0005  max mem: 3500\n",
            "Epoch: [23]  [100/295]  eta: 0:00:54  lr: 0.003879  min_lr: 0.003879  loss: 2.6930 (2.7575)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0015  max mem: 3500\n",
            "Epoch: [23]  [110/295]  eta: 0:00:51  lr: 0.003877  min_lr: 0.003877  loss: 2.6834 (2.7536)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0033  max mem: 3500\n",
            "Epoch: [23]  [120/295]  eta: 0:00:48  lr: 0.003874  min_lr: 0.003874  loss: 2.7002 (2.7404)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0033  max mem: 3500\n",
            "Epoch: [23]  [130/295]  eta: 0:00:45  lr: 0.003872  min_lr: 0.003872  loss: 2.6481 (2.7390)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0021  max mem: 3500\n",
            "Epoch: [23]  [140/295]  eta: 0:00:42  lr: 0.003869  min_lr: 0.003869  loss: 2.7551 (2.7465)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0018  max mem: 3500\n",
            "Epoch: [23]  [150/295]  eta: 0:00:39  lr: 0.003867  min_lr: 0.003867  loss: 2.7617 (2.7472)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0019  max mem: 3500\n",
            "Epoch: [23]  [160/295]  eta: 0:00:37  lr: 0.003864  min_lr: 0.003864  loss: 2.7762 (2.7473)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0018  max mem: 3500\n",
            "Epoch: [23]  [170/295]  eta: 0:00:34  lr: 0.003861  min_lr: 0.003861  loss: 2.7427 (2.7481)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0031  max mem: 3500\n",
            "Epoch: [23]  [180/295]  eta: 0:00:31  lr: 0.003858  min_lr: 0.003858  loss: 2.7475 (2.7487)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0041  max mem: 3500\n",
            "Epoch: [23]  [190/295]  eta: 0:00:28  lr: 0.003856  min_lr: 0.003856  loss: 2.7677 (2.7499)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0025  max mem: 3500\n",
            "Epoch: [23]  [200/295]  eta: 0:00:25  lr: 0.003853  min_lr: 0.003853  loss: 2.8157 (2.7513)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0014  max mem: 3500\n",
            "Epoch: [23]  [210/295]  eta: 0:00:23  lr: 0.003851  min_lr: 0.003851  loss: 2.7947 (2.7499)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0021  max mem: 3500\n",
            "Epoch: [23]  [220/295]  eta: 0:00:20  lr: 0.003848  min_lr: 0.003848  loss: 2.7255 (2.7485)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0027  max mem: 3500\n",
            "Epoch: [23]  [230/295]  eta: 0:00:17  lr: 0.003845  min_lr: 0.003845  loss: 2.7578 (2.7485)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0035  max mem: 3500\n",
            "Epoch: [23]  [240/295]  eta: 0:00:14  lr: 0.003842  min_lr: 0.003842  loss: 2.7897 (2.7520)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0045  max mem: 3500\n",
            "Epoch: [23]  [250/295]  eta: 0:00:12  lr: 0.003840  min_lr: 0.003840  loss: 2.7897 (2.7506)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0052  max mem: 3500\n",
            "Epoch: [23]  [260/295]  eta: 0:00:09  lr: 0.003836  min_lr: 0.003836  loss: 2.7083 (2.7492)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0035  max mem: 3500\n",
            "Epoch: [23]  [270/295]  eta: 0:00:06  lr: 0.003834  min_lr: 0.003834  loss: 2.7227 (2.7503)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0011  max mem: 3500\n",
            "Epoch: [23]  [280/295]  eta: 0:00:04  lr: 0.003831  min_lr: 0.003831  loss: 2.7092 (2.7477)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0009  max mem: 3500\n",
            "Epoch: [23]  [290/295]  eta: 0:00:01  lr: 0.003828  min_lr: 0.003828  loss: 2.5986 (2.7422)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0007  max mem: 3500\n",
            "Epoch: [23]  [294/295]  eta: 0:00:00  lr: 0.003828  min_lr: 0.003828  loss: 2.5890 (2.7412)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0001  max mem: 3500\n",
            "Epoch: [23] Total time: 0:01:19 (0.2686 s / it)\n",
            "Averaged stats: lr: 0.003828  min_lr: 0.003828  loss: 2.5890 (2.7412)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:37  loss: 0.9806 (0.9806)  acc1: 85.4167 (85.4167)  acc5: 91.6667 (91.6667)  time: 2.6523  data: 2.4468  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 1.2391 (1.2332)  acc1: 72.9167 (70.6439)  acc5: 89.5833 (88.6364)  time: 0.3684  data: 0.2269  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 1.2391 (1.2855)  acc1: 64.5833 (65.9722)  acc5: 89.5833 (90.2778)  time: 0.1392  data: 0.0122  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 1.5194 (1.4731)  acc1: 50.0000 (54.0995)  acc5: 91.6667 (90.5242)  time: 0.1293  data: 0.0113  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.3583 (1.4368)  acc1: 52.0833 (54.8272)  acc5: 95.8333 (92.0224)  time: 0.1216  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.1978 (1.3763)  acc1: 66.6667 (58.6601)  acc5: 97.9167 (93.0556)  time: 0.1248  data: 0.0068  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.1523 (1.3182)  acc1: 70.8333 (61.0314)  acc5: 95.8333 (93.3402)  time: 0.1244  data: 0.0064  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.2783 (1.3437)  acc1: 60.4167 (60.1819)  acc5: 95.8333 (93.2512)  time: 0.1200  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3006 (1.3270)  acc1: 60.4167 (61.1111)  acc5: 93.7500 (93.2613)  time: 0.1176  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3006 (1.3270)  acc1: 60.4167 (61.0955)  acc5: 93.7500 (93.1975)  time: 0.1164  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1615 s / it)\n",
            "* Acc@1 61.096 Acc@5 93.197 loss 1.327\n",
            "Accuracy of the model on the 3925 test images: 61.1%\n",
            "Max accuracy: 61.10%\n",
            "Test:  [ 0/82]  eta: 0:03:53  loss: 5.2797 (5.2797)  acc1: 4.1667 (4.1667)  acc5: 62.5000 (62.5000)  time: 2.8505  data: 2.6671  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 5.1417 (5.1576)  acc1: 6.2500 (11.1742)  acc5: 66.6667 (66.4773)  time: 0.4023  data: 0.2673  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 5.1072 (5.1213)  acc1: 16.6667 (14.6825)  acc5: 64.5833 (65.9722)  time: 0.1607  data: 0.0282  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 5.5339 (5.3943)  acc1: 16.6667 (11.4919)  acc5: 56.2500 (52.8226)  time: 0.1515  data: 0.0162  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.0567 (5.5074)  acc1: 2.0833 (9.9085)  acc5: 39.5833 (50.8638)  time: 0.1311  data: 0.0022  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.3511 (5.3707)  acc1: 12.5000 (14.0114)  acc5: 56.2500 (54.2484)  time: 0.1230  data: 0.0020  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.7515 (5.3349)  acc1: 20.8333 (13.6270)  acc5: 66.6667 (55.1913)  time: 0.1241  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 5.1938 (5.3588)  acc1: 10.4167 (13.9378)  acc5: 58.3333 (55.0763)  time: 0.1220  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 4.8182 (5.0823)  acc1: 31.2500 (19.8560)  acc5: 66.6667 (58.3591)  time: 0.1189  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 4.7767 (5.0552)  acc1: 33.3333 (20.3312)  acc5: 66.6667 (58.5987)  time: 0.1174  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1708 s / it)\n",
            "* Acc@1 20.331 Acc@5 58.599 loss 5.055\n",
            "Accuracy of the model EMA on 3925 test images: 20.3%\n",
            "Max EMA accuracy: 20.33%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [24]  [  0/295]  eta: 0:08:51  lr: 0.003827  min_lr: 0.003827  loss: 2.8481 (2.8481)  weight_decay: 0.0500 (0.0500)  time: 1.8008  data: 1.4176  max mem: 3500\n",
            "Epoch: [24]  [ 10/295]  eta: 0:02:10  lr: 0.003825  min_lr: 0.003825  loss: 2.8151 (2.7682)  weight_decay: 0.0500 (0.0500)  time: 0.4564  data: 0.1313  max mem: 3500\n",
            "Epoch: [24]  [ 20/295]  eta: 0:01:41  lr: 0.003821  min_lr: 0.003821  loss: 2.7769 (2.7381)  weight_decay: 0.0500 (0.0500)  time: 0.2987  data: 0.0047  max mem: 3500\n",
            "Epoch: [24]  [ 30/295]  eta: 0:01:29  lr: 0.003819  min_lr: 0.003819  loss: 2.7098 (2.7144)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0055  max mem: 3500\n",
            "Epoch: [24]  [ 40/295]  eta: 0:01:21  lr: 0.003815  min_lr: 0.003815  loss: 2.7457 (2.7386)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0030  max mem: 3500\n",
            "Epoch: [24]  [ 50/295]  eta: 0:01:15  lr: 0.003813  min_lr: 0.003813  loss: 2.8135 (2.7506)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0018  max mem: 3500\n",
            "Epoch: [24]  [ 60/295]  eta: 0:01:10  lr: 0.003809  min_lr: 0.003809  loss: 2.8548 (2.7654)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0019  max mem: 3500\n",
            "Epoch: [24]  [ 70/295]  eta: 0:01:06  lr: 0.003807  min_lr: 0.003807  loss: 2.8548 (2.7698)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0023  max mem: 3500\n",
            "Epoch: [24]  [ 80/295]  eta: 0:01:03  lr: 0.003803  min_lr: 0.003803  loss: 2.7969 (2.7699)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0033  max mem: 3500\n",
            "Epoch: [24]  [ 90/295]  eta: 0:00:59  lr: 0.003801  min_lr: 0.003801  loss: 2.7279 (2.7589)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0037  max mem: 3500\n",
            "Epoch: [24]  [100/295]  eta: 0:00:56  lr: 0.003797  min_lr: 0.003797  loss: 2.7099 (2.7617)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0027  max mem: 3500\n",
            "Epoch: [24]  [110/295]  eta: 0:00:52  lr: 0.003794  min_lr: 0.003794  loss: 2.7725 (2.7572)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0022  max mem: 3500\n",
            "Epoch: [24]  [120/295]  eta: 0:00:49  lr: 0.003790  min_lr: 0.003790  loss: 2.6921 (2.7491)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0025  max mem: 3500\n",
            "Epoch: [24]  [130/295]  eta: 0:00:46  lr: 0.003788  min_lr: 0.003788  loss: 2.6983 (2.7475)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0031  max mem: 3500\n",
            "Epoch: [24]  [140/295]  eta: 0:00:43  lr: 0.003784  min_lr: 0.003784  loss: 2.7461 (2.7506)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0045  max mem: 3500\n",
            "Epoch: [24]  [150/295]  eta: 0:00:40  lr: 0.003781  min_lr: 0.003781  loss: 2.7860 (2.7529)  weight_decay: 0.0500 (0.0500)  time: 0.2773  data: 0.0050  max mem: 3500\n",
            "Epoch: [24]  [160/295]  eta: 0:00:37  lr: 0.003777  min_lr: 0.003777  loss: 2.6791 (2.7494)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0035  max mem: 3500\n",
            "Epoch: [24]  [170/295]  eta: 0:00:35  lr: 0.003775  min_lr: 0.003775  loss: 2.6733 (2.7450)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0024  max mem: 3500\n",
            "Epoch: [24]  [180/295]  eta: 0:00:32  lr: 0.003771  min_lr: 0.003771  loss: 2.6892 (2.7462)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0015  max mem: 3500\n",
            "Epoch: [24]  [190/295]  eta: 0:00:29  lr: 0.003768  min_lr: 0.003768  loss: 2.7593 (2.7446)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0011  max mem: 3500\n",
            "Epoch: [24]  [200/295]  eta: 0:00:26  lr: 0.003764  min_lr: 0.003764  loss: 2.6824 (2.7391)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0019  max mem: 3500\n",
            "Epoch: [24]  [210/295]  eta: 0:00:23  lr: 0.003761  min_lr: 0.003761  loss: 2.7748 (2.7402)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0016  max mem: 3500\n",
            "Epoch: [24]  [220/295]  eta: 0:00:20  lr: 0.003757  min_lr: 0.003757  loss: 2.7777 (2.7426)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0033  max mem: 3500\n",
            "Epoch: [24]  [230/295]  eta: 0:00:17  lr: 0.003755  min_lr: 0.003755  loss: 2.7056 (2.7384)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0038  max mem: 3500\n",
            "Epoch: [24]  [240/295]  eta: 0:00:15  lr: 0.003750  min_lr: 0.003750  loss: 2.6460 (2.7347)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0026  max mem: 3500\n",
            "Epoch: [24]  [250/295]  eta: 0:00:12  lr: 0.003748  min_lr: 0.003748  loss: 2.6760 (2.7361)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0021  max mem: 3500\n",
            "Epoch: [24]  [260/295]  eta: 0:00:09  lr: 0.003743  min_lr: 0.003743  loss: 2.8158 (2.7375)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0018  max mem: 3500\n",
            "Epoch: [24]  [270/295]  eta: 0:00:06  lr: 0.003741  min_lr: 0.003741  loss: 2.7536 (2.7344)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0018  max mem: 3500\n",
            "Epoch: [24]  [280/295]  eta: 0:00:04  lr: 0.003736  min_lr: 0.003736  loss: 2.7572 (2.7358)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0007  max mem: 3500\n",
            "Epoch: [24]  [290/295]  eta: 0:00:01  lr: 0.003734  min_lr: 0.003734  loss: 2.7346 (2.7345)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0002  max mem: 3500\n",
            "Epoch: [24]  [294/295]  eta: 0:00:00  lr: 0.003734  min_lr: 0.003734  loss: 2.7346 (2.7346)  weight_decay: 0.0500 (0.0500)  time: 0.2216  data: 0.0001  max mem: 3500\n",
            "Epoch: [24] Total time: 0:01:20 (0.2716 s / it)\n",
            "Averaged stats: lr: 0.003734  min_lr: 0.003734  loss: 2.7346 (2.7346)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:31  loss: 0.9611 (0.9611)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 1.8463  data: 1.6793  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.0901 (1.1175)  acc1: 72.9167 (73.1061)  acc5: 97.9167 (97.3485)  time: 0.2831  data: 0.1590  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 1.2470 (1.2087)  acc1: 70.8333 (70.1389)  acc5: 97.9167 (96.4286)  time: 0.1237  data: 0.0042  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.4190 (1.4964)  acc1: 60.4167 (55.3091)  acc5: 89.5833 (93.3468)  time: 0.1250  data: 0.0035  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.5069 (1.4889)  acc1: 58.3333 (56.1484)  acc5: 91.6667 (93.8516)  time: 0.1257  data: 0.0043  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.4303 (1.4849)  acc1: 58.3333 (56.9036)  acc5: 93.7500 (93.7500)  time: 0.1223  data: 0.0042  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.3927 (1.4605)  acc1: 62.5000 (58.8115)  acc5: 93.7500 (93.5109)  time: 0.1220  data: 0.0061  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.2794 (1.4300)  acc1: 68.7500 (60.2993)  acc5: 95.8333 (93.5739)  time: 0.1200  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1030 (1.3777)  acc1: 77.0833 (62.5257)  acc5: 95.8333 (93.7500)  time: 0.1183  data: 0.0008  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1030 (1.3764)  acc1: 77.0833 (62.5733)  acc5: 95.8333 (93.7070)  time: 0.1164  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1494 s / it)\n",
            "* Acc@1 62.573 Acc@5 93.707 loss 1.376\n",
            "Accuracy of the model on the 3925 test images: 62.6%\n",
            "Max accuracy: 62.57%\n",
            "Test:  [ 0/82]  eta: 0:03:58  loss: 5.1581 (5.1581)  acc1: 2.0833 (2.0833)  acc5: 60.4167 (60.4167)  time: 2.9066  data: 2.7418  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 4.9922 (5.0301)  acc1: 6.2500 (10.6061)  acc5: 66.6667 (67.8030)  time: 0.3839  data: 0.2567  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 4.9713 (5.0025)  acc1: 16.6667 (14.2857)  acc5: 66.6667 (67.3611)  time: 0.1296  data: 0.0052  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 5.4435 (5.2944)  acc1: 16.6667 (11.2231)  acc5: 58.3333 (54.5027)  time: 0.1266  data: 0.0039  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.0321 (5.4222)  acc1: 2.0833 (9.7561)  acc5: 39.5833 (52.3374)  time: 0.1235  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 5.2795 (5.2812)  acc1: 10.4167 (13.8889)  acc5: 56.2500 (55.5556)  time: 0.1228  data: 0.0040  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6806 (5.2537)  acc1: 20.8333 (13.5929)  acc5: 66.6667 (56.4549)  time: 0.1230  data: 0.0041  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 5.0374 (5.2761)  acc1: 8.3333 (13.9085)  acc5: 60.4167 (56.4554)  time: 0.1201  data: 0.0015  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 4.6373 (4.9915)  acc1: 31.2500 (20.0103)  acc5: 68.7500 (59.6193)  time: 0.1181  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 4.6234 (4.9639)  acc1: 35.4167 (20.4841)  acc5: 68.7500 (59.8726)  time: 0.1170  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1617 s / it)\n",
            "* Acc@1 20.484 Acc@5 59.873 loss 4.964\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "Max EMA accuracy: 20.48%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [25]  [  0/295]  eta: 0:14:19  lr: 0.003732  min_lr: 0.003732  loss: 2.6890 (2.6890)  weight_decay: 0.0500 (0.0500)  time: 2.9144  data: 2.3873  max mem: 3500\n",
            "Epoch: [25]  [ 10/295]  eta: 0:02:34  lr: 0.003729  min_lr: 0.003729  loss: 2.6890 (2.6863)  weight_decay: 0.0500 (0.0500)  time: 0.5407  data: 0.2195  max mem: 3500\n",
            "Epoch: [25]  [ 20/295]  eta: 0:01:52  lr: 0.003725  min_lr: 0.003725  loss: 2.6694 (2.6868)  weight_decay: 0.0500 (0.0500)  time: 0.2838  data: 0.0019  max mem: 3500\n",
            "Epoch: [25]  [ 30/295]  eta: 0:01:36  lr: 0.003722  min_lr: 0.003722  loss: 2.6645 (2.6942)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0007  max mem: 3500\n",
            "Epoch: [25]  [ 40/295]  eta: 0:01:26  lr: 0.003718  min_lr: 0.003718  loss: 2.7349 (2.7201)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0009  max mem: 3500\n",
            "Epoch: [25]  [ 50/295]  eta: 0:01:19  lr: 0.003715  min_lr: 0.003715  loss: 2.7551 (2.7112)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0024  max mem: 3500\n",
            "Epoch: [25]  [ 60/295]  eta: 0:01:14  lr: 0.003710  min_lr: 0.003710  loss: 2.6908 (2.7086)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0032  max mem: 3500\n",
            "Epoch: [25]  [ 70/295]  eta: 0:01:09  lr: 0.003707  min_lr: 0.003707  loss: 2.7291 (2.7228)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0037  max mem: 3500\n",
            "Epoch: [25]  [ 80/295]  eta: 0:01:05  lr: 0.003703  min_lr: 0.003703  loss: 2.7763 (2.7289)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0033  max mem: 3500\n",
            "Epoch: [25]  [ 90/295]  eta: 0:01:01  lr: 0.003700  min_lr: 0.003700  loss: 2.6985 (2.7259)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0020  max mem: 3500\n",
            "Epoch: [25]  [100/295]  eta: 0:00:57  lr: 0.003695  min_lr: 0.003695  loss: 2.6710 (2.7259)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0016  max mem: 3500\n",
            "Epoch: [25]  [110/295]  eta: 0:00:54  lr: 0.003692  min_lr: 0.003692  loss: 2.7076 (2.7255)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0021  max mem: 3500\n",
            "Epoch: [25]  [120/295]  eta: 0:00:50  lr: 0.003688  min_lr: 0.003688  loss: 2.6005 (2.7078)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0027  max mem: 3500\n",
            "Epoch: [25]  [130/295]  eta: 0:00:47  lr: 0.003684  min_lr: 0.003684  loss: 2.5938 (2.7061)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0037  max mem: 3500\n",
            "Epoch: [25]  [140/295]  eta: 0:00:44  lr: 0.003680  min_lr: 0.003680  loss: 2.6982 (2.7077)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0042  max mem: 3500\n",
            "Epoch: [25]  [150/295]  eta: 0:00:41  lr: 0.003677  min_lr: 0.003677  loss: 2.6982 (2.7070)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0034  max mem: 3500\n",
            "Epoch: [25]  [160/295]  eta: 0:00:38  lr: 0.003672  min_lr: 0.003672  loss: 2.7345 (2.7072)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0039  max mem: 3500\n",
            "Epoch: [25]  [170/295]  eta: 0:00:35  lr: 0.003669  min_lr: 0.003669  loss: 2.7791 (2.7099)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0029  max mem: 3500\n",
            "Epoch: [25]  [180/295]  eta: 0:00:32  lr: 0.003664  min_lr: 0.003664  loss: 2.6886 (2.7083)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0027  max mem: 3500\n",
            "Epoch: [25]  [190/295]  eta: 0:00:29  lr: 0.003661  min_lr: 0.003661  loss: 2.6466 (2.7052)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0052  max mem: 3500\n",
            "Epoch: [25]  [200/295]  eta: 0:00:26  lr: 0.003656  min_lr: 0.003656  loss: 2.6466 (2.7043)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0049  max mem: 3500\n",
            "Epoch: [25]  [210/295]  eta: 0:00:23  lr: 0.003653  min_lr: 0.003653  loss: 2.6447 (2.7025)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0035  max mem: 3500\n",
            "Epoch: [25]  [220/295]  eta: 0:00:20  lr: 0.003648  min_lr: 0.003648  loss: 2.7080 (2.7047)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0018  max mem: 3500\n",
            "Epoch: [25]  [230/295]  eta: 0:00:18  lr: 0.003645  min_lr: 0.003645  loss: 2.7452 (2.7010)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0004  max mem: 3500\n",
            "Epoch: [25]  [240/295]  eta: 0:00:15  lr: 0.003640  min_lr: 0.003640  loss: 2.6621 (2.7011)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0012  max mem: 3500\n",
            "Epoch: [25]  [250/295]  eta: 0:00:12  lr: 0.003636  min_lr: 0.003636  loss: 2.7079 (2.7024)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0026  max mem: 3500\n",
            "Epoch: [25]  [260/295]  eta: 0:00:09  lr: 0.003632  min_lr: 0.003632  loss: 2.7496 (2.7042)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0042  max mem: 3500\n",
            "Epoch: [25]  [270/295]  eta: 0:00:06  lr: 0.003628  min_lr: 0.003628  loss: 2.6785 (2.7008)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0045  max mem: 3500\n",
            "Epoch: [25]  [280/295]  eta: 0:00:04  lr: 0.003623  min_lr: 0.003623  loss: 2.6500 (2.7031)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0026  max mem: 3500\n",
            "Epoch: [25]  [290/295]  eta: 0:00:01  lr: 0.003620  min_lr: 0.003620  loss: 2.7429 (2.7039)  weight_decay: 0.0500 (0.0500)  time: 0.2567  data: 0.0007  max mem: 3500\n",
            "Epoch: [25]  [294/295]  eta: 0:00:00  lr: 0.003620  min_lr: 0.003620  loss: 2.7354 (2.7032)  weight_decay: 0.0500 (0.0500)  time: 0.2184  data: 0.0001  max mem: 3500\n",
            "Epoch: [25] Total time: 0:01:20 (0.2736 s / it)\n",
            "Averaged stats: lr: 0.003620  min_lr: 0.003620  loss: 2.7354 (2.7032)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:40  loss: 0.9022 (0.9022)  acc1: 81.2500 (81.2500)  acc5: 91.6667 (91.6667)  time: 1.9595  data: 1.7975  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 1.1092 (1.1040)  acc1: 72.9167 (73.2955)  acc5: 93.7500 (93.9394)  time: 0.3096  data: 0.1668  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 1.1092 (1.0865)  acc1: 75.0000 (74.5040)  acc5: 95.8333 (95.4365)  time: 0.1527  data: 0.0166  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 1.1875 (1.3388)  acc1: 66.6667 (60.9543)  acc5: 93.7500 (93.8844)  time: 0.1672  data: 0.0321  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.3841 (1.3353)  acc1: 60.4167 (60.9248)  acc5: 93.7500 (94.4614)  time: 0.1786  data: 0.0374  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.2780 (1.3299)  acc1: 62.5000 (61.8056)  acc5: 95.8333 (94.7304)  time: 0.1984  data: 0.0448  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.2630 (1.3234)  acc1: 62.5000 (62.4658)  acc5: 95.8333 (94.4672)  time: 0.2037  data: 0.0451  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.2714 (1.3499)  acc1: 60.4167 (61.2383)  acc5: 93.7500 (93.6620)  time: 0.1798  data: 0.0348  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2401 (1.3106)  acc1: 64.5833 (62.7315)  acc5: 93.7500 (93.8272)  time: 0.1419  data: 0.0145  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2401 (1.3099)  acc1: 64.5833 (62.8280)  acc5: 93.7500 (93.7325)  time: 0.1395  data: 0.0143  max mem: 3500\n",
            "Test: Total time: 0:00:16 (0.1961 s / it)\n",
            "* Acc@1 62.828 Acc@5 93.732 loss 1.310\n",
            "Accuracy of the model on the 3925 test images: 62.8%\n",
            "Max accuracy: 62.83%\n",
            "Test:  [ 0/82]  eta: 0:02:43  loss: 5.0403 (5.0403)  acc1: 6.2500 (6.2500)  acc5: 66.6667 (66.6667)  time: 1.9917  data: 1.8267  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 4.8506 (4.9094)  acc1: 6.2500 (10.6061)  acc5: 66.6667 (69.1288)  time: 0.2939  data: 0.1676  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 4.8400 (4.8907)  acc1: 16.6667 (14.1865)  acc5: 66.6667 (68.7500)  time: 0.1228  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 5.3559 (5.2001)  acc1: 14.5833 (11.0887)  acc5: 60.4167 (56.2500)  time: 0.1235  data: 0.0050  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 6.0214 (5.3449)  acc1: 2.0833 (9.7561)  acc5: 43.7500 (54.0142)  time: 0.1253  data: 0.0061  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 5.2258 (5.2021)  acc1: 12.5000 (13.8889)  acc5: 58.3333 (57.0670)  time: 0.1285  data: 0.0039  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6248 (5.1845)  acc1: 18.7500 (13.4904)  acc5: 66.6667 (57.7186)  time: 0.1409  data: 0.0025  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.8935 (5.2051)  acc1: 8.3333 (13.8791)  acc5: 62.5000 (57.5411)  time: 0.1464  data: 0.0015  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 4.4779 (4.9129)  acc1: 31.2500 (20.1132)  acc5: 70.8333 (60.6739)  time: 0.1313  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 4.4631 (4.8850)  acc1: 39.5833 (20.5860)  acc5: 70.8333 (60.9172)  time: 0.1287  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1580 s / it)\n",
            "* Acc@1 20.586 Acc@5 60.917 loss 4.885\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "Max EMA accuracy: 20.59%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [26]  [  0/295]  eta: 0:09:30  lr: 0.003618  min_lr: 0.003618  loss: 2.6953 (2.6953)  weight_decay: 0.0500 (0.0500)  time: 1.9328  data: 1.5634  max mem: 3500\n",
            "Epoch: [26]  [ 10/295]  eta: 0:02:00  lr: 0.003615  min_lr: 0.003615  loss: 2.6529 (2.6519)  weight_decay: 0.0500 (0.0500)  time: 0.4217  data: 0.1442  max mem: 3500\n",
            "Epoch: [26]  [ 20/295]  eta: 0:01:35  lr: 0.003610  min_lr: 0.003610  loss: 2.6438 (2.6358)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0019  max mem: 3500\n",
            "Epoch: [26]  [ 30/295]  eta: 0:01:24  lr: 0.003606  min_lr: 0.003606  loss: 2.6539 (2.6589)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0013  max mem: 3500\n",
            "Epoch: [26]  [ 40/295]  eta: 0:01:18  lr: 0.003601  min_lr: 0.003601  loss: 2.7237 (2.6924)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0031  max mem: 3500\n",
            "Epoch: [26]  [ 50/295]  eta: 0:01:13  lr: 0.003598  min_lr: 0.003598  loss: 2.7684 (2.7080)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0049  max mem: 3500\n",
            "Epoch: [26]  [ 60/295]  eta: 0:01:09  lr: 0.003592  min_lr: 0.003592  loss: 2.7465 (2.7064)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0029  max mem: 3500\n",
            "Epoch: [26]  [ 70/295]  eta: 0:01:05  lr: 0.003589  min_lr: 0.003589  loss: 2.7779 (2.7089)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0013  max mem: 3500\n",
            "Epoch: [26]  [ 80/295]  eta: 0:01:01  lr: 0.003584  min_lr: 0.003584  loss: 2.7367 (2.7081)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0013  max mem: 3500\n",
            "Epoch: [26]  [ 90/295]  eta: 0:00:58  lr: 0.003580  min_lr: 0.003580  loss: 2.6904 (2.7159)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0014  max mem: 3500\n",
            "Epoch: [26]  [100/295]  eta: 0:00:55  lr: 0.003575  min_lr: 0.003575  loss: 2.8007 (2.7220)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0010  max mem: 3500\n",
            "Epoch: [26]  [110/295]  eta: 0:00:51  lr: 0.003571  min_lr: 0.003571  loss: 2.7122 (2.7175)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0023  max mem: 3500\n",
            "Epoch: [26]  [120/295]  eta: 0:00:49  lr: 0.003566  min_lr: 0.003566  loss: 2.6936 (2.7206)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0036  max mem: 3500\n",
            "Epoch: [26]  [130/295]  eta: 0:00:45  lr: 0.003562  min_lr: 0.003562  loss: 2.7560 (2.7152)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0026  max mem: 3500\n",
            "Epoch: [26]  [140/295]  eta: 0:00:42  lr: 0.003557  min_lr: 0.003557  loss: 2.6084 (2.7120)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0016  max mem: 3500\n",
            "Epoch: [26]  [150/295]  eta: 0:00:40  lr: 0.003554  min_lr: 0.003554  loss: 2.6710 (2.7091)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0010  max mem: 3500\n",
            "Epoch: [26]  [160/295]  eta: 0:00:37  lr: 0.003548  min_lr: 0.003548  loss: 2.6710 (2.7046)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0011  max mem: 3500\n",
            "Epoch: [26]  [170/295]  eta: 0:00:34  lr: 0.003544  min_lr: 0.003544  loss: 2.6287 (2.7011)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0030  max mem: 3500\n",
            "Epoch: [26]  [180/295]  eta: 0:00:31  lr: 0.003539  min_lr: 0.003539  loss: 2.6873 (2.7008)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0037  max mem: 3500\n",
            "Epoch: [26]  [190/295]  eta: 0:00:28  lr: 0.003535  min_lr: 0.003535  loss: 2.6873 (2.6961)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0031  max mem: 3500\n",
            "Epoch: [26]  [200/295]  eta: 0:00:25  lr: 0.003530  min_lr: 0.003530  loss: 2.5875 (2.6969)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0027  max mem: 3500\n",
            "Epoch: [26]  [210/295]  eta: 0:00:23  lr: 0.003526  min_lr: 0.003526  loss: 2.7174 (2.6964)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0018  max mem: 3500\n",
            "Epoch: [26]  [220/295]  eta: 0:00:20  lr: 0.003520  min_lr: 0.003520  loss: 2.7174 (2.6976)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0020  max mem: 3500\n",
            "Epoch: [26]  [230/295]  eta: 0:00:17  lr: 0.003517  min_lr: 0.003517  loss: 2.7415 (2.6983)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0015  max mem: 3500\n",
            "Epoch: [26]  [240/295]  eta: 0:00:14  lr: 0.003511  min_lr: 0.003511  loss: 2.7085 (2.6975)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0017  max mem: 3500\n",
            "Epoch: [26]  [250/295]  eta: 0:00:12  lr: 0.003507  min_lr: 0.003507  loss: 2.6419 (2.6972)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0037  max mem: 3500\n",
            "Epoch: [26]  [260/295]  eta: 0:00:09  lr: 0.003502  min_lr: 0.003502  loss: 2.6952 (2.6987)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0042  max mem: 3500\n",
            "Epoch: [26]  [270/295]  eta: 0:00:06  lr: 0.003498  min_lr: 0.003498  loss: 2.7358 (2.7011)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0024  max mem: 3500\n",
            "Epoch: [26]  [280/295]  eta: 0:00:04  lr: 0.003492  min_lr: 0.003492  loss: 2.7891 (2.7045)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0011  max mem: 3500\n",
            "Epoch: [26]  [290/295]  eta: 0:00:01  lr: 0.003488  min_lr: 0.003488  loss: 2.7435 (2.7050)  weight_decay: 0.0500 (0.0500)  time: 0.2568  data: 0.0005  max mem: 3500\n",
            "Epoch: [26]  [294/295]  eta: 0:00:00  lr: 0.003488  min_lr: 0.003488  loss: 2.7435 (2.7055)  weight_decay: 0.0500 (0.0500)  time: 0.2189  data: 0.0001  max mem: 3500\n",
            "Epoch: [26] Total time: 0:01:19 (0.2683 s / it)\n",
            "Averaged stats: lr: 0.003488  min_lr: 0.003488  loss: 2.7435 (2.7055)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:32  loss: 1.0188 (1.0188)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 2.5907  data: 2.4342  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 1.2577 (1.1906)  acc1: 64.5833 (69.5076)  acc5: 93.7500 (91.8561)  time: 0.3744  data: 0.2363  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 1.1157 (1.1266)  acc1: 70.8333 (71.6270)  acc5: 93.7500 (94.3452)  time: 0.1539  data: 0.0199  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 1.1773 (1.4661)  acc1: 64.5833 (56.8548)  acc5: 93.7500 (87.2312)  time: 0.1397  data: 0.0132  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.3377 (1.4349)  acc1: 62.5000 (58.2317)  acc5: 89.5833 (88.8211)  time: 0.1237  data: 0.0038  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.2432 (1.4143)  acc1: 64.5833 (59.3546)  acc5: 95.8333 (90.1144)  time: 0.1238  data: 0.0036  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.2308 (1.3887)  acc1: 60.4167 (60.1093)  acc5: 95.8333 (90.8470)  time: 0.1237  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.2135 (1.3673)  acc1: 60.4167 (60.5927)  acc5: 95.8333 (91.6373)  time: 0.1207  data: 0.0040  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1899 (1.3095)  acc1: 68.7500 (62.9115)  acc5: 95.8333 (92.1039)  time: 0.1181  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1881 (1.3077)  acc1: 68.7500 (62.9809)  acc5: 95.8333 (92.0255)  time: 0.1168  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1639 s / it)\n",
            "* Acc@1 62.981 Acc@5 92.025 loss 1.308\n",
            "Accuracy of the model on the 3925 test images: 63.0%\n",
            "Max accuracy: 62.98%\n",
            "Test:  [ 0/82]  eta: 0:04:15  loss: 4.9375 (4.9375)  acc1: 4.1667 (4.1667)  acc5: 68.7500 (68.7500)  time: 3.1219  data: 2.9341  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 4.7272 (4.8062)  acc1: 4.1667 (9.4697)  acc5: 68.7500 (70.4545)  time: 0.4453  data: 0.3095  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 4.7258 (4.7957)  acc1: 14.5833 (13.7897)  acc5: 68.7500 (69.6429)  time: 0.1646  data: 0.0312  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 5.2851 (5.1214)  acc1: 14.5833 (10.8871)  acc5: 58.3333 (58.1317)  time: 0.1593  data: 0.0224  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 6.0107 (5.2801)  acc1: 2.0833 (9.7053)  acc5: 43.7500 (55.7419)  time: 0.1553  data: 0.0173  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.1824 (5.1360)  acc1: 12.5000 (13.8072)  acc5: 58.3333 (58.4150)  time: 0.1338  data: 0.0040  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5838 (5.1271)  acc1: 18.7500 (13.3538)  acc5: 66.6667 (58.9822)  time: 0.1231  data: 0.0029  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.7932 (5.1441)  acc1: 8.3333 (13.8791)  acc5: 62.5000 (58.8615)  time: 0.1205  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 4.3318 (4.8445)  acc1: 33.3333 (20.0874)  acc5: 70.8333 (61.8570)  time: 0.1191  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 4.2943 (4.8162)  acc1: 39.5833 (20.5605)  acc5: 72.9167 (62.0892)  time: 0.1176  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1804 s / it)\n",
            "* Acc@1 20.561 Acc@5 62.089 loss 4.816\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [27]  [  0/295]  eta: 0:07:05  lr: 0.003486  min_lr: 0.003486  loss: 2.8653 (2.8653)  weight_decay: 0.0500 (0.0500)  time: 1.4441  data: 1.0909  max mem: 3500\n",
            "Epoch: [27]  [ 10/295]  eta: 0:01:49  lr: 0.003483  min_lr: 0.003483  loss: 2.7078 (2.6993)  weight_decay: 0.0500 (0.0500)  time: 0.3859  data: 0.1086  max mem: 3500\n",
            "Epoch: [27]  [ 20/295]  eta: 0:01:31  lr: 0.003477  min_lr: 0.003477  loss: 2.7046 (2.7003)  weight_decay: 0.0500 (0.0500)  time: 0.2775  data: 0.0075  max mem: 3500\n",
            "Epoch: [27]  [ 30/295]  eta: 0:01:23  lr: 0.003473  min_lr: 0.003473  loss: 2.7319 (2.7116)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0043  max mem: 3500\n",
            "Epoch: [27]  [ 40/295]  eta: 0:01:17  lr: 0.003467  min_lr: 0.003467  loss: 2.7319 (2.7018)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0031  max mem: 3500\n",
            "Epoch: [27]  [ 50/295]  eta: 0:01:12  lr: 0.003463  min_lr: 0.003463  loss: 2.6166 (2.6971)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0015  max mem: 3500\n",
            "Epoch: [27]  [ 60/295]  eta: 0:01:08  lr: 0.003457  min_lr: 0.003457  loss: 2.6166 (2.7028)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0005  max mem: 3500\n",
            "Epoch: [27]  [ 70/295]  eta: 0:01:04  lr: 0.003453  min_lr: 0.003453  loss: 2.5991 (2.6834)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0011  max mem: 3500\n",
            "Epoch: [27]  [ 80/295]  eta: 0:01:01  lr: 0.003447  min_lr: 0.003447  loss: 2.6080 (2.6830)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0031  max mem: 3500\n",
            "Epoch: [27]  [ 90/295]  eta: 0:00:58  lr: 0.003443  min_lr: 0.003443  loss: 2.6589 (2.6787)  weight_decay: 0.0500 (0.0500)  time: 0.2781  data: 0.0043  max mem: 3500\n",
            "Epoch: [27]  [100/295]  eta: 0:00:55  lr: 0.003437  min_lr: 0.003437  loss: 2.6752 (2.6851)  weight_decay: 0.0500 (0.0500)  time: 0.2756  data: 0.0051  max mem: 3500\n",
            "Epoch: [27]  [110/295]  eta: 0:00:52  lr: 0.003433  min_lr: 0.003433  loss: 2.6752 (2.6819)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0034  max mem: 3500\n",
            "Epoch: [27]  [120/295]  eta: 0:00:49  lr: 0.003427  min_lr: 0.003427  loss: 2.6153 (2.6715)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0013  max mem: 3500\n",
            "Epoch: [27]  [130/295]  eta: 0:00:45  lr: 0.003423  min_lr: 0.003423  loss: 2.6153 (2.6749)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0027  max mem: 3500\n",
            "Epoch: [27]  [140/295]  eta: 0:00:43  lr: 0.003417  min_lr: 0.003417  loss: 2.7015 (2.6765)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0024  max mem: 3500\n",
            "Epoch: [27]  [150/295]  eta: 0:00:40  lr: 0.003413  min_lr: 0.003413  loss: 2.6935 (2.6727)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0008  max mem: 3500\n",
            "Epoch: [27]  [160/295]  eta: 0:00:37  lr: 0.003407  min_lr: 0.003407  loss: 2.6443 (2.6686)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0012  max mem: 3500\n",
            "Epoch: [27]  [170/295]  eta: 0:00:34  lr: 0.003403  min_lr: 0.003403  loss: 2.6244 (2.6642)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0023  max mem: 3500\n",
            "Epoch: [27]  [180/295]  eta: 0:00:31  lr: 0.003397  min_lr: 0.003397  loss: 2.5808 (2.6614)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0021  max mem: 3500\n",
            "Epoch: [27]  [190/295]  eta: 0:00:28  lr: 0.003393  min_lr: 0.003393  loss: 2.7315 (2.6681)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0011  max mem: 3500\n",
            "Epoch: [27]  [200/295]  eta: 0:00:25  lr: 0.003387  min_lr: 0.003387  loss: 2.7315 (2.6705)  weight_decay: 0.0500 (0.0500)  time: 0.2571  data: 0.0009  max mem: 3500\n",
            "Epoch: [27]  [210/295]  eta: 0:00:23  lr: 0.003383  min_lr: 0.003383  loss: 2.5884 (2.6693)  weight_decay: 0.0500 (0.0500)  time: 0.2568  data: 0.0007  max mem: 3500\n",
            "Epoch: [27]  [220/295]  eta: 0:00:20  lr: 0.003376  min_lr: 0.003376  loss: 2.7218 (2.6750)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0014  max mem: 3500\n",
            "Epoch: [27]  [230/295]  eta: 0:00:17  lr: 0.003372  min_lr: 0.003372  loss: 2.8143 (2.6808)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0045  max mem: 3500\n",
            "Epoch: [27]  [240/295]  eta: 0:00:14  lr: 0.003366  min_lr: 0.003366  loss: 2.7892 (2.6836)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0053  max mem: 3500\n",
            "Epoch: [27]  [250/295]  eta: 0:00:12  lr: 0.003362  min_lr: 0.003362  loss: 2.7239 (2.6863)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0026  max mem: 3500\n",
            "Epoch: [27]  [260/295]  eta: 0:00:09  lr: 0.003355  min_lr: 0.003355  loss: 2.6948 (2.6837)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0010  max mem: 3500\n",
            "Epoch: [27]  [270/295]  eta: 0:00:06  lr: 0.003351  min_lr: 0.003351  loss: 2.6361 (2.6844)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0012  max mem: 3500\n",
            "Epoch: [27]  [280/295]  eta: 0:00:04  lr: 0.003345  min_lr: 0.003345  loss: 2.6838 (2.6853)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0011  max mem: 3500\n",
            "Epoch: [27]  [290/295]  eta: 0:00:01  lr: 0.003341  min_lr: 0.003341  loss: 2.7535 (2.6866)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0002  max mem: 3500\n",
            "Epoch: [27]  [294/295]  eta: 0:00:00  lr: 0.003341  min_lr: 0.003341  loss: 2.7535 (2.6866)  weight_decay: 0.0500 (0.0500)  time: 0.2208  data: 0.0001  max mem: 3500\n",
            "Epoch: [27] Total time: 0:01:19 (0.2685 s / it)\n",
            "Averaged stats: lr: 0.003341  min_lr: 0.003341  loss: 2.7535 (2.6866)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:28  loss: 0.9908 (0.9908)  acc1: 79.1667 (79.1667)  acc5: 91.6667 (91.6667)  time: 2.5461  data: 2.3843  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 1.2439 (1.2505)  acc1: 68.7500 (66.6667)  acc5: 93.7500 (92.9924)  time: 0.3424  data: 0.2188  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 1.1755 (1.1829)  acc1: 68.7500 (67.6587)  acc5: 93.7500 (94.4444)  time: 0.1227  data: 0.0032  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 1.3303 (1.4874)  acc1: 58.3333 (53.7634)  acc5: 89.5833 (90.8602)  time: 0.1232  data: 0.0040  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.0618 (1.3789)  acc1: 68.7500 (58.1301)  acc5: 93.7500 (92.5813)  time: 0.1238  data: 0.0049  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.0698 (1.3482)  acc1: 70.8333 (59.5997)  acc5: 100.0000 (93.4641)  time: 0.1244  data: 0.0064  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.3383 (1.3861)  acc1: 56.2500 (57.8210)  acc5: 95.8333 (92.9986)  time: 0.1232  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.5125 (1.4073)  acc1: 52.0833 (57.1009)  acc5: 93.7500 (92.9577)  time: 0.1199  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3179 (1.3328)  acc1: 58.3333 (59.5936)  acc5: 97.9167 (93.5957)  time: 0.1177  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2286 (1.3261)  acc1: 58.3333 (59.8471)  acc5: 97.9167 (93.5541)  time: 0.1164  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1569 s / it)\n",
            "* Acc@1 59.847 Acc@5 93.554 loss 1.326\n",
            "Accuracy of the model on the 3925 test images: 59.8%\n",
            "Max accuracy: 62.98%\n",
            "Test:  [ 0/82]  eta: 0:03:35  loss: 4.8440 (4.8440)  acc1: 6.2500 (6.2500)  acc5: 68.7500 (68.7500)  time: 2.6330  data: 2.4664  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 4.6227 (4.7112)  acc1: 6.2500 (9.8485)  acc5: 68.7500 (70.6439)  time: 0.3953  data: 0.2619  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 4.6167 (4.7042)  acc1: 14.5833 (13.8889)  acc5: 68.7500 (70.3373)  time: 0.1538  data: 0.0257  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 5.2078 (5.0456)  acc1: 12.5000 (10.8199)  acc5: 58.3333 (60.0134)  time: 0.1478  data: 0.0228  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 6.0073 (5.2196)  acc1: 2.0833 (9.6037)  acc5: 41.6667 (57.2663)  time: 0.1425  data: 0.0199  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.1535 (5.0768)  acc1: 10.4167 (13.6029)  acc5: 58.3333 (59.6405)  time: 0.1240  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5585 (5.0774)  acc1: 18.7500 (13.0806)  acc5: 66.6667 (60.1093)  time: 0.1225  data: 0.0038  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6973 (5.0906)  acc1: 8.3333 (13.6737)  acc5: 64.5833 (59.8592)  time: 0.1207  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 4.1593 (4.7839)  acc1: 33.3333 (19.9846)  acc5: 75.0000 (62.8601)  time: 0.1186  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 4.1287 (4.7552)  acc1: 39.5833 (20.4586)  acc5: 75.0000 (63.0828)  time: 0.1176  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1691 s / it)\n",
            "* Acc@1 20.459 Acc@5 63.083 loss 4.755\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [28]  [  0/295]  eta: 0:08:25  lr: 0.003338  min_lr: 0.003338  loss: 2.8627 (2.8627)  weight_decay: 0.0500 (0.0500)  time: 1.7119  data: 1.3570  max mem: 3500\n",
            "Epoch: [28]  [ 10/295]  eta: 0:01:57  lr: 0.003334  min_lr: 0.003334  loss: 2.6730 (2.6646)  weight_decay: 0.0500 (0.0500)  time: 0.4121  data: 0.1263  max mem: 3500\n",
            "Epoch: [28]  [ 20/295]  eta: 0:01:35  lr: 0.003328  min_lr: 0.003328  loss: 2.6190 (2.6481)  weight_decay: 0.0500 (0.0500)  time: 0.2799  data: 0.0040  max mem: 3500\n",
            "Epoch: [28]  [ 30/295]  eta: 0:01:25  lr: 0.003323  min_lr: 0.003323  loss: 2.6188 (2.6349)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0037  max mem: 3500\n",
            "Epoch: [28]  [ 40/295]  eta: 0:01:18  lr: 0.003317  min_lr: 0.003317  loss: 2.6300 (2.6372)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0014  max mem: 3500\n",
            "Epoch: [28]  [ 50/295]  eta: 0:01:13  lr: 0.003313  min_lr: 0.003313  loss: 2.6212 (2.6352)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0012  max mem: 3500\n",
            "Epoch: [28]  [ 60/295]  eta: 0:01:08  lr: 0.003306  min_lr: 0.003306  loss: 2.6065 (2.6496)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0013  max mem: 3500\n",
            "Epoch: [28]  [ 70/295]  eta: 0:01:04  lr: 0.003302  min_lr: 0.003302  loss: 2.7430 (2.6701)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0011  max mem: 3500\n",
            "Epoch: [28]  [ 80/295]  eta: 0:01:01  lr: 0.003295  min_lr: 0.003295  loss: 2.7415 (2.6678)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0046  max mem: 3500\n",
            "Epoch: [28]  [ 90/295]  eta: 0:00:58  lr: 0.003291  min_lr: 0.003291  loss: 2.6577 (2.6668)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0075  max mem: 3500\n",
            "Epoch: [28]  [100/295]  eta: 0:00:55  lr: 0.003284  min_lr: 0.003284  loss: 2.6844 (2.6663)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0044  max mem: 3500\n",
            "Epoch: [28]  [110/295]  eta: 0:00:52  lr: 0.003280  min_lr: 0.003280  loss: 2.7293 (2.6723)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0008  max mem: 3500\n",
            "Epoch: [28]  [120/295]  eta: 0:00:48  lr: 0.003273  min_lr: 0.003273  loss: 2.7360 (2.6688)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0004  max mem: 3500\n",
            "Epoch: [28]  [130/295]  eta: 0:00:45  lr: 0.003269  min_lr: 0.003269  loss: 2.7259 (2.6747)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0008  max mem: 3500\n",
            "Epoch: [28]  [140/295]  eta: 0:00:42  lr: 0.003262  min_lr: 0.003262  loss: 2.7880 (2.6763)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0015  max mem: 3500\n",
            "Epoch: [28]  [150/295]  eta: 0:00:40  lr: 0.003258  min_lr: 0.003258  loss: 2.7708 (2.6811)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0032  max mem: 3500\n",
            "Epoch: [28]  [160/295]  eta: 0:00:37  lr: 0.003251  min_lr: 0.003251  loss: 2.6735 (2.6789)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0043  max mem: 3500\n",
            "Epoch: [28]  [170/295]  eta: 0:00:34  lr: 0.003247  min_lr: 0.003247  loss: 2.6450 (2.6806)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0032  max mem: 3500\n",
            "Epoch: [28]  [180/295]  eta: 0:00:31  lr: 0.003240  min_lr: 0.003240  loss: 2.6623 (2.6813)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0016  max mem: 3500\n",
            "Epoch: [28]  [190/295]  eta: 0:00:28  lr: 0.003235  min_lr: 0.003235  loss: 2.7351 (2.6825)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0008  max mem: 3500\n",
            "Epoch: [28]  [200/295]  eta: 0:00:25  lr: 0.003228  min_lr: 0.003228  loss: 2.7649 (2.6859)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0012  max mem: 3500\n",
            "Epoch: [28]  [210/295]  eta: 0:00:23  lr: 0.003224  min_lr: 0.003224  loss: 2.6425 (2.6849)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0024  max mem: 3500\n",
            "Epoch: [28]  [220/295]  eta: 0:00:20  lr: 0.003217  min_lr: 0.003217  loss: 2.7313 (2.6909)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0040  max mem: 3500\n",
            "Epoch: [28]  [230/295]  eta: 0:00:17  lr: 0.003213  min_lr: 0.003213  loss: 2.7228 (2.6910)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0037  max mem: 3500\n",
            "Epoch: [28]  [240/295]  eta: 0:00:14  lr: 0.003206  min_lr: 0.003206  loss: 2.6691 (2.6909)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0018  max mem: 3500\n",
            "Epoch: [28]  [250/295]  eta: 0:00:12  lr: 0.003201  min_lr: 0.003201  loss: 2.6457 (2.6902)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0012  max mem: 3500\n",
            "Epoch: [28]  [260/295]  eta: 0:00:09  lr: 0.003194  min_lr: 0.003194  loss: 2.6318 (2.6879)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0026  max mem: 3500\n",
            "Epoch: [28]  [270/295]  eta: 0:00:06  lr: 0.003190  min_lr: 0.003190  loss: 2.6145 (2.6871)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0042  max mem: 3500\n",
            "Epoch: [28]  [280/295]  eta: 0:00:04  lr: 0.003183  min_lr: 0.003183  loss: 2.6953 (2.6879)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0027  max mem: 3500\n",
            "Epoch: [28]  [290/295]  eta: 0:00:01  lr: 0.003178  min_lr: 0.003178  loss: 2.6632 (2.6862)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0003  max mem: 3500\n",
            "Epoch: [28]  [294/295]  eta: 0:00:00  lr: 0.003178  min_lr: 0.003178  loss: 2.6016 (2.6855)  weight_decay: 0.0500 (0.0500)  time: 0.2239  data: 0.0002  max mem: 3500\n",
            "Epoch: [28] Total time: 0:01:19 (0.2693 s / it)\n",
            "Averaged stats: lr: 0.003178  min_lr: 0.003178  loss: 2.6016 (2.6855)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:34  loss: 0.7114 (0.7114)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 1.8882  data: 1.7066  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.8975 (0.9962)  acc1: 79.1667 (73.8636)  acc5: 95.8333 (96.2121)  time: 0.2895  data: 0.1599  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.0358 (1.1042)  acc1: 72.9167 (69.6429)  acc5: 95.8333 (95.3373)  time: 0.1262  data: 0.0040  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.3757 (1.3528)  acc1: 56.2500 (58.6022)  acc5: 91.6667 (93.1452)  time: 0.1225  data: 0.0027  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.2307 (1.3203)  acc1: 66.6667 (60.8232)  acc5: 93.7500 (93.7500)  time: 0.1236  data: 0.0043  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.2086 (1.3151)  acc1: 66.6667 (61.2337)  acc5: 95.8333 (94.0768)  time: 0.1249  data: 0.0068  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.1716 (1.2898)  acc1: 62.5000 (62.6025)  acc5: 93.7500 (93.7500)  time: 0.1231  data: 0.0051  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.1485 (1.2729)  acc1: 70.8333 (63.5857)  acc5: 95.8333 (93.9261)  time: 0.1196  data: 0.0014  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0072 (1.2220)  acc1: 75.0000 (65.7150)  acc5: 95.8333 (94.2644)  time: 0.1181  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0072 (1.2200)  acc1: 75.0000 (65.7580)  acc5: 95.8333 (94.2420)  time: 0.1164  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1508 s / it)\n",
            "* Acc@1 65.758 Acc@5 94.242 loss 1.220\n",
            "Accuracy of the model on the 3925 test images: 65.8%\n",
            "Max accuracy: 65.76%\n",
            "Test:  [ 0/82]  eta: 0:03:45  loss: 4.7483 (4.7483)  acc1: 6.2500 (6.2500)  acc5: 68.7500 (68.7500)  time: 2.7552  data: 2.5871  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 4.5202 (4.6195)  acc1: 6.2500 (9.4697)  acc5: 70.8333 (72.5379)  time: 0.3734  data: 0.2461  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 4.5201 (4.6198)  acc1: 14.5833 (13.2937)  acc5: 70.8333 (71.6270)  time: 0.1323  data: 0.0091  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 5.1522 (4.9777)  acc1: 12.5000 (10.4167)  acc5: 60.4167 (62.2312)  time: 0.1264  data: 0.0052  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 5.9974 (5.1640)  acc1: 2.0833 (9.3496)  acc5: 43.7500 (59.0955)  time: 0.1234  data: 0.0037  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 5.1410 (5.0251)  acc1: 10.4167 (13.1944)  acc5: 58.3333 (60.9886)  time: 0.1233  data: 0.0035  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5450 (5.0351)  acc1: 16.6667 (12.6025)  acc5: 66.6667 (61.1680)  time: 0.1243  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5572 (5.0437)  acc1: 8.3333 (13.2923)  acc5: 68.7500 (61.0329)  time: 0.1218  data: 0.0036  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.9901 (4.7306)  acc1: 35.4167 (19.8302)  acc5: 75.0000 (63.9403)  time: 0.1179  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 3.9664 (4.7017)  acc1: 39.5833 (20.3312)  acc5: 79.1667 (64.1529)  time: 0.1164  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1610 s / it)\n",
            "* Acc@1 20.331 Acc@5 64.153 loss 4.702\n",
            "Accuracy of the model EMA on 3925 test images: 20.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [29]  [  0/295]  eta: 0:12:47  lr: 0.003176  min_lr: 0.003176  loss: 2.7460 (2.7460)  weight_decay: 0.0500 (0.0500)  time: 2.6029  data: 2.1640  max mem: 3500\n",
            "Epoch: [29]  [ 10/295]  eta: 0:02:25  lr: 0.003171  min_lr: 0.003171  loss: 2.5935 (2.5803)  weight_decay: 0.0500 (0.0500)  time: 0.5109  data: 0.1989  max mem: 3500\n",
            "Epoch: [29]  [ 20/295]  eta: 0:01:48  lr: 0.003164  min_lr: 0.003164  loss: 2.5935 (2.5960)  weight_decay: 0.0500 (0.0500)  time: 0.2848  data: 0.0020  max mem: 3500\n",
            "Epoch: [29]  [ 30/295]  eta: 0:01:33  lr: 0.003159  min_lr: 0.003159  loss: 2.6625 (2.6245)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0012  max mem: 3500\n",
            "Epoch: [29]  [ 40/295]  eta: 0:01:24  lr: 0.003152  min_lr: 0.003152  loss: 2.7628 (2.6640)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0017  max mem: 3500\n",
            "Epoch: [29]  [ 50/295]  eta: 0:01:17  lr: 0.003148  min_lr: 0.003148  loss: 2.7299 (2.6671)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0018  max mem: 3500\n",
            "Epoch: [29]  [ 60/295]  eta: 0:01:12  lr: 0.003141  min_lr: 0.003141  loss: 2.6052 (2.6601)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0019  max mem: 3500\n",
            "Epoch: [29]  [ 70/295]  eta: 0:01:08  lr: 0.003136  min_lr: 0.003136  loss: 2.5798 (2.6477)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0027  max mem: 3500\n",
            "Epoch: [29]  [ 80/295]  eta: 0:01:04  lr: 0.003129  min_lr: 0.003129  loss: 2.5798 (2.6507)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0030  max mem: 3500\n",
            "Epoch: [29]  [ 90/295]  eta: 0:01:00  lr: 0.003124  min_lr: 0.003124  loss: 2.6719 (2.6573)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0029  max mem: 3500\n",
            "Epoch: [29]  [100/295]  eta: 0:00:57  lr: 0.003117  min_lr: 0.003117  loss: 2.6864 (2.6574)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0017  max mem: 3500\n",
            "Epoch: [29]  [110/295]  eta: 0:00:53  lr: 0.003112  min_lr: 0.003112  loss: 2.5946 (2.6524)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0010  max mem: 3500\n",
            "Epoch: [29]  [120/295]  eta: 0:00:50  lr: 0.003105  min_lr: 0.003105  loss: 2.6154 (2.6523)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0006  max mem: 3500\n",
            "Epoch: [29]  [130/295]  eta: 0:00:47  lr: 0.003100  min_lr: 0.003100  loss: 2.7323 (2.6625)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0019  max mem: 3500\n",
            "Epoch: [29]  [140/295]  eta: 0:00:44  lr: 0.003093  min_lr: 0.003093  loss: 2.7354 (2.6690)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0034  max mem: 3500\n",
            "Epoch: [29]  [150/295]  eta: 0:00:41  lr: 0.003088  min_lr: 0.003088  loss: 2.6991 (2.6674)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0029  max mem: 3500\n",
            "Epoch: [29]  [160/295]  eta: 0:00:38  lr: 0.003081  min_lr: 0.003081  loss: 2.5911 (2.6655)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0019  max mem: 3500\n",
            "Epoch: [29]  [170/295]  eta: 0:00:35  lr: 0.003076  min_lr: 0.003076  loss: 2.5798 (2.6637)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0015  max mem: 3500\n",
            "Epoch: [29]  [180/295]  eta: 0:00:32  lr: 0.003069  min_lr: 0.003069  loss: 2.6782 (2.6653)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0023  max mem: 3500\n",
            "Epoch: [29]  [190/295]  eta: 0:00:29  lr: 0.003064  min_lr: 0.003064  loss: 2.6329 (2.6503)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0032  max mem: 3500\n",
            "Epoch: [29]  [200/295]  eta: 0:00:26  lr: 0.003057  min_lr: 0.003057  loss: 2.5017 (2.6496)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0034  max mem: 3500\n",
            "Epoch: [29]  [210/295]  eta: 0:00:23  lr: 0.003052  min_lr: 0.003052  loss: 2.7599 (2.6567)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0032  max mem: 3500\n",
            "Epoch: [29]  [220/295]  eta: 0:00:20  lr: 0.003045  min_lr: 0.003045  loss: 2.7519 (2.6584)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0035  max mem: 3500\n",
            "Epoch: [29]  [230/295]  eta: 0:00:17  lr: 0.003040  min_lr: 0.003040  loss: 2.6664 (2.6572)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0027  max mem: 3500\n",
            "Epoch: [29]  [240/295]  eta: 0:00:15  lr: 0.003032  min_lr: 0.003032  loss: 2.6103 (2.6561)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0022  max mem: 3500\n",
            "Epoch: [29]  [250/295]  eta: 0:00:12  lr: 0.003027  min_lr: 0.003027  loss: 2.7182 (2.6595)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0021  max mem: 3500\n",
            "Epoch: [29]  [260/295]  eta: 0:00:09  lr: 0.003020  min_lr: 0.003020  loss: 2.7182 (2.6591)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0018  max mem: 3500\n",
            "Epoch: [29]  [270/295]  eta: 0:00:06  lr: 0.003015  min_lr: 0.003015  loss: 2.7175 (2.6641)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0024  max mem: 3500\n",
            "Epoch: [29]  [280/295]  eta: 0:00:04  lr: 0.003008  min_lr: 0.003008  loss: 2.7175 (2.6644)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0023  max mem: 3500\n",
            "Epoch: [29]  [290/295]  eta: 0:00:01  lr: 0.003003  min_lr: 0.003003  loss: 2.7095 (2.6669)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0009  max mem: 3500\n",
            "Epoch: [29]  [294/295]  eta: 0:00:00  lr: 0.003003  min_lr: 0.003003  loss: 2.7241 (2.6675)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0001  max mem: 3500\n",
            "Epoch: [29] Total time: 0:01:20 (0.2722 s / it)\n",
            "Averaged stats: lr: 0.003003  min_lr: 0.003003  loss: 2.7241 (2.6675)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:35  loss: 1.0164 (1.0164)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 1.8960  data: 1.7306  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.2470 (1.2365)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (94.1288)  time: 0.2857  data: 0.1619  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 1.1515 (1.1207)  acc1: 72.9167 (73.4127)  acc5: 97.9167 (95.8333)  time: 0.1246  data: 0.0037  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.1655 (1.4056)  acc1: 70.8333 (58.2661)  acc5: 91.6667 (92.2043)  time: 0.1243  data: 0.0022  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.1789 (1.3435)  acc1: 64.5833 (61.7886)  acc5: 93.7500 (92.9370)  time: 0.1325  data: 0.0038  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.1789 (1.3659)  acc1: 72.9167 (61.2337)  acc5: 95.8333 (93.0556)  time: 0.1467  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.2226 (1.3331)  acc1: 66.6667 (62.7732)  acc5: 95.8333 (93.6475)  time: 0.1479  data: 0.0014  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.1318 (1.3053)  acc1: 68.7500 (63.9965)  acc5: 95.8333 (93.9554)  time: 0.1415  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0914 (1.2603)  acc1: 75.0000 (65.5864)  acc5: 95.8333 (94.0072)  time: 0.1294  data: 0.0037  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0895 (1.2583)  acc1: 75.0000 (65.6306)  acc5: 95.8333 (93.9618)  time: 0.1272  data: 0.0037  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1605 s / it)\n",
            "* Acc@1 65.631 Acc@5 93.962 loss 1.258\n",
            "Accuracy of the model on the 3925 test images: 65.6%\n",
            "Max accuracy: 65.76%\n",
            "Test:  [ 0/82]  eta: 0:02:39  loss: 4.6692 (4.6692)  acc1: 6.2500 (6.2500)  acc5: 68.7500 (68.7500)  time: 1.9456  data: 1.7735  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 4.4590 (4.5435)  acc1: 6.2500 (9.4697)  acc5: 72.9167 (73.8636)  time: 0.2873  data: 0.1634  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 4.4385 (4.5456)  acc1: 16.6667 (13.3929)  acc5: 72.9167 (73.0159)  time: 0.1210  data: 0.0022  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 5.0911 (4.9182)  acc1: 14.5833 (10.5511)  acc5: 62.5000 (63.9113)  time: 0.1226  data: 0.0030  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.9772 (5.1133)  acc1: 2.0833 (9.4004)  acc5: 41.6667 (60.5691)  time: 0.1240  data: 0.0034  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 5.1292 (4.9784)  acc1: 10.4167 (13.1536)  acc5: 58.3333 (62.2141)  time: 0.1230  data: 0.0041  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5122 (4.9969)  acc1: 14.5833 (12.3634)  acc5: 66.6667 (62.2609)  time: 0.1222  data: 0.0049  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5154 (5.0000)  acc1: 8.3333 (13.1162)  acc5: 70.8333 (62.2359)  time: 0.1197  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.8276 (4.6810)  acc1: 35.4167 (19.7531)  acc5: 79.1667 (65.0463)  time: 0.1180  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 3.8066 (4.6519)  acc1: 39.5833 (20.2548)  acc5: 81.2500 (65.2484)  time: 0.1172  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1506 s / it)\n",
            "* Acc@1 20.255 Acc@5 65.248 loss 4.652\n",
            "Accuracy of the model EMA on 3925 test images: 20.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [30]  [  0/295]  eta: 0:12:56  lr: 0.003000  min_lr: 0.003000  loss: 2.7299 (2.7299)  weight_decay: 0.0500 (0.0500)  time: 2.6335  data: 2.0495  max mem: 3500\n",
            "Epoch: [30]  [ 10/295]  eta: 0:02:27  lr: 0.002995  min_lr: 0.002995  loss: 2.7122 (2.6903)  weight_decay: 0.0500 (0.0500)  time: 0.5171  data: 0.1881  max mem: 3500\n",
            "Epoch: [30]  [ 20/295]  eta: 0:01:48  lr: 0.002988  min_lr: 0.002988  loss: 2.6525 (2.6609)  weight_decay: 0.0500 (0.0500)  time: 0.2841  data: 0.0014  max mem: 3500\n",
            "Epoch: [30]  [ 30/295]  eta: 0:01:33  lr: 0.002983  min_lr: 0.002983  loss: 2.6343 (2.6719)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0009  max mem: 3500\n",
            "Epoch: [30]  [ 40/295]  eta: 0:01:24  lr: 0.002975  min_lr: 0.002975  loss: 2.6515 (2.6666)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0008  max mem: 3500\n",
            "Epoch: [30]  [ 50/295]  eta: 0:01:18  lr: 0.002970  min_lr: 0.002970  loss: 2.6623 (2.6858)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0029  max mem: 3500\n",
            "Epoch: [30]  [ 60/295]  eta: 0:01:13  lr: 0.002963  min_lr: 0.002963  loss: 2.7230 (2.6734)  weight_decay: 0.0500 (0.0500)  time: 0.2765  data: 0.0057  max mem: 3500\n",
            "Epoch: [30]  [ 70/295]  eta: 0:01:09  lr: 0.002958  min_lr: 0.002958  loss: 2.6446 (2.6729)  weight_decay: 0.0500 (0.0500)  time: 0.2755  data: 0.0033  max mem: 3500\n",
            "Epoch: [30]  [ 80/295]  eta: 0:01:05  lr: 0.002950  min_lr: 0.002950  loss: 2.6446 (2.6684)  weight_decay: 0.0500 (0.0500)  time: 0.2756  data: 0.0022  max mem: 3500\n",
            "Epoch: [30]  [ 90/295]  eta: 0:01:01  lr: 0.002945  min_lr: 0.002945  loss: 2.6448 (2.6724)  weight_decay: 0.0500 (0.0500)  time: 0.2771  data: 0.0031  max mem: 3500\n",
            "Epoch: [30]  [100/295]  eta: 0:00:57  lr: 0.002938  min_lr: 0.002938  loss: 2.6654 (2.6710)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0018  max mem: 3500\n",
            "Epoch: [30]  [110/295]  eta: 0:00:54  lr: 0.002932  min_lr: 0.002932  loss: 2.6756 (2.6720)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0018  max mem: 3500\n",
            "Epoch: [30]  [120/295]  eta: 0:00:50  lr: 0.002925  min_lr: 0.002925  loss: 2.7510 (2.6720)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0021  max mem: 3500\n",
            "Epoch: [30]  [130/295]  eta: 0:00:47  lr: 0.002920  min_lr: 0.002920  loss: 2.7333 (2.6691)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0029  max mem: 3500\n",
            "Epoch: [30]  [140/295]  eta: 0:00:44  lr: 0.002912  min_lr: 0.002912  loss: 2.6214 (2.6649)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0055  max mem: 3500\n",
            "Epoch: [30]  [150/295]  eta: 0:00:41  lr: 0.002907  min_lr: 0.002907  loss: 2.5393 (2.6538)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0059  max mem: 3500\n",
            "Epoch: [30]  [160/295]  eta: 0:00:38  lr: 0.002899  min_lr: 0.002899  loss: 2.5705 (2.6557)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0031  max mem: 3500\n",
            "Epoch: [30]  [170/295]  eta: 0:00:35  lr: 0.002894  min_lr: 0.002894  loss: 2.6926 (2.6565)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0020  max mem: 3500\n",
            "Epoch: [30]  [180/295]  eta: 0:00:32  lr: 0.002886  min_lr: 0.002886  loss: 2.6456 (2.6546)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0019  max mem: 3500\n",
            "Epoch: [30]  [190/295]  eta: 0:00:29  lr: 0.002881  min_lr: 0.002881  loss: 2.5895 (2.6480)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0018  max mem: 3500\n",
            "Epoch: [30]  [200/295]  eta: 0:00:26  lr: 0.002874  min_lr: 0.002874  loss: 2.5979 (2.6468)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0015  max mem: 3500\n",
            "Epoch: [30]  [210/295]  eta: 0:00:23  lr: 0.002868  min_lr: 0.002868  loss: 2.5985 (2.6472)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0009  max mem: 3500\n",
            "Epoch: [30]  [220/295]  eta: 0:00:20  lr: 0.002861  min_lr: 0.002861  loss: 2.6475 (2.6477)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0015  max mem: 3500\n",
            "Epoch: [30]  [230/295]  eta: 0:00:18  lr: 0.002855  min_lr: 0.002855  loss: 2.6193 (2.6415)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0021  max mem: 3500\n",
            "Epoch: [30]  [240/295]  eta: 0:00:15  lr: 0.002848  min_lr: 0.002848  loss: 2.4880 (2.6392)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0019  max mem: 3500\n",
            "Epoch: [30]  [250/295]  eta: 0:00:12  lr: 0.002842  min_lr: 0.002842  loss: 2.6263 (2.6419)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0021  max mem: 3500\n",
            "Epoch: [30]  [260/295]  eta: 0:00:09  lr: 0.002835  min_lr: 0.002835  loss: 2.7480 (2.6449)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0019  max mem: 3500\n",
            "Epoch: [30]  [270/295]  eta: 0:00:06  lr: 0.002829  min_lr: 0.002829  loss: 2.7194 (2.6485)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0027  max mem: 3500\n",
            "Epoch: [30]  [280/295]  eta: 0:00:04  lr: 0.002822  min_lr: 0.002822  loss: 2.7400 (2.6507)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0027  max mem: 3500\n",
            "Epoch: [30]  [290/295]  eta: 0:00:01  lr: 0.002816  min_lr: 0.002816  loss: 2.7206 (2.6528)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0008  max mem: 3500\n",
            "Epoch: [30]  [294/295]  eta: 0:00:00  lr: 0.002816  min_lr: 0.002816  loss: 2.7416 (2.6535)  weight_decay: 0.0500 (0.0500)  time: 0.2217  data: 0.0002  max mem: 3500\n",
            "Epoch: [30] Total time: 0:01:20 (0.2727 s / it)\n",
            "Averaged stats: lr: 0.002816  min_lr: 0.002816  loss: 2.7416 (2.6535)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:13  loss: 0.6453 (0.6453)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 1.6248  data: 1.4632  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.7854 (0.8610)  acc1: 85.4167 (81.8182)  acc5: 95.8333 (96.0227)  time: 0.2841  data: 0.1595  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 1.0527 (1.0311)  acc1: 72.9167 (75.8929)  acc5: 95.8333 (96.1310)  time: 0.1361  data: 0.0161  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.3613 (1.2434)  acc1: 60.4167 (64.8522)  acc5: 95.8333 (96.1694)  time: 0.1221  data: 0.0027  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 1.3480 (1.2527)  acc1: 66.6667 (65.8537)  acc5: 97.9167 (96.5447)  time: 0.1220  data: 0.0036  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.3211 (1.2927)  acc1: 68.7500 (64.9510)  acc5: 97.9167 (96.2827)  time: 0.1224  data: 0.0058  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.4349 (1.3157)  acc1: 62.5000 (64.6175)  acc5: 95.8333 (95.4577)  time: 0.1245  data: 0.0057  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.4582 (1.3398)  acc1: 60.4167 (63.6737)  acc5: 91.6667 (95.1585)  time: 0.1246  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3348 (1.3053)  acc1: 64.5833 (65.5093)  acc5: 95.8333 (95.4733)  time: 0.1204  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3198 (1.3036)  acc1: 66.6667 (65.6051)  acc5: 95.8333 (95.3885)  time: 0.1170  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1517 s / it)\n",
            "* Acc@1 65.605 Acc@5 95.389 loss 1.304\n",
            "Accuracy of the model on the 3925 test images: 65.6%\n",
            "Max accuracy: 65.76%\n",
            "Test:  [ 0/82]  eta: 0:04:07  loss: 4.5867 (4.5867)  acc1: 8.3333 (8.3333)  acc5: 68.7500 (68.7500)  time: 3.0190  data: 2.8480  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 4.3994 (4.4674)  acc1: 4.1667 (9.4697)  acc5: 75.0000 (75.3788)  time: 0.3945  data: 0.2618  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 4.3674 (4.4721)  acc1: 14.5833 (13.2937)  acc5: 72.9167 (74.2064)  time: 0.1271  data: 0.0036  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 5.0381 (4.8592)  acc1: 14.5833 (10.4167)  acc5: 62.5000 (65.1210)  time: 0.1216  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 5.9514 (5.0622)  acc1: 2.0833 (9.2480)  acc5: 43.7500 (61.5854)  time: 0.1216  data: 0.0030  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 5.1231 (4.9337)  acc1: 8.3333 (13.0719)  acc5: 58.3333 (63.0310)  time: 0.1222  data: 0.0050  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.4998 (4.9620)  acc1: 14.5833 (12.2951)  acc5: 66.6667 (62.8415)  time: 0.1209  data: 0.0045  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.4998 (4.9599)  acc1: 8.3333 (13.2042)  acc5: 70.8333 (62.8228)  time: 0.1190  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.6712 (4.6358)  acc1: 35.4167 (19.9331)  acc5: 79.1667 (65.6893)  time: 0.1179  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 3.6521 (4.6066)  acc1: 39.5833 (20.4331)  acc5: 81.2500 (65.8854)  time: 0.1160  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1611 s / it)\n",
            "* Acc@1 20.433 Acc@5 65.885 loss 4.607\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [31]  [  0/295]  eta: 0:12:43  lr: 0.002814  min_lr: 0.002814  loss: 2.4135 (2.4135)  weight_decay: 0.0500 (0.0500)  time: 2.5881  data: 2.1027  max mem: 3500\n",
            "Epoch: [31]  [ 10/295]  eta: 0:02:34  lr: 0.002809  min_lr: 0.002809  loss: 2.6905 (2.6873)  weight_decay: 0.0500 (0.0500)  time: 0.5433  data: 0.1935  max mem: 3500\n",
            "Epoch: [31]  [ 20/295]  eta: 0:01:53  lr: 0.002801  min_lr: 0.002801  loss: 2.7284 (2.6751)  weight_decay: 0.0500 (0.0500)  time: 0.3034  data: 0.0030  max mem: 3500\n",
            "Epoch: [31]  [ 30/295]  eta: 0:01:36  lr: 0.002795  min_lr: 0.002795  loss: 2.5950 (2.6668)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0028  max mem: 3500\n",
            "Epoch: [31]  [ 40/295]  eta: 0:01:26  lr: 0.002787  min_lr: 0.002787  loss: 2.6225 (2.6729)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0022  max mem: 3500\n",
            "Epoch: [31]  [ 50/295]  eta: 0:01:19  lr: 0.002782  min_lr: 0.002782  loss: 2.6225 (2.6517)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0028  max mem: 3500\n",
            "Epoch: [31]  [ 60/295]  eta: 0:01:14  lr: 0.002774  min_lr: 0.002774  loss: 2.5401 (2.6398)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0032  max mem: 3500\n",
            "Epoch: [31]  [ 70/295]  eta: 0:01:09  lr: 0.002769  min_lr: 0.002769  loss: 2.6308 (2.6355)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0035  max mem: 3500\n",
            "Epoch: [31]  [ 80/295]  eta: 0:01:05  lr: 0.002761  min_lr: 0.002761  loss: 2.6434 (2.6318)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0054  max mem: 3500\n",
            "Epoch: [31]  [ 90/295]  eta: 0:01:01  lr: 0.002756  min_lr: 0.002756  loss: 2.6118 (2.6274)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0044  max mem: 3500\n",
            "Epoch: [31]  [100/295]  eta: 0:00:57  lr: 0.002748  min_lr: 0.002748  loss: 2.5999 (2.6298)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0017  max mem: 3500\n",
            "Epoch: [31]  [110/295]  eta: 0:00:54  lr: 0.002742  min_lr: 0.002742  loss: 2.6460 (2.6367)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0020  max mem: 3500\n",
            "Epoch: [31]  [120/295]  eta: 0:00:50  lr: 0.002734  min_lr: 0.002734  loss: 2.8490 (2.6589)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0019  max mem: 3500\n",
            "Epoch: [31]  [130/295]  eta: 0:00:47  lr: 0.002729  min_lr: 0.002729  loss: 2.7995 (2.6561)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0021  max mem: 3500\n",
            "Epoch: [31]  [140/295]  eta: 0:00:44  lr: 0.002721  min_lr: 0.002721  loss: 2.5850 (2.6512)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0026  max mem: 3500\n",
            "Epoch: [31]  [150/295]  eta: 0:00:41  lr: 0.002716  min_lr: 0.002716  loss: 2.6009 (2.6529)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0027  max mem: 3500\n",
            "Epoch: [31]  [160/295]  eta: 0:00:38  lr: 0.002708  min_lr: 0.002708  loss: 2.6276 (2.6541)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0035  max mem: 3500\n",
            "Epoch: [31]  [170/295]  eta: 0:00:35  lr: 0.002702  min_lr: 0.002702  loss: 2.6459 (2.6544)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0032  max mem: 3500\n",
            "Epoch: [31]  [180/295]  eta: 0:00:32  lr: 0.002694  min_lr: 0.002694  loss: 2.6888 (2.6545)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0019  max mem: 3500\n",
            "Epoch: [31]  [190/295]  eta: 0:00:29  lr: 0.002689  min_lr: 0.002689  loss: 2.7514 (2.6566)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0026  max mem: 3500\n",
            "Epoch: [31]  [200/295]  eta: 0:00:26  lr: 0.002681  min_lr: 0.002681  loss: 2.7459 (2.6604)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0031  max mem: 3500\n",
            "Epoch: [31]  [210/295]  eta: 0:00:23  lr: 0.002675  min_lr: 0.002675  loss: 2.7342 (2.6666)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0046  max mem: 3500\n",
            "Epoch: [31]  [220/295]  eta: 0:00:20  lr: 0.002667  min_lr: 0.002667  loss: 2.6635 (2.6651)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0037  max mem: 3500\n",
            "Epoch: [31]  [230/295]  eta: 0:00:18  lr: 0.002662  min_lr: 0.002662  loss: 2.6252 (2.6623)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0008  max mem: 3500\n",
            "Epoch: [31]  [240/295]  eta: 0:00:15  lr: 0.002654  min_lr: 0.002654  loss: 2.6162 (2.6621)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0022  max mem: 3500\n",
            "Epoch: [31]  [250/295]  eta: 0:00:12  lr: 0.002648  min_lr: 0.002648  loss: 2.5927 (2.6631)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0039  max mem: 3500\n",
            "Epoch: [31]  [260/295]  eta: 0:00:09  lr: 0.002640  min_lr: 0.002640  loss: 2.6352 (2.6662)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0047  max mem: 3500\n",
            "Epoch: [31]  [270/295]  eta: 0:00:06  lr: 0.002635  min_lr: 0.002635  loss: 2.6290 (2.6623)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0056  max mem: 3500\n",
            "Epoch: [31]  [280/295]  eta: 0:00:04  lr: 0.002627  min_lr: 0.002627  loss: 2.5430 (2.6590)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0035  max mem: 3500\n",
            "Epoch: [31]  [290/295]  eta: 0:00:01  lr: 0.002621  min_lr: 0.002621  loss: 2.5244 (2.6567)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0005  max mem: 3500\n",
            "Epoch: [31]  [294/295]  eta: 0:00:00  lr: 0.002621  min_lr: 0.002621  loss: 2.5244 (2.6572)  weight_decay: 0.0500 (0.0500)  time: 0.2195  data: 0.0001  max mem: 3500\n",
            "Epoch: [31] Total time: 0:01:20 (0.2744 s / it)\n",
            "Averaged stats: lr: 0.002621  min_lr: 0.002621  loss: 2.5244 (2.6572)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:44  loss: 0.7304 (0.7304)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.0058  data: 1.8385  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.8518 (0.8785)  acc1: 81.2500 (79.9242)  acc5: 95.8333 (95.8333)  time: 0.2939  data: 0.1679  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.8539 (0.8948)  acc1: 81.2500 (80.3571)  acc5: 95.8333 (96.2302)  time: 0.1227  data: 0.0012  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.0658 (1.2031)  acc1: 72.9167 (64.7177)  acc5: 93.7500 (94.0188)  time: 0.1284  data: 0.0032  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.1126 (1.1928)  acc1: 66.6667 (65.8028)  acc5: 95.8333 (94.8171)  time: 0.1411  data: 0.0025  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.0986 (1.1780)  acc1: 72.9167 (66.5033)  acc5: 95.8333 (94.9755)  time: 0.1534  data: 0.0002  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.2821 (1.2193)  acc1: 62.5000 (64.7541)  acc5: 95.8333 (94.7404)  time: 0.1540  data: 0.0068  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.3174 (1.2351)  acc1: 62.5000 (64.4073)  acc5: 93.7500 (94.6596)  time: 0.1468  data: 0.0070  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2698 (1.2003)  acc1: 66.6667 (65.8693)  acc5: 95.8333 (94.8045)  time: 0.1308  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2367 (1.1992)  acc1: 68.7500 (65.9108)  acc5: 95.8333 (94.7516)  time: 0.1294  data: 0.0004  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1640 s / it)\n",
            "* Acc@1 65.911 Acc@5 94.752 loss 1.199\n",
            "Accuracy of the model on the 3925 test images: 65.9%\n",
            "Max accuracy: 65.91%\n",
            "Test:  [ 0/82]  eta: 0:02:24  loss: 4.5140 (4.5140)  acc1: 6.2500 (6.2500)  acc5: 68.7500 (68.7500)  time: 1.7661  data: 1.6031  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 4.3509 (4.4008)  acc1: 4.1667 (9.2803)  acc5: 75.0000 (76.1364)  time: 0.2731  data: 0.1506  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 4.3035 (4.4074)  acc1: 14.5833 (13.3929)  acc5: 75.0000 (74.9008)  time: 0.1238  data: 0.0038  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.9876 (4.8075)  acc1: 14.5833 (10.3495)  acc5: 62.5000 (65.9946)  time: 0.1224  data: 0.0026  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 5.9303 (5.0177)  acc1: 2.0833 (9.1972)  acc5: 50.0000 (62.7541)  time: 0.1226  data: 0.0028  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 5.1153 (4.8955)  acc1: 8.3333 (12.9493)  acc5: 58.3333 (64.0114)  time: 0.1226  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.4940 (4.9340)  acc1: 14.5833 (12.0560)  acc5: 68.7500 (63.7637)  time: 0.1278  data: 0.0053  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5019 (4.9267)  acc1: 8.3333 (13.0575)  acc5: 70.8333 (63.7031)  time: 0.1317  data: 0.0044  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.5265 (4.5971)  acc1: 35.4167 (19.9074)  acc5: 81.2500 (66.5381)  time: 0.1234  data: 0.0011  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 3.5049 (4.5678)  acc1: 39.5833 (20.4331)  acc5: 81.2500 (66.7261)  time: 0.1212  data: 0.0011  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1511 s / it)\n",
            "* Acc@1 20.433 Acc@5 66.726 loss 4.568\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [32]  [  0/295]  eta: 0:12:06  lr: 0.002618  min_lr: 0.002618  loss: 2.7897 (2.7897)  weight_decay: 0.0500 (0.0500)  time: 2.4629  data: 1.9982  max mem: 3500\n",
            "Epoch: [32]  [ 10/295]  eta: 0:02:18  lr: 0.002613  min_lr: 0.002613  loss: 2.6789 (2.6670)  weight_decay: 0.0500 (0.0500)  time: 0.4858  data: 0.1830  max mem: 3500\n",
            "Epoch: [32]  [ 20/295]  eta: 0:01:44  lr: 0.002605  min_lr: 0.002605  loss: 2.6201 (2.6398)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0013  max mem: 3500\n",
            "Epoch: [32]  [ 30/295]  eta: 0:01:30  lr: 0.002599  min_lr: 0.002599  loss: 2.5474 (2.6241)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0013  max mem: 3500\n",
            "Epoch: [32]  [ 40/295]  eta: 0:01:22  lr: 0.002591  min_lr: 0.002591  loss: 2.5700 (2.6220)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0009  max mem: 3500\n",
            "Epoch: [32]  [ 50/295]  eta: 0:01:16  lr: 0.002586  min_lr: 0.002586  loss: 2.6548 (2.6306)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0029  max mem: 3500\n",
            "Epoch: [32]  [ 60/295]  eta: 0:01:11  lr: 0.002577  min_lr: 0.002577  loss: 2.6591 (2.6419)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0033  max mem: 3500\n",
            "Epoch: [32]  [ 70/295]  eta: 0:01:07  lr: 0.002572  min_lr: 0.002572  loss: 2.5962 (2.6404)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0021  max mem: 3500\n",
            "Epoch: [32]  [ 80/295]  eta: 0:01:03  lr: 0.002564  min_lr: 0.002564  loss: 2.5721 (2.6295)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0023  max mem: 3500\n",
            "Epoch: [32]  [ 90/295]  eta: 0:00:59  lr: 0.002558  min_lr: 0.002558  loss: 2.6398 (2.6355)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0012  max mem: 3500\n",
            "Epoch: [32]  [100/295]  eta: 0:00:56  lr: 0.002550  min_lr: 0.002550  loss: 2.6455 (2.6332)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0015  max mem: 3500\n",
            "Epoch: [32]  [110/295]  eta: 0:00:53  lr: 0.002544  min_lr: 0.002544  loss: 2.6455 (2.6414)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0026  max mem: 3500\n",
            "Epoch: [32]  [120/295]  eta: 0:00:49  lr: 0.002536  min_lr: 0.002536  loss: 2.6917 (2.6428)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0030  max mem: 3500\n",
            "Epoch: [32]  [130/295]  eta: 0:00:46  lr: 0.002530  min_lr: 0.002530  loss: 2.6799 (2.6366)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0025  max mem: 3500\n",
            "Epoch: [32]  [140/295]  eta: 0:00:43  lr: 0.002522  min_lr: 0.002522  loss: 2.6799 (2.6379)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0033  max mem: 3500\n",
            "Epoch: [32]  [150/295]  eta: 0:00:40  lr: 0.002517  min_lr: 0.002517  loss: 2.6123 (2.6364)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0030  max mem: 3500\n",
            "Epoch: [32]  [160/295]  eta: 0:00:37  lr: 0.002508  min_lr: 0.002508  loss: 2.6451 (2.6350)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0010  max mem: 3500\n",
            "Epoch: [32]  [170/295]  eta: 0:00:34  lr: 0.002503  min_lr: 0.002503  loss: 2.6451 (2.6320)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0004  max mem: 3500\n",
            "Epoch: [32]  [180/295]  eta: 0:00:31  lr: 0.002494  min_lr: 0.002494  loss: 2.5349 (2.6245)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0024  max mem: 3500\n",
            "Epoch: [32]  [190/295]  eta: 0:00:29  lr: 0.002489  min_lr: 0.002489  loss: 2.6021 (2.6266)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0066  max mem: 3500\n",
            "Epoch: [32]  [200/295]  eta: 0:00:26  lr: 0.002481  min_lr: 0.002481  loss: 2.7028 (2.6309)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0068  max mem: 3500\n",
            "Epoch: [32]  [210/295]  eta: 0:00:23  lr: 0.002475  min_lr: 0.002475  loss: 2.7116 (2.6325)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0031  max mem: 3500\n",
            "Epoch: [32]  [220/295]  eta: 0:00:20  lr: 0.002467  min_lr: 0.002467  loss: 2.6348 (2.6290)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0011  max mem: 3500\n",
            "Epoch: [32]  [230/295]  eta: 0:00:17  lr: 0.002461  min_lr: 0.002461  loss: 2.5597 (2.6244)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0014  max mem: 3500\n",
            "Epoch: [32]  [240/295]  eta: 0:00:15  lr: 0.002453  min_lr: 0.002453  loss: 2.5781 (2.6249)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0026  max mem: 3500\n",
            "Epoch: [32]  [250/295]  eta: 0:00:12  lr: 0.002447  min_lr: 0.002447  loss: 2.6723 (2.6260)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0030  max mem: 3500\n",
            "Epoch: [32]  [260/295]  eta: 0:00:09  lr: 0.002439  min_lr: 0.002439  loss: 2.7162 (2.6281)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0034  max mem: 3500\n",
            "Epoch: [32]  [270/295]  eta: 0:00:06  lr: 0.002433  min_lr: 0.002433  loss: 2.5984 (2.6263)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0030  max mem: 3500\n",
            "Epoch: [32]  [280/295]  eta: 0:00:04  lr: 0.002425  min_lr: 0.002425  loss: 2.5973 (2.6271)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0021  max mem: 3500\n",
            "Epoch: [32]  [290/295]  eta: 0:00:01  lr: 0.002419  min_lr: 0.002419  loss: 2.5687 (2.6243)  weight_decay: 0.0500 (0.0500)  time: 0.2570  data: 0.0013  max mem: 3500\n",
            "Epoch: [32]  [294/295]  eta: 0:00:00  lr: 0.002419  min_lr: 0.002419  loss: 2.5411 (2.6235)  weight_decay: 0.0500 (0.0500)  time: 0.2186  data: 0.0002  max mem: 3500\n",
            "Epoch: [32] Total time: 0:01:19 (0.2708 s / it)\n",
            "Averaged stats: lr: 0.002419  min_lr: 0.002419  loss: 2.5411 (2.6235)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:19  loss: 0.8958 (0.8958)  acc1: 83.3333 (83.3333)  acc5: 91.6667 (91.6667)  time: 1.6960  data: 1.5282  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.9837 (0.9716)  acc1: 77.0833 (76.7045)  acc5: 95.8333 (95.4545)  time: 0.2979  data: 0.1560  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.8566 (0.8619)  acc1: 81.2500 (80.6548)  acc5: 97.9167 (96.8254)  time: 0.1621  data: 0.0247  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8566 (1.0917)  acc1: 79.1667 (68.5484)  acc5: 97.9167 (96.8414)  time: 0.1704  data: 0.0343  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.0929 (1.0939)  acc1: 70.8333 (69.5122)  acc5: 97.9167 (96.9512)  time: 0.1816  data: 0.0433  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.0857 (1.1174)  acc1: 70.8333 (68.6275)  acc5: 97.9167 (96.8546)  time: 0.1637  data: 0.0249  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.2350 (1.1496)  acc1: 62.5000 (67.2131)  acc5: 95.8333 (96.2090)  time: 0.1457  data: 0.0126  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.3977 (1.1933)  acc1: 56.2500 (65.2876)  acc5: 93.7500 (95.7747)  time: 0.1368  data: 0.0121  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3811 (1.1693)  acc1: 56.2500 (66.4352)  acc5: 95.8333 (95.8591)  time: 0.1195  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3688 (1.1686)  acc1: 62.5000 (66.4968)  acc5: 95.8333 (95.7707)  time: 0.1180  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1749 s / it)\n",
            "* Acc@1 66.497 Acc@5 95.771 loss 1.169\n",
            "Accuracy of the model on the 3925 test images: 66.5%\n",
            "Max accuracy: 66.50%\n",
            "Test:  [ 0/82]  eta: 0:02:03  loss: 4.4407 (4.4407)  acc1: 8.3333 (8.3333)  acc5: 68.7500 (68.7500)  time: 1.5090  data: 1.3473  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 4.3006 (4.3342)  acc1: 4.1667 (10.2273)  acc5: 75.0000 (76.1364)  time: 0.2657  data: 0.1407  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 4.2413 (4.3472)  acc1: 14.5833 (14.1865)  acc5: 75.0000 (75.2976)  time: 0.1312  data: 0.0112  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.9520 (4.7618)  acc1: 14.5833 (10.8871)  acc5: 62.5000 (66.5995)  time: 0.1227  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 5.8989 (4.9762)  acc1: 2.0833 (9.6037)  acc5: 52.0833 (63.5671)  time: 0.1327  data: 0.0023  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 5.1209 (4.8627)  acc1: 8.3333 (12.9493)  acc5: 58.3333 (64.5425)  time: 0.1455  data: 0.0021  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.4914 (4.9104)  acc1: 10.4167 (11.9536)  acc5: 66.6667 (64.1393)  time: 0.1518  data: 0.0033  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5126 (4.8968)  acc1: 8.3333 (13.0575)  acc5: 70.8333 (64.0845)  time: 0.1498  data: 0.0065  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.3903 (4.5620)  acc1: 37.5000 (19.9846)  acc5: 83.3333 (67.0525)  time: 0.1397  data: 0.0118  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 3.3626 (4.5325)  acc1: 39.5833 (20.5096)  acc5: 83.3333 (67.2357)  time: 0.1374  data: 0.0118  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1632 s / it)\n",
            "* Acc@1 20.510 Acc@5 67.236 loss 4.532\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [33]  [  0/295]  eta: 0:15:49  lr: 0.002416  min_lr: 0.002416  loss: 2.8270 (2.8270)  weight_decay: 0.0500 (0.0500)  time: 3.2178  data: 2.7010  max mem: 3500\n",
            "Epoch: [33]  [ 10/295]  eta: 0:02:39  lr: 0.002411  min_lr: 0.002411  loss: 2.6762 (2.6960)  weight_decay: 0.0500 (0.0500)  time: 0.5595  data: 0.2477  max mem: 3500\n",
            "Epoch: [33]  [ 20/295]  eta: 0:01:54  lr: 0.002402  min_lr: 0.002402  loss: 2.6326 (2.6415)  weight_decay: 0.0500 (0.0500)  time: 0.2776  data: 0.0013  max mem: 3500\n",
            "Epoch: [33]  [ 30/295]  eta: 0:01:37  lr: 0.002397  min_lr: 0.002397  loss: 2.6782 (2.6645)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0009  max mem: 3500\n",
            "Epoch: [33]  [ 40/295]  eta: 0:01:27  lr: 0.002388  min_lr: 0.002388  loss: 2.6764 (2.6702)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0017  max mem: 3500\n",
            "Epoch: [33]  [ 50/295]  eta: 0:01:20  lr: 0.002382  min_lr: 0.002382  loss: 2.6659 (2.6643)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0013  max mem: 3500\n",
            "Epoch: [33]  [ 60/295]  eta: 0:01:14  lr: 0.002374  min_lr: 0.002374  loss: 2.6056 (2.6513)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0016  max mem: 3500\n",
            "Epoch: [33]  [ 70/295]  eta: 0:01:09  lr: 0.002368  min_lr: 0.002368  loss: 2.5716 (2.6398)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0023  max mem: 3500\n",
            "Epoch: [33]  [ 80/295]  eta: 0:01:05  lr: 0.002360  min_lr: 0.002360  loss: 2.5731 (2.6452)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0016  max mem: 3500\n",
            "Epoch: [33]  [ 90/295]  eta: 0:01:01  lr: 0.002354  min_lr: 0.002354  loss: 2.5669 (2.6342)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0010  max mem: 3500\n",
            "Epoch: [33]  [100/295]  eta: 0:00:57  lr: 0.002346  min_lr: 0.002346  loss: 2.5439 (2.6408)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0014  max mem: 3500\n",
            "Epoch: [33]  [110/295]  eta: 0:00:54  lr: 0.002340  min_lr: 0.002340  loss: 2.7251 (2.6403)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0021  max mem: 3500\n",
            "Epoch: [33]  [120/295]  eta: 0:00:51  lr: 0.002332  min_lr: 0.002332  loss: 2.7061 (2.6385)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0023  max mem: 3500\n",
            "Epoch: [33]  [130/295]  eta: 0:00:47  lr: 0.002326  min_lr: 0.002326  loss: 2.7061 (2.6346)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0020  max mem: 3500\n",
            "Epoch: [33]  [140/295]  eta: 0:00:44  lr: 0.002318  min_lr: 0.002318  loss: 2.6418 (2.6366)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0017  max mem: 3500\n",
            "Epoch: [33]  [150/295]  eta: 0:00:41  lr: 0.002312  min_lr: 0.002312  loss: 2.5676 (2.6323)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0012  max mem: 3500\n",
            "Epoch: [33]  [160/295]  eta: 0:00:38  lr: 0.002303  min_lr: 0.002303  loss: 2.5448 (2.6294)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0011  max mem: 3500\n",
            "Epoch: [33]  [170/295]  eta: 0:00:35  lr: 0.002298  min_lr: 0.002298  loss: 2.6661 (2.6329)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0027  max mem: 3500\n",
            "Epoch: [33]  [180/295]  eta: 0:00:32  lr: 0.002289  min_lr: 0.002289  loss: 2.6661 (2.6328)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0046  max mem: 3500\n",
            "Epoch: [33]  [190/295]  eta: 0:00:29  lr: 0.002284  min_lr: 0.002284  loss: 2.5953 (2.6287)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0044  max mem: 3500\n",
            "Epoch: [33]  [200/295]  eta: 0:00:26  lr: 0.002275  min_lr: 0.002275  loss: 2.5783 (2.6304)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0025  max mem: 3500\n",
            "Epoch: [33]  [210/295]  eta: 0:00:23  lr: 0.002269  min_lr: 0.002269  loss: 2.6258 (2.6298)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0015  max mem: 3500\n",
            "Epoch: [33]  [220/295]  eta: 0:00:20  lr: 0.002261  min_lr: 0.002261  loss: 2.6258 (2.6311)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0010  max mem: 3500\n",
            "Epoch: [33]  [230/295]  eta: 0:00:18  lr: 0.002255  min_lr: 0.002255  loss: 2.6989 (2.6336)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0011  max mem: 3500\n",
            "Epoch: [33]  [240/295]  eta: 0:00:15  lr: 0.002247  min_lr: 0.002247  loss: 2.6394 (2.6335)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0040  max mem: 3500\n",
            "Epoch: [33]  [250/295]  eta: 0:00:12  lr: 0.002241  min_lr: 0.002241  loss: 2.6203 (2.6334)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0064  max mem: 3500\n",
            "Epoch: [33]  [260/295]  eta: 0:00:09  lr: 0.002232  min_lr: 0.002232  loss: 2.6264 (2.6351)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0041  max mem: 3500\n",
            "Epoch: [33]  [270/295]  eta: 0:00:06  lr: 0.002227  min_lr: 0.002227  loss: 2.6636 (2.6367)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0022  max mem: 3500\n",
            "Epoch: [33]  [280/295]  eta: 0:00:04  lr: 0.002218  min_lr: 0.002218  loss: 2.6636 (2.6370)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0017  max mem: 3500\n",
            "Epoch: [33]  [290/295]  eta: 0:00:01  lr: 0.002212  min_lr: 0.002212  loss: 2.6652 (2.6383)  weight_decay: 0.0500 (0.0500)  time: 0.2565  data: 0.0003  max mem: 3500\n",
            "Epoch: [33]  [294/295]  eta: 0:00:00  lr: 0.002212  min_lr: 0.002212  loss: 2.6144 (2.6374)  weight_decay: 0.0500 (0.0500)  time: 0.2185  data: 0.0002  max mem: 3500\n",
            "Epoch: [33] Total time: 0:01:20 (0.2730 s / it)\n",
            "Averaged stats: lr: 0.002212  min_lr: 0.002212  loss: 2.6144 (2.6374)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:59  loss: 0.7197 (0.7197)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 2.9195  data: 2.7016  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.8444 (0.8717)  acc1: 81.2500 (79.9242)  acc5: 95.8333 (96.7803)  time: 0.4117  data: 0.2713  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.8991 (0.9051)  acc1: 79.1667 (79.4643)  acc5: 97.9167 (97.0238)  time: 0.1541  data: 0.0197  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 1.0098 (1.2377)  acc1: 70.8333 (63.8441)  acc5: 93.7500 (92.8763)  time: 0.1395  data: 0.0064  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.1128 (1.1992)  acc1: 68.7500 (66.3618)  acc5: 93.7500 (93.8516)  time: 0.1267  data: 0.0020  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.0559 (1.1937)  acc1: 75.0000 (67.1160)  acc5: 97.9167 (94.5261)  time: 0.1237  data: 0.0037  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.1344 (1.1870)  acc1: 68.7500 (67.4863)  acc5: 97.9167 (94.5014)  time: 0.1271  data: 0.0041  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.2350 (1.2026)  acc1: 66.6667 (66.9308)  acc5: 95.8333 (94.6303)  time: 0.1231  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2244 (1.1627)  acc1: 68.7500 (68.5185)  acc5: 95.8333 (94.8817)  time: 0.1177  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2112 (1.1610)  acc1: 68.7500 (68.5860)  acc5: 95.8333 (94.8026)  time: 0.1161  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1697 s / it)\n",
            "* Acc@1 68.586 Acc@5 94.803 loss 1.161\n",
            "Accuracy of the model on the 3925 test images: 68.6%\n",
            "Max accuracy: 68.59%\n",
            "Test:  [ 0/82]  eta: 0:01:50  loss: 4.3729 (4.3729)  acc1: 8.3333 (8.3333)  acc5: 68.7500 (68.7500)  time: 1.3448  data: 1.1828  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 4.2582 (4.2755)  acc1: 4.1667 (9.6591)  acc5: 77.0833 (76.1364)  time: 0.3219  data: 0.1888  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 4.1915 (4.2912)  acc1: 14.5833 (13.9881)  acc5: 77.0833 (75.3968)  time: 0.1984  data: 0.0663  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 4.9109 (4.7183)  acc1: 14.5833 (10.7527)  acc5: 64.5833 (66.9355)  time: 0.1809  data: 0.0484  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.8628 (4.9359)  acc1: 2.0833 (9.5528)  acc5: 50.0000 (63.9228)  time: 0.1799  data: 0.0491  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.1129 (4.8316)  acc1: 8.3333 (12.7451)  acc5: 58.3333 (64.7467)  time: 0.1598  data: 0.0286  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.4949 (4.8874)  acc1: 10.4167 (11.7145)  acc5: 66.6667 (64.2760)  time: 0.1379  data: 0.0128  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5246 (4.8668)  acc1: 8.3333 (12.9108)  acc5: 75.0000 (64.3193)  time: 0.1253  data: 0.0065  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.2529 (4.5271)  acc1: 39.5833 (19.9074)  acc5: 83.3333 (67.4126)  time: 0.1190  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 3.2213 (4.4974)  acc1: 39.5833 (20.4331)  acc5: 86.4865 (67.5924)  time: 0.1179  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1770 s / it)\n",
            "* Acc@1 20.433 Acc@5 67.592 loss 4.497\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [34]  [  0/295]  eta: 0:07:56  lr: 0.002210  min_lr: 0.002210  loss: 2.6794 (2.6794)  weight_decay: 0.0500 (0.0500)  time: 1.6167  data: 1.2548  max mem: 3500\n",
            "Epoch: [34]  [ 10/295]  eta: 0:01:53  lr: 0.002204  min_lr: 0.002204  loss: 2.5937 (2.5607)  weight_decay: 0.0500 (0.0500)  time: 0.3974  data: 0.1173  max mem: 3500\n",
            "Epoch: [34]  [ 20/295]  eta: 0:01:32  lr: 0.002195  min_lr: 0.002195  loss: 2.5272 (2.5775)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0029  max mem: 3500\n",
            "Epoch: [34]  [ 30/295]  eta: 0:01:24  lr: 0.002190  min_lr: 0.002190  loss: 2.5307 (2.5912)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0041  max mem: 3500\n",
            "Epoch: [34]  [ 40/295]  eta: 0:01:18  lr: 0.002181  min_lr: 0.002181  loss: 2.6328 (2.5868)  weight_decay: 0.0500 (0.0500)  time: 0.2767  data: 0.0031  max mem: 3500\n",
            "Epoch: [34]  [ 50/295]  eta: 0:01:13  lr: 0.002175  min_lr: 0.002175  loss: 2.6687 (2.6037)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0013  max mem: 3500\n",
            "Epoch: [34]  [ 60/295]  eta: 0:01:09  lr: 0.002167  min_lr: 0.002167  loss: 2.5957 (2.5762)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0020  max mem: 3500\n",
            "Epoch: [34]  [ 70/295]  eta: 0:01:05  lr: 0.002161  min_lr: 0.002161  loss: 2.5446 (2.5772)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0023  max mem: 3500\n",
            "Epoch: [34]  [ 80/295]  eta: 0:01:01  lr: 0.002152  min_lr: 0.002152  loss: 2.5932 (2.5828)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0018  max mem: 3500\n",
            "Epoch: [34]  [ 90/295]  eta: 0:00:58  lr: 0.002147  min_lr: 0.002147  loss: 2.5217 (2.5673)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0028  max mem: 3500\n",
            "Epoch: [34]  [100/295]  eta: 0:00:55  lr: 0.002138  min_lr: 0.002138  loss: 2.5639 (2.5827)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0055  max mem: 3500\n",
            "Epoch: [34]  [110/295]  eta: 0:00:52  lr: 0.002132  min_lr: 0.002132  loss: 2.6558 (2.5801)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0045  max mem: 3500\n",
            "Epoch: [34]  [120/295]  eta: 0:00:48  lr: 0.002124  min_lr: 0.002124  loss: 2.6011 (2.5845)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0023  max mem: 3500\n",
            "Epoch: [34]  [130/295]  eta: 0:00:45  lr: 0.002118  min_lr: 0.002118  loss: 2.6568 (2.5911)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0015  max mem: 3500\n",
            "Epoch: [34]  [140/295]  eta: 0:00:42  lr: 0.002109  min_lr: 0.002109  loss: 2.7030 (2.5952)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0017  max mem: 3500\n",
            "Epoch: [34]  [150/295]  eta: 0:00:40  lr: 0.002104  min_lr: 0.002104  loss: 2.6693 (2.5959)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0028  max mem: 3500\n",
            "Epoch: [34]  [160/295]  eta: 0:00:37  lr: 0.002095  min_lr: 0.002095  loss: 2.4839 (2.5889)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0038  max mem: 3500\n",
            "Epoch: [34]  [170/295]  eta: 0:00:34  lr: 0.002089  min_lr: 0.002089  loss: 2.5242 (2.5890)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0037  max mem: 3500\n",
            "Epoch: [34]  [180/295]  eta: 0:00:31  lr: 0.002081  min_lr: 0.002081  loss: 2.5405 (2.5868)  weight_decay: 0.0500 (0.0500)  time: 0.2754  data: 0.0066  max mem: 3500\n",
            "Epoch: [34]  [190/295]  eta: 0:00:28  lr: 0.002075  min_lr: 0.002075  loss: 2.5089 (2.5835)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0062  max mem: 3500\n",
            "Epoch: [34]  [200/295]  eta: 0:00:26  lr: 0.002066  min_lr: 0.002066  loss: 2.5414 (2.5807)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0024  max mem: 3500\n",
            "Epoch: [34]  [210/295]  eta: 0:00:23  lr: 0.002061  min_lr: 0.002061  loss: 2.5398 (2.5753)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0026  max mem: 3500\n",
            "Epoch: [34]  [220/295]  eta: 0:00:20  lr: 0.002052  min_lr: 0.002052  loss: 2.5398 (2.5749)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0026  max mem: 3500\n",
            "Epoch: [34]  [230/295]  eta: 0:00:17  lr: 0.002046  min_lr: 0.002046  loss: 2.6398 (2.5780)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0023  max mem: 3500\n",
            "Epoch: [34]  [240/295]  eta: 0:00:14  lr: 0.002038  min_lr: 0.002038  loss: 2.6478 (2.5788)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0035  max mem: 3500\n",
            "Epoch: [34]  [250/295]  eta: 0:00:12  lr: 0.002032  min_lr: 0.002032  loss: 2.5748 (2.5786)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0029  max mem: 3500\n",
            "Epoch: [34]  [260/295]  eta: 0:00:09  lr: 0.002023  min_lr: 0.002023  loss: 2.6136 (2.5804)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0013  max mem: 3500\n",
            "Epoch: [34]  [270/295]  eta: 0:00:06  lr: 0.002018  min_lr: 0.002018  loss: 2.6268 (2.5808)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0008  max mem: 3500\n",
            "Epoch: [34]  [280/295]  eta: 0:00:04  lr: 0.002009  min_lr: 0.002009  loss: 2.6176 (2.5793)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0002  max mem: 3500\n",
            "Epoch: [34]  [290/295]  eta: 0:00:01  lr: 0.002003  min_lr: 0.002003  loss: 2.4359 (2.5789)  weight_decay: 0.0500 (0.0500)  time: 0.2566  data: 0.0002  max mem: 3500\n",
            "Epoch: [34]  [294/295]  eta: 0:00:00  lr: 0.002003  min_lr: 0.002003  loss: 2.4359 (2.5806)  weight_decay: 0.0500 (0.0500)  time: 0.2191  data: 0.0002  max mem: 3500\n",
            "Epoch: [34] Total time: 0:01:19 (0.2695 s / it)\n",
            "Averaged stats: lr: 0.002003  min_lr: 0.002003  loss: 2.4359 (2.5806)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:01  loss: 0.6341 (0.6341)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 2.9485  data: 2.7865  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 0.6827 (0.7371)  acc1: 83.3333 (84.2803)  acc5: 95.8333 (96.5909)  time: 0.4022  data: 0.2571  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.7499 (0.7488)  acc1: 83.3333 (84.7222)  acc5: 97.9167 (97.7183)  time: 0.1390  data: 0.0041  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8242 (1.0981)  acc1: 79.1667 (68.6156)  acc5: 97.9167 (95.5645)  time: 0.1261  data: 0.0034  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.0329 (1.0861)  acc1: 68.7500 (69.4106)  acc5: 93.7500 (95.7317)  time: 0.1236  data: 0.0047  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.9800 (1.0701)  acc1: 72.9167 (70.1389)  acc5: 97.9167 (95.9967)  time: 0.1235  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9800 (1.0562)  acc1: 70.8333 (70.6967)  acc5: 97.9167 (95.9016)  time: 0.1215  data: 0.0031  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.0880 (1.0778)  acc1: 68.7500 (69.6596)  acc5: 95.8333 (95.7747)  time: 0.1201  data: 0.0019  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1053 (1.0706)  acc1: 68.7500 (70.3447)  acc5: 95.8333 (95.8076)  time: 0.1185  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1053 (1.0730)  acc1: 68.7500 (70.2930)  acc5: 95.8333 (95.7452)  time: 0.1172  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1646 s / it)\n",
            "* Acc@1 70.293 Acc@5 95.745 loss 1.073\n",
            "Accuracy of the model on the 3925 test images: 70.3%\n",
            "Max accuracy: 70.29%\n",
            "Test:  [ 0/82]  eta: 0:02:33  loss: 4.3093 (4.3093)  acc1: 8.3333 (8.3333)  acc5: 68.7500 (68.7500)  time: 1.8692  data: 1.6906  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 4.2065 (4.2229)  acc1: 4.1667 (9.2803)  acc5: 77.0833 (77.0833)  time: 0.3548  data: 0.2237  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 4.1450 (4.2424)  acc1: 14.5833 (13.8889)  acc5: 77.0833 (76.3889)  time: 0.1899  data: 0.0625  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 4.8820 (4.6824)  acc1: 14.5833 (10.6855)  acc5: 66.6667 (68.0108)  time: 0.1726  data: 0.0440  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 5.8282 (4.9019)  acc1: 2.0833 (9.6037)  acc5: 52.0833 (64.9390)  time: 0.1532  data: 0.0242  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.0720 (4.8073)  acc1: 8.3333 (12.7042)  acc5: 58.3333 (65.5637)  time: 0.1518  data: 0.0270  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5108 (4.8707)  acc1: 10.4167 (11.6462)  acc5: 64.5833 (64.9249)  time: 0.1473  data: 0.0246  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5363 (4.8433)  acc1: 8.3333 (12.9401)  acc5: 81.2500 (65.1115)  time: 0.1256  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.1280 (4.4985)  acc1: 39.5833 (19.9588)  acc5: 83.3333 (68.1327)  time: 0.1208  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 3.0912 (4.4687)  acc1: 41.6667 (20.4841)  acc5: 86.4865 (68.3057)  time: 0.1186  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1773 s / it)\n",
            "* Acc@1 20.484 Acc@5 68.306 loss 4.469\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [35]  [  0/295]  eta: 0:06:44  lr: 0.002001  min_lr: 0.002001  loss: 2.9910 (2.9910)  weight_decay: 0.0500 (0.0500)  time: 1.3727  data: 1.0832  max mem: 3500\n",
            "Epoch: [35]  [ 10/295]  eta: 0:01:52  lr: 0.001995  min_lr: 0.001995  loss: 2.5270 (2.5871)  weight_decay: 0.0500 (0.0500)  time: 0.3933  data: 0.0995  max mem: 3500\n",
            "Epoch: [35]  [ 20/295]  eta: 0:01:32  lr: 0.001986  min_lr: 0.001986  loss: 2.5270 (2.5733)  weight_decay: 0.0500 (0.0500)  time: 0.2856  data: 0.0025  max mem: 3500\n",
            "Epoch: [35]  [ 30/295]  eta: 0:01:23  lr: 0.001980  min_lr: 0.001980  loss: 2.5419 (2.5536)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0042  max mem: 3500\n",
            "Epoch: [35]  [ 40/295]  eta: 0:01:17  lr: 0.001972  min_lr: 0.001972  loss: 2.6435 (2.6104)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0040  max mem: 3500\n",
            "Epoch: [35]  [ 50/295]  eta: 0:01:12  lr: 0.001966  min_lr: 0.001966  loss: 2.7014 (2.6149)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0025  max mem: 3500\n",
            "Epoch: [35]  [ 60/295]  eta: 0:01:08  lr: 0.001957  min_lr: 0.001957  loss: 2.6020 (2.6118)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0010  max mem: 3500\n",
            "Epoch: [35]  [ 70/295]  eta: 0:01:04  lr: 0.001952  min_lr: 0.001952  loss: 2.5720 (2.5996)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0007  max mem: 3500\n",
            "Epoch: [35]  [ 80/295]  eta: 0:01:01  lr: 0.001943  min_lr: 0.001943  loss: 2.5181 (2.5982)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0016  max mem: 3500\n",
            "Epoch: [35]  [ 90/295]  eta: 0:00:57  lr: 0.001937  min_lr: 0.001937  loss: 2.5975 (2.6105)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0032  max mem: 3500\n",
            "Epoch: [35]  [100/295]  eta: 0:00:54  lr: 0.001929  min_lr: 0.001929  loss: 2.6427 (2.6047)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0046  max mem: 3500\n",
            "Epoch: [35]  [110/295]  eta: 0:00:51  lr: 0.001923  min_lr: 0.001923  loss: 2.6133 (2.6071)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0043  max mem: 3500\n",
            "Epoch: [35]  [120/295]  eta: 0:00:48  lr: 0.001914  min_lr: 0.001914  loss: 2.5823 (2.6010)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0025  max mem: 3500\n",
            "Epoch: [35]  [130/295]  eta: 0:00:45  lr: 0.001909  min_lr: 0.001909  loss: 2.5721 (2.6051)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0014  max mem: 3500\n",
            "Epoch: [35]  [140/295]  eta: 0:00:42  lr: 0.001900  min_lr: 0.001900  loss: 2.5790 (2.5998)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0014  max mem: 3500\n",
            "Epoch: [35]  [150/295]  eta: 0:00:39  lr: 0.001894  min_lr: 0.001894  loss: 2.6547 (2.6025)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0020  max mem: 3500\n",
            "Epoch: [35]  [160/295]  eta: 0:00:37  lr: 0.001886  min_lr: 0.001886  loss: 2.6599 (2.6035)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0032  max mem: 3500\n",
            "Epoch: [35]  [170/295]  eta: 0:00:34  lr: 0.001880  min_lr: 0.001880  loss: 2.6829 (2.6072)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0048  max mem: 3500\n",
            "Epoch: [35]  [180/295]  eta: 0:00:31  lr: 0.001872  min_lr: 0.001872  loss: 2.7274 (2.6098)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0040  max mem: 3500\n",
            "Epoch: [35]  [190/295]  eta: 0:00:28  lr: 0.001866  min_lr: 0.001866  loss: 2.5452 (2.6059)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0016  max mem: 3500\n",
            "Epoch: [35]  [200/295]  eta: 0:00:25  lr: 0.001857  min_lr: 0.001857  loss: 2.5452 (2.6051)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0011  max mem: 3500\n",
            "Epoch: [35]  [210/295]  eta: 0:00:23  lr: 0.001851  min_lr: 0.001851  loss: 2.6299 (2.6064)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0013  max mem: 3500\n",
            "Epoch: [35]  [220/295]  eta: 0:00:20  lr: 0.001843  min_lr: 0.001843  loss: 2.6163 (2.6060)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0046  max mem: 3500\n",
            "Epoch: [35]  [230/295]  eta: 0:00:17  lr: 0.001837  min_lr: 0.001837  loss: 2.6740 (2.6098)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0060  max mem: 3500\n",
            "Epoch: [35]  [240/295]  eta: 0:00:14  lr: 0.001829  min_lr: 0.001829  loss: 2.6894 (2.6109)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0029  max mem: 3500\n",
            "Epoch: [35]  [250/295]  eta: 0:00:12  lr: 0.001823  min_lr: 0.001823  loss: 2.6600 (2.6098)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0016  max mem: 3500\n",
            "Epoch: [35]  [260/295]  eta: 0:00:09  lr: 0.001814  min_lr: 0.001814  loss: 2.5590 (2.6081)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0013  max mem: 3500\n",
            "Epoch: [35]  [270/295]  eta: 0:00:06  lr: 0.001809  min_lr: 0.001809  loss: 2.6006 (2.6076)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0008  max mem: 3500\n",
            "Epoch: [35]  [280/295]  eta: 0:00:04  lr: 0.001800  min_lr: 0.001800  loss: 2.6479 (2.6109)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0008  max mem: 3500\n",
            "Epoch: [35]  [290/295]  eta: 0:00:01  lr: 0.001794  min_lr: 0.001794  loss: 2.7287 (2.6137)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0006  max mem: 3500\n",
            "Epoch: [35]  [294/295]  eta: 0:00:00  lr: 0.001794  min_lr: 0.001794  loss: 2.7600 (2.6142)  weight_decay: 0.0500 (0.0500)  time: 0.2214  data: 0.0001  max mem: 3500\n",
            "Epoch: [35] Total time: 0:01:19 (0.2681 s / it)\n",
            "Averaged stats: lr: 0.001794  min_lr: 0.001794  loss: 2.7600 (2.6142)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:06  loss: 0.6851 (0.6851)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 1.5394  data: 1.3882  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.8432 (0.8957)  acc1: 81.2500 (78.2197)  acc5: 95.8333 (95.8333)  time: 0.2840  data: 0.1572  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.8786 (0.9349)  acc1: 79.1667 (77.9762)  acc5: 95.8333 (96.5278)  time: 0.1401  data: 0.0179  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.1563 (1.0901)  acc1: 75.0000 (70.1613)  acc5: 97.9167 (96.8414)  time: 0.1243  data: 0.0032  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.1700 (1.0922)  acc1: 68.7500 (71.0874)  acc5: 97.9167 (96.4431)  time: 0.1249  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.0364 (1.0917)  acc1: 72.9167 (70.8333)  acc5: 97.9167 (96.6912)  time: 0.1227  data: 0.0039  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.0883 (1.1008)  acc1: 70.8333 (70.3210)  acc5: 97.9167 (96.5164)  time: 0.1241  data: 0.0059  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.2105 (1.1329)  acc1: 62.5000 (68.8087)  acc5: 93.7500 (96.3322)  time: 0.1226  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1956 (1.0963)  acc1: 62.5000 (70.1389)  acc5: 95.8333 (96.4506)  time: 0.1185  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1698 (1.0941)  acc1: 66.6667 (70.2166)  acc5: 95.8333 (96.4076)  time: 0.1172  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1513 s / it)\n",
            "* Acc@1 70.217 Acc@5 96.408 loss 1.094\n",
            "Accuracy of the model on the 3925 test images: 70.2%\n",
            "Max accuracy: 70.29%\n",
            "Test:  [ 0/82]  eta: 0:04:21  loss: 4.2546 (4.2546)  acc1: 6.2500 (6.2500)  acc5: 70.8333 (70.8333)  time: 3.1927  data: 3.0067  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 4.1543 (4.1777)  acc1: 4.1667 (8.9015)  acc5: 77.0833 (77.2727)  time: 0.4574  data: 0.2963  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:20  loss: 4.0988 (4.1950)  acc1: 14.5833 (13.4921)  acc5: 77.0833 (76.9841)  time: 0.1836  data: 0.0339  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 4.8446 (4.6465)  acc1: 14.5833 (10.3495)  acc5: 68.7500 (68.8844)  time: 0.1613  data: 0.0269  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.7894 (4.8674)  acc1: 2.0833 (9.3496)  acc5: 54.1667 (65.7520)  time: 0.1333  data: 0.0067  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 5.0325 (4.7841)  acc1: 8.3333 (12.1732)  acc5: 58.3333 (66.0539)  time: 0.1256  data: 0.0041  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5343 (4.8552)  acc1: 10.4167 (11.1680)  acc5: 64.5833 (65.3347)  time: 0.1246  data: 0.0071  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5520 (4.8215)  acc1: 8.3333 (12.5587)  acc5: 81.2500 (65.6397)  time: 0.1232  data: 0.0042  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.0123 (4.4721)  acc1: 41.6667 (19.6502)  acc5: 87.5000 (68.6471)  time: 0.1198  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.9711 (4.4421)  acc1: 41.6667 (20.1783)  acc5: 87.5000 (68.8153)  time: 0.1186  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1818 s / it)\n",
            "* Acc@1 20.178 Acc@5 68.815 loss 4.442\n",
            "Accuracy of the model EMA on 3925 test images: 20.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [36]  [  0/295]  eta: 0:08:10  lr: 0.001791  min_lr: 0.001791  loss: 2.8141 (2.8141)  weight_decay: 0.0500 (0.0500)  time: 1.6619  data: 1.2947  max mem: 3500\n",
            "Epoch: [36]  [ 10/295]  eta: 0:01:53  lr: 0.001786  min_lr: 0.001786  loss: 2.6031 (2.6292)  weight_decay: 0.0500 (0.0500)  time: 0.3968  data: 0.1186  max mem: 3500\n",
            "Epoch: [36]  [ 20/295]  eta: 0:01:33  lr: 0.001777  min_lr: 0.001777  loss: 2.5577 (2.5915)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0022  max mem: 3500\n",
            "Epoch: [36]  [ 30/295]  eta: 0:01:23  lr: 0.001772  min_lr: 0.001772  loss: 2.5577 (2.5960)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0033  max mem: 3500\n",
            "Epoch: [36]  [ 40/295]  eta: 0:01:17  lr: 0.001763  min_lr: 0.001763  loss: 2.5974 (2.6006)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0022  max mem: 3500\n",
            "Epoch: [36]  [ 50/295]  eta: 0:01:12  lr: 0.001757  min_lr: 0.001757  loss: 2.5802 (2.5914)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0009  max mem: 3500\n",
            "Epoch: [36]  [ 60/295]  eta: 0:01:08  lr: 0.001749  min_lr: 0.001749  loss: 2.5989 (2.5978)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0009  max mem: 3500\n",
            "Epoch: [36]  [ 70/295]  eta: 0:01:04  lr: 0.001743  min_lr: 0.001743  loss: 2.6089 (2.6076)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0020  max mem: 3500\n",
            "Epoch: [36]  [ 80/295]  eta: 0:01:01  lr: 0.001735  min_lr: 0.001735  loss: 2.6409 (2.6132)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0020  max mem: 3500\n",
            "Epoch: [36]  [ 90/295]  eta: 0:00:58  lr: 0.001729  min_lr: 0.001729  loss: 2.5432 (2.6011)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0020  max mem: 3500\n",
            "Epoch: [36]  [100/295]  eta: 0:00:54  lr: 0.001720  min_lr: 0.001720  loss: 2.4759 (2.5886)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0034  max mem: 3500\n",
            "Epoch: [36]  [110/295]  eta: 0:00:51  lr: 0.001715  min_lr: 0.001715  loss: 2.6564 (2.5992)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0033  max mem: 3500\n",
            "Epoch: [36]  [120/295]  eta: 0:00:48  lr: 0.001706  min_lr: 0.001706  loss: 2.5511 (2.5864)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0021  max mem: 3500\n",
            "Epoch: [36]  [130/295]  eta: 0:00:45  lr: 0.001700  min_lr: 0.001700  loss: 2.4652 (2.5833)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0021  max mem: 3500\n",
            "Epoch: [36]  [140/295]  eta: 0:00:42  lr: 0.001692  min_lr: 0.001692  loss: 2.5408 (2.5792)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0024  max mem: 3500\n",
            "Epoch: [36]  [150/295]  eta: 0:00:39  lr: 0.001686  min_lr: 0.001686  loss: 2.5245 (2.5762)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0030  max mem: 3500\n",
            "Epoch: [36]  [160/295]  eta: 0:00:37  lr: 0.001678  min_lr: 0.001678  loss: 2.5556 (2.5796)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0031  max mem: 3500\n",
            "Epoch: [36]  [170/295]  eta: 0:00:34  lr: 0.001672  min_lr: 0.001672  loss: 2.6545 (2.5846)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0029  max mem: 3500\n",
            "Epoch: [36]  [180/295]  eta: 0:00:31  lr: 0.001664  min_lr: 0.001664  loss: 2.5748 (2.5833)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0032  max mem: 3500\n",
            "Epoch: [36]  [190/295]  eta: 0:00:28  lr: 0.001658  min_lr: 0.001658  loss: 2.5340 (2.5810)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0029  max mem: 3500\n",
            "Epoch: [36]  [200/295]  eta: 0:00:25  lr: 0.001650  min_lr: 0.001650  loss: 2.5468 (2.5814)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0029  max mem: 3500\n",
            "Epoch: [36]  [210/295]  eta: 0:00:23  lr: 0.001644  min_lr: 0.001644  loss: 2.6064 (2.5798)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0019  max mem: 3500\n",
            "Epoch: [36]  [220/295]  eta: 0:00:20  lr: 0.001635  min_lr: 0.001635  loss: 2.5710 (2.5787)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0030  max mem: 3500\n",
            "Epoch: [36]  [230/295]  eta: 0:00:17  lr: 0.001630  min_lr: 0.001630  loss: 2.6395 (2.5805)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0039  max mem: 3500\n",
            "Epoch: [36]  [240/295]  eta: 0:00:14  lr: 0.001621  min_lr: 0.001621  loss: 2.6395 (2.5812)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0037  max mem: 3500\n",
            "Epoch: [36]  [250/295]  eta: 0:00:12  lr: 0.001616  min_lr: 0.001616  loss: 2.6041 (2.5829)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0035  max mem: 3500\n",
            "Epoch: [36]  [260/295]  eta: 0:00:09  lr: 0.001607  min_lr: 0.001607  loss: 2.6073 (2.5804)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0019  max mem: 3500\n",
            "Epoch: [36]  [270/295]  eta: 0:00:06  lr: 0.001602  min_lr: 0.001602  loss: 2.5857 (2.5789)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0016  max mem: 3500\n",
            "Epoch: [36]  [280/295]  eta: 0:00:04  lr: 0.001593  min_lr: 0.001593  loss: 2.5232 (2.5794)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0010  max mem: 3500\n",
            "Epoch: [36]  [290/295]  eta: 0:00:01  lr: 0.001588  min_lr: 0.001588  loss: 2.5243 (2.5767)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0001  max mem: 3500\n",
            "Epoch: [36]  [294/295]  eta: 0:00:00  lr: 0.001588  min_lr: 0.001588  loss: 2.5243 (2.5760)  weight_decay: 0.0500 (0.0500)  time: 0.2210  data: 0.0001  max mem: 3500\n",
            "Epoch: [36] Total time: 0:01:19 (0.2679 s / it)\n",
            "Averaged stats: lr: 0.001588  min_lr: 0.001588  loss: 2.5243 (2.5760)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:17  loss: 0.6385 (0.6385)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 1.6792  data: 1.4965  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 0.6815 (0.7383)  acc1: 87.5000 (84.4697)  acc5: 97.9167 (97.5379)  time: 0.2658  data: 0.1373  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.7144 (0.7481)  acc1: 83.3333 (82.5397)  acc5: 97.9167 (97.6190)  time: 0.1235  data: 0.0028  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:08  loss: 0.8583 (0.9823)  acc1: 72.9167 (72.5806)  acc5: 95.8333 (96.3710)  time: 0.1219  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 0.9207 (0.9526)  acc1: 79.1667 (74.4919)  acc5: 95.8333 (96.5955)  time: 0.1222  data: 0.0020  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 0.9262 (0.9902)  acc1: 77.0833 (73.2435)  acc5: 97.9167 (96.5278)  time: 0.1233  data: 0.0044  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.0234 (0.9897)  acc1: 66.6667 (72.9850)  acc5: 97.9167 (96.2773)  time: 0.1224  data: 0.0061  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.2208 (1.0275)  acc1: 64.5833 (71.4789)  acc5: 95.8333 (96.1268)  time: 0.1200  data: 0.0031  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1834 (1.0158)  acc1: 64.5833 (72.1965)  acc5: 95.8333 (96.2191)  time: 0.1182  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1013 (1.0165)  acc1: 66.6667 (72.2293)  acc5: 95.8333 (96.1529)  time: 0.1169  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1471 s / it)\n",
            "* Acc@1 72.229 Acc@5 96.153 loss 1.017\n",
            "Accuracy of the model on the 3925 test images: 72.2%\n",
            "Max accuracy: 72.23%\n",
            "Test:  [ 0/82]  eta: 0:03:23  loss: 4.1961 (4.1961)  acc1: 6.2500 (6.2500)  acc5: 70.8333 (70.8333)  time: 2.4828  data: 2.3188  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 4.0975 (4.1305)  acc1: 4.1667 (8.7121)  acc5: 79.1667 (78.4091)  time: 0.3537  data: 0.2275  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 4.0550 (4.1479)  acc1: 16.6667 (13.5913)  acc5: 79.1667 (77.6786)  time: 0.1309  data: 0.0096  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 4.8089 (4.6100)  acc1: 14.5833 (10.4839)  acc5: 70.8333 (69.6237)  time: 0.1229  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.7458 (4.8316)  acc1: 2.0833 (9.5020)  acc5: 54.1667 (66.4634)  time: 0.1261  data: 0.0034  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.9907 (4.7595)  acc1: 6.2500 (12.1732)  acc5: 58.3333 (66.6667)  time: 0.1250  data: 0.0042  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5550 (4.8374)  acc1: 8.3333 (10.9973)  acc5: 64.5833 (65.7445)  time: 0.1215  data: 0.0044  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5615 (4.7981)  acc1: 6.2500 (12.4707)  acc5: 81.2500 (65.9624)  time: 0.1197  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.9082 (4.4447)  acc1: 41.6667 (19.5730)  acc5: 87.5000 (68.9815)  time: 0.1185  data: 0.0010  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.8622 (4.4146)  acc1: 43.7500 (20.1019)  acc5: 87.5000 (69.1465)  time: 0.1162  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1573 s / it)\n",
            "* Acc@1 20.102 Acc@5 69.146 loss 4.415\n",
            "Accuracy of the model EMA on 3925 test images: 20.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [37]  [  0/295]  eta: 0:11:51  lr: 0.001585  min_lr: 0.001585  loss: 2.1718 (2.1718)  weight_decay: 0.0500 (0.0500)  time: 2.4109  data: 1.7775  max mem: 3500\n",
            "Epoch: [37]  [ 10/295]  eta: 0:02:28  lr: 0.001579  min_lr: 0.001579  loss: 2.6909 (2.5656)  weight_decay: 0.0500 (0.0500)  time: 0.5199  data: 0.1650  max mem: 3500\n",
            "Epoch: [37]  [ 20/295]  eta: 0:01:49  lr: 0.001571  min_lr: 0.001571  loss: 2.6212 (2.5318)  weight_decay: 0.0500 (0.0500)  time: 0.2987  data: 0.0020  max mem: 3500\n",
            "Epoch: [37]  [ 30/295]  eta: 0:01:34  lr: 0.001565  min_lr: 0.001565  loss: 2.5253 (2.5411)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0016  max mem: 3500\n",
            "Epoch: [37]  [ 40/295]  eta: 0:01:24  lr: 0.001557  min_lr: 0.001557  loss: 2.5101 (2.5341)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0027  max mem: 3500\n",
            "Epoch: [37]  [ 50/295]  eta: 0:01:18  lr: 0.001551  min_lr: 0.001551  loss: 2.5875 (2.5636)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0027  max mem: 3500\n",
            "Epoch: [37]  [ 60/295]  eta: 0:01:13  lr: 0.001543  min_lr: 0.001543  loss: 2.6408 (2.5732)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0029  max mem: 3500\n",
            "Epoch: [37]  [ 70/295]  eta: 0:01:08  lr: 0.001537  min_lr: 0.001537  loss: 2.6445 (2.5786)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0029  max mem: 3500\n",
            "Epoch: [37]  [ 80/295]  eta: 0:01:04  lr: 0.001529  min_lr: 0.001529  loss: 2.6010 (2.5785)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0034  max mem: 3500\n",
            "Epoch: [37]  [ 90/295]  eta: 0:01:00  lr: 0.001523  min_lr: 0.001523  loss: 2.4948 (2.5765)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0037  max mem: 3500\n",
            "Epoch: [37]  [100/295]  eta: 0:00:57  lr: 0.001515  min_lr: 0.001515  loss: 2.6487 (2.5859)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0038  max mem: 3500\n",
            "Epoch: [37]  [110/295]  eta: 0:00:53  lr: 0.001509  min_lr: 0.001509  loss: 2.7231 (2.5898)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0023  max mem: 3500\n",
            "Epoch: [37]  [120/295]  eta: 0:00:50  lr: 0.001501  min_lr: 0.001501  loss: 2.6338 (2.5902)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0010  max mem: 3500\n",
            "Epoch: [37]  [130/295]  eta: 0:00:47  lr: 0.001495  min_lr: 0.001495  loss: 2.6233 (2.5848)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0006  max mem: 3500\n",
            "Epoch: [37]  [140/295]  eta: 0:00:44  lr: 0.001487  min_lr: 0.001487  loss: 2.6838 (2.5888)  weight_decay: 0.0500 (0.0500)  time: 0.2773  data: 0.0020  max mem: 3500\n",
            "Epoch: [37]  [150/295]  eta: 0:00:41  lr: 0.001482  min_lr: 0.001482  loss: 2.5689 (2.5830)  weight_decay: 0.0500 (0.0500)  time: 0.2794  data: 0.0051  max mem: 3500\n",
            "Epoch: [37]  [160/295]  eta: 0:00:38  lr: 0.001473  min_lr: 0.001473  loss: 2.4989 (2.5815)  weight_decay: 0.0500 (0.0500)  time: 0.2769  data: 0.0068  max mem: 3500\n",
            "Epoch: [37]  [170/295]  eta: 0:00:35  lr: 0.001468  min_lr: 0.001468  loss: 2.5530 (2.5856)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0061  max mem: 3500\n",
            "Epoch: [37]  [180/295]  eta: 0:00:32  lr: 0.001459  min_lr: 0.001459  loss: 2.6640 (2.5903)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0033  max mem: 3500\n",
            "Epoch: [37]  [190/295]  eta: 0:00:29  lr: 0.001454  min_lr: 0.001454  loss: 2.5830 (2.5846)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0017  max mem: 3500\n",
            "Epoch: [37]  [200/295]  eta: 0:00:26  lr: 0.001446  min_lr: 0.001446  loss: 2.5828 (2.5874)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0021  max mem: 3500\n",
            "Epoch: [37]  [210/295]  eta: 0:00:23  lr: 0.001440  min_lr: 0.001440  loss: 2.6851 (2.5917)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0017  max mem: 3500\n",
            "Epoch: [37]  [220/295]  eta: 0:00:20  lr: 0.001432  min_lr: 0.001432  loss: 2.7171 (2.5978)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0026  max mem: 3500\n",
            "Epoch: [37]  [230/295]  eta: 0:00:18  lr: 0.001426  min_lr: 0.001426  loss: 2.6712 (2.5957)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0037  max mem: 3500\n",
            "Epoch: [37]  [240/295]  eta: 0:00:15  lr: 0.001418  min_lr: 0.001418  loss: 2.5399 (2.5954)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0029  max mem: 3500\n",
            "Epoch: [37]  [250/295]  eta: 0:00:12  lr: 0.001413  min_lr: 0.001413  loss: 2.6968 (2.5984)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0024  max mem: 3500\n",
            "Epoch: [37]  [260/295]  eta: 0:00:09  lr: 0.001404  min_lr: 0.001404  loss: 2.6630 (2.5979)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0023  max mem: 3500\n",
            "Epoch: [37]  [270/295]  eta: 0:00:06  lr: 0.001399  min_lr: 0.001399  loss: 2.5129 (2.5921)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0017  max mem: 3500\n",
            "Epoch: [37]  [280/295]  eta: 0:00:04  lr: 0.001391  min_lr: 0.001391  loss: 2.5129 (2.5901)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0008  max mem: 3500\n",
            "Epoch: [37]  [290/295]  eta: 0:00:01  lr: 0.001385  min_lr: 0.001385  loss: 2.6051 (2.5901)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0003  max mem: 3500\n",
            "Epoch: [37]  [294/295]  eta: 0:00:00  lr: 0.001385  min_lr: 0.001385  loss: 2.6051 (2.5908)  weight_decay: 0.0500 (0.0500)  time: 0.2210  data: 0.0001  max mem: 3500\n",
            "Epoch: [37] Total time: 0:01:20 (0.2738 s / it)\n",
            "Averaged stats: lr: 0.001385  min_lr: 0.001385  loss: 2.6051 (2.5908)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:06  loss: 0.7276 (0.7276)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.2700  data: 2.1014  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.7776 (0.8157)  acc1: 85.4167 (82.5758)  acc5: 95.8333 (96.0227)  time: 0.3177  data: 0.1927  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.7587 (0.7721)  acc1: 83.3333 (82.7381)  acc5: 95.8333 (96.8254)  time: 0.1233  data: 0.0027  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.8247 (1.0489)  acc1: 75.0000 (70.9677)  acc5: 95.8333 (94.9597)  time: 0.1237  data: 0.0039  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.2685 (1.0918)  acc1: 66.6667 (70.1728)  acc5: 93.7500 (95.2744)  time: 0.1241  data: 0.0044  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.1751 (1.1057)  acc1: 66.6667 (69.6078)  acc5: 95.8333 (95.4248)  time: 0.1225  data: 0.0041  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.0449 (1.0801)  acc1: 68.7500 (70.1503)  acc5: 95.8333 (95.5943)  time: 0.1209  data: 0.0038  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.0449 (1.0856)  acc1: 70.8333 (69.9824)  acc5: 95.8333 (95.6279)  time: 0.1199  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9585 (1.0499)  acc1: 72.9167 (71.1677)  acc5: 97.9167 (95.8591)  time: 0.1180  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9585 (1.0498)  acc1: 75.0000 (71.2102)  acc5: 97.9167 (95.8217)  time: 0.1165  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1542 s / it)\n",
            "* Acc@1 71.210 Acc@5 95.822 loss 1.050\n",
            "Accuracy of the model on the 3925 test images: 71.2%\n",
            "Max accuracy: 72.23%\n",
            "Test:  [ 0/82]  eta: 0:04:03  loss: 4.1366 (4.1366)  acc1: 6.2500 (6.2500)  acc5: 77.0833 (77.0833)  time: 2.9737  data: 2.8053  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 4.0416 (4.0862)  acc1: 4.1667 (9.0909)  acc5: 79.1667 (79.5455)  time: 0.3999  data: 0.2571  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 4.0188 (4.1054)  acc1: 16.6667 (13.7897)  acc5: 79.1667 (78.3730)  time: 0.1379  data: 0.0043  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.7697 (4.5746)  acc1: 14.5833 (10.5511)  acc5: 70.8333 (70.2285)  time: 0.1281  data: 0.0047  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 5.6978 (4.7955)  acc1: 2.0833 (9.5528)  acc5: 54.1667 (67.0224)  time: 0.1224  data: 0.0033  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.9448 (4.7343)  acc1: 6.2500 (12.0915)  acc5: 58.3333 (67.0752)  time: 0.1224  data: 0.0036  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5723 (4.8185)  acc1: 8.3333 (10.8607)  acc5: 64.5833 (66.0178)  time: 0.1228  data: 0.0048  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5723 (4.7733)  acc1: 4.1667 (12.4120)  acc5: 81.2500 (66.2852)  time: 0.1214  data: 0.0030  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.8102 (4.4166)  acc1: 41.6667 (19.4702)  acc5: 87.5000 (69.3158)  time: 0.1192  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.7562 (4.3863)  acc1: 45.8333 (20.0000)  acc5: 89.1892 (69.5032)  time: 0.1174  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1647 s / it)\n",
            "* Acc@1 20.000 Acc@5 69.503 loss 4.386\n",
            "Accuracy of the model EMA on 3925 test images: 20.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [38]  [  0/295]  eta: 0:08:06  lr: 0.001383  min_lr: 0.001383  loss: 2.4291 (2.4291)  weight_decay: 0.0500 (0.0500)  time: 1.6506  data: 1.2991  max mem: 3500\n",
            "Epoch: [38]  [ 10/295]  eta: 0:02:00  lr: 0.001377  min_lr: 0.001377  loss: 2.4291 (2.4953)  weight_decay: 0.0500 (0.0500)  time: 0.4225  data: 0.1194  max mem: 3500\n",
            "Epoch: [38]  [ 20/295]  eta: 0:01:36  lr: 0.001369  min_lr: 0.001369  loss: 2.4722 (2.4911)  weight_decay: 0.0500 (0.0500)  time: 0.2862  data: 0.0031  max mem: 3500\n",
            "Epoch: [38]  [ 30/295]  eta: 0:01:25  lr: 0.001364  min_lr: 0.001364  loss: 2.5644 (2.5317)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0028  max mem: 3500\n",
            "Epoch: [38]  [ 40/295]  eta: 0:01:18  lr: 0.001355  min_lr: 0.001355  loss: 2.5870 (2.5387)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0013  max mem: 3500\n",
            "Epoch: [38]  [ 50/295]  eta: 0:01:13  lr: 0.001350  min_lr: 0.001350  loss: 2.4479 (2.5172)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0010  max mem: 3500\n",
            "Epoch: [38]  [ 60/295]  eta: 0:01:08  lr: 0.001342  min_lr: 0.001342  loss: 2.5696 (2.5276)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0003  max mem: 3500\n",
            "Epoch: [38]  [ 70/295]  eta: 0:01:05  lr: 0.001336  min_lr: 0.001336  loss: 2.5809 (2.5256)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0009  max mem: 3500\n",
            "Epoch: [38]  [ 80/295]  eta: 0:01:01  lr: 0.001328  min_lr: 0.001328  loss: 2.5665 (2.5296)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0022  max mem: 3500\n",
            "Epoch: [38]  [ 90/295]  eta: 0:00:58  lr: 0.001323  min_lr: 0.001323  loss: 2.6322 (2.5315)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0027  max mem: 3500\n",
            "Epoch: [38]  [100/295]  eta: 0:00:55  lr: 0.001315  min_lr: 0.001315  loss: 2.5605 (2.5349)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0026  max mem: 3500\n",
            "Epoch: [38]  [110/295]  eta: 0:00:52  lr: 0.001309  min_lr: 0.001309  loss: 2.5605 (2.5329)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0024  max mem: 3500\n",
            "Epoch: [38]  [120/295]  eta: 0:00:48  lr: 0.001301  min_lr: 0.001301  loss: 2.5724 (2.5376)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0012  max mem: 3500\n",
            "Epoch: [38]  [130/295]  eta: 0:00:45  lr: 0.001296  min_lr: 0.001296  loss: 2.5856 (2.5405)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0007  max mem: 3500\n",
            "Epoch: [38]  [140/295]  eta: 0:00:42  lr: 0.001288  min_lr: 0.001288  loss: 2.5959 (2.5422)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0014  max mem: 3500\n",
            "Epoch: [38]  [150/295]  eta: 0:00:40  lr: 0.001283  min_lr: 0.001283  loss: 2.4805 (2.5359)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0025  max mem: 3500\n",
            "Epoch: [38]  [160/295]  eta: 0:00:37  lr: 0.001275  min_lr: 0.001275  loss: 2.4805 (2.5380)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0034  max mem: 3500\n",
            "Epoch: [38]  [170/295]  eta: 0:00:34  lr: 0.001269  min_lr: 0.001269  loss: 2.5848 (2.5386)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0028  max mem: 3500\n",
            "Epoch: [38]  [180/295]  eta: 0:00:31  lr: 0.001261  min_lr: 0.001261  loss: 2.5839 (2.5396)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0011  max mem: 3500\n",
            "Epoch: [38]  [190/295]  eta: 0:00:28  lr: 0.001256  min_lr: 0.001256  loss: 2.5545 (2.5413)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0008  max mem: 3500\n",
            "Epoch: [38]  [200/295]  eta: 0:00:25  lr: 0.001248  min_lr: 0.001248  loss: 2.7042 (2.5501)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0021  max mem: 3500\n",
            "Epoch: [38]  [210/295]  eta: 0:00:23  lr: 0.001243  min_lr: 0.001243  loss: 2.6904 (2.5507)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0041  max mem: 3500\n",
            "Epoch: [38]  [220/295]  eta: 0:00:20  lr: 0.001235  min_lr: 0.001235  loss: 2.5452 (2.5531)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0047  max mem: 3500\n",
            "Epoch: [38]  [230/295]  eta: 0:00:17  lr: 0.001229  min_lr: 0.001229  loss: 2.5831 (2.5568)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0039  max mem: 3500\n",
            "Epoch: [38]  [240/295]  eta: 0:00:14  lr: 0.001221  min_lr: 0.001221  loss: 2.5831 (2.5560)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0027  max mem: 3500\n",
            "Epoch: [38]  [250/295]  eta: 0:00:12  lr: 0.001216  min_lr: 0.001216  loss: 2.5848 (2.5588)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0013  max mem: 3500\n",
            "Epoch: [38]  [260/295]  eta: 0:00:09  lr: 0.001208  min_lr: 0.001208  loss: 2.5391 (2.5553)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0013  max mem: 3500\n",
            "Epoch: [38]  [270/295]  eta: 0:00:06  lr: 0.001203  min_lr: 0.001203  loss: 2.4766 (2.5521)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0023  max mem: 3500\n",
            "Epoch: [38]  [280/295]  eta: 0:00:04  lr: 0.001195  min_lr: 0.001195  loss: 2.5687 (2.5549)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0022  max mem: 3500\n",
            "Epoch: [38]  [290/295]  eta: 0:00:01  lr: 0.001190  min_lr: 0.001190  loss: 2.5687 (2.5573)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0010  max mem: 3500\n",
            "Epoch: [38]  [294/295]  eta: 0:00:00  lr: 0.001190  min_lr: 0.001190  loss: 2.5577 (2.5564)  weight_decay: 0.0500 (0.0500)  time: 0.2212  data: 0.0003  max mem: 3500\n",
            "Epoch: [38] Total time: 0:01:19 (0.2679 s / it)\n",
            "Averaged stats: lr: 0.001190  min_lr: 0.001190  loss: 2.5577 (2.5564)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:35  loss: 0.5993 (0.5993)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 1.8970  data: 1.7331  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 0.6580 (0.7301)  acc1: 83.3333 (82.0076)  acc5: 95.8333 (96.5909)  time: 0.3465  data: 0.2151  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.7868 (0.7989)  acc1: 79.1667 (80.4564)  acc5: 95.8333 (96.9246)  time: 0.1812  data: 0.0480  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.9090 (0.9767)  acc1: 75.0000 (73.1855)  acc5: 97.9167 (96.6398)  time: 0.1726  data: 0.0379  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.9434 (0.9650)  acc1: 72.9167 (74.0346)  acc5: 95.8333 (96.7988)  time: 0.1806  data: 0.0444  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.9176 (0.9562)  acc1: 77.0833 (74.4281)  acc5: 97.9167 (97.0180)  time: 0.1995  data: 0.0492  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9176 (0.9543)  acc1: 75.0000 (74.4536)  acc5: 97.9167 (96.7896)  time: 0.2033  data: 0.0509  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.1023 (0.9906)  acc1: 66.6667 (72.6819)  acc5: 95.8333 (96.3615)  time: 0.1828  data: 0.0442  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0196 (0.9579)  acc1: 68.7500 (73.9969)  acc5: 95.8333 (96.5021)  time: 0.1513  data: 0.0267  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9999 (0.9568)  acc1: 72.9167 (74.0637)  acc5: 95.8333 (96.4586)  time: 0.1318  data: 0.0081  max mem: 3500\n",
            "Test: Total time: 0:00:16 (0.2052 s / it)\n",
            "* Acc@1 74.064 Acc@5 96.459 loss 0.957\n",
            "Accuracy of the model on the 3925 test images: 74.1%\n",
            "Max accuracy: 74.06%\n",
            "Test:  [ 0/82]  eta: 0:02:22  loss: 4.0748 (4.0748)  acc1: 6.2500 (6.2500)  acc5: 81.2500 (81.2500)  time: 1.7337  data: 1.5720  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 3.9833 (4.0387)  acc1: 4.1667 (9.4697)  acc5: 81.2500 (80.4924)  time: 0.2678  data: 0.1449  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.9790 (4.0619)  acc1: 14.5833 (13.9881)  acc5: 79.1667 (78.7698)  time: 0.1214  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.7317 (4.5384)  acc1: 14.5833 (10.8199)  acc5: 70.8333 (70.6317)  time: 0.1224  data: 0.0034  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 5.6515 (4.7596)  acc1: 2.0833 (9.7053)  acc5: 54.1667 (67.2256)  time: 0.1233  data: 0.0038  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 4.9040 (4.7113)  acc1: 6.2500 (12.0098)  acc5: 58.3333 (67.1569)  time: 0.1230  data: 0.0038  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5860 (4.8020)  acc1: 6.2500 (10.5533)  acc5: 64.5833 (66.1202)  time: 0.1240  data: 0.0049  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5860 (4.7514)  acc1: 2.0833 (12.2359)  acc5: 81.2500 (66.3732)  time: 0.1232  data: 0.0034  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.7186 (4.3911)  acc1: 43.7500 (19.3930)  acc5: 89.5833 (69.4959)  time: 0.1201  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.6590 (4.3608)  acc1: 45.8333 (19.9236)  acc5: 89.5833 (69.6815)  time: 0.1185  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1481 s / it)\n",
            "* Acc@1 19.924 Acc@5 69.682 loss 4.361\n",
            "Accuracy of the model EMA on 3925 test images: 19.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [39]  [  0/295]  eta: 0:11:57  lr: 0.001187  min_lr: 0.001187  loss: 2.4529 (2.4529)  weight_decay: 0.0500 (0.0500)  time: 2.4317  data: 1.8983  max mem: 3500\n",
            "Epoch: [39]  [ 10/295]  eta: 0:02:22  lr: 0.001182  min_lr: 0.001182  loss: 2.4811 (2.5302)  weight_decay: 0.0500 (0.0500)  time: 0.5009  data: 0.1741  max mem: 3500\n",
            "Epoch: [39]  [ 20/295]  eta: 0:01:46  lr: 0.001174  min_lr: 0.001174  loss: 2.5956 (2.5450)  weight_decay: 0.0500 (0.0500)  time: 0.2861  data: 0.0016  max mem: 3500\n",
            "Epoch: [39]  [ 30/295]  eta: 0:01:32  lr: 0.001169  min_lr: 0.001169  loss: 2.6231 (2.5389)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0014  max mem: 3500\n",
            "Epoch: [39]  [ 40/295]  eta: 0:01:23  lr: 0.001161  min_lr: 0.001161  loss: 2.5594 (2.5560)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0014  max mem: 3500\n",
            "Epoch: [39]  [ 50/295]  eta: 0:01:17  lr: 0.001156  min_lr: 0.001156  loss: 2.5553 (2.5558)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0008  max mem: 3500\n",
            "Epoch: [39]  [ 60/295]  eta: 0:01:12  lr: 0.001148  min_lr: 0.001148  loss: 2.5517 (2.5558)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0010  max mem: 3500\n",
            "Epoch: [39]  [ 70/295]  eta: 0:01:08  lr: 0.001143  min_lr: 0.001143  loss: 2.5517 (2.5625)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0019  max mem: 3500\n",
            "Epoch: [39]  [ 80/295]  eta: 0:01:03  lr: 0.001135  min_lr: 0.001135  loss: 2.6326 (2.5714)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0015  max mem: 3500\n",
            "Epoch: [39]  [ 90/295]  eta: 0:01:00  lr: 0.001130  min_lr: 0.001130  loss: 2.6326 (2.5753)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0013  max mem: 3500\n",
            "Epoch: [39]  [100/295]  eta: 0:00:56  lr: 0.001122  min_lr: 0.001122  loss: 2.4603 (2.5564)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0018  max mem: 3500\n",
            "Epoch: [39]  [110/295]  eta: 0:00:53  lr: 0.001117  min_lr: 0.001117  loss: 2.4190 (2.5537)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0018  max mem: 3500\n",
            "Epoch: [39]  [120/295]  eta: 0:00:50  lr: 0.001109  min_lr: 0.001109  loss: 2.5197 (2.5498)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0028  max mem: 3500\n",
            "Epoch: [39]  [130/295]  eta: 0:00:47  lr: 0.001104  min_lr: 0.001104  loss: 2.5197 (2.5459)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0040  max mem: 3500\n",
            "Epoch: [39]  [140/295]  eta: 0:00:43  lr: 0.001097  min_lr: 0.001097  loss: 2.5419 (2.5436)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0022  max mem: 3500\n",
            "Epoch: [39]  [150/295]  eta: 0:00:40  lr: 0.001091  min_lr: 0.001091  loss: 2.6018 (2.5502)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0013  max mem: 3500\n",
            "Epoch: [39]  [160/295]  eta: 0:00:37  lr: 0.001084  min_lr: 0.001084  loss: 2.5701 (2.5446)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0024  max mem: 3500\n",
            "Epoch: [39]  [170/295]  eta: 0:00:34  lr: 0.001079  min_lr: 0.001079  loss: 2.5466 (2.5516)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0027  max mem: 3500\n",
            "Epoch: [39]  [180/295]  eta: 0:00:32  lr: 0.001071  min_lr: 0.001071  loss: 2.6635 (2.5556)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0028  max mem: 3500\n",
            "Epoch: [39]  [190/295]  eta: 0:00:29  lr: 0.001066  min_lr: 0.001066  loss: 2.6832 (2.5623)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0014  max mem: 3500\n",
            "Epoch: [39]  [200/295]  eta: 0:00:26  lr: 0.001058  min_lr: 0.001058  loss: 2.6215 (2.5609)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0020  max mem: 3500\n",
            "Epoch: [39]  [210/295]  eta: 0:00:23  lr: 0.001053  min_lr: 0.001053  loss: 2.5264 (2.5565)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0032  max mem: 3500\n",
            "Epoch: [39]  [220/295]  eta: 0:00:20  lr: 0.001046  min_lr: 0.001046  loss: 2.5296 (2.5540)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0022  max mem: 3500\n",
            "Epoch: [39]  [230/295]  eta: 0:00:17  lr: 0.001041  min_lr: 0.001041  loss: 2.5716 (2.5528)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0023  max mem: 3500\n",
            "Epoch: [39]  [240/295]  eta: 0:00:15  lr: 0.001033  min_lr: 0.001033  loss: 2.5716 (2.5494)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0024  max mem: 3500\n",
            "Epoch: [39]  [250/295]  eta: 0:00:12  lr: 0.001028  min_lr: 0.001028  loss: 2.4544 (2.5506)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0028  max mem: 3500\n",
            "Epoch: [39]  [260/295]  eta: 0:00:09  lr: 0.001021  min_lr: 0.001021  loss: 2.4544 (2.5452)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0045  max mem: 3500\n",
            "Epoch: [39]  [270/295]  eta: 0:00:06  lr: 0.001016  min_lr: 0.001016  loss: 2.4624 (2.5439)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0050  max mem: 3500\n",
            "Epoch: [39]  [280/295]  eta: 0:00:04  lr: 0.001008  min_lr: 0.001008  loss: 2.4624 (2.5398)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0025  max mem: 3500\n",
            "Epoch: [39]  [290/295]  eta: 0:00:01  lr: 0.001003  min_lr: 0.001003  loss: 2.4562 (2.5377)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0002  max mem: 3500\n",
            "Epoch: [39]  [294/295]  eta: 0:00:00  lr: 0.001003  min_lr: 0.001003  loss: 2.4562 (2.5385)  weight_decay: 0.0500 (0.0500)  time: 0.2189  data: 0.0002  max mem: 3500\n",
            "Epoch: [39] Total time: 0:01:19 (0.2710 s / it)\n",
            "Averaged stats: lr: 0.001003  min_lr: 0.001003  loss: 2.4562 (2.5385)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:40  loss: 0.5461 (0.5461)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 1.9526  data: 1.7894  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.5544 (0.5986)  acc1: 87.5000 (86.9318)  acc5: 95.8333 (96.7803)  time: 0.3057  data: 0.1637  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.6826 (0.6625)  acc1: 85.4167 (85.1191)  acc5: 97.9167 (97.4206)  time: 0.1377  data: 0.0022  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.8453 (0.8892)  acc1: 77.0833 (75.6720)  acc5: 97.9167 (97.2446)  time: 0.1582  data: 0.0239  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.9867 (0.8944)  acc1: 68.7500 (75.9654)  acc5: 97.9167 (97.0528)  time: 0.1744  data: 0.0345  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.9025 (0.9059)  acc1: 75.0000 (75.6536)  acc5: 97.9167 (97.0180)  time: 0.1538  data: 0.0134  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9307 (0.9065)  acc1: 75.0000 (75.9221)  acc5: 95.8333 (96.6872)  time: 0.1474  data: 0.0081  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.1460 (0.9571)  acc1: 64.5833 (74.0317)  acc5: 95.8333 (96.3322)  time: 0.1450  data: 0.0139  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1265 (0.9340)  acc1: 64.5833 (74.9743)  acc5: 95.8333 (96.5021)  time: 0.1270  data: 0.0071  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0691 (0.9339)  acc1: 70.8333 (75.0064)  acc5: 95.8333 (96.4586)  time: 0.1181  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1730 s / it)\n",
            "* Acc@1 75.006 Acc@5 96.459 loss 0.934\n",
            "Accuracy of the model on the 3925 test images: 75.0%\n",
            "Max accuracy: 75.01%\n",
            "Test:  [ 0/82]  eta: 0:02:19  loss: 4.0016 (4.0016)  acc1: 8.3333 (8.3333)  acc5: 81.2500 (81.2500)  time: 1.7033  data: 1.5429  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 3.9478 (3.9845)  acc1: 4.1667 (9.8485)  acc5: 81.2500 (81.8182)  time: 0.2760  data: 0.1522  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.9162 (4.0168)  acc1: 14.5833 (14.1865)  acc5: 79.1667 (79.7619)  time: 0.1276  data: 0.0074  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.6999 (4.5020)  acc1: 12.5000 (10.9543)  acc5: 70.8333 (71.4382)  time: 0.1231  data: 0.0016  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 5.6011 (4.7228)  acc1: 2.0833 (9.7561)  acc5: 54.1667 (67.7846)  time: 0.1281  data: 0.0019  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8598 (4.6871)  acc1: 6.2500 (11.9690)  acc5: 56.2500 (67.6062)  time: 0.1342  data: 0.0016  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5987 (4.7843)  acc1: 6.2500 (10.4850)  acc5: 64.5833 (66.4276)  time: 0.1357  data: 0.0011  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5987 (4.7286)  acc1: 2.0833 (12.1772)  acc5: 81.2500 (66.6080)  time: 0.1397  data: 0.0097  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.6305 (4.3649)  acc1: 45.8333 (19.4702)  acc5: 89.5833 (69.7531)  time: 0.1406  data: 0.0167  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.5652 (4.3343)  acc1: 45.8333 (20.0000)  acc5: 89.5833 (69.9363)  time: 0.1395  data: 0.0167  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1577 s / it)\n",
            "* Acc@1 20.000 Acc@5 69.936 loss 4.334\n",
            "Accuracy of the model EMA on 3925 test images: 20.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [40]  [  0/295]  eta: 0:08:54  lr: 0.001001  min_lr: 0.001001  loss: 2.3167 (2.3167)  weight_decay: 0.0500 (0.0500)  time: 1.8117  data: 1.4631  max mem: 3500\n",
            "Epoch: [40]  [ 10/295]  eta: 0:01:57  lr: 0.000996  min_lr: 0.000996  loss: 2.3853 (2.4334)  weight_decay: 0.0500 (0.0500)  time: 0.4113  data: 0.1343  max mem: 3500\n",
            "Epoch: [40]  [ 20/295]  eta: 0:01:33  lr: 0.000988  min_lr: 0.000988  loss: 2.3853 (2.3997)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0014  max mem: 3500\n",
            "Epoch: [40]  [ 30/295]  eta: 0:01:23  lr: 0.000983  min_lr: 0.000983  loss: 2.4776 (2.4556)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0020  max mem: 3500\n",
            "Epoch: [40]  [ 40/295]  eta: 0:01:17  lr: 0.000976  min_lr: 0.000976  loss: 2.4878 (2.4643)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0040  max mem: 3500\n",
            "Epoch: [40]  [ 50/295]  eta: 0:01:13  lr: 0.000971  min_lr: 0.000971  loss: 2.5682 (2.5004)  weight_decay: 0.0500 (0.0500)  time: 0.2747  data: 0.0042  max mem: 3500\n",
            "Epoch: [40]  [ 60/295]  eta: 0:01:09  lr: 0.000964  min_lr: 0.000964  loss: 2.5690 (2.5049)  weight_decay: 0.0500 (0.0500)  time: 0.2765  data: 0.0025  max mem: 3500\n",
            "Epoch: [40]  [ 70/295]  eta: 0:01:06  lr: 0.000959  min_lr: 0.000959  loss: 2.5071 (2.5097)  weight_decay: 0.0500 (0.0500)  time: 0.2779  data: 0.0022  max mem: 3500\n",
            "Epoch: [40]  [ 80/295]  eta: 0:01:02  lr: 0.000951  min_lr: 0.000951  loss: 2.5382 (2.5233)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0030  max mem: 3500\n",
            "Epoch: [40]  [ 90/295]  eta: 0:00:58  lr: 0.000947  min_lr: 0.000947  loss: 2.5586 (2.5216)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0024  max mem: 3500\n",
            "Epoch: [40]  [100/295]  eta: 0:00:55  lr: 0.000939  min_lr: 0.000939  loss: 2.5586 (2.5236)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0019  max mem: 3500\n",
            "Epoch: [40]  [110/295]  eta: 0:00:52  lr: 0.000934  min_lr: 0.000934  loss: 2.5088 (2.5261)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0023  max mem: 3500\n",
            "Epoch: [40]  [120/295]  eta: 0:00:49  lr: 0.000927  min_lr: 0.000927  loss: 2.4428 (2.5230)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0037  max mem: 3500\n",
            "Epoch: [40]  [130/295]  eta: 0:00:46  lr: 0.000922  min_lr: 0.000922  loss: 2.4845 (2.5300)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0057  max mem: 3500\n",
            "Epoch: [40]  [140/295]  eta: 0:00:43  lr: 0.000915  min_lr: 0.000915  loss: 2.4757 (2.5235)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0055  max mem: 3500\n",
            "Epoch: [40]  [150/295]  eta: 0:00:40  lr: 0.000910  min_lr: 0.000910  loss: 2.3561 (2.5089)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0036  max mem: 3500\n",
            "Epoch: [40]  [160/295]  eta: 0:00:37  lr: 0.000903  min_lr: 0.000903  loss: 2.4765 (2.5116)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0013  max mem: 3500\n",
            "Epoch: [40]  [170/295]  eta: 0:00:34  lr: 0.000898  min_lr: 0.000898  loss: 2.5963 (2.5139)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0014  max mem: 3500\n",
            "Epoch: [40]  [180/295]  eta: 0:00:31  lr: 0.000891  min_lr: 0.000891  loss: 2.5741 (2.5163)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0031  max mem: 3500\n",
            "Epoch: [40]  [190/295]  eta: 0:00:28  lr: 0.000886  min_lr: 0.000886  loss: 2.5421 (2.5152)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0040  max mem: 3500\n",
            "Epoch: [40]  [200/295]  eta: 0:00:26  lr: 0.000879  min_lr: 0.000879  loss: 2.4670 (2.5131)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0046  max mem: 3500\n",
            "Epoch: [40]  [210/295]  eta: 0:00:23  lr: 0.000874  min_lr: 0.000874  loss: 2.4452 (2.5138)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0029  max mem: 3500\n",
            "Epoch: [40]  [220/295]  eta: 0:00:20  lr: 0.000867  min_lr: 0.000867  loss: 2.4625 (2.5154)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0012  max mem: 3500\n",
            "Epoch: [40]  [230/295]  eta: 0:00:17  lr: 0.000863  min_lr: 0.000863  loss: 2.5387 (2.5141)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0021  max mem: 3500\n",
            "Epoch: [40]  [240/295]  eta: 0:00:14  lr: 0.000856  min_lr: 0.000856  loss: 2.7184 (2.5180)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0019  max mem: 3500\n",
            "Epoch: [40]  [250/295]  eta: 0:00:12  lr: 0.000851  min_lr: 0.000851  loss: 2.5600 (2.5152)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0019  max mem: 3500\n",
            "Epoch: [40]  [260/295]  eta: 0:00:09  lr: 0.000844  min_lr: 0.000844  loss: 2.5600 (2.5155)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0023  max mem: 3500\n",
            "Epoch: [40]  [270/295]  eta: 0:00:06  lr: 0.000839  min_lr: 0.000839  loss: 2.5790 (2.5147)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0032  max mem: 3500\n",
            "Epoch: [40]  [280/295]  eta: 0:00:04  lr: 0.000832  min_lr: 0.000832  loss: 2.5790 (2.5176)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0023  max mem: 3500\n",
            "Epoch: [40]  [290/295]  eta: 0:00:01  lr: 0.000828  min_lr: 0.000828  loss: 2.5762 (2.5164)  weight_decay: 0.0500 (0.0500)  time: 0.2567  data: 0.0002  max mem: 3500\n",
            "Epoch: [40]  [294/295]  eta: 0:00:00  lr: 0.000828  min_lr: 0.000828  loss: 2.5460 (2.5161)  weight_decay: 0.0500 (0.0500)  time: 0.2189  data: 0.0001  max mem: 3500\n",
            "Epoch: [40] Total time: 0:01:19 (0.2697 s / it)\n",
            "Averaged stats: lr: 0.000828  min_lr: 0.000828  loss: 2.5460 (2.5161)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:48  loss: 0.6220 (0.6220)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 2.0539  data: 1.8846  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.6497 (0.6723)  acc1: 83.3333 (84.4697)  acc5: 95.8333 (96.4015)  time: 0.3219  data: 0.1844  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.6633 (0.6889)  acc1: 83.3333 (84.3254)  acc5: 97.9167 (97.2222)  time: 0.1607  data: 0.0287  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7745 (0.8737)  acc1: 79.1667 (76.8817)  acc5: 97.9167 (97.3790)  time: 0.1751  data: 0.0412  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.9211 (0.8683)  acc1: 77.0833 (77.9472)  acc5: 97.9167 (97.3577)  time: 0.1681  data: 0.0341  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.9211 (0.9034)  acc1: 77.0833 (76.8791)  acc5: 97.9167 (97.3856)  time: 0.1603  data: 0.0250  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9427 (0.9026)  acc1: 72.9167 (76.8101)  acc5: 97.9167 (97.1995)  time: 0.1470  data: 0.0120  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0142 (0.9343)  acc1: 70.8333 (75.4988)  acc5: 95.8333 (96.8897)  time: 0.1253  data: 0.0014  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9683 (0.9125)  acc1: 72.9167 (76.1317)  acc5: 95.8333 (96.9393)  time: 0.1181  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9679 (0.9131)  acc1: 72.9167 (76.1274)  acc5: 95.8333 (96.8917)  time: 0.1171  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1756 s / it)\n",
            "* Acc@1 76.127 Acc@5 96.892 loss 0.913\n",
            "Accuracy of the model on the 3925 test images: 76.1%\n",
            "Max accuracy: 76.13%\n",
            "Test:  [ 0/82]  eta: 0:02:09  loss: 3.9385 (3.9385)  acc1: 8.3333 (8.3333)  acc5: 81.2500 (81.2500)  time: 1.5804  data: 1.4133  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:18  loss: 3.9089 (3.9362)  acc1: 4.1667 (9.4697)  acc5: 81.2500 (82.1970)  time: 0.2580  data: 0.1334  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.8790 (3.9748)  acc1: 14.5833 (13.8889)  acc5: 81.2500 (80.0595)  time: 0.1251  data: 0.0034  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.6660 (4.4675)  acc1: 12.5000 (10.7527)  acc5: 70.8333 (71.5726)  time: 0.1277  data: 0.0017  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.5487 (4.6871)  acc1: 2.0833 (9.5020)  acc5: 54.1667 (67.8354)  time: 0.1388  data: 0.0030  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8147 (4.6642)  acc1: 6.2500 (11.7239)  acc5: 56.2500 (67.6062)  time: 0.1426  data: 0.0038  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6017 (4.7661)  acc1: 4.1667 (10.2459)  acc5: 62.5000 (66.3251)  time: 0.1539  data: 0.0184  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.6017 (4.7055)  acc1: 2.0833 (12.1185)  acc5: 81.2500 (66.4613)  time: 0.1603  data: 0.0261  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.5482 (4.3386)  acc1: 45.8333 (19.4702)  acc5: 89.5833 (69.6502)  time: 0.1349  data: 0.0097  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.4775 (4.3079)  acc1: 47.9167 (20.0255)  acc5: 89.5833 (69.8344)  time: 0.1233  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1606 s / it)\n",
            "* Acc@1 20.025 Acc@5 69.834 loss 4.308\n",
            "Accuracy of the model EMA on 3925 test images: 20.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [41]  [  0/295]  eta: 0:07:36  lr: 0.000825  min_lr: 0.000825  loss: 2.1501 (2.1501)  weight_decay: 0.0500 (0.0500)  time: 1.5487  data: 1.1899  max mem: 3500\n",
            "Epoch: [41]  [ 10/295]  eta: 0:01:52  lr: 0.000821  min_lr: 0.000821  loss: 2.2937 (2.4188)  weight_decay: 0.0500 (0.0500)  time: 0.3931  data: 0.1161  max mem: 3500\n",
            "Epoch: [41]  [ 20/295]  eta: 0:01:31  lr: 0.000814  min_lr: 0.000814  loss: 2.6118 (2.5095)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0047  max mem: 3500\n",
            "Epoch: [41]  [ 30/295]  eta: 0:01:21  lr: 0.000809  min_lr: 0.000809  loss: 2.5856 (2.5303)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0011  max mem: 3500\n",
            "Epoch: [41]  [ 40/295]  eta: 0:01:16  lr: 0.000802  min_lr: 0.000802  loss: 2.5859 (2.5563)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0012  max mem: 3500\n",
            "Epoch: [41]  [ 50/295]  eta: 0:01:12  lr: 0.000798  min_lr: 0.000798  loss: 2.5859 (2.5379)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0011  max mem: 3500\n",
            "Epoch: [41]  [ 60/295]  eta: 0:01:08  lr: 0.000791  min_lr: 0.000791  loss: 2.5712 (2.5486)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0029  max mem: 3500\n",
            "Epoch: [41]  [ 70/295]  eta: 0:01:04  lr: 0.000786  min_lr: 0.000786  loss: 2.6039 (2.5467)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0027  max mem: 3500\n",
            "Epoch: [41]  [ 80/295]  eta: 0:01:01  lr: 0.000779  min_lr: 0.000779  loss: 2.5534 (2.5419)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0014  max mem: 3500\n",
            "Epoch: [41]  [ 90/295]  eta: 0:00:57  lr: 0.000775  min_lr: 0.000775  loss: 2.6033 (2.5453)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0018  max mem: 3500\n",
            "Epoch: [41]  [100/295]  eta: 0:00:54  lr: 0.000768  min_lr: 0.000768  loss: 2.6413 (2.5507)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0020  max mem: 3500\n",
            "Epoch: [41]  [110/295]  eta: 0:00:51  lr: 0.000763  min_lr: 0.000763  loss: 2.6319 (2.5532)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0022  max mem: 3500\n",
            "Epoch: [41]  [120/295]  eta: 0:00:48  lr: 0.000757  min_lr: 0.000757  loss: 2.6080 (2.5567)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0029  max mem: 3500\n",
            "Epoch: [41]  [130/295]  eta: 0:00:45  lr: 0.000752  min_lr: 0.000752  loss: 2.6080 (2.5553)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0030  max mem: 3500\n",
            "Epoch: [41]  [140/295]  eta: 0:00:42  lr: 0.000746  min_lr: 0.000746  loss: 2.6366 (2.5648)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0018  max mem: 3500\n",
            "Epoch: [41]  [150/295]  eta: 0:00:39  lr: 0.000741  min_lr: 0.000741  loss: 2.6389 (2.5681)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0013  max mem: 3500\n",
            "Epoch: [41]  [160/295]  eta: 0:00:36  lr: 0.000734  min_lr: 0.000734  loss: 2.5127 (2.5551)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0007  max mem: 3500\n",
            "Epoch: [41]  [170/295]  eta: 0:00:34  lr: 0.000730  min_lr: 0.000730  loss: 2.5127 (2.5595)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0023  max mem: 3500\n",
            "Epoch: [41]  [180/295]  eta: 0:00:31  lr: 0.000723  min_lr: 0.000723  loss: 2.5513 (2.5495)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0052  max mem: 3500\n",
            "Epoch: [41]  [190/295]  eta: 0:00:28  lr: 0.000719  min_lr: 0.000719  loss: 2.4293 (2.5504)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0045  max mem: 3500\n",
            "Epoch: [41]  [200/295]  eta: 0:00:25  lr: 0.000712  min_lr: 0.000712  loss: 2.4647 (2.5462)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0030  max mem: 3500\n",
            "Epoch: [41]  [210/295]  eta: 0:00:23  lr: 0.000708  min_lr: 0.000708  loss: 2.5114 (2.5466)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0020  max mem: 3500\n",
            "Epoch: [41]  [220/295]  eta: 0:00:20  lr: 0.000701  min_lr: 0.000701  loss: 2.5016 (2.5359)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0013  max mem: 3500\n",
            "Epoch: [41]  [230/295]  eta: 0:00:17  lr: 0.000697  min_lr: 0.000697  loss: 2.5077 (2.5380)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0019  max mem: 3500\n",
            "Epoch: [41]  [240/295]  eta: 0:00:14  lr: 0.000691  min_lr: 0.000691  loss: 2.5628 (2.5376)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0041  max mem: 3500\n",
            "Epoch: [41]  [250/295]  eta: 0:00:12  lr: 0.000686  min_lr: 0.000686  loss: 2.4551 (2.5325)  weight_decay: 0.0500 (0.0500)  time: 0.2765  data: 0.0071  max mem: 3500\n",
            "Epoch: [41]  [260/295]  eta: 0:00:09  lr: 0.000680  min_lr: 0.000680  loss: 2.5781 (2.5334)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0066  max mem: 3500\n",
            "Epoch: [41]  [270/295]  eta: 0:00:06  lr: 0.000675  min_lr: 0.000675  loss: 2.6305 (2.5376)  weight_decay: 0.0500 (0.0500)  time: 0.2743  data: 0.0032  max mem: 3500\n",
            "Epoch: [41]  [280/295]  eta: 0:00:04  lr: 0.000669  min_lr: 0.000669  loss: 2.6090 (2.5399)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0014  max mem: 3500\n",
            "Epoch: [41]  [290/295]  eta: 0:00:01  lr: 0.000665  min_lr: 0.000665  loss: 2.6090 (2.5422)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0007  max mem: 3500\n",
            "Epoch: [41]  [294/295]  eta: 0:00:00  lr: 0.000665  min_lr: 0.000665  loss: 2.6013 (2.5418)  weight_decay: 0.0500 (0.0500)  time: 0.2184  data: 0.0001  max mem: 3500\n",
            "Epoch: [41] Total time: 0:01:19 (0.2689 s / it)\n",
            "Averaged stats: lr: 0.000665  min_lr: 0.000665  loss: 2.6013 (2.5418)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:25  loss: 0.6391 (0.6391)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 1.7700  data: 1.5769  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.6391 (0.6754)  acc1: 85.4167 (85.2273)  acc5: 95.8333 (96.5909)  time: 0.2788  data: 0.1517  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.6734 (0.6737)  acc1: 87.5000 (85.7143)  acc5: 97.9167 (97.5198)  time: 0.1301  data: 0.0051  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.7432 (0.9276)  acc1: 81.2500 (74.4624)  acc5: 95.8333 (96.3710)  time: 0.1339  data: 0.0015  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8374 (0.8978)  acc1: 81.2500 (76.5244)  acc5: 95.8333 (96.7480)  time: 0.1539  data: 0.0219  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8374 (0.9061)  acc1: 81.2500 (76.3072)  acc5: 97.9167 (96.8954)  time: 0.1642  data: 0.0283  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9661 (0.9209)  acc1: 75.0000 (75.7514)  acc5: 97.9167 (96.7555)  time: 0.1522  data: 0.0193  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0000 (0.9461)  acc1: 70.8333 (74.7066)  acc5: 95.8333 (96.5669)  time: 0.1445  data: 0.0216  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9261 (0.9276)  acc1: 77.0833 (75.7202)  acc5: 95.8333 (96.6564)  time: 0.1307  data: 0.0097  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9261 (0.9290)  acc1: 77.0833 (75.6943)  acc5: 95.8333 (96.6115)  time: 0.1290  data: 0.0093  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1666 s / it)\n",
            "* Acc@1 75.694 Acc@5 96.611 loss 0.929\n",
            "Accuracy of the model on the 3925 test images: 75.7%\n",
            "Max accuracy: 76.13%\n",
            "Test:  [ 0/82]  eta: 0:02:24  loss: 3.8762 (3.8762)  acc1: 8.3333 (8.3333)  acc5: 81.2500 (81.2500)  time: 1.7596  data: 1.5812  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 3.8673 (3.8873)  acc1: 4.1667 (9.0909)  acc5: 81.2500 (82.1970)  time: 0.2712  data: 0.1452  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.8463 (3.9312)  acc1: 14.5833 (13.6905)  acc5: 81.2500 (80.4564)  time: 0.1224  data: 0.0035  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.6311 (4.4310)  acc1: 12.5000 (10.5511)  acc5: 70.8333 (71.9086)  time: 0.1232  data: 0.0038  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 5.4895 (4.6482)  acc1: 2.0833 (9.3496)  acc5: 56.2500 (68.2927)  time: 0.1242  data: 0.0035  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:04  loss: 4.8368 (4.6376)  acc1: 6.2500 (11.4788)  acc5: 58.3333 (68.0147)  time: 0.1239  data: 0.0054  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6015 (4.7445)  acc1: 4.1667 (9.9727)  acc5: 62.5000 (66.6667)  time: 0.1224  data: 0.0052  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.6015 (4.6794)  acc1: 2.0833 (11.9131)  acc5: 81.2500 (66.7547)  time: 0.1213  data: 0.0028  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.4691 (4.3102)  acc1: 45.8333 (19.3158)  acc5: 89.5833 (69.9074)  time: 0.1197  data: 0.0006  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.3904 (4.2794)  acc1: 50.0000 (19.8726)  acc5: 89.5833 (70.0892)  time: 0.1178  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1476 s / it)\n",
            "* Acc@1 19.873 Acc@5 70.089 loss 4.279\n",
            "Accuracy of the model EMA on 3925 test images: 19.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [42]  [  0/295]  eta: 0:12:12  lr: 0.000663  min_lr: 0.000663  loss: 2.4624 (2.4624)  weight_decay: 0.0500 (0.0500)  time: 2.4844  data: 1.8450  max mem: 3500\n",
            "Epoch: [42]  [ 10/295]  eta: 0:02:22  lr: 0.000658  min_lr: 0.000658  loss: 2.6409 (2.5411)  weight_decay: 0.0500 (0.0500)  time: 0.4989  data: 0.1682  max mem: 3500\n",
            "Epoch: [42]  [ 20/295]  eta: 0:01:46  lr: 0.000652  min_lr: 0.000652  loss: 2.6099 (2.5426)  weight_decay: 0.0500 (0.0500)  time: 0.2811  data: 0.0004  max mem: 3500\n",
            "Epoch: [42]  [ 30/295]  eta: 0:01:31  lr: 0.000648  min_lr: 0.000648  loss: 2.5611 (2.5307)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0008  max mem: 3500\n",
            "Epoch: [42]  [ 40/295]  eta: 0:01:23  lr: 0.000641  min_lr: 0.000641  loss: 2.3854 (2.4942)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0008  max mem: 3500\n",
            "Epoch: [42]  [ 50/295]  eta: 0:01:17  lr: 0.000637  min_lr: 0.000637  loss: 2.3854 (2.4952)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0024  max mem: 3500\n",
            "Epoch: [42]  [ 60/295]  eta: 0:01:12  lr: 0.000631  min_lr: 0.000631  loss: 2.5883 (2.5098)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0036  max mem: 3500\n",
            "Epoch: [42]  [ 70/295]  eta: 0:01:08  lr: 0.000627  min_lr: 0.000627  loss: 2.5377 (2.5115)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0021  max mem: 3500\n",
            "Epoch: [42]  [ 80/295]  eta: 0:01:03  lr: 0.000620  min_lr: 0.000620  loss: 2.5377 (2.5057)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0017  max mem: 3500\n",
            "Epoch: [42]  [ 90/295]  eta: 0:01:00  lr: 0.000616  min_lr: 0.000616  loss: 2.5596 (2.5127)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0013  max mem: 3500\n",
            "Epoch: [42]  [100/295]  eta: 0:00:56  lr: 0.000610  min_lr: 0.000610  loss: 2.6346 (2.5171)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0008  max mem: 3500\n",
            "Epoch: [42]  [110/295]  eta: 0:00:53  lr: 0.000606  min_lr: 0.000606  loss: 2.6275 (2.5161)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0012  max mem: 3500\n",
            "Epoch: [42]  [120/295]  eta: 0:00:50  lr: 0.000600  min_lr: 0.000600  loss: 2.4366 (2.5044)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0042  max mem: 3500\n",
            "Epoch: [42]  [130/295]  eta: 0:00:47  lr: 0.000596  min_lr: 0.000596  loss: 2.4683 (2.5122)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0071  max mem: 3500\n",
            "Epoch: [42]  [140/295]  eta: 0:00:43  lr: 0.000590  min_lr: 0.000590  loss: 2.4993 (2.5091)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0054  max mem: 3500\n",
            "Epoch: [42]  [150/295]  eta: 0:00:40  lr: 0.000586  min_lr: 0.000586  loss: 2.4993 (2.5141)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0030  max mem: 3500\n",
            "Epoch: [42]  [160/295]  eta: 0:00:37  lr: 0.000580  min_lr: 0.000580  loss: 2.5120 (2.5129)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0021  max mem: 3500\n",
            "Epoch: [42]  [170/295]  eta: 0:00:34  lr: 0.000576  min_lr: 0.000576  loss: 2.4350 (2.5040)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0024  max mem: 3500\n",
            "Epoch: [42]  [180/295]  eta: 0:00:32  lr: 0.000570  min_lr: 0.000570  loss: 2.4128 (2.5038)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0023  max mem: 3500\n",
            "Epoch: [42]  [190/295]  eta: 0:00:29  lr: 0.000566  min_lr: 0.000566  loss: 2.4969 (2.5005)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0024  max mem: 3500\n",
            "Epoch: [42]  [200/295]  eta: 0:00:26  lr: 0.000560  min_lr: 0.000560  loss: 2.4682 (2.4987)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0048  max mem: 3500\n",
            "Epoch: [42]  [210/295]  eta: 0:00:23  lr: 0.000556  min_lr: 0.000556  loss: 2.5585 (2.5033)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0041  max mem: 3500\n",
            "Epoch: [42]  [220/295]  eta: 0:00:20  lr: 0.000550  min_lr: 0.000550  loss: 2.5585 (2.5023)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0016  max mem: 3500\n",
            "Epoch: [42]  [230/295]  eta: 0:00:17  lr: 0.000546  min_lr: 0.000546  loss: 2.5741 (2.5022)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0011  max mem: 3500\n",
            "Epoch: [42]  [240/295]  eta: 0:00:15  lr: 0.000540  min_lr: 0.000540  loss: 2.6155 (2.5070)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0015  max mem: 3500\n",
            "Epoch: [42]  [250/295]  eta: 0:00:12  lr: 0.000536  min_lr: 0.000536  loss: 2.6817 (2.5102)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0034  max mem: 3500\n",
            "Epoch: [42]  [260/295]  eta: 0:00:09  lr: 0.000530  min_lr: 0.000530  loss: 2.5130 (2.5101)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0053  max mem: 3500\n",
            "Epoch: [42]  [270/295]  eta: 0:00:06  lr: 0.000526  min_lr: 0.000526  loss: 2.4549 (2.5057)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0051  max mem: 3500\n",
            "Epoch: [42]  [280/295]  eta: 0:00:04  lr: 0.000520  min_lr: 0.000520  loss: 2.6119 (2.5096)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0024  max mem: 3500\n",
            "Epoch: [42]  [290/295]  eta: 0:00:01  lr: 0.000517  min_lr: 0.000517  loss: 2.4672 (2.5039)  weight_decay: 0.0500 (0.0500)  time: 0.2569  data: 0.0002  max mem: 3500\n",
            "Epoch: [42]  [294/295]  eta: 0:00:00  lr: 0.000517  min_lr: 0.000517  loss: 2.5728 (2.5043)  weight_decay: 0.0500 (0.0500)  time: 0.2188  data: 0.0001  max mem: 3500\n",
            "Epoch: [42] Total time: 0:01:20 (0.2713 s / it)\n",
            "Averaged stats: lr: 0.000517  min_lr: 0.000517  loss: 2.5728 (2.5043)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:49  loss: 0.6437 (0.6437)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.0643  data: 1.8780  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 0.6392 (0.6827)  acc1: 87.5000 (85.4167)  acc5: 95.8333 (96.4015)  time: 0.3540  data: 0.2078  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.6931 (0.7006)  acc1: 83.3333 (84.2262)  acc5: 97.9167 (97.1230)  time: 0.1742  data: 0.0360  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.7894 (0.8871)  acc1: 79.1667 (76.2769)  acc5: 97.9167 (97.1774)  time: 0.1704  data: 0.0358  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7894 (0.8544)  acc1: 81.2500 (77.9980)  acc5: 97.9167 (97.4085)  time: 0.1621  data: 0.0219  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8323 (0.8863)  acc1: 81.2500 (76.7565)  acc5: 97.9167 (97.4673)  time: 0.1435  data: 0.0024  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9247 (0.8889)  acc1: 75.0000 (76.5710)  acc5: 97.9167 (97.4727)  time: 0.1311  data: 0.0029  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9316 (0.9144)  acc1: 72.9167 (75.4108)  acc5: 95.8333 (97.1244)  time: 0.1222  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8608 (0.8892)  acc1: 75.0000 (76.3632)  acc5: 95.8333 (97.2222)  time: 0.1191  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8608 (0.8901)  acc1: 75.6757 (76.3567)  acc5: 95.8333 (97.1720)  time: 0.1182  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1740 s / it)\n",
            "* Acc@1 76.357 Acc@5 97.172 loss 0.890\n",
            "Accuracy of the model on the 3925 test images: 76.4%\n",
            "Max accuracy: 76.36%\n",
            "Test:  [ 0/82]  eta: 0:02:34  loss: 3.8106 (3.8106)  acc1: 8.3333 (8.3333)  acc5: 79.1667 (79.1667)  time: 1.8832  data: 1.7172  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.8106 (3.8355)  acc1: 6.2500 (9.4697)  acc5: 83.3333 (82.7652)  time: 0.2850  data: 0.1598  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.8153 (3.8859)  acc1: 14.5833 (13.9881)  acc5: 81.2500 (80.8532)  time: 0.1269  data: 0.0033  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.5896 (4.3927)  acc1: 12.5000 (10.6183)  acc5: 72.9167 (71.9758)  time: 0.1339  data: 0.0025  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.4292 (4.6075)  acc1: 2.0833 (9.4004)  acc5: 56.2500 (68.4451)  time: 0.1353  data: 0.0022  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8626 (4.6090)  acc1: 8.3333 (11.5196)  acc5: 58.3333 (67.9739)  time: 0.1415  data: 0.0121  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5937 (4.7191)  acc1: 4.1667 (9.9385)  acc5: 60.4167 (66.4959)  time: 0.1527  data: 0.0268  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5937 (4.6496)  acc1: 0.0000 (12.0599)  acc5: 81.2500 (66.6080)  time: 0.1533  data: 0.0232  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.3958 (4.2788)  acc1: 45.8333 (19.4444)  acc5: 91.6667 (69.8302)  time: 0.1369  data: 0.0075  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.3095 (4.2480)  acc1: 52.0833 (20.0000)  acc5: 91.6667 (70.0127)  time: 0.1333  data: 0.0075  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1632 s / it)\n",
            "* Acc@1 20.000 Acc@5 70.013 loss 4.248\n",
            "Accuracy of the model EMA on 3925 test images: 20.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [43]  [  0/295]  eta: 0:08:08  lr: 0.000515  min_lr: 0.000515  loss: 2.1554 (2.1554)  weight_decay: 0.0500 (0.0500)  time: 1.6561  data: 1.2854  max mem: 3500\n",
            "Epoch: [43]  [ 10/295]  eta: 0:01:58  lr: 0.000511  min_lr: 0.000511  loss: 2.4381 (2.4069)  weight_decay: 0.0500 (0.0500)  time: 0.4155  data: 0.1204  max mem: 3500\n",
            "Epoch: [43]  [ 20/295]  eta: 0:01:36  lr: 0.000505  min_lr: 0.000505  loss: 2.5039 (2.4829)  weight_decay: 0.0500 (0.0500)  time: 0.2849  data: 0.0053  max mem: 3500\n",
            "Epoch: [43]  [ 30/295]  eta: 0:01:26  lr: 0.000501  min_lr: 0.000501  loss: 2.5796 (2.5052)  weight_decay: 0.0500 (0.0500)  time: 0.2751  data: 0.0059  max mem: 3500\n",
            "Epoch: [43]  [ 40/295]  eta: 0:01:19  lr: 0.000496  min_lr: 0.000496  loss: 2.5794 (2.5189)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0055  max mem: 3500\n",
            "Epoch: [43]  [ 50/295]  eta: 0:01:14  lr: 0.000492  min_lr: 0.000492  loss: 2.5769 (2.5130)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0045  max mem: 3500\n",
            "Epoch: [43]  [ 60/295]  eta: 0:01:10  lr: 0.000486  min_lr: 0.000486  loss: 2.5707 (2.5203)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0030  max mem: 3500\n",
            "Epoch: [43]  [ 70/295]  eta: 0:01:06  lr: 0.000482  min_lr: 0.000482  loss: 2.4982 (2.5144)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0028  max mem: 3500\n",
            "Epoch: [43]  [ 80/295]  eta: 0:01:02  lr: 0.000477  min_lr: 0.000477  loss: 2.5563 (2.5119)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0026  max mem: 3500\n",
            "Epoch: [43]  [ 90/295]  eta: 0:00:58  lr: 0.000473  min_lr: 0.000473  loss: 2.5563 (2.5175)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0023  max mem: 3500\n",
            "Epoch: [43]  [100/295]  eta: 0:00:55  lr: 0.000468  min_lr: 0.000468  loss: 2.5751 (2.5253)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0023  max mem: 3500\n",
            "Epoch: [43]  [110/295]  eta: 0:00:52  lr: 0.000464  min_lr: 0.000464  loss: 2.5455 (2.5122)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0027  max mem: 3500\n",
            "Epoch: [43]  [120/295]  eta: 0:00:49  lr: 0.000458  min_lr: 0.000458  loss: 2.3893 (2.5033)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0054  max mem: 3500\n",
            "Epoch: [43]  [130/295]  eta: 0:00:46  lr: 0.000455  min_lr: 0.000455  loss: 2.4373 (2.4993)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0049  max mem: 3500\n",
            "Epoch: [43]  [140/295]  eta: 0:00:43  lr: 0.000449  min_lr: 0.000449  loss: 2.4840 (2.4919)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0015  max mem: 3500\n",
            "Epoch: [43]  [150/295]  eta: 0:00:40  lr: 0.000446  min_lr: 0.000446  loss: 2.4562 (2.4939)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0010  max mem: 3500\n",
            "Epoch: [43]  [160/295]  eta: 0:00:37  lr: 0.000440  min_lr: 0.000440  loss: 2.5013 (2.4963)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0010  max mem: 3500\n",
            "Epoch: [43]  [170/295]  eta: 0:00:34  lr: 0.000437  min_lr: 0.000437  loss: 2.5013 (2.4953)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0026  max mem: 3500\n",
            "Epoch: [43]  [180/295]  eta: 0:00:31  lr: 0.000431  min_lr: 0.000431  loss: 2.6159 (2.5046)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0051  max mem: 3500\n",
            "Epoch: [43]  [190/295]  eta: 0:00:28  lr: 0.000428  min_lr: 0.000428  loss: 2.6632 (2.5029)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0045  max mem: 3500\n",
            "Epoch: [43]  [200/295]  eta: 0:00:26  lr: 0.000423  min_lr: 0.000423  loss: 2.4891 (2.5053)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0018  max mem: 3500\n",
            "Epoch: [43]  [210/295]  eta: 0:00:23  lr: 0.000419  min_lr: 0.000419  loss: 2.6025 (2.5096)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0014  max mem: 3500\n",
            "Epoch: [43]  [220/295]  eta: 0:00:20  lr: 0.000414  min_lr: 0.000414  loss: 2.6025 (2.5077)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0021  max mem: 3500\n",
            "Epoch: [43]  [230/295]  eta: 0:00:17  lr: 0.000410  min_lr: 0.000410  loss: 2.6030 (2.5120)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0020  max mem: 3500\n",
            "Epoch: [43]  [240/295]  eta: 0:00:14  lr: 0.000405  min_lr: 0.000405  loss: 2.6311 (2.5161)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0023  max mem: 3500\n",
            "Epoch: [43]  [250/295]  eta: 0:00:12  lr: 0.000402  min_lr: 0.000402  loss: 2.5926 (2.5184)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0048  max mem: 3500\n",
            "Epoch: [43]  [260/295]  eta: 0:00:09  lr: 0.000396  min_lr: 0.000396  loss: 2.5873 (2.5208)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0046  max mem: 3500\n",
            "Epoch: [43]  [270/295]  eta: 0:00:06  lr: 0.000393  min_lr: 0.000393  loss: 2.5477 (2.5187)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0023  max mem: 3500\n",
            "Epoch: [43]  [280/295]  eta: 0:00:04  lr: 0.000388  min_lr: 0.000388  loss: 2.6037 (2.5174)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0015  max mem: 3500\n",
            "Epoch: [43]  [290/295]  eta: 0:00:01  lr: 0.000385  min_lr: 0.000385  loss: 2.5357 (2.5165)  weight_decay: 0.0500 (0.0500)  time: 0.2563  data: 0.0006  max mem: 3500\n",
            "Epoch: [43]  [294/295]  eta: 0:00:00  lr: 0.000385  min_lr: 0.000385  loss: 2.5357 (2.5175)  weight_decay: 0.0500 (0.0500)  time: 0.2187  data: 0.0001  max mem: 3500\n",
            "Epoch: [43] Total time: 0:01:19 (0.2696 s / it)\n",
            "Averaged stats: lr: 0.000385  min_lr: 0.000385  loss: 2.5357 (2.5175)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:06  loss: 0.6786 (0.6786)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 2.2785  data: 2.1159  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.6786 (0.7110)  acc1: 85.4167 (84.2803)  acc5: 95.8333 (96.5909)  time: 0.4089  data: 0.2488  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.6894 (0.7298)  acc1: 83.3333 (83.3333)  acc5: 97.9167 (97.1230)  time: 0.1730  data: 0.0322  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8174 (0.9283)  acc1: 77.0833 (74.7984)  acc5: 97.9167 (96.7070)  time: 0.1252  data: 0.0035  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8416 (0.8949)  acc1: 77.0833 (76.4736)  acc5: 97.9167 (97.1037)  time: 0.1243  data: 0.0053  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7729 (0.8844)  acc1: 77.0833 (77.0016)  acc5: 97.9167 (97.3448)  time: 0.1222  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8858 (0.8953)  acc1: 77.0833 (76.6052)  acc5: 97.9167 (97.1311)  time: 0.1225  data: 0.0044  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0498 (0.9288)  acc1: 68.7500 (75.1761)  acc5: 95.8333 (96.8310)  time: 0.1202  data: 0.0033  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8717 (0.8973)  acc1: 72.9167 (76.1831)  acc5: 97.9167 (96.9907)  time: 0.1180  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8717 (0.8973)  acc1: 77.0833 (76.2038)  acc5: 97.9167 (96.9427)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1649 s / it)\n",
            "* Acc@1 76.204 Acc@5 96.943 loss 0.897\n",
            "Accuracy of the model on the 3925 test images: 76.2%\n",
            "Max accuracy: 76.36%\n",
            "Test:  [ 0/82]  eta: 0:02:41  loss: 3.7527 (3.7527)  acc1: 10.4167 (10.4167)  acc5: 83.3333 (83.3333)  time: 1.9645  data: 1.7897  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 3.7629 (3.7903)  acc1: 6.2500 (9.6591)  acc5: 83.3333 (83.5227)  time: 0.3342  data: 0.2019  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 3.7818 (3.8439)  acc1: 14.5833 (13.9881)  acc5: 83.3333 (81.7460)  time: 0.1582  data: 0.0287  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.5440 (4.3565)  acc1: 12.5000 (10.6183)  acc5: 72.9167 (72.5806)  time: 0.1730  data: 0.0431  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 5.3648 (4.5677)  acc1: 2.0833 (9.3496)  acc5: 54.1667 (69.0041)  time: 0.1704  data: 0.0365  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.8899 (4.5813)  acc1: 8.3333 (11.3971)  acc5: 58.3333 (68.2190)  time: 0.1384  data: 0.0013  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6119 (4.6944)  acc1: 4.1667 (9.8019)  acc5: 60.4167 (66.7691)  time: 0.1299  data: 0.0015  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5892 (4.6202)  acc1: 0.0000 (12.0305)  acc5: 81.2500 (66.8721)  time: 0.1215  data: 0.0009  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.3230 (4.2480)  acc1: 47.9167 (19.4444)  acc5: 91.6667 (70.0617)  time: 0.1199  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.2294 (4.2172)  acc1: 54.1667 (20.0000)  acc5: 91.6667 (70.2420)  time: 0.1187  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1717 s / it)\n",
            "* Acc@1 20.000 Acc@5 70.242 loss 4.217\n",
            "Accuracy of the model EMA on 3925 test images: 20.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [44]  [  0/295]  eta: 0:07:28  lr: 0.000383  min_lr: 0.000383  loss: 2.1722 (2.1722)  weight_decay: 0.0500 (0.0500)  time: 1.5206  data: 1.1588  max mem: 3500\n",
            "Epoch: [44]  [ 10/295]  eta: 0:01:50  lr: 0.000380  min_lr: 0.000380  loss: 2.5272 (2.4784)  weight_decay: 0.0500 (0.0500)  time: 0.3861  data: 0.1059  max mem: 3500\n",
            "Epoch: [44]  [ 20/295]  eta: 0:01:30  lr: 0.000374  min_lr: 0.000374  loss: 2.5272 (2.4580)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0020  max mem: 3500\n",
            "Epoch: [44]  [ 30/295]  eta: 0:01:22  lr: 0.000371  min_lr: 0.000371  loss: 2.5398 (2.4822)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0026  max mem: 3500\n",
            "Epoch: [44]  [ 40/295]  eta: 0:01:16  lr: 0.000366  min_lr: 0.000366  loss: 2.4809 (2.4716)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0022  max mem: 3500\n",
            "Epoch: [44]  [ 50/295]  eta: 0:01:12  lr: 0.000363  min_lr: 0.000363  loss: 2.4224 (2.4785)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0028  max mem: 3500\n",
            "Epoch: [44]  [ 60/295]  eta: 0:01:07  lr: 0.000358  min_lr: 0.000358  loss: 2.4312 (2.4703)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0027  max mem: 3500\n",
            "Epoch: [44]  [ 70/295]  eta: 0:01:04  lr: 0.000355  min_lr: 0.000355  loss: 2.4683 (2.4787)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0022  max mem: 3500\n",
            "Epoch: [44]  [ 80/295]  eta: 0:01:00  lr: 0.000350  min_lr: 0.000350  loss: 2.5185 (2.4880)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0017  max mem: 3500\n",
            "Epoch: [44]  [ 90/295]  eta: 0:00:57  lr: 0.000347  min_lr: 0.000347  loss: 2.4803 (2.4749)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0035  max mem: 3500\n",
            "Epoch: [44]  [100/295]  eta: 0:00:54  lr: 0.000342  min_lr: 0.000342  loss: 2.5070 (2.4771)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0054  max mem: 3500\n",
            "Epoch: [44]  [110/295]  eta: 0:00:51  lr: 0.000339  min_lr: 0.000339  loss: 2.5206 (2.4693)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0039  max mem: 3500\n",
            "Epoch: [44]  [120/295]  eta: 0:00:48  lr: 0.000334  min_lr: 0.000334  loss: 2.4154 (2.4646)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0022  max mem: 3500\n",
            "Epoch: [44]  [130/295]  eta: 0:00:45  lr: 0.000331  min_lr: 0.000331  loss: 2.4154 (2.4640)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0018  max mem: 3500\n",
            "Epoch: [44]  [140/295]  eta: 0:00:42  lr: 0.000326  min_lr: 0.000326  loss: 2.5148 (2.4678)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0027  max mem: 3500\n",
            "Epoch: [44]  [150/295]  eta: 0:00:39  lr: 0.000323  min_lr: 0.000323  loss: 2.5319 (2.4737)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0033  max mem: 3500\n",
            "Epoch: [44]  [160/295]  eta: 0:00:36  lr: 0.000318  min_lr: 0.000318  loss: 2.5369 (2.4821)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0034  max mem: 3500\n",
            "Epoch: [44]  [170/295]  eta: 0:00:34  lr: 0.000315  min_lr: 0.000315  loss: 2.5912 (2.4812)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0037  max mem: 3500\n",
            "Epoch: [44]  [180/295]  eta: 0:00:31  lr: 0.000310  min_lr: 0.000310  loss: 2.6387 (2.4934)  weight_decay: 0.0500 (0.0500)  time: 0.2749  data: 0.0036  max mem: 3500\n",
            "Epoch: [44]  [190/295]  eta: 0:00:28  lr: 0.000307  min_lr: 0.000307  loss: 2.7108 (2.5016)  weight_decay: 0.0500 (0.0500)  time: 0.2741  data: 0.0044  max mem: 3500\n",
            "Epoch: [44]  [200/295]  eta: 0:00:25  lr: 0.000303  min_lr: 0.000303  loss: 2.5043 (2.4998)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0045  max mem: 3500\n",
            "Epoch: [44]  [210/295]  eta: 0:00:23  lr: 0.000300  min_lr: 0.000300  loss: 2.4646 (2.4982)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0032  max mem: 3500\n",
            "Epoch: [44]  [220/295]  eta: 0:00:20  lr: 0.000295  min_lr: 0.000295  loss: 2.4992 (2.4982)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0025  max mem: 3500\n",
            "Epoch: [44]  [230/295]  eta: 0:00:17  lr: 0.000292  min_lr: 0.000292  loss: 2.4995 (2.4994)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0026  max mem: 3500\n",
            "Epoch: [44]  [240/295]  eta: 0:00:14  lr: 0.000288  min_lr: 0.000288  loss: 2.5591 (2.4981)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0031  max mem: 3500\n",
            "Epoch: [44]  [250/295]  eta: 0:00:12  lr: 0.000285  min_lr: 0.000285  loss: 2.3865 (2.4975)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0033  max mem: 3500\n",
            "Epoch: [44]  [260/295]  eta: 0:00:09  lr: 0.000280  min_lr: 0.000280  loss: 2.4495 (2.4972)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0017  max mem: 3500\n",
            "Epoch: [44]  [270/295]  eta: 0:00:06  lr: 0.000278  min_lr: 0.000278  loss: 2.4979 (2.4955)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0008  max mem: 3500\n",
            "Epoch: [44]  [280/295]  eta: 0:00:04  lr: 0.000273  min_lr: 0.000273  loss: 2.4016 (2.4906)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0012  max mem: 3500\n",
            "Epoch: [44]  [290/295]  eta: 0:00:01  lr: 0.000270  min_lr: 0.000270  loss: 2.3784 (2.4860)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0006  max mem: 3500\n",
            "Epoch: [44]  [294/295]  eta: 0:00:00  lr: 0.000270  min_lr: 0.000270  loss: 2.3784 (2.4854)  weight_decay: 0.0500 (0.0500)  time: 0.2195  data: 0.0002  max mem: 3500\n",
            "Epoch: [44] Total time: 0:01:19 (0.2685 s / it)\n",
            "Averaged stats: lr: 0.000270  min_lr: 0.000270  loss: 2.3784 (2.4854)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:29  loss: 0.7328 (0.7328)  acc1: 85.4167 (85.4167)  acc5: 91.6667 (91.6667)  time: 2.5555  data: 2.3632  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.7328 (0.7206)  acc1: 85.4167 (83.3333)  acc5: 95.8333 (96.2121)  time: 0.3795  data: 0.2443  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.7341 (0.7327)  acc1: 81.2500 (82.1429)  acc5: 97.9167 (97.2222)  time: 0.1485  data: 0.0179  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8477 (0.9190)  acc1: 77.0833 (74.7984)  acc5: 97.9167 (97.0430)  time: 0.1300  data: 0.0027  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8478 (0.8742)  acc1: 77.0833 (76.7276)  acc5: 97.9167 (97.4594)  time: 0.1237  data: 0.0029  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7142 (0.8556)  acc1: 81.2500 (77.4918)  acc5: 100.0000 (97.7533)  time: 0.1238  data: 0.0038  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8161 (0.8613)  acc1: 79.1667 (77.3224)  acc5: 97.9167 (97.6093)  time: 0.1243  data: 0.0043  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.0154 (0.8986)  acc1: 66.6667 (75.8803)  acc5: 95.8333 (97.2711)  time: 0.1207  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8842 (0.8727)  acc1: 77.0833 (76.8519)  acc5: 97.9167 (97.4280)  time: 0.1180  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8842 (0.8735)  acc1: 77.0833 (76.8662)  acc5: 97.9167 (97.3758)  time: 0.1170  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1623 s / it)\n",
            "* Acc@1 76.866 Acc@5 97.376 loss 0.874\n",
            "Accuracy of the model on the 3925 test images: 76.9%\n",
            "Max accuracy: 76.87%\n",
            "Test:  [ 0/82]  eta: 0:03:45  loss: 3.6932 (3.6932)  acc1: 10.4167 (10.4167)  acc5: 83.3333 (83.3333)  time: 2.7453  data: 2.5378  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 3.7227 (3.7423)  acc1: 6.2500 (9.6591)  acc5: 83.3333 (83.7121)  time: 0.4054  data: 0.2684  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.7448 (3.7999)  acc1: 14.5833 (14.0873)  acc5: 83.3333 (82.1429)  time: 0.1808  data: 0.0436  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 4.4947 (4.3186)  acc1: 12.5000 (10.6183)  acc5: 75.0000 (72.8495)  time: 0.1685  data: 0.0240  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.2995 (4.5265)  acc1: 2.0833 (9.4512)  acc5: 56.2500 (69.4614)  time: 0.1402  data: 0.0046  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.9139 (4.5520)  acc1: 8.3333 (11.4379)  acc5: 58.3333 (68.6275)  time: 0.1282  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6439 (4.6679)  acc1: 4.1667 (9.8019)  acc5: 58.3333 (67.1107)  time: 0.1232  data: 0.0023  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5819 (4.5895)  acc1: 0.0000 (12.0892)  acc5: 81.2500 (67.1655)  time: 0.1222  data: 0.0010  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.2545 (4.2163)  acc1: 50.0000 (19.5216)  acc5: 91.6667 (70.3704)  time: 0.1202  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.1538 (4.1856)  acc1: 54.1667 (20.0764)  acc5: 91.6667 (70.5478)  time: 0.1182  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1768 s / it)\n",
            "* Acc@1 20.076 Acc@5 70.548 loss 4.186\n",
            "Accuracy of the model EMA on 3925 test images: 20.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [45]  [  0/295]  eta: 0:07:11  lr: 0.000269  min_lr: 0.000269  loss: 2.7871 (2.7871)  weight_decay: 0.0500 (0.0500)  time: 1.4623  data: 1.1515  max mem: 3500\n",
            "Epoch: [45]  [ 10/295]  eta: 0:01:51  lr: 0.000266  min_lr: 0.000266  loss: 2.6741 (2.6643)  weight_decay: 0.0500 (0.0500)  time: 0.3917  data: 0.1116  max mem: 3500\n",
            "Epoch: [45]  [ 20/295]  eta: 0:01:32  lr: 0.000262  min_lr: 0.000262  loss: 2.5904 (2.5599)  weight_decay: 0.0500 (0.0500)  time: 0.2793  data: 0.0052  max mem: 3500\n",
            "Epoch: [45]  [ 30/295]  eta: 0:01:23  lr: 0.000259  min_lr: 0.000259  loss: 2.5619 (2.5795)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0019  max mem: 3500\n",
            "Epoch: [45]  [ 40/295]  eta: 0:01:17  lr: 0.000255  min_lr: 0.000255  loss: 2.6734 (2.5919)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0031  max mem: 3500\n",
            "Epoch: [45]  [ 50/295]  eta: 0:01:12  lr: 0.000252  min_lr: 0.000252  loss: 2.6205 (2.5884)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0042  max mem: 3500\n",
            "Epoch: [45]  [ 60/295]  eta: 0:01:08  lr: 0.000248  min_lr: 0.000248  loss: 2.5623 (2.5491)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0029  max mem: 3500\n",
            "Epoch: [45]  [ 70/295]  eta: 0:01:04  lr: 0.000245  min_lr: 0.000245  loss: 2.4065 (2.5364)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0025  max mem: 3500\n",
            "Epoch: [45]  [ 80/295]  eta: 0:01:01  lr: 0.000241  min_lr: 0.000241  loss: 2.5644 (2.5435)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0017  max mem: 3500\n",
            "Epoch: [45]  [ 90/295]  eta: 0:00:57  lr: 0.000238  min_lr: 0.000238  loss: 2.4806 (2.5303)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0020  max mem: 3500\n",
            "Epoch: [45]  [100/295]  eta: 0:00:54  lr: 0.000234  min_lr: 0.000234  loss: 2.4520 (2.5294)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0027  max mem: 3500\n",
            "Epoch: [45]  [110/295]  eta: 0:00:51  lr: 0.000231  min_lr: 0.000231  loss: 2.5656 (2.5269)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0024  max mem: 3500\n",
            "Epoch: [45]  [120/295]  eta: 0:00:48  lr: 0.000227  min_lr: 0.000227  loss: 2.4434 (2.5177)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0015  max mem: 3500\n",
            "Epoch: [45]  [130/295]  eta: 0:00:45  lr: 0.000225  min_lr: 0.000225  loss: 2.6058 (2.5217)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0010  max mem: 3500\n",
            "Epoch: [45]  [140/295]  eta: 0:00:42  lr: 0.000221  min_lr: 0.000221  loss: 2.6058 (2.5160)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0009  max mem: 3500\n",
            "Epoch: [45]  [150/295]  eta: 0:00:39  lr: 0.000218  min_lr: 0.000218  loss: 2.5686 (2.5181)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0020  max mem: 3500\n",
            "Epoch: [45]  [160/295]  eta: 0:00:37  lr: 0.000214  min_lr: 0.000214  loss: 2.4911 (2.5113)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0038  max mem: 3500\n",
            "Epoch: [45]  [170/295]  eta: 0:00:34  lr: 0.000212  min_lr: 0.000212  loss: 2.4607 (2.5135)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0026  max mem: 3500\n",
            "Epoch: [45]  [180/295]  eta: 0:00:31  lr: 0.000208  min_lr: 0.000208  loss: 2.5729 (2.5073)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0014  max mem: 3500\n",
            "Epoch: [45]  [190/295]  eta: 0:00:28  lr: 0.000205  min_lr: 0.000205  loss: 2.5852 (2.5125)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0011  max mem: 3500\n",
            "Epoch: [45]  [200/295]  eta: 0:00:25  lr: 0.000202  min_lr: 0.000202  loss: 2.4669 (2.5037)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0010  max mem: 3500\n",
            "Epoch: [45]  [210/295]  eta: 0:00:23  lr: 0.000199  min_lr: 0.000199  loss: 2.5831 (2.5106)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0009  max mem: 3500\n",
            "Epoch: [45]  [220/295]  eta: 0:00:20  lr: 0.000195  min_lr: 0.000195  loss: 2.4828 (2.5014)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0012  max mem: 3500\n",
            "Epoch: [45]  [230/295]  eta: 0:00:17  lr: 0.000193  min_lr: 0.000193  loss: 2.3925 (2.4988)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0026  max mem: 3500\n",
            "Epoch: [45]  [240/295]  eta: 0:00:14  lr: 0.000189  min_lr: 0.000189  loss: 2.5943 (2.5010)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0027  max mem: 3500\n",
            "Epoch: [45]  [250/295]  eta: 0:00:12  lr: 0.000187  min_lr: 0.000187  loss: 2.5825 (2.4984)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0011  max mem: 3500\n",
            "Epoch: [45]  [260/295]  eta: 0:00:09  lr: 0.000183  min_lr: 0.000183  loss: 2.5970 (2.5034)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0008  max mem: 3500\n",
            "Epoch: [45]  [270/295]  eta: 0:00:06  lr: 0.000181  min_lr: 0.000181  loss: 2.5970 (2.5046)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0014  max mem: 3500\n",
            "Epoch: [45]  [280/295]  eta: 0:00:04  lr: 0.000177  min_lr: 0.000177  loss: 2.4930 (2.5030)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0012  max mem: 3500\n",
            "Epoch: [45]  [290/295]  eta: 0:00:01  lr: 0.000175  min_lr: 0.000175  loss: 2.5801 (2.5040)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0006  max mem: 3500\n",
            "Epoch: [45]  [294/295]  eta: 0:00:00  lr: 0.000175  min_lr: 0.000175  loss: 2.5801 (2.5022)  weight_decay: 0.0500 (0.0500)  time: 0.2210  data: 0.0002  max mem: 3500\n",
            "Epoch: [45] Total time: 0:01:18 (0.2673 s / it)\n",
            "Averaged stats: lr: 0.000175  min_lr: 0.000175  loss: 2.5801 (2.5022)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:01:52  loss: 0.6865 (0.6865)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 1.3759  data: 1.2039  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:18  loss: 0.6689 (0.6729)  acc1: 87.5000 (85.7955)  acc5: 95.8333 (96.7803)  time: 0.2603  data: 0.1385  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.6433 (0.6769)  acc1: 85.4167 (85.1191)  acc5: 97.9167 (97.5198)  time: 0.1353  data: 0.0172  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:08  loss: 0.7847 (0.8938)  acc1: 79.1667 (75.6048)  acc5: 97.9167 (97.1102)  time: 0.1243  data: 0.0017  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 0.7847 (0.8484)  acc1: 81.2500 (77.8963)  acc5: 97.9167 (97.5610)  time: 0.1255  data: 0.0023  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7530 (0.8517)  acc1: 81.2500 (77.9820)  acc5: 97.9167 (97.7124)  time: 0.1321  data: 0.0025  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8674 (0.8616)  acc1: 77.0833 (77.5956)  acc5: 97.9167 (97.6093)  time: 0.1418  data: 0.0019  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9491 (0.8902)  acc1: 70.8333 (76.4671)  acc5: 97.9167 (97.3298)  time: 0.1433  data: 0.0015  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8039 (0.8627)  acc1: 77.0833 (77.4434)  acc5: 97.9167 (97.4794)  time: 0.1305  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8039 (0.8634)  acc1: 77.0833 (77.4268)  acc5: 97.9167 (97.4268)  time: 0.1274  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1553 s / it)\n",
            "* Acc@1 77.427 Acc@5 97.427 loss 0.863\n",
            "Accuracy of the model on the 3925 test images: 77.4%\n",
            "Max accuracy: 77.43%\n",
            "Test:  [ 0/82]  eta: 0:04:42  loss: 3.6360 (3.6360)  acc1: 8.3333 (8.3333)  acc5: 83.3333 (83.3333)  time: 3.4447  data: 3.2746  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 3.6847 (3.6977)  acc1: 6.2500 (9.6591)  acc5: 83.3333 (84.2803)  time: 0.4500  data: 0.3087  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.7097 (3.7601)  acc1: 12.5000 (13.8889)  acc5: 83.3333 (82.6389)  time: 0.1450  data: 0.0151  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 4.4519 (4.2838)  acc1: 10.4167 (10.4839)  acc5: 75.0000 (73.1183)  time: 0.1313  data: 0.0118  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.2302 (4.4865)  acc1: 2.0833 (9.3496)  acc5: 56.2500 (69.7154)  time: 0.1231  data: 0.0051  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.9059 (4.5235)  acc1: 6.2500 (11.3154)  acc5: 58.3333 (68.6683)  time: 0.1227  data: 0.0048  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6477 (4.6418)  acc1: 4.1667 (9.6995)  acc5: 58.3333 (67.1790)  time: 0.1219  data: 0.0043  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5724 (4.5595)  acc1: 0.0000 (12.0599)  acc5: 81.2500 (67.1948)  time: 0.1201  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.1875 (4.1853)  acc1: 50.0000 (19.4959)  acc5: 91.6667 (70.4475)  time: 0.1183  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.0811 (4.1546)  acc1: 54.1667 (20.0510)  acc5: 91.6667 (70.6242)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1714 s / it)\n",
            "* Acc@1 20.051 Acc@5 70.624 loss 4.155\n",
            "Accuracy of the model EMA on 3925 test images: 20.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [46]  [  0/295]  eta: 0:07:23  lr: 0.000174  min_lr: 0.000174  loss: 2.3614 (2.3614)  weight_decay: 0.0500 (0.0500)  time: 1.5019  data: 1.1599  max mem: 3500\n",
            "Epoch: [46]  [ 10/295]  eta: 0:02:00  lr: 0.000172  min_lr: 0.000172  loss: 2.4472 (2.4437)  weight_decay: 0.0500 (0.0500)  time: 0.4218  data: 0.1101  max mem: 3500\n",
            "Epoch: [46]  [ 20/295]  eta: 0:01:36  lr: 0.000168  min_lr: 0.000168  loss: 2.4743 (2.4816)  weight_decay: 0.0500 (0.0500)  time: 0.2936  data: 0.0040  max mem: 3500\n",
            "Epoch: [46]  [ 30/295]  eta: 0:01:26  lr: 0.000166  min_lr: 0.000166  loss: 2.4626 (2.4706)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0030  max mem: 3500\n",
            "Epoch: [46]  [ 40/295]  eta: 0:01:19  lr: 0.000162  min_lr: 0.000162  loss: 2.4252 (2.4937)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0023  max mem: 3500\n",
            "Epoch: [46]  [ 50/295]  eta: 0:01:13  lr: 0.000160  min_lr: 0.000160  loss: 2.4953 (2.4855)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0016  max mem: 3500\n",
            "Epoch: [46]  [ 60/295]  eta: 0:01:09  lr: 0.000157  min_lr: 0.000157  loss: 2.5366 (2.4902)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0014  max mem: 3500\n",
            "Epoch: [46]  [ 70/295]  eta: 0:01:05  lr: 0.000155  min_lr: 0.000155  loss: 2.6233 (2.5109)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0015  max mem: 3500\n",
            "Epoch: [46]  [ 80/295]  eta: 0:01:02  lr: 0.000151  min_lr: 0.000151  loss: 2.5587 (2.5071)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0028  max mem: 3500\n",
            "Epoch: [46]  [ 90/295]  eta: 0:00:58  lr: 0.000149  min_lr: 0.000149  loss: 2.4275 (2.4931)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0031  max mem: 3500\n",
            "Epoch: [46]  [100/295]  eta: 0:00:55  lr: 0.000146  min_lr: 0.000146  loss: 2.5411 (2.5056)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0027  max mem: 3500\n",
            "Epoch: [46]  [110/295]  eta: 0:00:52  lr: 0.000144  min_lr: 0.000144  loss: 2.6111 (2.5005)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0018  max mem: 3500\n",
            "Epoch: [46]  [120/295]  eta: 0:00:49  lr: 0.000141  min_lr: 0.000141  loss: 2.4565 (2.4993)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0013  max mem: 3500\n",
            "Epoch: [46]  [130/295]  eta: 0:00:46  lr: 0.000138  min_lr: 0.000138  loss: 2.4780 (2.5018)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0017  max mem: 3500\n",
            "Epoch: [46]  [140/295]  eta: 0:00:43  lr: 0.000135  min_lr: 0.000135  loss: 2.5174 (2.4982)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0028  max mem: 3500\n",
            "Epoch: [46]  [150/295]  eta: 0:00:40  lr: 0.000133  min_lr: 0.000133  loss: 2.4400 (2.4947)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0044  max mem: 3500\n",
            "Epoch: [46]  [160/295]  eta: 0:00:37  lr: 0.000130  min_lr: 0.000130  loss: 2.5173 (2.4953)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0058  max mem: 3500\n",
            "Epoch: [46]  [170/295]  eta: 0:00:34  lr: 0.000128  min_lr: 0.000128  loss: 2.5546 (2.5007)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0048  max mem: 3500\n",
            "Epoch: [46]  [180/295]  eta: 0:00:31  lr: 0.000125  min_lr: 0.000125  loss: 2.5124 (2.4915)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0019  max mem: 3500\n",
            "Epoch: [46]  [190/295]  eta: 0:00:28  lr: 0.000123  min_lr: 0.000123  loss: 2.4418 (2.4911)  weight_decay: 0.0500 (0.0500)  time: 0.2566  data: 0.0010  max mem: 3500\n",
            "Epoch: [46]  [200/295]  eta: 0:00:25  lr: 0.000120  min_lr: 0.000120  loss: 2.5024 (2.4892)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0009  max mem: 3500\n",
            "Epoch: [46]  [210/295]  eta: 0:00:23  lr: 0.000118  min_lr: 0.000118  loss: 2.5561 (2.4922)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0040  max mem: 3500\n",
            "Epoch: [46]  [220/295]  eta: 0:00:20  lr: 0.000115  min_lr: 0.000115  loss: 2.4911 (2.4904)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0066  max mem: 3500\n",
            "Epoch: [46]  [230/295]  eta: 0:00:17  lr: 0.000114  min_lr: 0.000114  loss: 2.4273 (2.4888)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0046  max mem: 3500\n",
            "Epoch: [46]  [240/295]  eta: 0:00:14  lr: 0.000111  min_lr: 0.000111  loss: 2.3781 (2.4858)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0029  max mem: 3500\n",
            "Epoch: [46]  [250/295]  eta: 0:00:12  lr: 0.000109  min_lr: 0.000109  loss: 2.3900 (2.4865)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0016  max mem: 3500\n",
            "Epoch: [46]  [260/295]  eta: 0:00:09  lr: 0.000106  min_lr: 0.000106  loss: 2.4402 (2.4865)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0009  max mem: 3500\n",
            "Epoch: [46]  [270/295]  eta: 0:00:06  lr: 0.000104  min_lr: 0.000104  loss: 2.3597 (2.4826)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0027  max mem: 3500\n",
            "Epoch: [46]  [280/295]  eta: 0:00:04  lr: 0.000102  min_lr: 0.000102  loss: 2.4102 (2.4845)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0031  max mem: 3500\n",
            "Epoch: [46]  [290/295]  eta: 0:00:01  lr: 0.000100  min_lr: 0.000100  loss: 2.3580 (2.4805)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0012  max mem: 3500\n",
            "Epoch: [46]  [294/295]  eta: 0:00:00  lr: 0.000100  min_lr: 0.000100  loss: 2.4038 (2.4802)  weight_decay: 0.0500 (0.0500)  time: 0.2210  data: 0.0001  max mem: 3500\n",
            "Epoch: [46] Total time: 0:01:19 (0.2689 s / it)\n",
            "Averaged stats: lr: 0.000100  min_lr: 0.000100  loss: 2.4038 (2.4802)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:01:46  loss: 0.6835 (0.6835)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 1.2950  data: 1.1323  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 0.6447 (0.6439)  acc1: 85.4167 (85.7955)  acc5: 95.8333 (96.9697)  time: 0.2745  data: 0.1453  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.6441 (0.6516)  acc1: 85.4167 (84.9206)  acc5: 97.9167 (97.8175)  time: 0.1501  data: 0.0248  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.7614 (0.8570)  acc1: 79.1667 (76.6129)  acc5: 97.9167 (97.5134)  time: 0.1252  data: 0.0040  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 0.8134 (0.8286)  acc1: 79.1667 (78.2520)  acc5: 97.9167 (97.7134)  time: 0.1228  data: 0.0050  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7304 (0.8341)  acc1: 81.2500 (78.2680)  acc5: 97.9167 (97.7941)  time: 0.1257  data: 0.0072  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8520 (0.8423)  acc1: 77.0833 (77.9372)  acc5: 97.9167 (97.6093)  time: 0.1310  data: 0.0058  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9480 (0.8701)  acc1: 70.8333 (76.8193)  acc5: 97.9167 (97.3298)  time: 0.1351  data: 0.0011  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8358 (0.8492)  acc1: 77.0833 (77.5977)  acc5: 97.9167 (97.4537)  time: 0.1278  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8358 (0.8505)  acc1: 77.0833 (77.5796)  acc5: 97.9167 (97.4013)  time: 0.1252  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1529 s / it)\n",
            "* Acc@1 77.580 Acc@5 97.401 loss 0.850\n",
            "Accuracy of the model on the 3925 test images: 77.6%\n",
            "Max accuracy: 77.58%\n",
            "Test:  [ 0/82]  eta: 0:02:44  loss: 3.5757 (3.5757)  acc1: 10.4167 (10.4167)  acc5: 83.3333 (83.3333)  time: 2.0119  data: 1.8491  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.6420 (3.6509)  acc1: 8.3333 (9.8485)  acc5: 85.4167 (84.4697)  time: 0.2956  data: 0.1695  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.6752 (3.7194)  acc1: 10.4167 (13.7897)  acc5: 83.3333 (83.1349)  time: 0.1226  data: 0.0017  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.4094 (4.2477)  acc1: 10.4167 (10.3495)  acc5: 75.0000 (73.4543)  time: 0.1211  data: 0.0026  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.1596 (4.4454)  acc1: 4.1667 (9.3496)  acc5: 58.3333 (70.0203)  time: 0.1232  data: 0.0042  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8461 (4.4934)  acc1: 6.2500 (11.3154)  acc5: 58.3333 (68.8317)  time: 0.1239  data: 0.0043  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6647 (4.6139)  acc1: 4.1667 (9.6995)  acc5: 58.3333 (67.2814)  time: 0.1216  data: 0.0048  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5595 (4.5283)  acc1: 0.0000 (12.0599)  acc5: 79.1667 (67.2535)  time: 0.1191  data: 0.0032  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.1251 (4.1534)  acc1: 50.0000 (19.4702)  acc5: 93.7500 (70.5247)  time: 0.1177  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.0135 (4.1228)  acc1: 54.1667 (20.0255)  acc5: 93.7500 (70.7006)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1505 s / it)\n",
            "* Acc@1 20.025 Acc@5 70.701 loss 4.123\n",
            "Accuracy of the model EMA on 3925 test images: 20.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [47]  [  0/295]  eta: 0:13:44  lr: 0.000099  min_lr: 0.000099  loss: 2.4003 (2.4003)  weight_decay: 0.0500 (0.0500)  time: 2.7962  data: 2.3226  max mem: 3500\n",
            "Epoch: [47]  [ 10/295]  eta: 0:02:27  lr: 0.000097  min_lr: 0.000097  loss: 2.6181 (2.5776)  weight_decay: 0.0500 (0.0500)  time: 0.5160  data: 0.2141  max mem: 3500\n",
            "Epoch: [47]  [ 20/295]  eta: 0:01:48  lr: 0.000094  min_lr: 0.000094  loss: 2.5464 (2.5046)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0025  max mem: 3500\n",
            "Epoch: [47]  [ 30/295]  eta: 0:01:33  lr: 0.000093  min_lr: 0.000093  loss: 2.4216 (2.4439)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0020  max mem: 3500\n",
            "Epoch: [47]  [ 40/295]  eta: 0:01:24  lr: 0.000090  min_lr: 0.000090  loss: 2.4216 (2.4656)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0020  max mem: 3500\n",
            "Epoch: [47]  [ 50/295]  eta: 0:01:17  lr: 0.000089  min_lr: 0.000089  loss: 2.4906 (2.4640)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0014  max mem: 3500\n",
            "Epoch: [47]  [ 60/295]  eta: 0:01:13  lr: 0.000086  min_lr: 0.000086  loss: 2.5176 (2.4844)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0020  max mem: 3500\n",
            "Epoch: [47]  [ 70/295]  eta: 0:01:08  lr: 0.000084  min_lr: 0.000084  loss: 2.5901 (2.5012)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0030  max mem: 3500\n",
            "Epoch: [47]  [ 80/295]  eta: 0:01:04  lr: 0.000082  min_lr: 0.000082  loss: 2.5802 (2.5197)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0030  max mem: 3500\n",
            "Epoch: [47]  [ 90/295]  eta: 0:01:00  lr: 0.000080  min_lr: 0.000080  loss: 2.5652 (2.5047)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0029  max mem: 3500\n",
            "Epoch: [47]  [100/295]  eta: 0:00:57  lr: 0.000078  min_lr: 0.000078  loss: 2.4411 (2.5061)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0026  max mem: 3500\n",
            "Epoch: [47]  [110/295]  eta: 0:00:53  lr: 0.000076  min_lr: 0.000076  loss: 2.5000 (2.5088)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0021  max mem: 3500\n",
            "Epoch: [47]  [120/295]  eta: 0:00:50  lr: 0.000074  min_lr: 0.000074  loss: 2.5365 (2.5125)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0035  max mem: 3500\n",
            "Epoch: [47]  [130/295]  eta: 0:00:47  lr: 0.000073  min_lr: 0.000073  loss: 2.5202 (2.5049)  weight_decay: 0.0500 (0.0500)  time: 0.2758  data: 0.0055  max mem: 3500\n",
            "Epoch: [47]  [140/295]  eta: 0:00:44  lr: 0.000070  min_lr: 0.000070  loss: 2.5883 (2.5138)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0045  max mem: 3500\n",
            "Epoch: [47]  [150/295]  eta: 0:00:41  lr: 0.000069  min_lr: 0.000069  loss: 2.5883 (2.5105)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0031  max mem: 3500\n",
            "Epoch: [47]  [160/295]  eta: 0:00:38  lr: 0.000067  min_lr: 0.000067  loss: 2.5224 (2.5099)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0026  max mem: 3500\n",
            "Epoch: [47]  [170/295]  eta: 0:00:35  lr: 0.000065  min_lr: 0.000065  loss: 2.6160 (2.5112)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0019  max mem: 3500\n",
            "Epoch: [47]  [180/295]  eta: 0:00:32  lr: 0.000063  min_lr: 0.000063  loss: 2.4863 (2.5097)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0017  max mem: 3500\n",
            "Epoch: [47]  [190/295]  eta: 0:00:29  lr: 0.000062  min_lr: 0.000062  loss: 2.4863 (2.5082)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0017  max mem: 3500\n",
            "Epoch: [47]  [200/295]  eta: 0:00:26  lr: 0.000059  min_lr: 0.000059  loss: 2.4909 (2.5075)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0035  max mem: 3500\n",
            "Epoch: [47]  [210/295]  eta: 0:00:23  lr: 0.000058  min_lr: 0.000058  loss: 2.4632 (2.5052)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0054  max mem: 3500\n",
            "Epoch: [47]  [220/295]  eta: 0:00:20  lr: 0.000056  min_lr: 0.000056  loss: 2.5062 (2.5069)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0034  max mem: 3500\n",
            "Epoch: [47]  [230/295]  eta: 0:00:18  lr: 0.000055  min_lr: 0.000055  loss: 2.5062 (2.5026)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0018  max mem: 3500\n",
            "Epoch: [47]  [240/295]  eta: 0:00:15  lr: 0.000053  min_lr: 0.000053  loss: 2.4964 (2.5063)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0016  max mem: 3500\n",
            "Epoch: [47]  [250/295]  eta: 0:00:12  lr: 0.000051  min_lr: 0.000051  loss: 2.5422 (2.5080)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0007  max mem: 3500\n",
            "Epoch: [47]  [260/295]  eta: 0:00:09  lr: 0.000050  min_lr: 0.000050  loss: 2.5465 (2.5109)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0021  max mem: 3500\n",
            "Epoch: [47]  [270/295]  eta: 0:00:06  lr: 0.000048  min_lr: 0.000048  loss: 2.5465 (2.5119)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0036  max mem: 3500\n",
            "Epoch: [47]  [280/295]  eta: 0:00:04  lr: 0.000047  min_lr: 0.000047  loss: 2.5516 (2.5140)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0026  max mem: 3500\n",
            "Epoch: [47]  [290/295]  eta: 0:00:01  lr: 0.000045  min_lr: 0.000045  loss: 2.4284 (2.5098)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0009  max mem: 3500\n",
            "Epoch: [47]  [294/295]  eta: 0:00:00  lr: 0.000045  min_lr: 0.000045  loss: 2.4284 (2.5104)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0001  max mem: 3500\n",
            "Epoch: [47] Total time: 0:01:20 (0.2729 s / it)\n",
            "Averaged stats: lr: 0.000045  min_lr: 0.000045  loss: 2.4284 (2.5104)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:27  loss: 0.6353 (0.6353)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 1.8036  data: 1.6396  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 0.5927 (0.6264)  acc1: 87.5000 (85.9849)  acc5: 95.8333 (96.5909)  time: 0.2758  data: 0.1514  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.6024 (0.6465)  acc1: 87.5000 (85.3175)  acc5: 97.9167 (97.5198)  time: 0.1244  data: 0.0030  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.7599 (0.8629)  acc1: 79.1667 (76.5457)  acc5: 97.9167 (97.4462)  time: 0.1283  data: 0.0070  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8505 (0.8413)  acc1: 79.1667 (78.0996)  acc5: 97.9167 (97.7134)  time: 0.1386  data: 0.0079  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7543 (0.8462)  acc1: 79.1667 (78.0637)  acc5: 97.9167 (97.7124)  time: 0.1393  data: 0.0028  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8674 (0.8500)  acc1: 77.0833 (77.8347)  acc5: 97.9167 (97.5751)  time: 0.1369  data: 0.0021  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9416 (0.8780)  acc1: 72.9167 (76.8193)  acc5: 97.9167 (97.3005)  time: 0.1395  data: 0.0019  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8391 (0.8558)  acc1: 75.0000 (77.6492)  acc5: 97.9167 (97.4023)  time: 0.1296  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8391 (0.8568)  acc1: 77.0833 (77.6561)  acc5: 97.9167 (97.3503)  time: 0.1258  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1593 s / it)\n",
            "* Acc@1 77.656 Acc@5 97.350 loss 0.857\n",
            "Accuracy of the model on the 3925 test images: 77.7%\n",
            "Max accuracy: 77.66%\n",
            "Test:  [ 0/82]  eta: 0:02:32  loss: 3.5164 (3.5164)  acc1: 10.4167 (10.4167)  acc5: 85.4167 (85.4167)  time: 1.8604  data: 1.7006  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.5985 (3.6044)  acc1: 8.3333 (10.2273)  acc5: 85.4167 (85.4167)  time: 0.2837  data: 0.1560  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.6409 (3.6786)  acc1: 10.4167 (13.7897)  acc5: 85.4167 (83.8294)  time: 0.1252  data: 0.0021  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.3669 (4.2113)  acc1: 10.4167 (10.3495)  acc5: 75.0000 (73.8575)  time: 0.1231  data: 0.0030  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 5.0902 (4.4042)  acc1: 4.1667 (9.3496)  acc5: 56.2500 (70.2236)  time: 0.1228  data: 0.0050  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8407 (4.4633)  acc1: 6.2500 (11.2745)  acc5: 58.3333 (68.9543)  time: 0.1238  data: 0.0069  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6821 (4.5859)  acc1: 4.1667 (9.6995)  acc5: 58.3333 (67.3839)  time: 0.1221  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5464 (4.4970)  acc1: 0.0000 (12.1772)  acc5: 79.1667 (67.3709)  time: 0.1198  data: 0.0016  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.0651 (4.1217)  acc1: 50.0000 (19.5988)  acc5: 95.8333 (70.7305)  time: 0.1192  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.9501 (4.0912)  acc1: 54.1667 (20.1529)  acc5: 95.8333 (70.9045)  time: 0.1177  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1502 s / it)\n",
            "* Acc@1 20.153 Acc@5 70.904 loss 4.091\n",
            "Accuracy of the model EMA on 3925 test images: 20.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [48]  [  0/295]  eta: 0:13:42  lr: 0.000045  min_lr: 0.000045  loss: 2.4500 (2.4500)  weight_decay: 0.0500 (0.0500)  time: 2.7878  data: 2.2527  max mem: 3500\n",
            "Epoch: [48]  [ 10/295]  eta: 0:02:24  lr: 0.000044  min_lr: 0.000044  loss: 2.5275 (2.5219)  weight_decay: 0.0500 (0.0500)  time: 0.5058  data: 0.2062  max mem: 3500\n",
            "Epoch: [48]  [ 20/295]  eta: 0:01:47  lr: 0.000042  min_lr: 0.000042  loss: 2.6030 (2.5430)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0016  max mem: 3500\n",
            "Epoch: [48]  [ 30/295]  eta: 0:01:32  lr: 0.000041  min_lr: 0.000041  loss: 2.5874 (2.5397)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0013  max mem: 3500\n",
            "Epoch: [48]  [ 40/295]  eta: 0:01:23  lr: 0.000039  min_lr: 0.000039  loss: 2.5697 (2.5489)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0008  max mem: 3500\n",
            "Epoch: [48]  [ 50/295]  eta: 0:01:18  lr: 0.000038  min_lr: 0.000038  loss: 2.5290 (2.5242)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0023  max mem: 3500\n",
            "Epoch: [48]  [ 60/295]  eta: 0:01:13  lr: 0.000036  min_lr: 0.000036  loss: 2.3375 (2.4873)  weight_decay: 0.0500 (0.0500)  time: 0.2764  data: 0.0037  max mem: 3500\n",
            "Epoch: [48]  [ 70/295]  eta: 0:01:08  lr: 0.000035  min_lr: 0.000035  loss: 2.3270 (2.4825)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0038  max mem: 3500\n",
            "Epoch: [48]  [ 80/295]  eta: 0:01:04  lr: 0.000034  min_lr: 0.000034  loss: 2.5935 (2.4870)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0030  max mem: 3500\n",
            "Epoch: [48]  [ 90/295]  eta: 0:01:00  lr: 0.000033  min_lr: 0.000033  loss: 2.5477 (2.4860)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0016  max mem: 3500\n",
            "Epoch: [48]  [100/295]  eta: 0:00:57  lr: 0.000031  min_lr: 0.000031  loss: 2.4828 (2.4862)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0014  max mem: 3500\n",
            "Epoch: [48]  [110/295]  eta: 0:00:53  lr: 0.000030  min_lr: 0.000030  loss: 2.4752 (2.4773)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0027  max mem: 3500\n",
            "Epoch: [48]  [120/295]  eta: 0:00:50  lr: 0.000029  min_lr: 0.000029  loss: 2.5129 (2.4989)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0046  max mem: 3500\n",
            "Epoch: [48]  [130/295]  eta: 0:00:47  lr: 0.000028  min_lr: 0.000028  loss: 2.6029 (2.4945)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0051  max mem: 3500\n",
            "Epoch: [48]  [140/295]  eta: 0:00:44  lr: 0.000026  min_lr: 0.000026  loss: 2.4126 (2.4923)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0044  max mem: 3500\n",
            "Epoch: [48]  [150/295]  eta: 0:00:41  lr: 0.000025  min_lr: 0.000025  loss: 2.4263 (2.4896)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0033  max mem: 3500\n",
            "Epoch: [48]  [160/295]  eta: 0:00:38  lr: 0.000024  min_lr: 0.000024  loss: 2.5435 (2.4920)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0017  max mem: 3500\n",
            "Epoch: [48]  [170/295]  eta: 0:00:35  lr: 0.000023  min_lr: 0.000023  loss: 2.5160 (2.4829)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0015  max mem: 3500\n",
            "Epoch: [48]  [180/295]  eta: 0:00:32  lr: 0.000022  min_lr: 0.000022  loss: 2.3346 (2.4829)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0040  max mem: 3500\n",
            "Epoch: [48]  [190/295]  eta: 0:00:29  lr: 0.000021  min_lr: 0.000021  loss: 2.4874 (2.4796)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0053  max mem: 3500\n",
            "Epoch: [48]  [200/295]  eta: 0:00:26  lr: 0.000020  min_lr: 0.000020  loss: 2.4330 (2.4807)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0040  max mem: 3500\n",
            "Epoch: [48]  [210/295]  eta: 0:00:23  lr: 0.000019  min_lr: 0.000019  loss: 2.5892 (2.4878)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0025  max mem: 3500\n",
            "Epoch: [48]  [220/295]  eta: 0:00:20  lr: 0.000018  min_lr: 0.000018  loss: 2.4774 (2.4851)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0017  max mem: 3500\n",
            "Epoch: [48]  [230/295]  eta: 0:00:17  lr: 0.000017  min_lr: 0.000017  loss: 2.4597 (2.4845)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0020  max mem: 3500\n",
            "Epoch: [48]  [240/295]  eta: 0:00:15  lr: 0.000016  min_lr: 0.000016  loss: 2.5016 (2.4848)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0018  max mem: 3500\n",
            "Epoch: [48]  [250/295]  eta: 0:00:12  lr: 0.000015  min_lr: 0.000015  loss: 2.5695 (2.4875)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0033  max mem: 3500\n",
            "Epoch: [48]  [260/295]  eta: 0:00:09  lr: 0.000014  min_lr: 0.000014  loss: 2.5429 (2.4825)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0042  max mem: 3500\n",
            "Epoch: [48]  [270/295]  eta: 0:00:06  lr: 0.000014  min_lr: 0.000014  loss: 2.4799 (2.4834)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0034  max mem: 3500\n",
            "Epoch: [48]  [280/295]  eta: 0:00:04  lr: 0.000013  min_lr: 0.000013  loss: 2.5691 (2.4878)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0023  max mem: 3500\n",
            "Epoch: [48]  [290/295]  eta: 0:00:01  lr: 0.000012  min_lr: 0.000012  loss: 2.4900 (2.4866)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0006  max mem: 3500\n",
            "Epoch: [48]  [294/295]  eta: 0:00:00  lr: 0.000012  min_lr: 0.000012  loss: 2.4848 (2.4854)  weight_decay: 0.0500 (0.0500)  time: 0.2205  data: 0.0002  max mem: 3500\n",
            "Epoch: [48] Total time: 0:01:20 (0.2727 s / it)\n",
            "Averaged stats: lr: 0.000012  min_lr: 0.000012  loss: 2.4848 (2.4854)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:58  loss: 0.6350 (0.6350)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 2.9121  data: 2.7529  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 0.5974 (0.6192)  acc1: 87.5000 (86.1742)  acc5: 95.8333 (96.5909)  time: 0.4473  data: 0.3072  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.6187 (0.6438)  acc1: 87.5000 (85.0198)  acc5: 97.9167 (97.5198)  time: 0.1769  data: 0.0416  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.7685 (0.8499)  acc1: 77.0833 (76.9489)  acc5: 97.9167 (97.4462)  time: 0.1503  data: 0.0202  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.8800 (0.8341)  acc1: 79.1667 (78.2520)  acc5: 97.9167 (97.7134)  time: 0.1469  data: 0.0148  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7714 (0.8393)  acc1: 79.1667 (78.3497)  acc5: 97.9167 (97.7941)  time: 0.1385  data: 0.0064  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8593 (0.8417)  acc1: 77.0833 (78.1762)  acc5: 97.9167 (97.6434)  time: 0.1266  data: 0.0023  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9447 (0.8705)  acc1: 72.9167 (77.2007)  acc5: 97.9167 (97.3885)  time: 0.1205  data: 0.0010  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8443 (0.8487)  acc1: 77.0833 (78.0350)  acc5: 97.9167 (97.4794)  time: 0.1184  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8443 (0.8496)  acc1: 78.3784 (78.0382)  acc5: 97.9167 (97.4268)  time: 0.1170  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1807 s / it)\n",
            "* Acc@1 78.038 Acc@5 97.427 loss 0.850\n",
            "Accuracy of the model on the 3925 test images: 78.0%\n",
            "Max accuracy: 78.04%\n",
            "Test:  [ 0/82]  eta: 0:02:46  loss: 3.4581 (3.4581)  acc1: 10.4167 (10.4167)  acc5: 87.5000 (87.5000)  time: 2.0268  data: 1.8677  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.5547 (3.5582)  acc1: 6.2500 (10.0379)  acc5: 87.5000 (86.7424)  time: 0.2953  data: 0.1730  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.6066 (3.6381)  acc1: 10.4167 (13.6905)  acc5: 85.4167 (84.5238)  time: 0.1282  data: 0.0037  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 4.3244 (4.1749)  acc1: 10.4167 (10.2151)  acc5: 75.0000 (74.3280)  time: 0.1357  data: 0.0020  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.0201 (4.3627)  acc1: 4.1667 (9.3496)  acc5: 58.3333 (70.7317)  time: 0.1485  data: 0.0127  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8468 (4.4326)  acc1: 8.3333 (11.1520)  acc5: 58.3333 (69.3219)  time: 0.1700  data: 0.0320  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6984 (4.5568)  acc1: 4.1667 (9.5970)  acc5: 56.2500 (67.6230)  time: 0.1692  data: 0.0330  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5306 (4.4650)  acc1: 0.0000 (12.1479)  acc5: 79.1667 (67.6056)  time: 0.1470  data: 0.0137  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.0076 (4.0894)  acc1: 50.0000 (19.5988)  acc5: 95.8333 (70.9362)  time: 0.1277  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8900 (4.0590)  acc1: 56.2500 (20.1529)  acc5: 95.8333 (71.1083)  time: 0.1267  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1706 s / it)\n",
            "* Acc@1 20.153 Acc@5 71.108 loss 4.059\n",
            "Accuracy of the model EMA on 3925 test images: 20.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [49]  [  0/295]  eta: 0:08:28  lr: 0.000012  min_lr: 0.000012  loss: 2.5288 (2.5288)  weight_decay: 0.0500 (0.0500)  time: 1.7250  data: 1.3151  max mem: 3500\n",
            "Epoch: [49]  [ 10/295]  eta: 0:01:54  lr: 0.000011  min_lr: 0.000011  loss: 2.5341 (2.4530)  weight_decay: 0.0500 (0.0500)  time: 0.4032  data: 0.1205  max mem: 3500\n",
            "Epoch: [49]  [ 20/295]  eta: 0:01:32  lr: 0.000011  min_lr: 0.000011  loss: 2.4300 (2.4149)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0017  max mem: 3500\n",
            "Epoch: [49]  [ 30/295]  eta: 0:01:23  lr: 0.000010  min_lr: 0.000010  loss: 2.4266 (2.4164)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0018  max mem: 3500\n",
            "Epoch: [49]  [ 40/295]  eta: 0:01:17  lr: 0.000009  min_lr: 0.000009  loss: 2.5059 (2.4527)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0017  max mem: 3500\n",
            "Epoch: [49]  [ 50/295]  eta: 0:01:12  lr: 0.000009  min_lr: 0.000009  loss: 2.5068 (2.4638)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0022  max mem: 3500\n",
            "Epoch: [49]  [ 60/295]  eta: 0:01:08  lr: 0.000008  min_lr: 0.000008  loss: 2.4680 (2.4629)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0019  max mem: 3500\n",
            "Epoch: [49]  [ 70/295]  eta: 0:01:04  lr: 0.000007  min_lr: 0.000007  loss: 2.4680 (2.4546)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0014  max mem: 3500\n",
            "Epoch: [49]  [ 80/295]  eta: 0:01:01  lr: 0.000007  min_lr: 0.000007  loss: 2.5167 (2.4588)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0011  max mem: 3500\n",
            "Epoch: [49]  [ 90/295]  eta: 0:00:57  lr: 0.000006  min_lr: 0.000006  loss: 2.4158 (2.4489)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0024  max mem: 3500\n",
            "Epoch: [49]  [100/295]  eta: 0:00:54  lr: 0.000006  min_lr: 0.000006  loss: 2.3422 (2.4496)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0033  max mem: 3500\n",
            "Epoch: [49]  [110/295]  eta: 0:00:51  lr: 0.000005  min_lr: 0.000005  loss: 2.4864 (2.4510)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0030  max mem: 3500\n",
            "Epoch: [49]  [120/295]  eta: 0:00:48  lr: 0.000005  min_lr: 0.000005  loss: 2.5197 (2.4556)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0039  max mem: 3500\n",
            "Epoch: [49]  [130/295]  eta: 0:00:45  lr: 0.000004  min_lr: 0.000004  loss: 2.5045 (2.4514)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0026  max mem: 3500\n",
            "Epoch: [49]  [140/295]  eta: 0:00:42  lr: 0.000004  min_lr: 0.000004  loss: 2.4733 (2.4512)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0023  max mem: 3500\n",
            "Epoch: [49]  [150/295]  eta: 0:00:39  lr: 0.000004  min_lr: 0.000004  loss: 2.3922 (2.4489)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0028  max mem: 3500\n",
            "Epoch: [49]  [160/295]  eta: 0:00:37  lr: 0.000003  min_lr: 0.000003  loss: 2.3922 (2.4506)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0010  max mem: 3500\n",
            "Epoch: [49]  [170/295]  eta: 0:00:34  lr: 0.000003  min_lr: 0.000003  loss: 2.5238 (2.4594)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0011  max mem: 3500\n",
            "Epoch: [49]  [180/295]  eta: 0:00:31  lr: 0.000003  min_lr: 0.000003  loss: 2.5238 (2.4607)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0036  max mem: 3500\n",
            "Epoch: [49]  [190/295]  eta: 0:00:28  lr: 0.000002  min_lr: 0.000002  loss: 2.5029 (2.4614)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0042  max mem: 3500\n",
            "Epoch: [49]  [200/295]  eta: 0:00:25  lr: 0.000002  min_lr: 0.000002  loss: 2.5182 (2.4644)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0022  max mem: 3500\n",
            "Epoch: [49]  [210/295]  eta: 0:00:23  lr: 0.000002  min_lr: 0.000002  loss: 2.5624 (2.4659)  weight_decay: 0.0500 (0.0500)  time: 0.2573  data: 0.0010  max mem: 3500\n",
            "Epoch: [49]  [220/295]  eta: 0:00:20  lr: 0.000002  min_lr: 0.000002  loss: 2.5070 (2.4675)  weight_decay: 0.0500 (0.0500)  time: 0.2571  data: 0.0010  max mem: 3500\n",
            "Epoch: [49]  [230/295]  eta: 0:00:17  lr: 0.000002  min_lr: 0.000002  loss: 2.6015 (2.4737)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0015  max mem: 3500\n",
            "Epoch: [49]  [240/295]  eta: 0:00:14  lr: 0.000001  min_lr: 0.000001  loss: 2.6262 (2.4782)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0034  max mem: 3500\n",
            "Epoch: [49]  [250/295]  eta: 0:00:12  lr: 0.000001  min_lr: 0.000001  loss: 2.5158 (2.4751)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0034  max mem: 3500\n",
            "Epoch: [49]  [260/295]  eta: 0:00:09  lr: 0.000001  min_lr: 0.000001  loss: 2.5394 (2.4815)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0017  max mem: 3500\n",
            "Epoch: [49]  [270/295]  eta: 0:00:06  lr: 0.000001  min_lr: 0.000001  loss: 2.5533 (2.4796)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0020  max mem: 3500\n",
            "Epoch: [49]  [280/295]  eta: 0:00:04  lr: 0.000001  min_lr: 0.000001  loss: 2.4541 (2.4814)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0013  max mem: 3500\n",
            "Epoch: [49]  [290/295]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000001  loss: 2.6067 (2.4825)  weight_decay: 0.0500 (0.0500)  time: 0.2569  data: 0.0002  max mem: 3500\n",
            "Epoch: [49]  [294/295]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.5087 (2.4815)  weight_decay: 0.0500 (0.0500)  time: 0.2192  data: 0.0001  max mem: 3500\n",
            "Epoch: [49] Total time: 0:01:19 (0.2682 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.5087 (2.4815)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:22  loss: 0.6387 (0.6387)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 2.4687  data: 2.2994  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.6007 (0.6230)  acc1: 87.5000 (85.9849)  acc5: 95.8333 (96.5909)  time: 0.4055  data: 0.2514  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.6250 (0.6463)  acc1: 87.5000 (84.9206)  acc5: 97.9167 (97.5198)  time: 0.1698  data: 0.0248  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7703 (0.8540)  acc1: 77.0833 (76.7473)  acc5: 97.9167 (97.4462)  time: 0.1313  data: 0.0022  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8680 (0.8350)  acc1: 79.1667 (78.0996)  acc5: 97.9167 (97.7134)  time: 0.1229  data: 0.0017  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7612 (0.8373)  acc1: 79.1667 (78.2271)  acc5: 97.9167 (97.8350)  time: 0.1247  data: 0.0052  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8447 (0.8399)  acc1: 77.0833 (78.0738)  acc5: 97.9167 (97.6776)  time: 0.1242  data: 0.0067  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9447 (0.8690)  acc1: 72.9167 (77.0833)  acc5: 97.9167 (97.4178)  time: 0.1202  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8444 (0.8475)  acc1: 77.0833 (77.9321)  acc5: 97.9167 (97.5051)  time: 0.1178  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8444 (0.8485)  acc1: 78.3784 (77.9363)  acc5: 97.9167 (97.4522)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1662 s / it)\n",
            "* Acc@1 77.936 Acc@5 97.452 loss 0.849\n",
            "Accuracy of the model on the 3925 test images: 77.9%\n",
            "Max accuracy: 78.04%\n",
            "Test:  [ 0/82]  eta: 0:02:13  loss: 3.4001 (3.4001)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 1.6295  data: 1.4797  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 3.5099 (3.5117)  acc1: 6.2500 (10.4167)  acc5: 87.5000 (87.1212)  time: 0.3087  data: 0.1706  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 3.5667 (3.5976)  acc1: 10.4167 (13.6905)  acc5: 85.4167 (85.0198)  time: 0.1638  data: 0.0255  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.2816 (4.1380)  acc1: 10.4167 (10.2823)  acc5: 75.0000 (74.8656)  time: 0.1691  data: 0.0388  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.9496 (4.3206)  acc1: 4.1667 (9.5020)  acc5: 58.3333 (71.1890)  time: 0.1740  data: 0.0506  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.7913 (4.4009)  acc1: 8.3333 (11.1111)  acc5: 58.3333 (69.4853)  time: 0.1536  data: 0.0239  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.7129 (4.5265)  acc1: 4.1667 (9.5628)  acc5: 54.1667 (67.7596)  time: 0.1361  data: 0.0080  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5117 (4.4320)  acc1: 0.0000 (12.1185)  acc5: 79.1667 (67.7230)  time: 0.1238  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.9527 (4.0565)  acc1: 50.0000 (19.6245)  acc5: 95.8333 (71.0905)  time: 0.1207  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8333 (4.0261)  acc1: 58.3333 (20.1783)  acc5: 95.8333 (71.2611)  time: 0.1192  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1715 s / it)\n",
            "* Acc@1 20.178 Acc@5 71.261 loss 4.026\n",
            "Accuracy of the model EMA on 3925 test images: 20.2%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/result_tiny)... Done. 11.6s\n",
            "Training time 1:31:49\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▁▂▁▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema ▁▁▁▁▁▁▁▁▂▂▃▄▆▆▇▇▇███████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▁▂▂▂▄▄▅▅▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema ▁▁▁▁▁▁▁▁▂▃▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss ██▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema █████▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss █▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr ▁▂▂▂▃▃▄▄▅▅▅▆▆▇▇▇████▇▇▇▇▆▆▅▅▄▄▄▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr ▁▂▂▂▃▃▄▄▅▅▅▆▆▇▇▇████▇▇▇▇▆▆▅▅▄▄▄▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss █▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇█████▇▇▇▆▆▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇█████▇▇▇▆▆▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 77.93631\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema 20.17834\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 97.45223\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema 71.26115\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.84854\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema 4.02606\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 2.48155\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 3649\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 2.20265\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 49\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 28589128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mclean-frog-12\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/lsmcg0yh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230304_224509-lsmcg0yh/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/result_tiny\n",
        "%cd /content/ConvNeXt\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_tiny \\\n",
        "                                    --epochs 50 \\\n",
        "                                    --batch_size 32 \\\n",
        "                                    --lr 4e-3 \\\n",
        "                                    --update_freq 4 \\\n",
        "                                    --model_ema true \\\n",
        "                                    --model_ema_eval true \\\n",
        "                                    --aa original \\\n",
        "                                    --drop_path 0.1 \\\n",
        "                                    --opt adamw \\\n",
        "                                    --train_interpolation bicubic \\\n",
        "                                    --input_size 160 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --output_dir /content/result_tiny \\\n",
        "                                    --log_dir /content/result_tiny \\\n",
        "                                    --enable_wandb true --wandb_ckpt true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python main.py --model convnext_tiny --eval true \\\n",
        "                --resume /content/result_tiny/checkpoint-best.pth \\\n",
        "                --input_size 160 --drop_path 0.1 \\\n",
        "                --data_path /content/imagenette2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZIKd8PwVTvh",
        "outputId": "fecd653f-bb09-4f59-99d9-7ad8912c1d7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny/checkpoint-best.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7f780a23bb80>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f780a1c9eb0>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f780a246100>\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 147\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 2940\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny/checkpoint-best.pth\n",
            "With optim & sched!\n",
            "Eval only mode\n",
            "Test:  [ 0/41]  eta: 0:05:22  loss: 0.5394 (0.5394)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 7.8567  data: 4.3514  max mem: 2077\n",
            "Test:  [10/41]  eta: 0:00:28  loss: 0.6531 (0.6498)  acc1: 84.3750 (84.7538)  acc5: 96.8750 (97.5379)  time: 0.9095  data: 0.3979  max mem: 2077\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.7081 (0.8320)  acc1: 83.3333 (78.2738)  acc5: 97.9167 (97.7183)  time: 0.2171  data: 0.0027  max mem: 2077\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.8288 (0.8501)  acc1: 77.0833 (77.7890)  acc5: 97.9167 (97.5134)  time: 0.2162  data: 0.0015  max mem: 2077\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8635 (0.8492)  acc1: 77.0833 (78.0382)  acc5: 97.9167 (97.4268)  time: 0.2141  data: 0.0001  max mem: 2077\n",
            "Test: Total time: 0:00:16 (0.4109 s / it)\n",
            "* Acc@1 78.038 Acc@5 97.427 loss 0.849\n",
            "Accuracy of the network on 3925 test images: 78.03822%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acc@1 after 50 epochs: 78.083"
      ],
      "metadata": {
        "id": "zxqXDWb1XWgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/result_tiny\n",
        "%cd /content/ConvNeXt\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_tiny \\\n",
        "                                    --resume /content/result_tiny/checkpoint-49.pth \\\n",
        "                                    --epochs 80 \\\n",
        "                                    --start_epoch 50 \\\n",
        "                                    --batch_size 32 \\\n",
        "                                    --lr 4e-3 \\\n",
        "                                    --update_freq 4 \\\n",
        "                                    --model_ema true \\\n",
        "                                    --model_ema_eval true \\\n",
        "                                    --aa original \\\n",
        "                                    --drop_path 0.1 \\\n",
        "                                    --opt adamw \\\n",
        "                                    --train_interpolation bicubic \\\n",
        "                                    --input_size 160 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --output_dir /content/result_tiny \\\n",
        "                                    --log_dir /content/result_tiny \\\n",
        "                                    --enable_wandb true --wandb_ckpt true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5ss_t4sMV22",
        "outputId": "58a8ad42-369d-4cc1-8017-77d3246e143a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt\n",
            "| distributed init (rank 0): env://, gpu 0\n",
            "Namespace(aa='original', auto_resume=True, batch_size=32, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_backend='nccl', dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=True, drop_path=0.1, enable_wandb=True, epochs=80, eval=False, eval_data_path=None, finetune='', gpu=0, head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=0, log_dir='/content/result_tiny', lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=True, model_ema_decay=0.9999, model_ema_eval=True, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/content/result_tiny', pin_mem=True, project='convnext', rank=0, recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny/checkpoint-49.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=50, train_interpolation='bicubic', update_freq=4, use_amp=False, wandb_ckpt=True, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.AutoAugment object at 0x7f6b2d98e7f0>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f6b2d97cdc0>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f6b2d911130>\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlolikgiovi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ConvNeXt/wandb/run-20230305_005228-m3kel4es\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-shape-17\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/m3kel4es\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Using EMA with decay = 0.99990000\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 128\n",
            "Update frequent = 4\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 73\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 1460\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny/checkpoint-49.pth\n",
            "With optim & sched!\n",
            "Start training for 80 epochs\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [50]  [  0/295]  eta: 0:20:13  lr: 0.002001  min_lr: 0.002001  loss: 2.6954 (2.6954)  weight_decay: 0.0500 (0.0500)  time: 4.1136  data: 2.0732  max mem: 3719\n",
            "Epoch: [50]  [ 10/295]  eta: 0:02:49  lr: 0.001998  min_lr: 0.001998  loss: 2.7294 (2.6244)  weight_decay: 0.0500 (0.0500)  time: 0.5945  data: 0.1890  max mem: 3719\n",
            "Epoch: [50]  [ 20/295]  eta: 0:01:57  lr: 0.001993  min_lr: 0.001993  loss: 2.6275 (2.5658)  weight_decay: 0.0500 (0.0500)  time: 0.2437  data: 0.0007  max mem: 3719\n",
            "Epoch: [50]  [ 30/295]  eta: 0:01:38  lr: 0.001990  min_lr: 0.001990  loss: 2.4912 (2.5414)  weight_decay: 0.0500 (0.0500)  time: 0.2463  data: 0.0009  max mem: 3719\n",
            "Epoch: [50]  [ 40/295]  eta: 0:01:27  lr: 0.001986  min_lr: 0.001986  loss: 2.5515 (2.5493)  weight_decay: 0.0500 (0.0500)  time: 0.2535  data: 0.0015  max mem: 3719\n",
            "Epoch: [50]  [ 50/295]  eta: 0:01:19  lr: 0.001983  min_lr: 0.001983  loss: 2.5683 (2.5435)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0020  max mem: 3719\n",
            "Epoch: [50]  [ 60/295]  eta: 0:01:14  lr: 0.001979  min_lr: 0.001979  loss: 2.5443 (2.5607)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0013  max mem: 3719\n",
            "Epoch: [50]  [ 70/295]  eta: 0:01:08  lr: 0.001976  min_lr: 0.001976  loss: 2.5443 (2.5626)  weight_decay: 0.0500 (0.0500)  time: 0.2546  data: 0.0010  max mem: 3719\n",
            "Epoch: [50]  [ 80/295]  eta: 0:01:04  lr: 0.001972  min_lr: 0.001972  loss: 2.4234 (2.5495)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0038  max mem: 3719\n",
            "Epoch: [50]  [ 90/295]  eta: 0:01:00  lr: 0.001969  min_lr: 0.001969  loss: 2.4234 (2.5463)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0036  max mem: 3719\n",
            "Epoch: [50]  [100/295]  eta: 0:00:57  lr: 0.001965  min_lr: 0.001965  loss: 2.5936 (2.5614)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0012  max mem: 3719\n",
            "Epoch: [50]  [110/295]  eta: 0:00:53  lr: 0.001962  min_lr: 0.001962  loss: 2.6324 (2.5651)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0022  max mem: 3719\n",
            "Epoch: [50]  [120/295]  eta: 0:00:50  lr: 0.001957  min_lr: 0.001957  loss: 2.6409 (2.5748)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0024  max mem: 3719\n",
            "Epoch: [50]  [130/295]  eta: 0:00:47  lr: 0.001955  min_lr: 0.001955  loss: 2.6409 (2.5772)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0018  max mem: 3719\n",
            "Epoch: [50]  [140/295]  eta: 0:00:44  lr: 0.001950  min_lr: 0.001950  loss: 2.5501 (2.5711)  weight_decay: 0.0500 (0.0500)  time: 0.2565  data: 0.0019  max mem: 3719\n",
            "Epoch: [50]  [150/295]  eta: 0:00:40  lr: 0.001947  min_lr: 0.001947  loss: 2.6014 (2.5759)  weight_decay: 0.0500 (0.0500)  time: 0.2536  data: 0.0017  max mem: 3719\n",
            "Epoch: [50]  [160/295]  eta: 0:00:37  lr: 0.001943  min_lr: 0.001943  loss: 2.6781 (2.5774)  weight_decay: 0.0500 (0.0500)  time: 0.2554  data: 0.0017  max mem: 3719\n",
            "Epoch: [50]  [170/295]  eta: 0:00:34  lr: 0.001940  min_lr: 0.001940  loss: 2.5511 (2.5699)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0023  max mem: 3719\n",
            "Epoch: [50]  [180/295]  eta: 0:00:32  lr: 0.001936  min_lr: 0.001936  loss: 2.4108 (2.5686)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0026  max mem: 3719\n",
            "Epoch: [50]  [190/295]  eta: 0:00:29  lr: 0.001933  min_lr: 0.001933  loss: 2.4863 (2.5626)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0027  max mem: 3719\n",
            "Epoch: [50]  [200/295]  eta: 0:00:26  lr: 0.001929  min_lr: 0.001929  loss: 2.3732 (2.5530)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0018  max mem: 3719\n",
            "Epoch: [50]  [210/295]  eta: 0:00:23  lr: 0.001926  min_lr: 0.001926  loss: 2.4253 (2.5513)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0009  max mem: 3719\n",
            "Epoch: [50]  [220/295]  eta: 0:00:20  lr: 0.001922  min_lr: 0.001922  loss: 2.5006 (2.5456)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0014  max mem: 3719\n",
            "Epoch: [50]  [230/295]  eta: 0:00:17  lr: 0.001919  min_lr: 0.001919  loss: 2.5088 (2.5470)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0015  max mem: 3719\n",
            "Epoch: [50]  [240/295]  eta: 0:00:15  lr: 0.001914  min_lr: 0.001914  loss: 2.5286 (2.5446)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0022  max mem: 3719\n",
            "Epoch: [50]  [250/295]  eta: 0:00:12  lr: 0.001912  min_lr: 0.001912  loss: 2.4465 (2.5438)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0038  max mem: 3719\n",
            "Epoch: [50]  [260/295]  eta: 0:00:09  lr: 0.001907  min_lr: 0.001907  loss: 2.4465 (2.5427)  weight_decay: 0.0500 (0.0500)  time: 0.2746  data: 0.0051  max mem: 3719\n",
            "Epoch: [50]  [270/295]  eta: 0:00:06  lr: 0.001904  min_lr: 0.001904  loss: 2.5424 (2.5437)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0036  max mem: 3719\n",
            "Epoch: [50]  [280/295]  eta: 0:00:04  lr: 0.001900  min_lr: 0.001900  loss: 2.5661 (2.5462)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0018  max mem: 3719\n",
            "Epoch: [50]  [290/295]  eta: 0:00:01  lr: 0.001897  min_lr: 0.001897  loss: 2.5851 (2.5480)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0009  max mem: 3719\n",
            "Epoch: [50]  [294/295]  eta: 0:00:00  lr: 0.001897  min_lr: 0.001897  loss: 2.6289 (2.5486)  weight_decay: 0.0500 (0.0500)  time: 0.2241  data: 0.0002  max mem: 3719\n",
            "Epoch: [50] Total time: 0:01:20 (0.2729 s / it)\n",
            "Averaged stats: lr: 0.001897  min_lr: 0.001897  loss: 2.6289 (2.5486)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:10  loss: 0.6772 (0.6772)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 3.0492  data: 2.6944  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:34  loss: 0.6772 (0.6974)  acc1: 85.4167 (86.1742)  acc5: 97.9167 (96.7803)  time: 0.4822  data: 0.3027  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:20  loss: 0.6720 (0.6929)  acc1: 87.5000 (86.1111)  acc5: 97.9167 (97.5198)  time: 0.1977  data: 0.0352  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 0.7861 (0.9585)  acc1: 79.1667 (73.7903)  acc5: 97.9167 (97.1102)  time: 0.1628  data: 0.0064  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 0.7726 (0.9042)  acc1: 79.1667 (76.3720)  acc5: 97.9167 (97.4085)  time: 0.1583  data: 0.0071  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.7697 (0.9208)  acc1: 83.3333 (76.0212)  acc5: 97.9167 (97.4265)  time: 0.1443  data: 0.0051  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9653 (0.9288)  acc1: 75.0000 (75.7514)  acc5: 97.9167 (97.1312)  time: 0.1259  data: 0.0024  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.1873 (0.9757)  acc1: 66.6667 (73.9437)  acc5: 95.8333 (96.7430)  time: 0.1221  data: 0.0016  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1712 (0.9546)  acc1: 68.7500 (74.7171)  acc5: 97.9167 (96.9650)  time: 0.1193  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0466 (0.9541)  acc1: 68.7500 (74.7261)  acc5: 97.9167 (96.9172)  time: 0.1206  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1908 s / it)\n",
            "* Acc@1 74.726 Acc@5 96.917 loss 0.954\n",
            "Accuracy of the model on the 3925 test images: 74.7%\n",
            "Max accuracy: 74.73%\n",
            "Test:  [ 0/82]  eta: 0:02:20  loss: 3.3441 (3.3441)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 1.7082  data: 1.5389  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.4627 (3.4642)  acc1: 8.3333 (10.7955)  acc5: 89.5833 (87.5000)  time: 0.2991  data: 0.1486  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 3.5145 (3.5532)  acc1: 10.4167 (13.8889)  acc5: 85.4167 (85.5159)  time: 0.1677  data: 0.0298  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.2333 (4.0956)  acc1: 10.4167 (10.4167)  acc5: 75.0000 (75.4032)  time: 0.1697  data: 0.0369  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.8937 (4.2773)  acc1: 4.1667 (9.6037)  acc5: 58.3333 (71.7988)  time: 0.1916  data: 0.0427  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.7617 (4.3668)  acc1: 8.3333 (11.0703)  acc5: 58.3333 (69.9755)  time: 0.2191  data: 0.0628  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.7238 (4.4920)  acc1: 4.1667 (9.5287)  acc5: 54.1667 (68.2036)  time: 0.1777  data: 0.0337  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.4774 (4.3953)  acc1: 0.0000 (12.1479)  acc5: 79.1667 (68.1338)  time: 0.1294  data: 0.0018  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.9032 (4.0206)  acc1: 52.0833 (19.6502)  acc5: 95.8333 (71.4506)  time: 0.1190  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.7799 (3.9903)  acc1: 58.3333 (20.2038)  acc5: 95.8333 (71.6178)  time: 0.1181  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1870 s / it)\n",
            "* Acc@1 20.204 Acc@5 71.618 loss 3.990\n",
            "Accuracy of the model EMA on 3925 test images: 20.2%\n",
            "Max EMA accuracy: 20.20%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [51]  [  0/295]  eta: 0:08:53  lr: 0.001896  min_lr: 0.001896  loss: 2.3794 (2.3794)  weight_decay: 0.0500 (0.0500)  time: 1.8084  data: 1.3368  max mem: 3719\n",
            "Epoch: [51]  [ 10/295]  eta: 0:02:00  lr: 0.001893  min_lr: 0.001893  loss: 2.6380 (2.6211)  weight_decay: 0.0500 (0.0500)  time: 0.4218  data: 0.1225  max mem: 3719\n",
            "Epoch: [51]  [ 20/295]  eta: 0:01:35  lr: 0.001889  min_lr: 0.001889  loss: 2.6441 (2.5992)  weight_decay: 0.0500 (0.0500)  time: 0.2756  data: 0.0008  max mem: 3719\n",
            "Epoch: [51]  [ 30/295]  eta: 0:01:25  lr: 0.001886  min_lr: 0.001886  loss: 2.6054 (2.6103)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0004  max mem: 3719\n",
            "Epoch: [51]  [ 40/295]  eta: 0:01:19  lr: 0.001882  min_lr: 0.001882  loss: 2.5854 (2.6185)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0008  max mem: 3719\n",
            "Epoch: [51]  [ 50/295]  eta: 0:01:13  lr: 0.001879  min_lr: 0.001879  loss: 2.4892 (2.5945)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0009  max mem: 3719\n",
            "Epoch: [51]  [ 60/295]  eta: 0:01:09  lr: 0.001874  min_lr: 0.001874  loss: 2.5709 (2.5947)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0016  max mem: 3719\n",
            "Epoch: [51]  [ 70/295]  eta: 0:01:05  lr: 0.001872  min_lr: 0.001872  loss: 2.5709 (2.5975)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0018  max mem: 3719\n",
            "Epoch: [51]  [ 80/295]  eta: 0:01:01  lr: 0.001867  min_lr: 0.001867  loss: 2.5503 (2.5884)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0018  max mem: 3719\n",
            "Epoch: [51]  [ 90/295]  eta: 0:00:58  lr: 0.001864  min_lr: 0.001864  loss: 2.5612 (2.5790)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0023  max mem: 3719\n",
            "Epoch: [51]  [100/295]  eta: 0:00:55  lr: 0.001860  min_lr: 0.001860  loss: 2.5434 (2.5657)  weight_decay: 0.0500 (0.0500)  time: 0.2756  data: 0.0025  max mem: 3719\n",
            "Epoch: [51]  [110/295]  eta: 0:00:52  lr: 0.001857  min_lr: 0.001857  loss: 2.5336 (2.5637)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0030  max mem: 3719\n",
            "Epoch: [51]  [120/295]  eta: 0:00:49  lr: 0.001853  min_lr: 0.001853  loss: 2.5577 (2.5666)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0026  max mem: 3719\n",
            "Epoch: [51]  [130/295]  eta: 0:00:46  lr: 0.001850  min_lr: 0.001850  loss: 2.6750 (2.5698)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0016  max mem: 3719\n",
            "Epoch: [51]  [140/295]  eta: 0:00:43  lr: 0.001846  min_lr: 0.001846  loss: 2.6361 (2.5731)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0016  max mem: 3719\n",
            "Epoch: [51]  [150/295]  eta: 0:00:40  lr: 0.001843  min_lr: 0.001843  loss: 2.6299 (2.5706)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0022  max mem: 3719\n",
            "Epoch: [51]  [160/295]  eta: 0:00:37  lr: 0.001839  min_lr: 0.001839  loss: 2.5703 (2.5705)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0022  max mem: 3719\n",
            "Epoch: [51]  [170/295]  eta: 0:00:34  lr: 0.001836  min_lr: 0.001836  loss: 2.5662 (2.5693)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0030  max mem: 3719\n",
            "Epoch: [51]  [180/295]  eta: 0:00:31  lr: 0.001831  min_lr: 0.001831  loss: 2.4026 (2.5581)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0028  max mem: 3719\n",
            "Epoch: [51]  [190/295]  eta: 0:00:29  lr: 0.001829  min_lr: 0.001829  loss: 2.4026 (2.5528)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0020  max mem: 3719\n",
            "Epoch: [51]  [200/295]  eta: 0:00:26  lr: 0.001824  min_lr: 0.001824  loss: 2.4766 (2.5492)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0019  max mem: 3719\n",
            "Epoch: [51]  [210/295]  eta: 0:00:23  lr: 0.001821  min_lr: 0.001821  loss: 2.6708 (2.5601)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0018  max mem: 3719\n",
            "Epoch: [51]  [220/295]  eta: 0:00:20  lr: 0.001817  min_lr: 0.001817  loss: 2.7093 (2.5578)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0023  max mem: 3719\n",
            "Epoch: [51]  [230/295]  eta: 0:00:17  lr: 0.001814  min_lr: 0.001814  loss: 2.5487 (2.5589)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0030  max mem: 3719\n",
            "Epoch: [51]  [240/295]  eta: 0:00:15  lr: 0.001810  min_lr: 0.001810  loss: 2.6242 (2.5630)  weight_decay: 0.0500 (0.0500)  time: 0.2772  data: 0.0025  max mem: 3719\n",
            "Epoch: [51]  [250/295]  eta: 0:00:12  lr: 0.001807  min_lr: 0.001807  loss: 2.6242 (2.5672)  weight_decay: 0.0500 (0.0500)  time: 0.2797  data: 0.0029  max mem: 3719\n",
            "Epoch: [51]  [260/295]  eta: 0:00:09  lr: 0.001803  min_lr: 0.001803  loss: 2.6009 (2.5700)  weight_decay: 0.0500 (0.0500)  time: 0.2776  data: 0.0029  max mem: 3719\n",
            "Epoch: [51]  [270/295]  eta: 0:00:06  lr: 0.001800  min_lr: 0.001800  loss: 2.5962 (2.5706)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0016  max mem: 3719\n",
            "Epoch: [51]  [280/295]  eta: 0:00:04  lr: 0.001796  min_lr: 0.001796  loss: 2.5310 (2.5725)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0009  max mem: 3719\n",
            "Epoch: [51]  [290/295]  eta: 0:00:01  lr: 0.001793  min_lr: 0.001793  loss: 2.5849 (2.5728)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0003  max mem: 3719\n",
            "Epoch: [51]  [294/295]  eta: 0:00:00  lr: 0.001793  min_lr: 0.001793  loss: 2.5523 (2.5713)  weight_decay: 0.0500 (0.0500)  time: 0.2198  data: 0.0003  max mem: 3719\n",
            "Epoch: [51] Total time: 0:01:20 (0.2723 s / it)\n",
            "Averaged stats: lr: 0.001793  min_lr: 0.001793  loss: 2.5523 (2.5713)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:52  loss: 0.9423 (0.9423)  acc1: 81.2500 (81.2500)  acc5: 91.6667 (91.6667)  time: 2.8368  data: 2.6535  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.9414 (0.9476)  acc1: 79.1667 (74.8106)  acc5: 95.8333 (95.6439)  time: 0.4139  data: 0.2461  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.8551 (0.9101)  acc1: 79.1667 (75.9921)  acc5: 97.9167 (96.5278)  time: 0.1877  data: 0.0129  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 1.0208 (1.1511)  acc1: 66.6667 (64.6505)  acc5: 95.8333 (95.8333)  time: 0.1787  data: 0.0157  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.0036 (1.0834)  acc1: 68.7500 (68.6992)  acc5: 97.9167 (96.4431)  time: 0.1388  data: 0.0060  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8700 (1.0698)  acc1: 79.1667 (69.9755)  acc5: 97.9167 (96.8546)  time: 0.1290  data: 0.0031  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9438 (1.0342)  acc1: 77.0833 (71.4822)  acc5: 97.9167 (96.7896)  time: 0.1303  data: 0.0051  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9003 (1.0347)  acc1: 75.0000 (71.5082)  acc5: 97.9167 (96.6549)  time: 0.1225  data: 0.0025  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8418 (0.9994)  acc1: 79.1667 (72.9681)  acc5: 97.9167 (96.7335)  time: 0.1184  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8418 (0.9996)  acc1: 79.1667 (72.9427)  acc5: 97.9167 (96.6369)  time: 0.1172  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1816 s / it)\n",
            "* Acc@1 72.943 Acc@5 96.637 loss 1.000\n",
            "Accuracy of the model on the 3925 test images: 72.9%\n",
            "Max accuracy: 74.73%\n",
            "Test:  [ 0/82]  eta: 0:02:46  loss: 3.2910 (3.2910)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 2.0358  data: 1.8731  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 3.4240 (3.4219)  acc1: 8.3333 (10.4167)  acc5: 89.5833 (88.2576)  time: 0.3430  data: 0.1919  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.4650 (3.5145)  acc1: 10.4167 (13.4921)  acc5: 85.4167 (86.1111)  time: 0.1698  data: 0.0222  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.1969 (4.0578)  acc1: 10.4167 (10.0806)  acc5: 77.0833 (75.6720)  time: 0.1662  data: 0.0229  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.8326 (4.2366)  acc1: 4.1667 (9.2480)  acc5: 58.3333 (72.1545)  time: 0.1962  data: 0.0379  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.7197 (4.3352)  acc1: 8.3333 (10.6209)  acc5: 60.4167 (70.1389)  time: 0.2028  data: 0.0306  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.7380 (4.4595)  acc1: 4.1667 (9.1530)  acc5: 52.0833 (68.3743)  time: 0.1632  data: 0.0064  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.4417 (4.3604)  acc1: 2.0833 (11.8838)  acc5: 79.1667 (68.3099)  time: 0.1349  data: 0.0013  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.8539 (3.9865)  acc1: 52.0833 (19.4444)  acc5: 95.8333 (71.6821)  time: 0.1219  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.7284 (3.9563)  acc1: 60.4167 (20.0000)  acc5: 95.8333 (71.8471)  time: 0.1195  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1895 s / it)\n",
            "* Acc@1 20.000 Acc@5 71.847 loss 3.956\n",
            "Accuracy of the model EMA on 3925 test images: 20.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [52]  [  0/295]  eta: 0:07:38  lr: 0.001791  min_lr: 0.001791  loss: 2.3150 (2.3150)  weight_decay: 0.0500 (0.0500)  time: 1.5554  data: 1.2325  max mem: 3719\n",
            "Epoch: [52]  [ 10/295]  eta: 0:02:02  lr: 0.001789  min_lr: 0.001789  loss: 2.6529 (2.5956)  weight_decay: 0.0500 (0.0500)  time: 0.4283  data: 0.1446  max mem: 3719\n",
            "Epoch: [52]  [ 20/295]  eta: 0:01:37  lr: 0.001784  min_lr: 0.001784  loss: 2.6529 (2.6156)  weight_decay: 0.0500 (0.0500)  time: 0.2930  data: 0.0186  max mem: 3719\n",
            "Epoch: [52]  [ 30/295]  eta: 0:01:26  lr: 0.001782  min_lr: 0.001782  loss: 2.5163 (2.5597)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0021  max mem: 3719\n",
            "Epoch: [52]  [ 40/295]  eta: 0:01:20  lr: 0.001777  min_lr: 0.001777  loss: 2.4657 (2.5673)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0023  max mem: 3719\n",
            "Epoch: [52]  [ 50/295]  eta: 0:01:14  lr: 0.001774  min_lr: 0.001774  loss: 2.5190 (2.5684)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0015  max mem: 3719\n",
            "Epoch: [52]  [ 60/295]  eta: 0:01:10  lr: 0.001770  min_lr: 0.001770  loss: 2.5246 (2.5688)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0014  max mem: 3719\n",
            "Epoch: [52]  [ 70/295]  eta: 0:01:05  lr: 0.001767  min_lr: 0.001767  loss: 2.5246 (2.5688)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0012  max mem: 3719\n",
            "Epoch: [52]  [ 80/295]  eta: 0:01:02  lr: 0.001763  min_lr: 0.001763  loss: 2.4574 (2.5602)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0010  max mem: 3719\n",
            "Epoch: [52]  [ 90/295]  eta: 0:00:58  lr: 0.001760  min_lr: 0.001760  loss: 2.4773 (2.5559)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0016  max mem: 3719\n",
            "Epoch: [52]  [100/295]  eta: 0:00:55  lr: 0.001756  min_lr: 0.001756  loss: 2.4422 (2.5477)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0025  max mem: 3719\n",
            "Epoch: [52]  [110/295]  eta: 0:00:52  lr: 0.001753  min_lr: 0.001753  loss: 2.5332 (2.5488)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0027  max mem: 3719\n",
            "Epoch: [52]  [120/295]  eta: 0:00:49  lr: 0.001749  min_lr: 0.001749  loss: 2.5460 (2.5436)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0019  max mem: 3719\n",
            "Epoch: [52]  [130/295]  eta: 0:00:46  lr: 0.001746  min_lr: 0.001746  loss: 2.4587 (2.5403)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0009  max mem: 3719\n",
            "Epoch: [52]  [140/295]  eta: 0:00:43  lr: 0.001742  min_lr: 0.001742  loss: 2.5259 (2.5438)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0004  max mem: 3719\n",
            "Epoch: [52]  [150/295]  eta: 0:00:40  lr: 0.001739  min_lr: 0.001739  loss: 2.5937 (2.5471)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0009  max mem: 3719\n",
            "Epoch: [52]  [160/295]  eta: 0:00:37  lr: 0.001735  min_lr: 0.001735  loss: 2.5896 (2.5465)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0033  max mem: 3719\n",
            "Epoch: [52]  [170/295]  eta: 0:00:34  lr: 0.001732  min_lr: 0.001732  loss: 2.5881 (2.5473)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0046  max mem: 3719\n",
            "Epoch: [52]  [180/295]  eta: 0:00:31  lr: 0.001727  min_lr: 0.001727  loss: 2.4669 (2.5474)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0034  max mem: 3719\n",
            "Epoch: [52]  [190/295]  eta: 0:00:28  lr: 0.001725  min_lr: 0.001725  loss: 2.4920 (2.5473)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0017  max mem: 3719\n",
            "Epoch: [52]  [200/295]  eta: 0:00:26  lr: 0.001720  min_lr: 0.001720  loss: 2.6389 (2.5489)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0009  max mem: 3719\n",
            "Epoch: [52]  [210/295]  eta: 0:00:23  lr: 0.001717  min_lr: 0.001717  loss: 2.6290 (2.5498)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0013  max mem: 3719\n",
            "Epoch: [52]  [220/295]  eta: 0:00:20  lr: 0.001713  min_lr: 0.001713  loss: 2.5916 (2.5472)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0018  max mem: 3719\n",
            "Epoch: [52]  [230/295]  eta: 0:00:17  lr: 0.001710  min_lr: 0.001710  loss: 2.4847 (2.5481)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0020  max mem: 3719\n",
            "Epoch: [52]  [240/295]  eta: 0:00:15  lr: 0.001706  min_lr: 0.001706  loss: 2.6036 (2.5478)  weight_decay: 0.0500 (0.0500)  time: 0.2774  data: 0.0029  max mem: 3719\n",
            "Epoch: [52]  [250/295]  eta: 0:00:12  lr: 0.001703  min_lr: 0.001703  loss: 2.5110 (2.5452)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0034  max mem: 3719\n",
            "Epoch: [52]  [260/295]  eta: 0:00:09  lr: 0.001699  min_lr: 0.001699  loss: 2.4777 (2.5466)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0020  max mem: 3719\n",
            "Epoch: [52]  [270/295]  eta: 0:00:06  lr: 0.001696  min_lr: 0.001696  loss: 2.5095 (2.5427)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0014  max mem: 3719\n",
            "Epoch: [52]  [280/295]  eta: 0:00:04  lr: 0.001692  min_lr: 0.001692  loss: 2.4821 (2.5416)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0013  max mem: 3719\n",
            "Epoch: [52]  [290/295]  eta: 0:00:01  lr: 0.001689  min_lr: 0.001689  loss: 2.4198 (2.5375)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0005  max mem: 3719\n",
            "Epoch: [52]  [294/295]  eta: 0:00:00  lr: 0.001689  min_lr: 0.001689  loss: 2.4198 (2.5372)  weight_decay: 0.0500 (0.0500)  time: 0.2215  data: 0.0002  max mem: 3719\n",
            "Epoch: [52] Total time: 0:01:19 (0.2711 s / it)\n",
            "Averaged stats: lr: 0.001689  min_lr: 0.001689  loss: 2.4198 (2.5372)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:08  loss: 0.6579 (0.6579)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 3.0255  data: 2.8213  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.7072 (0.7263)  acc1: 83.3333 (84.0909)  acc5: 97.9167 (97.5379)  time: 0.4121  data: 0.2614  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.7072 (0.7284)  acc1: 83.3333 (83.6310)  acc5: 97.9167 (97.9167)  time: 0.1458  data: 0.0037  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.7946 (0.9348)  acc1: 79.1667 (75.0000)  acc5: 97.9167 (97.1102)  time: 0.1351  data: 0.0019  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8365 (0.9006)  acc1: 77.0833 (76.5244)  acc5: 97.9167 (97.3577)  time: 0.1271  data: 0.0034  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7803 (0.8882)  acc1: 81.2500 (77.4101)  acc5: 97.9167 (97.5490)  time: 0.1249  data: 0.0045  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8875 (0.9033)  acc1: 79.1667 (76.4686)  acc5: 97.9167 (97.4044)  time: 0.1239  data: 0.0035  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0969 (0.9426)  acc1: 66.6667 (74.6479)  acc5: 95.8333 (97.0951)  time: 0.1204  data: 0.0017  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0508 (0.9170)  acc1: 70.8333 (75.7202)  acc5: 97.9167 (97.2222)  time: 0.1182  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9568 (0.9164)  acc1: 72.9167 (75.7197)  acc5: 97.9167 (97.1720)  time: 0.1170  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1701 s / it)\n",
            "* Acc@1 75.720 Acc@5 97.172 loss 0.916\n",
            "Accuracy of the model on the 3925 test images: 75.7%\n",
            "Max accuracy: 75.72%\n",
            "Test:  [ 0/82]  eta: 0:04:16  loss: 3.2341 (3.2341)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 3.1273  data: 2.9613  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:33  loss: 3.3802 (3.3750)  acc1: 8.3333 (10.9848)  acc5: 89.5833 (89.3939)  time: 0.4707  data: 0.2999  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:21  loss: 3.4108 (3.4739)  acc1: 10.4167 (13.7897)  acc5: 89.5833 (86.8056)  time: 0.2054  data: 0.0333  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 4.1527 (4.0204)  acc1: 10.4167 (10.3495)  acc5: 77.0833 (75.9409)  time: 0.1859  data: 0.0307  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:11  loss: 4.7708 (4.1956)  acc1: 4.1667 (9.5528)  acc5: 58.3333 (72.6626)  time: 0.1770  data: 0.0392  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:08  loss: 4.6616 (4.3023)  acc1: 8.3333 (10.8660)  acc5: 60.4167 (70.5474)  time: 0.2015  data: 0.0441  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:05  loss: 4.7462 (4.4258)  acc1: 4.1667 (9.3579)  acc5: 52.0833 (68.7500)  time: 0.1736  data: 0.0197  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.4064 (4.3252)  acc1: 2.0833 (12.1479)  acc5: 79.1667 (68.6033)  time: 0.1265  data: 0.0006  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.8093 (3.9522)  acc1: 52.0833 (19.6502)  acc5: 95.8333 (71.9907)  time: 0.1198  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.6834 (3.9222)  acc1: 60.4167 (20.2038)  acc5: 95.8333 (72.1529)  time: 0.1177  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:17 (0.2094 s / it)\n",
            "* Acc@1 20.204 Acc@5 72.153 loss 3.922\n",
            "Accuracy of the model EMA on 3925 test images: 20.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [53]  [  0/295]  eta: 0:11:20  lr: 0.001688  min_lr: 0.001688  loss: 2.2018 (2.2018)  weight_decay: 0.0500 (0.0500)  time: 2.3055  data: 1.8439  max mem: 3719\n",
            "Epoch: [53]  [ 10/295]  eta: 0:02:22  lr: 0.001685  min_lr: 0.001685  loss: 2.5895 (2.5866)  weight_decay: 0.0500 (0.0500)  time: 0.4992  data: 0.1701  max mem: 3719\n",
            "Epoch: [53]  [ 20/295]  eta: 0:01:49  lr: 0.001681  min_lr: 0.001681  loss: 2.5798 (2.5446)  weight_decay: 0.0500 (0.0500)  time: 0.3042  data: 0.0020  max mem: 3719\n",
            "Epoch: [53]  [ 30/295]  eta: 0:01:34  lr: 0.001678  min_lr: 0.001678  loss: 2.4562 (2.5143)  weight_decay: 0.0500 (0.0500)  time: 0.2780  data: 0.0018  max mem: 3719\n",
            "Epoch: [53]  [ 40/295]  eta: 0:01:25  lr: 0.001674  min_lr: 0.001674  loss: 2.4327 (2.5151)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0012  max mem: 3719\n",
            "Epoch: [53]  [ 50/295]  eta: 0:01:18  lr: 0.001671  min_lr: 0.001671  loss: 2.5383 (2.5104)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0011  max mem: 3719\n",
            "Epoch: [53]  [ 60/295]  eta: 0:01:13  lr: 0.001666  min_lr: 0.001666  loss: 2.5639 (2.5215)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0014  max mem: 3719\n",
            "Epoch: [53]  [ 70/295]  eta: 0:01:08  lr: 0.001664  min_lr: 0.001664  loss: 2.6087 (2.5278)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0020  max mem: 3719\n",
            "Epoch: [53]  [ 80/295]  eta: 0:01:04  lr: 0.001659  min_lr: 0.001659  loss: 2.6142 (2.5342)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0030  max mem: 3719\n",
            "Epoch: [53]  [ 90/295]  eta: 0:01:01  lr: 0.001657  min_lr: 0.001657  loss: 2.6142 (2.5439)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0026  max mem: 3719\n",
            "Epoch: [53]  [100/295]  eta: 0:00:57  lr: 0.001652  min_lr: 0.001652  loss: 2.5718 (2.5448)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0018  max mem: 3719\n",
            "Epoch: [53]  [110/295]  eta: 0:00:54  lr: 0.001650  min_lr: 0.001650  loss: 2.5106 (2.5412)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0007  max mem: 3719\n",
            "Epoch: [53]  [120/295]  eta: 0:00:50  lr: 0.001645  min_lr: 0.001645  loss: 2.5324 (2.5392)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0008  max mem: 3719\n",
            "Epoch: [53]  [130/295]  eta: 0:00:47  lr: 0.001642  min_lr: 0.001642  loss: 2.5770 (2.5414)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0017  max mem: 3719\n",
            "Epoch: [53]  [140/295]  eta: 0:00:44  lr: 0.001638  min_lr: 0.001638  loss: 2.5827 (2.5457)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0017  max mem: 3719\n",
            "Epoch: [53]  [150/295]  eta: 0:00:41  lr: 0.001635  min_lr: 0.001635  loss: 2.6145 (2.5509)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0010  max mem: 3719\n",
            "Epoch: [53]  [160/295]  eta: 0:00:38  lr: 0.001631  min_lr: 0.001631  loss: 2.6062 (2.5499)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0011  max mem: 3719\n",
            "Epoch: [53]  [170/295]  eta: 0:00:35  lr: 0.001628  min_lr: 0.001628  loss: 2.4116 (2.5508)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0015  max mem: 3719\n",
            "Epoch: [53]  [180/295]  eta: 0:00:32  lr: 0.001624  min_lr: 0.001624  loss: 2.6437 (2.5547)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0017  max mem: 3719\n",
            "Epoch: [53]  [190/295]  eta: 0:00:29  lr: 0.001621  min_lr: 0.001621  loss: 2.6089 (2.5536)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0015  max mem: 3719\n",
            "Epoch: [53]  [200/295]  eta: 0:00:26  lr: 0.001617  min_lr: 0.001617  loss: 2.5877 (2.5516)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0017  max mem: 3719\n",
            "Epoch: [53]  [210/295]  eta: 0:00:23  lr: 0.001614  min_lr: 0.001614  loss: 2.6050 (2.5555)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0020  max mem: 3719\n",
            "Epoch: [53]  [220/295]  eta: 0:00:20  lr: 0.001610  min_lr: 0.001610  loss: 2.6256 (2.5565)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0026  max mem: 3719\n",
            "Epoch: [53]  [230/295]  eta: 0:00:18  lr: 0.001607  min_lr: 0.001607  loss: 2.6043 (2.5575)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0020  max mem: 3719\n",
            "Epoch: [53]  [240/295]  eta: 0:00:15  lr: 0.001603  min_lr: 0.001603  loss: 2.5965 (2.5551)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0017  max mem: 3719\n",
            "Epoch: [53]  [250/295]  eta: 0:00:12  lr: 0.001600  min_lr: 0.001600  loss: 2.5901 (2.5555)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0024  max mem: 3719\n",
            "Epoch: [53]  [260/295]  eta: 0:00:09  lr: 0.001596  min_lr: 0.001596  loss: 2.5410 (2.5536)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0022  max mem: 3719\n",
            "Epoch: [53]  [270/295]  eta: 0:00:06  lr: 0.001593  min_lr: 0.001593  loss: 2.5410 (2.5526)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0028  max mem: 3719\n",
            "Epoch: [53]  [280/295]  eta: 0:00:04  lr: 0.001589  min_lr: 0.001589  loss: 2.4441 (2.5474)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0018  max mem: 3719\n",
            "Epoch: [53]  [290/295]  eta: 0:00:01  lr: 0.001586  min_lr: 0.001586  loss: 2.5765 (2.5512)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0002  max mem: 3719\n",
            "Epoch: [53]  [294/295]  eta: 0:00:00  lr: 0.001586  min_lr: 0.001586  loss: 2.5765 (2.5496)  weight_decay: 0.0500 (0.0500)  time: 0.2211  data: 0.0002  max mem: 3719\n",
            "Epoch: [53] Total time: 0:01:20 (0.2734 s / it)\n",
            "Averaged stats: lr: 0.001586  min_lr: 0.001586  loss: 2.5765 (2.5496)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:47  loss: 0.6242 (0.6242)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.0423  data: 1.8751  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.6023 (0.6052)  acc1: 87.5000 (86.7424)  acc5: 97.9167 (97.9167)  time: 0.3003  data: 0.1743  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.6023 (0.6514)  acc1: 87.5000 (84.9206)  acc5: 97.9167 (97.7183)  time: 0.1237  data: 0.0033  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.8846 (0.9429)  acc1: 75.0000 (72.3790)  acc5: 95.8333 (96.8414)  time: 0.1255  data: 0.0034  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8574 (0.9022)  acc1: 75.0000 (74.5935)  acc5: 95.8333 (97.1037)  time: 0.1302  data: 0.0064  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8487 (0.9202)  acc1: 79.1667 (74.6324)  acc5: 97.9167 (97.0588)  time: 0.1403  data: 0.0049  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8556 (0.8994)  acc1: 77.0833 (75.4781)  acc5: 97.9167 (97.1653)  time: 0.1474  data: 0.0013  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8644 (0.9098)  acc1: 77.0833 (75.3228)  acc5: 97.9167 (97.1831)  time: 0.1408  data: 0.0006  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8845 (0.8880)  acc1: 77.0833 (76.2860)  acc5: 97.9167 (97.0679)  time: 0.1278  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8845 (0.8891)  acc1: 77.0833 (76.2548)  acc5: 97.9167 (97.0191)  time: 0.1253  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1622 s / it)\n",
            "* Acc@1 76.255 Acc@5 97.019 loss 0.889\n",
            "Accuracy of the model on the 3925 test images: 76.3%\n",
            "Max accuracy: 76.25%\n",
            "Test:  [ 0/82]  eta: 0:02:42  loss: 3.1830 (3.1830)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 1.9757  data: 1.8055  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.3419 (3.3335)  acc1: 8.3333 (11.3636)  acc5: 91.6667 (89.7727)  time: 0.2942  data: 0.1677  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.3605 (3.4387)  acc1: 10.4167 (14.0873)  acc5: 89.5833 (87.2024)  time: 0.1231  data: 0.0032  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.1173 (3.9863)  acc1: 10.4167 (10.4167)  acc5: 77.0833 (76.4785)  time: 0.1214  data: 0.0033  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.7038 (4.1560)  acc1: 2.0833 (9.7053)  acc5: 58.3333 (73.0691)  time: 0.1233  data: 0.0048  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.5999 (4.2709)  acc1: 8.3333 (10.9477)  acc5: 60.4167 (70.7925)  time: 0.1247  data: 0.0056  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.7549 (4.3938)  acc1: 2.0833 (9.4262)  acc5: 54.1667 (69.0232)  time: 0.1236  data: 0.0055  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.3762 (4.2910)  acc1: 2.0833 (12.2359)  acc5: 79.1667 (68.8674)  time: 0.1202  data: 0.0030  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.7625 (3.9185)  acc1: 52.0833 (19.7531)  acc5: 95.8333 (72.2737)  time: 0.1188  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.6364 (3.8886)  acc1: 60.4167 (20.3057)  acc5: 95.8333 (72.4331)  time: 0.1173  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1520 s / it)\n",
            "* Acc@1 20.306 Acc@5 72.433 loss 3.889\n",
            "Accuracy of the model EMA on 3925 test images: 20.3%\n",
            "Max EMA accuracy: 20.31%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [54]  [  0/295]  eta: 0:15:29  lr: 0.001585  min_lr: 0.001585  loss: 3.0023 (3.0023)  weight_decay: 0.0500 (0.0500)  time: 3.1502  data: 2.7262  max mem: 3719\n",
            "Epoch: [54]  [ 10/295]  eta: 0:02:30  lr: 0.001582  min_lr: 0.001582  loss: 2.4488 (2.4214)  weight_decay: 0.0500 (0.0500)  time: 0.5280  data: 0.2500  max mem: 3719\n",
            "Epoch: [54]  [ 20/295]  eta: 0:01:50  lr: 0.001578  min_lr: 0.001578  loss: 2.4488 (2.4231)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0015  max mem: 3719\n",
            "Epoch: [54]  [ 30/295]  eta: 0:01:34  lr: 0.001575  min_lr: 0.001575  loss: 2.6269 (2.4766)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0010  max mem: 3719\n",
            "Epoch: [54]  [ 40/295]  eta: 0:01:25  lr: 0.001571  min_lr: 0.001571  loss: 2.6789 (2.5253)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0014  max mem: 3719\n",
            "Epoch: [54]  [ 50/295]  eta: 0:01:19  lr: 0.001568  min_lr: 0.001568  loss: 2.7260 (2.5416)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0040  max mem: 3719\n",
            "Epoch: [54]  [ 60/295]  eta: 0:01:14  lr: 0.001564  min_lr: 0.001564  loss: 2.5586 (2.5517)  weight_decay: 0.0500 (0.0500)  time: 0.2773  data: 0.0038  max mem: 3719\n",
            "Epoch: [54]  [ 70/295]  eta: 0:01:09  lr: 0.001561  min_lr: 0.001561  loss: 2.5337 (2.5464)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0012  max mem: 3719\n",
            "Epoch: [54]  [ 80/295]  eta: 0:01:05  lr: 0.001557  min_lr: 0.001557  loss: 2.5772 (2.5481)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0016  max mem: 3719\n",
            "Epoch: [54]  [ 90/295]  eta: 0:01:01  lr: 0.001554  min_lr: 0.001554  loss: 2.5744 (2.5493)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0022  max mem: 3719\n",
            "Epoch: [54]  [100/295]  eta: 0:00:58  lr: 0.001550  min_lr: 0.001550  loss: 2.4490 (2.5407)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0033  max mem: 3719\n",
            "Epoch: [54]  [110/295]  eta: 0:00:54  lr: 0.001547  min_lr: 0.001547  loss: 2.5064 (2.5419)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0030  max mem: 3719\n",
            "Epoch: [54]  [120/295]  eta: 0:00:51  lr: 0.001543  min_lr: 0.001543  loss: 2.5162 (2.5342)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0029  max mem: 3719\n",
            "Epoch: [54]  [130/295]  eta: 0:00:48  lr: 0.001540  min_lr: 0.001540  loss: 2.5580 (2.5365)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0021  max mem: 3719\n",
            "Epoch: [54]  [140/295]  eta: 0:00:44  lr: 0.001536  min_lr: 0.001536  loss: 2.6032 (2.5434)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0009  max mem: 3719\n",
            "Epoch: [54]  [150/295]  eta: 0:00:41  lr: 0.001533  min_lr: 0.001533  loss: 2.6320 (2.5456)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0015  max mem: 3719\n",
            "Epoch: [54]  [160/295]  eta: 0:00:38  lr: 0.001529  min_lr: 0.001529  loss: 2.6158 (2.5473)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0012  max mem: 3719\n",
            "Epoch: [54]  [170/295]  eta: 0:00:35  lr: 0.001526  min_lr: 0.001526  loss: 2.6043 (2.5496)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0012  max mem: 3719\n",
            "Epoch: [54]  [180/295]  eta: 0:00:32  lr: 0.001522  min_lr: 0.001522  loss: 2.5990 (2.5514)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0014  max mem: 3719\n",
            "Epoch: [54]  [190/295]  eta: 0:00:29  lr: 0.001519  min_lr: 0.001519  loss: 2.5387 (2.5486)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0025  max mem: 3719\n",
            "Epoch: [54]  [200/295]  eta: 0:00:26  lr: 0.001515  min_lr: 0.001515  loss: 2.5028 (2.5469)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0025  max mem: 3719\n",
            "Epoch: [54]  [210/295]  eta: 0:00:23  lr: 0.001512  min_lr: 0.001512  loss: 2.5244 (2.5428)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0017  max mem: 3719\n",
            "Epoch: [54]  [220/295]  eta: 0:00:21  lr: 0.001508  min_lr: 0.001508  loss: 2.4950 (2.5420)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0018  max mem: 3719\n",
            "Epoch: [54]  [230/295]  eta: 0:00:18  lr: 0.001505  min_lr: 0.001505  loss: 2.5260 (2.5441)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0013  max mem: 3719\n",
            "Epoch: [54]  [240/295]  eta: 0:00:15  lr: 0.001501  min_lr: 0.001501  loss: 2.5823 (2.5451)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0033  max mem: 3719\n",
            "Epoch: [54]  [250/295]  eta: 0:00:12  lr: 0.001498  min_lr: 0.001498  loss: 2.6249 (2.5493)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0037  max mem: 3719\n",
            "Epoch: [54]  [260/295]  eta: 0:00:09  lr: 0.001494  min_lr: 0.001494  loss: 2.6249 (2.5487)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0020  max mem: 3719\n",
            "Epoch: [54]  [270/295]  eta: 0:00:06  lr: 0.001491  min_lr: 0.001491  loss: 2.5002 (2.5460)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0016  max mem: 3719\n",
            "Epoch: [54]  [280/295]  eta: 0:00:04  lr: 0.001487  min_lr: 0.001487  loss: 2.4750 (2.5425)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0010  max mem: 3719\n",
            "Epoch: [54]  [290/295]  eta: 0:00:01  lr: 0.001484  min_lr: 0.001484  loss: 2.6322 (2.5454)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0005  max mem: 3719\n",
            "Epoch: [54]  [294/295]  eta: 0:00:00  lr: 0.001484  min_lr: 0.001484  loss: 2.6407 (2.5460)  weight_decay: 0.0500 (0.0500)  time: 0.2202  data: 0.0003  max mem: 3719\n",
            "Epoch: [54] Total time: 0:01:21 (0.2753 s / it)\n",
            "Averaged stats: lr: 0.001484  min_lr: 0.001484  loss: 2.6407 (2.5460)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:30  loss: 0.5802 (0.5802)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 3.2942  data: 3.1259  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 0.6111 (0.7667)  acc1: 87.5000 (81.2500)  acc5: 95.8333 (96.4015)  time: 0.4261  data: 0.2963  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.8396 (0.8990)  acc1: 77.0833 (77.5794)  acc5: 97.9167 (96.7262)  time: 0.1331  data: 0.0080  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 1.0985 (1.0800)  acc1: 64.5833 (68.5484)  acc5: 97.9167 (97.0430)  time: 0.1243  data: 0.0033  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.9142 (1.0191)  acc1: 72.9167 (71.6463)  acc5: 97.9167 (97.1545)  time: 0.1220  data: 0.0038  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8260 (0.9964)  acc1: 81.2500 (73.2435)  acc5: 97.9167 (97.1405)  time: 0.1228  data: 0.0035  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8784 (0.9828)  acc1: 79.1667 (73.9413)  acc5: 97.9167 (97.1995)  time: 0.1235  data: 0.0046  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9842 (0.9947)  acc1: 72.9167 (73.3862)  acc5: 97.9167 (96.9777)  time: 0.1213  data: 0.0034  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9472 (0.9638)  acc1: 72.9167 (74.6142)  acc5: 97.9167 (97.0679)  time: 0.1186  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9314 (0.9634)  acc1: 75.0000 (74.6242)  acc5: 97.9167 (97.0446)  time: 0.1170  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1694 s / it)\n",
            "* Acc@1 74.624 Acc@5 97.045 loss 0.963\n",
            "Accuracy of the model on the 3925 test images: 74.6%\n",
            "Max accuracy: 76.25%\n",
            "Test:  [ 0/82]  eta: 0:04:11  loss: 3.1350 (3.1350)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 3.0631  data: 2.8455  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 3.3038 (3.2913)  acc1: 10.4167 (12.1212)  acc5: 91.6667 (89.7727)  time: 0.4331  data: 0.2808  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.3134 (3.3997)  acc1: 10.4167 (14.0873)  acc5: 89.5833 (87.3016)  time: 0.1535  data: 0.0130  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 4.0701 (3.9488)  acc1: 10.4167 (10.3495)  acc5: 77.0833 (76.6129)  time: 0.1293  data: 0.0015  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.6292 (4.1118)  acc1: 2.0833 (9.6545)  acc5: 58.3333 (73.3232)  time: 0.1230  data: 0.0030  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.5465 (4.2357)  acc1: 8.3333 (10.9069)  acc5: 60.4167 (70.8742)  time: 0.1235  data: 0.0038  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.7633 (4.3578)  acc1: 2.0833 (9.3921)  acc5: 52.0833 (69.0574)  time: 0.1248  data: 0.0055  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.3455 (4.2527)  acc1: 2.0833 (12.2653)  acc5: 77.0833 (68.8674)  time: 0.1233  data: 0.0041  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.7158 (3.8815)  acc1: 52.0833 (19.8045)  acc5: 95.8333 (72.2737)  time: 0.1195  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.5899 (3.8518)  acc1: 60.4167 (20.3567)  acc5: 95.8333 (72.4331)  time: 0.1183  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1710 s / it)\n",
            "* Acc@1 20.357 Acc@5 72.433 loss 3.852\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "Max EMA accuracy: 20.36%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [55]  [  0/295]  eta: 0:12:22  lr: 0.001483  min_lr: 0.001483  loss: 2.8950 (2.8950)  weight_decay: 0.0500 (0.0500)  time: 2.5183  data: 2.0423  max mem: 3719\n",
            "Epoch: [55]  [ 10/295]  eta: 0:02:38  lr: 0.001480  min_lr: 0.001480  loss: 2.6215 (2.4809)  weight_decay: 0.0500 (0.0500)  time: 0.5578  data: 0.1876  max mem: 3719\n",
            "Epoch: [55]  [ 20/295]  eta: 0:01:55  lr: 0.001476  min_lr: 0.001476  loss: 2.6301 (2.5342)  weight_decay: 0.0500 (0.0500)  time: 0.3147  data: 0.0013  max mem: 3719\n",
            "Epoch: [55]  [ 30/295]  eta: 0:01:37  lr: 0.001473  min_lr: 0.001473  loss: 2.6138 (2.5067)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0014  max mem: 3719\n",
            "Epoch: [55]  [ 40/295]  eta: 0:01:27  lr: 0.001469  min_lr: 0.001469  loss: 2.4248 (2.4839)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0015  max mem: 3719\n",
            "Epoch: [55]  [ 50/295]  eta: 0:01:20  lr: 0.001466  min_lr: 0.001466  loss: 2.5187 (2.5062)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0007  max mem: 3719\n",
            "Epoch: [55]  [ 60/295]  eta: 0:01:14  lr: 0.001462  min_lr: 0.001462  loss: 2.5255 (2.4960)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0022  max mem: 3719\n",
            "Epoch: [55]  [ 70/295]  eta: 0:01:10  lr: 0.001459  min_lr: 0.001459  loss: 2.5148 (2.4929)  weight_decay: 0.0500 (0.0500)  time: 0.2756  data: 0.0039  max mem: 3719\n",
            "Epoch: [55]  [ 80/295]  eta: 0:01:06  lr: 0.001455  min_lr: 0.001455  loss: 2.3452 (2.4870)  weight_decay: 0.0500 (0.0500)  time: 0.2759  data: 0.0033  max mem: 3719\n",
            "Epoch: [55]  [ 90/295]  eta: 0:01:02  lr: 0.001453  min_lr: 0.001453  loss: 2.4731 (2.4904)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0019  max mem: 3719\n",
            "Epoch: [55]  [100/295]  eta: 0:00:58  lr: 0.001448  min_lr: 0.001448  loss: 2.5092 (2.4881)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0013  max mem: 3719\n",
            "Epoch: [55]  [110/295]  eta: 0:00:54  lr: 0.001446  min_lr: 0.001446  loss: 2.4656 (2.4884)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0017  max mem: 3719\n",
            "Epoch: [55]  [120/295]  eta: 0:00:51  lr: 0.001442  min_lr: 0.001442  loss: 2.5366 (2.4900)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0026  max mem: 3719\n",
            "Epoch: [55]  [130/295]  eta: 0:00:48  lr: 0.001439  min_lr: 0.001439  loss: 2.4368 (2.4752)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0030  max mem: 3719\n",
            "Epoch: [55]  [140/295]  eta: 0:00:45  lr: 0.001435  min_lr: 0.001435  loss: 2.2457 (2.4733)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0033  max mem: 3719\n",
            "Epoch: [55]  [150/295]  eta: 0:00:41  lr: 0.001432  min_lr: 0.001432  loss: 2.5485 (2.4848)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0024  max mem: 3719\n",
            "Epoch: [55]  [160/295]  eta: 0:00:38  lr: 0.001428  min_lr: 0.001428  loss: 2.5485 (2.4883)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0013  max mem: 3719\n",
            "Epoch: [55]  [170/295]  eta: 0:00:35  lr: 0.001425  min_lr: 0.001425  loss: 2.5340 (2.4942)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0015  max mem: 3719\n",
            "Epoch: [55]  [180/295]  eta: 0:00:32  lr: 0.001421  min_lr: 0.001421  loss: 2.5291 (2.4927)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0024  max mem: 3719\n",
            "Epoch: [55]  [190/295]  eta: 0:00:29  lr: 0.001418  min_lr: 0.001418  loss: 2.4672 (2.4918)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0028  max mem: 3719\n",
            "Epoch: [55]  [200/295]  eta: 0:00:26  lr: 0.001414  min_lr: 0.001414  loss: 2.5030 (2.4924)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0027  max mem: 3719\n",
            "Epoch: [55]  [210/295]  eta: 0:00:23  lr: 0.001411  min_lr: 0.001411  loss: 2.5325 (2.4984)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0021  max mem: 3719\n",
            "Epoch: [55]  [220/295]  eta: 0:00:21  lr: 0.001407  min_lr: 0.001407  loss: 2.5939 (2.5001)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0022  max mem: 3719\n",
            "Epoch: [55]  [230/295]  eta: 0:00:18  lr: 0.001404  min_lr: 0.001404  loss: 2.4534 (2.4968)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0028  max mem: 3719\n",
            "Epoch: [55]  [240/295]  eta: 0:00:15  lr: 0.001400  min_lr: 0.001400  loss: 2.4864 (2.5006)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0024  max mem: 3719\n",
            "Epoch: [55]  [250/295]  eta: 0:00:12  lr: 0.001398  min_lr: 0.001398  loss: 2.5505 (2.4955)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0026  max mem: 3719\n",
            "Epoch: [55]  [260/295]  eta: 0:00:09  lr: 0.001394  min_lr: 0.001394  loss: 2.4608 (2.4963)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0033  max mem: 3719\n",
            "Epoch: [55]  [270/295]  eta: 0:00:06  lr: 0.001391  min_lr: 0.001391  loss: 2.5185 (2.4985)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0035  max mem: 3719\n",
            "Epoch: [55]  [280/295]  eta: 0:00:04  lr: 0.001387  min_lr: 0.001387  loss: 2.5185 (2.4985)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0022  max mem: 3719\n",
            "Epoch: [55]  [290/295]  eta: 0:00:01  lr: 0.001384  min_lr: 0.001384  loss: 2.6112 (2.5004)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0006  max mem: 3719\n",
            "Epoch: [55]  [294/295]  eta: 0:00:00  lr: 0.001384  min_lr: 0.001384  loss: 2.6112 (2.5008)  weight_decay: 0.0500 (0.0500)  time: 0.2200  data: 0.0002  max mem: 3719\n",
            "Epoch: [55] Total time: 0:01:21 (0.2764 s / it)\n",
            "Averaged stats: lr: 0.001384  min_lr: 0.001384  loss: 2.6112 (2.5008)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:50  loss: 0.7067 (0.7067)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 2.8120  data: 2.6351  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.6534 (0.6813)  acc1: 83.3333 (84.6591)  acc5: 97.9167 (96.9697)  time: 0.3769  data: 0.2466  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.6843 (0.7093)  acc1: 83.3333 (83.2341)  acc5: 97.9167 (97.5198)  time: 0.1667  data: 0.0267  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.8754 (0.9965)  acc1: 75.0000 (71.7742)  acc5: 95.8333 (96.1694)  time: 0.1885  data: 0.0377  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.8319 (0.9339)  acc1: 77.0833 (74.4411)  acc5: 95.8333 (96.5955)  time: 0.1626  data: 0.0177  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.7379 (0.9051)  acc1: 81.2500 (75.6944)  acc5: 97.9167 (96.8546)  time: 0.1653  data: 0.0170  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7542 (0.8826)  acc1: 81.2500 (76.2295)  acc5: 97.9167 (97.1311)  time: 0.1546  data: 0.0155  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9570 (0.9037)  acc1: 72.9167 (75.5869)  acc5: 97.9167 (96.8603)  time: 0.1229  data: 0.0015  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9570 (0.8815)  acc1: 75.0000 (76.3632)  acc5: 97.9167 (97.0936)  time: 0.1190  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8991 (0.8817)  acc1: 75.6757 (76.3567)  acc5: 97.9167 (97.0701)  time: 0.1176  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1877 s / it)\n",
            "* Acc@1 76.357 Acc@5 97.070 loss 0.882\n",
            "Accuracy of the model on the 3925 test images: 76.4%\n",
            "Max accuracy: 76.36%\n",
            "Test:  [ 0/82]  eta: 0:02:41  loss: 3.0842 (3.0842)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 1.9660  data: 1.8061  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.2601 (3.2476)  acc1: 10.4167 (12.1212)  acc5: 91.6667 (90.1515)  time: 0.2907  data: 0.1649  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.2611 (3.3616)  acc1: 12.5000 (14.0873)  acc5: 89.5833 (87.7976)  time: 0.1261  data: 0.0033  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 4.0295 (3.9122)  acc1: 8.3333 (10.2823)  acc5: 77.0833 (76.7473)  time: 0.1438  data: 0.0080  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.5640 (4.0704)  acc1: 4.1667 (9.6545)  acc5: 58.3333 (73.4756)  time: 0.1535  data: 0.0119  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.5435 (4.2035)  acc1: 8.3333 (10.7435)  acc5: 60.4167 (70.8333)  time: 0.1679  data: 0.0303  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.7316 (4.3252)  acc1: 2.0833 (9.2896)  acc5: 52.0833 (68.9891)  time: 0.1758  data: 0.0385  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.3257 (4.2175)  acc1: 2.0833 (12.2066)  acc5: 77.0833 (68.8087)  time: 0.1483  data: 0.0158  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.6722 (3.8472)  acc1: 52.0833 (19.7531)  acc5: 95.8333 (72.2479)  time: 0.1254  data: 0.0009  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.5487 (3.8176)  acc1: 60.4167 (20.3057)  acc5: 95.8333 (72.4076)  time: 0.1213  data: 0.0009  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1722 s / it)\n",
            "* Acc@1 20.306 Acc@5 72.408 loss 3.818\n",
            "Accuracy of the model EMA on 3925 test images: 20.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [56]  [  0/295]  eta: 0:05:56  lr: 0.001383  min_lr: 0.001383  loss: 2.5690 (2.5690)  weight_decay: 0.0500 (0.0500)  time: 1.2091  data: 0.9411  max mem: 3719\n",
            "Epoch: [56]  [ 10/295]  eta: 0:01:53  lr: 0.001380  min_lr: 0.001380  loss: 2.4686 (2.4942)  weight_decay: 0.0500 (0.0500)  time: 0.3987  data: 0.1117  max mem: 3719\n",
            "Epoch: [56]  [ 20/295]  eta: 0:01:31  lr: 0.001376  min_lr: 0.001376  loss: 2.4973 (2.5321)  weight_decay: 0.0500 (0.0500)  time: 0.2902  data: 0.0146  max mem: 3719\n",
            "Epoch: [56]  [ 30/295]  eta: 0:01:22  lr: 0.001373  min_lr: 0.001373  loss: 2.6629 (2.5533)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0014  max mem: 3719\n",
            "Epoch: [56]  [ 40/295]  eta: 0:01:17  lr: 0.001369  min_lr: 0.001369  loss: 2.5025 (2.5257)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0021  max mem: 3719\n",
            "Epoch: [56]  [ 50/295]  eta: 0:01:12  lr: 0.001366  min_lr: 0.001366  loss: 2.4347 (2.5287)  weight_decay: 0.0500 (0.0500)  time: 0.2743  data: 0.0013  max mem: 3719\n",
            "Epoch: [56]  [ 60/295]  eta: 0:01:08  lr: 0.001362  min_lr: 0.001362  loss: 2.5878 (2.5529)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0005  max mem: 3719\n",
            "Epoch: [56]  [ 70/295]  eta: 0:01:04  lr: 0.001359  min_lr: 0.001359  loss: 2.6932 (2.5604)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0005  max mem: 3719\n",
            "Epoch: [56]  [ 80/295]  eta: 0:01:01  lr: 0.001355  min_lr: 0.001355  loss: 2.6194 (2.5663)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0008  max mem: 3719\n",
            "Epoch: [56]  [ 90/295]  eta: 0:00:57  lr: 0.001353  min_lr: 0.001353  loss: 2.6008 (2.5567)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0013  max mem: 3719\n",
            "Epoch: [56]  [100/295]  eta: 0:00:54  lr: 0.001349  min_lr: 0.001349  loss: 2.4234 (2.5471)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0027  max mem: 3719\n",
            "Epoch: [56]  [110/295]  eta: 0:00:51  lr: 0.001346  min_lr: 0.001346  loss: 2.4234 (2.5445)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0035  max mem: 3719\n",
            "Epoch: [56]  [120/295]  eta: 0:00:48  lr: 0.001342  min_lr: 0.001342  loss: 2.3551 (2.5293)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0025  max mem: 3719\n",
            "Epoch: [56]  [130/295]  eta: 0:00:45  lr: 0.001339  min_lr: 0.001339  loss: 2.3581 (2.5239)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0013  max mem: 3719\n",
            "Epoch: [56]  [140/295]  eta: 0:00:42  lr: 0.001335  min_lr: 0.001335  loss: 2.5486 (2.5297)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0009  max mem: 3719\n",
            "Epoch: [56]  [150/295]  eta: 0:00:39  lr: 0.001332  min_lr: 0.001332  loss: 2.5486 (2.5255)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0010  max mem: 3719\n",
            "Epoch: [56]  [160/295]  eta: 0:00:37  lr: 0.001328  min_lr: 0.001328  loss: 2.4990 (2.5253)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0015  max mem: 3719\n",
            "Epoch: [56]  [170/295]  eta: 0:00:34  lr: 0.001326  min_lr: 0.001326  loss: 2.5202 (2.5282)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0019  max mem: 3719\n",
            "Epoch: [56]  [180/295]  eta: 0:00:31  lr: 0.001322  min_lr: 0.001322  loss: 2.4415 (2.5196)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0022  max mem: 3719\n",
            "Epoch: [56]  [190/295]  eta: 0:00:28  lr: 0.001319  min_lr: 0.001319  loss: 2.3581 (2.5133)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0026  max mem: 3719\n",
            "Epoch: [56]  [200/295]  eta: 0:00:25  lr: 0.001315  min_lr: 0.001315  loss: 2.4923 (2.5139)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0021  max mem: 3719\n",
            "Epoch: [56]  [210/295]  eta: 0:00:23  lr: 0.001312  min_lr: 0.001312  loss: 2.4979 (2.5081)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0012  max mem: 3719\n",
            "Epoch: [56]  [220/295]  eta: 0:00:20  lr: 0.001308  min_lr: 0.001308  loss: 2.3674 (2.5019)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0006  max mem: 3719\n",
            "Epoch: [56]  [230/295]  eta: 0:00:17  lr: 0.001305  min_lr: 0.001305  loss: 2.4475 (2.5044)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0008  max mem: 3719\n",
            "Epoch: [56]  [240/295]  eta: 0:00:14  lr: 0.001301  min_lr: 0.001301  loss: 2.6030 (2.5104)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0025  max mem: 3719\n",
            "Epoch: [56]  [250/295]  eta: 0:00:12  lr: 0.001299  min_lr: 0.001299  loss: 2.6119 (2.5131)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0023  max mem: 3719\n",
            "Epoch: [56]  [260/295]  eta: 0:00:09  lr: 0.001295  min_lr: 0.001295  loss: 2.6108 (2.5146)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0010  max mem: 3719\n",
            "Epoch: [56]  [270/295]  eta: 0:00:06  lr: 0.001292  min_lr: 0.001292  loss: 2.5604 (2.5121)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0009  max mem: 3719\n",
            "Epoch: [56]  [280/295]  eta: 0:00:04  lr: 0.001288  min_lr: 0.001288  loss: 2.5752 (2.5146)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0005  max mem: 3719\n",
            "Epoch: [56]  [290/295]  eta: 0:00:01  lr: 0.001285  min_lr: 0.001285  loss: 2.5828 (2.5157)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0002  max mem: 3719\n",
            "Epoch: [56]  [294/295]  eta: 0:00:00  lr: 0.001285  min_lr: 0.001285  loss: 2.5768 (2.5150)  weight_decay: 0.0500 (0.0500)  time: 0.2233  data: 0.0002  max mem: 3719\n",
            "Epoch: [56] Total time: 0:01:19 (0.2690 s / it)\n",
            "Averaged stats: lr: 0.001285  min_lr: 0.001285  loss: 2.5768 (2.5150)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:18  loss: 0.5429 (0.5429)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.4245  data: 2.2650  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 0.5611 (0.6138)  acc1: 87.5000 (88.0682)  acc5: 100.0000 (98.4849)  time: 0.3337  data: 0.2072  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.6953 (0.6951)  acc1: 85.4167 (84.7222)  acc5: 100.0000 (98.5119)  time: 0.1250  data: 0.0026  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.8516 (0.9161)  acc1: 72.9167 (75.0672)  acc5: 97.9167 (98.2527)  time: 0.1268  data: 0.0041  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8737 (0.8888)  acc1: 75.0000 (76.5244)  acc5: 97.9167 (98.0691)  time: 0.1254  data: 0.0043  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8299 (0.8983)  acc1: 81.2500 (76.6748)  acc5: 97.9167 (98.0392)  time: 0.1225  data: 0.0032  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9237 (0.9103)  acc1: 79.1667 (76.7418)  acc5: 97.9167 (97.8142)  time: 0.1233  data: 0.0040  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9604 (0.9320)  acc1: 75.0000 (76.1150)  acc5: 95.8333 (97.4765)  time: 0.1220  data: 0.0035  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9098 (0.9033)  acc1: 77.0833 (77.2377)  acc5: 97.9167 (97.5566)  time: 0.1195  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9098 (0.9040)  acc1: 77.0833 (77.1720)  acc5: 97.9167 (97.5032)  time: 0.1182  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1579 s / it)\n",
            "* Acc@1 77.172 Acc@5 97.503 loss 0.904\n",
            "Accuracy of the model on the 3925 test images: 77.2%\n",
            "Max accuracy: 77.17%\n",
            "Test:  [ 0/82]  eta: 0:03:18  loss: 3.0390 (3.0390)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 2.4212  data: 2.2570  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 3.2137 (3.2072)  acc1: 10.4167 (12.1212)  acc5: 91.6667 (90.3409)  time: 0.3471  data: 0.2123  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.2226 (3.3241)  acc1: 12.5000 (14.1865)  acc5: 91.6667 (88.2937)  time: 0.1563  data: 0.0216  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.9867 (3.8761)  acc1: 8.3333 (10.3495)  acc5: 77.0833 (76.9489)  time: 0.1765  data: 0.0440  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.5440 (4.0307)  acc1: 4.1667 (9.8577)  acc5: 58.3333 (73.6789)  time: 0.1770  data: 0.0445  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.5049 (4.1726)  acc1: 8.3333 (10.7843)  acc5: 60.4167 (70.9967)  time: 0.1608  data: 0.0272  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6960 (4.2940)  acc1: 2.0833 (9.2555)  acc5: 52.0833 (68.9549)  time: 0.1544  data: 0.0249  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.3045 (4.1841)  acc1: 2.0833 (12.2653)  acc5: 77.0833 (68.9261)  time: 0.1638  data: 0.0278  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.6325 (3.8146)  acc1: 52.0833 (19.8045)  acc5: 95.8333 (72.3508)  time: 0.1543  data: 0.0237  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.5127 (3.7851)  acc1: 60.4167 (20.3567)  acc5: 95.8333 (72.5096)  time: 0.1513  data: 0.0237  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1947 s / it)\n",
            "* Acc@1 20.357 Acc@5 72.510 loss 3.785\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "Max EMA accuracy: 20.36%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [57]  [  0/295]  eta: 0:12:23  lr: 0.001284  min_lr: 0.001284  loss: 2.4893 (2.4893)  weight_decay: 0.0500 (0.0500)  time: 2.5216  data: 2.1553  max mem: 3719\n",
            "Epoch: [57]  [ 10/295]  eta: 0:02:13  lr: 0.001281  min_lr: 0.001281  loss: 2.5768 (2.4758)  weight_decay: 0.0500 (0.0500)  time: 0.4701  data: 0.1971  max mem: 3719\n",
            "Epoch: [57]  [ 20/295]  eta: 0:01:42  lr: 0.001277  min_lr: 0.001277  loss: 2.6377 (2.5401)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0016  max mem: 3719\n",
            "Epoch: [57]  [ 30/295]  eta: 0:01:29  lr: 0.001275  min_lr: 0.001275  loss: 2.5451 (2.5221)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0022  max mem: 3719\n",
            "Epoch: [57]  [ 40/295]  eta: 0:01:21  lr: 0.001271  min_lr: 0.001271  loss: 2.4458 (2.5166)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0016  max mem: 3719\n",
            "Epoch: [57]  [ 50/295]  eta: 0:01:15  lr: 0.001268  min_lr: 0.001268  loss: 2.5349 (2.5181)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0009  max mem: 3719\n",
            "Epoch: [57]  [ 60/295]  eta: 0:01:11  lr: 0.001264  min_lr: 0.001264  loss: 2.5349 (2.5111)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0013  max mem: 3719\n",
            "Epoch: [57]  [ 70/295]  eta: 0:01:07  lr: 0.001261  min_lr: 0.001261  loss: 2.6010 (2.5143)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0011  max mem: 3719\n",
            "Epoch: [57]  [ 80/295]  eta: 0:01:03  lr: 0.001257  min_lr: 0.001257  loss: 2.5074 (2.5024)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0008  max mem: 3719\n",
            "Epoch: [57]  [ 90/295]  eta: 0:00:59  lr: 0.001255  min_lr: 0.001255  loss: 2.5130 (2.5069)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0011  max mem: 3719\n",
            "Epoch: [57]  [100/295]  eta: 0:00:56  lr: 0.001251  min_lr: 0.001251  loss: 2.4979 (2.4999)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0011  max mem: 3719\n",
            "Epoch: [57]  [110/295]  eta: 0:00:53  lr: 0.001248  min_lr: 0.001248  loss: 2.4537 (2.4932)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0021  max mem: 3719\n",
            "Epoch: [57]  [120/295]  eta: 0:00:49  lr: 0.001244  min_lr: 0.001244  loss: 2.4737 (2.4854)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0031  max mem: 3719\n",
            "Epoch: [57]  [130/295]  eta: 0:00:46  lr: 0.001241  min_lr: 0.001241  loss: 2.3682 (2.4828)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0019  max mem: 3719\n",
            "Epoch: [57]  [140/295]  eta: 0:00:43  lr: 0.001237  min_lr: 0.001237  loss: 2.5169 (2.4893)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0008  max mem: 3719\n",
            "Epoch: [57]  [150/295]  eta: 0:00:40  lr: 0.001235  min_lr: 0.001235  loss: 2.5999 (2.4995)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0005  max mem: 3719\n",
            "Epoch: [57]  [160/295]  eta: 0:00:37  lr: 0.001231  min_lr: 0.001231  loss: 2.5655 (2.4942)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0014  max mem: 3719\n",
            "Epoch: [57]  [170/295]  eta: 0:00:34  lr: 0.001228  min_lr: 0.001228  loss: 2.4938 (2.4945)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0025  max mem: 3719\n",
            "Epoch: [57]  [180/295]  eta: 0:00:32  lr: 0.001224  min_lr: 0.001224  loss: 2.5536 (2.4988)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0029  max mem: 3719\n",
            "Epoch: [57]  [190/295]  eta: 0:00:29  lr: 0.001221  min_lr: 0.001221  loss: 2.5827 (2.5044)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0030  max mem: 3719\n",
            "Epoch: [57]  [200/295]  eta: 0:00:26  lr: 0.001217  min_lr: 0.001217  loss: 2.5755 (2.5031)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0017  max mem: 3719\n",
            "Epoch: [57]  [210/295]  eta: 0:00:23  lr: 0.001215  min_lr: 0.001215  loss: 2.4199 (2.4970)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0011  max mem: 3719\n",
            "Epoch: [57]  [220/295]  eta: 0:00:20  lr: 0.001211  min_lr: 0.001211  loss: 2.4658 (2.4998)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0013  max mem: 3719\n",
            "Epoch: [57]  [230/295]  eta: 0:00:17  lr: 0.001208  min_lr: 0.001208  loss: 2.5027 (2.4992)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0020  max mem: 3719\n",
            "Epoch: [57]  [240/295]  eta: 0:00:15  lr: 0.001204  min_lr: 0.001204  loss: 2.5817 (2.4979)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0031  max mem: 3719\n",
            "Epoch: [57]  [250/295]  eta: 0:00:12  lr: 0.001202  min_lr: 0.001202  loss: 2.5464 (2.4959)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0023  max mem: 3719\n",
            "Epoch: [57]  [260/295]  eta: 0:00:09  lr: 0.001198  min_lr: 0.001198  loss: 2.5219 (2.4962)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0013  max mem: 3719\n",
            "Epoch: [57]  [270/295]  eta: 0:00:06  lr: 0.001195  min_lr: 0.001195  loss: 2.4791 (2.4925)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0012  max mem: 3719\n",
            "Epoch: [57]  [280/295]  eta: 0:00:04  lr: 0.001191  min_lr: 0.001191  loss: 2.5584 (2.4997)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0008  max mem: 3719\n",
            "Epoch: [57]  [290/295]  eta: 0:00:01  lr: 0.001189  min_lr: 0.001189  loss: 2.6452 (2.5011)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0003  max mem: 3719\n",
            "Epoch: [57]  [294/295]  eta: 0:00:00  lr: 0.001189  min_lr: 0.001189  loss: 2.6561 (2.5025)  weight_decay: 0.0500 (0.0500)  time: 0.2201  data: 0.0003  max mem: 3719\n",
            "Epoch: [57] Total time: 0:01:20 (0.2718 s / it)\n",
            "Averaged stats: lr: 0.001189  min_lr: 0.001189  loss: 2.6561 (2.5025)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:07  loss: 0.6034 (0.6034)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 3.0236  data: 2.8106  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 0.5717 (0.6075)  acc1: 87.5000 (87.3106)  acc5: 97.9167 (97.7273)  time: 0.4181  data: 0.2811  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.6559 (0.6434)  acc1: 87.5000 (86.4087)  acc5: 97.9167 (98.1151)  time: 0.1434  data: 0.0156  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7854 (0.9320)  acc1: 81.2500 (74.3952)  acc5: 97.9167 (96.6398)  time: 0.1275  data: 0.0044  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8822 (0.9079)  acc1: 79.1667 (76.0671)  acc5: 97.9167 (97.1037)  time: 0.1251  data: 0.0035  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7778 (0.8871)  acc1: 81.2500 (77.0016)  acc5: 100.0000 (97.3856)  time: 0.1256  data: 0.0031  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8383 (0.8942)  acc1: 77.0833 (76.8784)  acc5: 97.9167 (97.1311)  time: 0.1269  data: 0.0066  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9296 (0.9092)  acc1: 72.9167 (76.0270)  acc5: 95.8333 (96.9190)  time: 0.1226  data: 0.0044  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7717 (0.8803)  acc1: 77.0833 (77.1605)  acc5: 97.9167 (97.0679)  time: 0.1182  data: 0.0004  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7717 (0.8811)  acc1: 77.0833 (77.0955)  acc5: 97.9167 (97.0446)  time: 0.1169  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1710 s / it)\n",
            "* Acc@1 77.096 Acc@5 97.045 loss 0.881\n",
            "Accuracy of the model on the 3925 test images: 77.1%\n",
            "Max accuracy: 77.17%\n",
            "Test:  [ 0/82]  eta: 0:04:28  loss: 2.9881 (2.9881)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 3.2725  data: 3.1106  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 3.1599 (3.1643)  acc1: 10.4167 (11.9318)  acc5: 91.6667 (90.5303)  time: 0.4317  data: 0.2844  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.1751 (3.2892)  acc1: 12.5000 (14.2857)  acc5: 91.6667 (88.3929)  time: 0.1476  data: 0.0030  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.9520 (3.8412)  acc1: 8.3333 (10.5511)  acc5: 77.0833 (77.0161)  time: 0.1352  data: 0.0034  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.5427 (3.9922)  acc1: 4.1667 (9.9085)  acc5: 62.5000 (73.8821)  time: 0.1227  data: 0.0021  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.4468 (4.1414)  acc1: 8.3333 (10.8252)  acc5: 62.5000 (71.0784)  time: 0.1224  data: 0.0027  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6526 (4.2612)  acc1: 2.0833 (9.2896)  acc5: 52.0833 (69.0232)  time: 0.1241  data: 0.0041  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.2672 (4.1496)  acc1: 2.0833 (12.3826)  acc5: 77.0833 (68.8967)  time: 0.1235  data: 0.0024  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.5890 (3.7810)  acc1: 52.0833 (19.9074)  acc5: 95.8333 (72.3251)  time: 0.1202  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4735 (3.7516)  acc1: 60.4167 (20.4586)  acc5: 95.8333 (72.4841)  time: 0.1179  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1722 s / it)\n",
            "* Acc@1 20.459 Acc@5 72.484 loss 3.752\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "Max EMA accuracy: 20.46%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [58]  [  0/295]  eta: 0:09:08  lr: 0.001187  min_lr: 0.001187  loss: 2.8769 (2.8769)  weight_decay: 0.0500 (0.0500)  time: 1.8594  data: 1.3235  max mem: 3719\n",
            "Epoch: [58]  [ 10/295]  eta: 0:02:28  lr: 0.001185  min_lr: 0.001185  loss: 2.5783 (2.6658)  weight_decay: 0.0500 (0.0500)  time: 0.5218  data: 0.1219  max mem: 3719\n",
            "Epoch: [58]  [ 20/295]  eta: 0:01:50  lr: 0.001181  min_lr: 0.001181  loss: 2.5604 (2.6222)  weight_decay: 0.0500 (0.0500)  time: 0.3292  data: 0.0017  max mem: 3719\n",
            "Epoch: [58]  [ 30/295]  eta: 0:01:34  lr: 0.001178  min_lr: 0.001178  loss: 2.4746 (2.5261)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0016  max mem: 3719\n",
            "Epoch: [58]  [ 40/295]  eta: 0:01:25  lr: 0.001174  min_lr: 0.001174  loss: 2.3749 (2.5228)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0013  max mem: 3719\n",
            "Epoch: [58]  [ 50/295]  eta: 0:01:18  lr: 0.001172  min_lr: 0.001172  loss: 2.3860 (2.4980)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0008  max mem: 3719\n",
            "Epoch: [58]  [ 60/295]  eta: 0:01:13  lr: 0.001168  min_lr: 0.001168  loss: 2.5150 (2.5166)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0019  max mem: 3719\n",
            "Epoch: [58]  [ 70/295]  eta: 0:01:08  lr: 0.001165  min_lr: 0.001165  loss: 2.5539 (2.5119)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0032  max mem: 3719\n",
            "Epoch: [58]  [ 80/295]  eta: 0:01:05  lr: 0.001161  min_lr: 0.001161  loss: 2.5044 (2.5180)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0024  max mem: 3719\n",
            "Epoch: [58]  [ 90/295]  eta: 0:01:01  lr: 0.001159  min_lr: 0.001159  loss: 2.4706 (2.5146)  weight_decay: 0.0500 (0.0500)  time: 0.2774  data: 0.0021  max mem: 3719\n",
            "Epoch: [58]  [100/295]  eta: 0:00:58  lr: 0.001155  min_lr: 0.001155  loss: 2.4613 (2.5101)  weight_decay: 0.0500 (0.0500)  time: 0.2775  data: 0.0027  max mem: 3719\n",
            "Epoch: [58]  [110/295]  eta: 0:00:54  lr: 0.001152  min_lr: 0.001152  loss: 2.4671 (2.5045)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0021  max mem: 3719\n",
            "Epoch: [58]  [120/295]  eta: 0:00:51  lr: 0.001148  min_lr: 0.001148  loss: 2.5424 (2.5086)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0009  max mem: 3719\n",
            "Epoch: [58]  [130/295]  eta: 0:00:47  lr: 0.001146  min_lr: 0.001146  loss: 2.5424 (2.5122)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0021  max mem: 3719\n",
            "Epoch: [58]  [140/295]  eta: 0:00:44  lr: 0.001142  min_lr: 0.001142  loss: 2.5143 (2.5121)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0026  max mem: 3719\n",
            "Epoch: [58]  [150/295]  eta: 0:00:41  lr: 0.001139  min_lr: 0.001139  loss: 2.4841 (2.5104)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0018  max mem: 3719\n",
            "Epoch: [58]  [160/295]  eta: 0:00:38  lr: 0.001135  min_lr: 0.001135  loss: 2.4666 (2.5103)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0018  max mem: 3719\n",
            "Epoch: [58]  [170/295]  eta: 0:00:35  lr: 0.001133  min_lr: 0.001133  loss: 2.4996 (2.5105)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0020  max mem: 3719\n",
            "Epoch: [58]  [180/295]  eta: 0:00:32  lr: 0.001129  min_lr: 0.001129  loss: 2.5333 (2.5085)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0021  max mem: 3719\n",
            "Epoch: [58]  [190/295]  eta: 0:00:29  lr: 0.001126  min_lr: 0.001126  loss: 2.5011 (2.5068)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0018  max mem: 3719\n",
            "Epoch: [58]  [200/295]  eta: 0:00:26  lr: 0.001122  min_lr: 0.001122  loss: 2.3891 (2.4973)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0010  max mem: 3719\n",
            "Epoch: [58]  [210/295]  eta: 0:00:23  lr: 0.001120  min_lr: 0.001120  loss: 2.4349 (2.4965)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0025  max mem: 3719\n",
            "Epoch: [58]  [220/295]  eta: 0:00:20  lr: 0.001116  min_lr: 0.001116  loss: 2.4860 (2.4939)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0040  max mem: 3719\n",
            "Epoch: [58]  [230/295]  eta: 0:00:18  lr: 0.001113  min_lr: 0.001113  loss: 2.5658 (2.4975)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0018  max mem: 3719\n",
            "Epoch: [58]  [240/295]  eta: 0:00:15  lr: 0.001109  min_lr: 0.001109  loss: 2.6266 (2.5042)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0011  max mem: 3719\n",
            "Epoch: [58]  [250/295]  eta: 0:00:12  lr: 0.001107  min_lr: 0.001107  loss: 2.6562 (2.5027)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0018  max mem: 3719\n",
            "Epoch: [58]  [260/295]  eta: 0:00:09  lr: 0.001103  min_lr: 0.001103  loss: 2.6056 (2.5058)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0013  max mem: 3719\n",
            "Epoch: [58]  [270/295]  eta: 0:00:06  lr: 0.001100  min_lr: 0.001100  loss: 2.5843 (2.5055)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0014  max mem: 3719\n",
            "Epoch: [58]  [280/295]  eta: 0:00:04  lr: 0.001097  min_lr: 0.001097  loss: 2.5187 (2.5073)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0017  max mem: 3719\n",
            "Epoch: [58]  [290/295]  eta: 0:00:01  lr: 0.001094  min_lr: 0.001094  loss: 2.5671 (2.5064)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0008  max mem: 3719\n",
            "Epoch: [58]  [294/295]  eta: 0:00:00  lr: 0.001094  min_lr: 0.001094  loss: 2.5876 (2.5072)  weight_decay: 0.0500 (0.0500)  time: 0.2206  data: 0.0002  max mem: 3719\n",
            "Epoch: [58] Total time: 0:01:20 (0.2743 s / it)\n",
            "Averaged stats: lr: 0.001094  min_lr: 0.001094  loss: 2.5876 (2.5072)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:20  loss: 0.6168 (0.6168)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 1.7098  data: 1.5541  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 0.6168 (0.6349)  acc1: 87.5000 (86.1742)  acc5: 97.9167 (97.5379)  time: 0.2722  data: 0.1462  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.6177 (0.6493)  acc1: 87.5000 (85.8135)  acc5: 97.9167 (98.1151)  time: 0.1262  data: 0.0042  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.7390 (0.8174)  acc1: 81.2500 (78.8306)  acc5: 100.0000 (98.2527)  time: 0.1295  data: 0.0034  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.1295 (0.8825)  acc1: 68.7500 (76.8293)  acc5: 97.9167 (97.7642)  time: 0.1396  data: 0.0037  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.9759 (0.8832)  acc1: 72.9167 (77.0016)  acc5: 97.9167 (97.9167)  time: 0.1512  data: 0.0067  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8650 (0.8852)  acc1: 77.0833 (76.6735)  acc5: 97.9167 (97.8142)  time: 0.1725  data: 0.0129  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0235 (0.9143)  acc1: 68.7500 (75.4401)  acc5: 97.9167 (97.3885)  time: 0.1867  data: 0.0146  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8823 (0.8858)  acc1: 75.0000 (76.5689)  acc5: 97.9167 (97.5051)  time: 0.1532  data: 0.0068  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8818 (0.8857)  acc1: 78.3784 (76.5860)  acc5: 97.9167 (97.4777)  time: 0.1489  data: 0.0068  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1718 s / it)\n",
            "* Acc@1 76.586 Acc@5 97.478 loss 0.886\n",
            "Accuracy of the model on the 3925 test images: 76.6%\n",
            "Max accuracy: 77.17%\n",
            "Test:  [ 0/82]  eta: 0:02:19  loss: 2.9375 (2.9375)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 1.7015  data: 1.5394  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 3.1081 (3.1224)  acc1: 10.4167 (12.3106)  acc5: 91.6667 (90.9091)  time: 0.2758  data: 0.1503  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.1301 (3.2511)  acc1: 14.5833 (14.4841)  acc5: 91.6667 (88.7897)  time: 0.1279  data: 0.0075  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.9170 (3.8031)  acc1: 8.3333 (10.7527)  acc5: 79.1667 (77.2177)  time: 0.1220  data: 0.0022  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 4.5381 (3.9512)  acc1: 4.1667 (10.1118)  acc5: 62.5000 (74.0346)  time: 0.1230  data: 0.0030  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.3883 (4.1077)  acc1: 8.3333 (10.8252)  acc5: 62.5000 (71.0784)  time: 0.1256  data: 0.0063  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6081 (4.2263)  acc1: 2.0833 (9.2896)  acc5: 52.0833 (69.0232)  time: 0.1252  data: 0.0055  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.2314 (4.1132)  acc1: 2.0833 (12.4413)  acc5: 77.0833 (68.8967)  time: 0.1240  data: 0.0020  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.5480 (3.7461)  acc1: 54.1667 (19.9588)  acc5: 95.8333 (72.3251)  time: 0.1213  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4363 (3.7168)  acc1: 60.4167 (20.5096)  acc5: 95.8333 (72.4841)  time: 0.1181  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1508 s / it)\n",
            "* Acc@1 20.510 Acc@5 72.484 loss 3.717\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "Max EMA accuracy: 20.51%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [59]  [  0/295]  eta: 0:13:29  lr: 0.001093  min_lr: 0.001093  loss: 2.3265 (2.3265)  weight_decay: 0.0500 (0.0500)  time: 2.7424  data: 2.3639  max mem: 3719\n",
            "Epoch: [59]  [ 10/295]  eta: 0:02:19  lr: 0.001090  min_lr: 0.001090  loss: 2.3993 (2.4885)  weight_decay: 0.0500 (0.0500)  time: 0.4886  data: 0.2166  max mem: 3719\n",
            "Epoch: [59]  [ 20/295]  eta: 0:01:44  lr: 0.001086  min_lr: 0.001086  loss: 2.5191 (2.5174)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0017  max mem: 3719\n",
            "Epoch: [59]  [ 30/295]  eta: 0:01:30  lr: 0.001084  min_lr: 0.001084  loss: 2.5532 (2.5078)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0012  max mem: 3719\n",
            "Epoch: [59]  [ 40/295]  eta: 0:01:22  lr: 0.001080  min_lr: 0.001080  loss: 2.5427 (2.4957)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0012  max mem: 3719\n",
            "Epoch: [59]  [ 50/295]  eta: 0:01:16  lr: 0.001077  min_lr: 0.001077  loss: 2.4275 (2.4832)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0017  max mem: 3719\n",
            "Epoch: [59]  [ 60/295]  eta: 0:01:11  lr: 0.001074  min_lr: 0.001074  loss: 2.4835 (2.4871)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0017  max mem: 3719\n",
            "Epoch: [59]  [ 70/295]  eta: 0:01:07  lr: 0.001071  min_lr: 0.001071  loss: 2.4835 (2.4718)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0011  max mem: 3719\n",
            "Epoch: [59]  [ 80/295]  eta: 0:01:03  lr: 0.001067  min_lr: 0.001067  loss: 2.5027 (2.4936)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0006  max mem: 3719\n",
            "Epoch: [59]  [ 90/295]  eta: 0:00:59  lr: 0.001065  min_lr: 0.001065  loss: 2.6507 (2.5028)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0007  max mem: 3719\n",
            "Epoch: [59]  [100/295]  eta: 0:00:56  lr: 0.001061  min_lr: 0.001061  loss: 2.5954 (2.5126)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0008  max mem: 3719\n",
            "Epoch: [59]  [110/295]  eta: 0:00:53  lr: 0.001058  min_lr: 0.001058  loss: 2.4952 (2.5026)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0007  max mem: 3719\n",
            "Epoch: [59]  [120/295]  eta: 0:00:50  lr: 0.001055  min_lr: 0.001055  loss: 2.4485 (2.5011)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0011  max mem: 3719\n",
            "Epoch: [59]  [130/295]  eta: 0:00:47  lr: 0.001052  min_lr: 0.001052  loss: 2.4543 (2.5051)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0021  max mem: 3719\n",
            "Epoch: [59]  [140/295]  eta: 0:00:43  lr: 0.001048  min_lr: 0.001048  loss: 2.5243 (2.5092)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0023  max mem: 3719\n",
            "Epoch: [59]  [150/295]  eta: 0:00:40  lr: 0.001046  min_lr: 0.001046  loss: 2.5257 (2.5047)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0016  max mem: 3719\n",
            "Epoch: [59]  [160/295]  eta: 0:00:37  lr: 0.001042  min_lr: 0.001042  loss: 2.5257 (2.5098)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0009  max mem: 3719\n",
            "Epoch: [59]  [170/295]  eta: 0:00:34  lr: 0.001039  min_lr: 0.001039  loss: 2.5207 (2.5042)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0019  max mem: 3719\n",
            "Epoch: [59]  [180/295]  eta: 0:00:32  lr: 0.001036  min_lr: 0.001036  loss: 2.4610 (2.5037)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0024  max mem: 3719\n",
            "Epoch: [59]  [190/295]  eta: 0:00:29  lr: 0.001033  min_lr: 0.001033  loss: 2.5458 (2.5046)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0017  max mem: 3719\n",
            "Epoch: [59]  [200/295]  eta: 0:00:26  lr: 0.001029  min_lr: 0.001029  loss: 2.3206 (2.4948)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0021  max mem: 3719\n",
            "Epoch: [59]  [210/295]  eta: 0:00:23  lr: 0.001027  min_lr: 0.001027  loss: 2.3365 (2.4946)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0016  max mem: 3719\n",
            "Epoch: [59]  [220/295]  eta: 0:00:20  lr: 0.001023  min_lr: 0.001023  loss: 2.3920 (2.4906)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0008  max mem: 3719\n",
            "Epoch: [59]  [230/295]  eta: 0:00:17  lr: 0.001021  min_lr: 0.001021  loss: 2.3950 (2.4890)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0024  max mem: 3719\n",
            "Epoch: [59]  [240/295]  eta: 0:00:15  lr: 0.001017  min_lr: 0.001017  loss: 2.5321 (2.4917)  weight_decay: 0.0500 (0.0500)  time: 0.2798  data: 0.0031  max mem: 3719\n",
            "Epoch: [59]  [250/295]  eta: 0:00:12  lr: 0.001014  min_lr: 0.001014  loss: 2.4606 (2.4884)  weight_decay: 0.0500 (0.0500)  time: 0.2813  data: 0.0028  max mem: 3719\n",
            "Epoch: [59]  [260/295]  eta: 0:00:09  lr: 0.001011  min_lr: 0.001011  loss: 2.3841 (2.4880)  weight_decay: 0.0500 (0.0500)  time: 0.2770  data: 0.0034  max mem: 3719\n",
            "Epoch: [59]  [270/295]  eta: 0:00:06  lr: 0.001008  min_lr: 0.001008  loss: 2.5828 (2.4913)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0023  max mem: 3719\n",
            "Epoch: [59]  [280/295]  eta: 0:00:04  lr: 0.001004  min_lr: 0.001004  loss: 2.6037 (2.4949)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0012  max mem: 3719\n",
            "Epoch: [59]  [290/295]  eta: 0:00:01  lr: 0.001002  min_lr: 0.001002  loss: 2.4508 (2.4898)  weight_decay: 0.0500 (0.0500)  time: 0.2570  data: 0.0007  max mem: 3719\n",
            "Epoch: [59]  [294/295]  eta: 0:00:00  lr: 0.001002  min_lr: 0.001002  loss: 2.4508 (2.4907)  weight_decay: 0.0500 (0.0500)  time: 0.2186  data: 0.0003  max mem: 3719\n",
            "Epoch: [59] Total time: 0:01:20 (0.2735 s / it)\n",
            "Averaged stats: lr: 0.001002  min_lr: 0.001002  loss: 2.4508 (2.4907)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:36  loss: 0.6649 (0.6649)  acc1: 83.3333 (83.3333)  acc5: 91.6667 (91.6667)  time: 1.9140  data: 1.7383  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 0.5863 (0.6262)  acc1: 87.5000 (87.1212)  acc5: 97.9167 (97.3485)  time: 0.3910  data: 0.2262  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.5797 (0.6028)  acc1: 89.5833 (88.8889)  acc5: 97.9167 (98.0159)  time: 0.2023  data: 0.0448  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.7207 (0.8770)  acc1: 81.2500 (77.1505)  acc5: 97.9167 (97.1774)  time: 0.1977  data: 0.0246  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 0.7862 (0.8365)  acc1: 79.1667 (78.6077)  acc5: 97.9167 (97.6626)  time: 0.2035  data: 0.0198  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.7862 (0.8518)  acc1: 81.2500 (78.1454)  acc5: 100.0000 (97.8758)  time: 0.1547  data: 0.0043  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8687 (0.8623)  acc1: 75.0000 (77.8347)  acc5: 97.9167 (97.7459)  time: 0.1297  data: 0.0040  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9319 (0.8791)  acc1: 72.9167 (77.0833)  acc5: 95.8333 (97.5646)  time: 0.1228  data: 0.0028  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8327 (0.8586)  acc1: 75.0000 (77.7006)  acc5: 97.9167 (97.6337)  time: 0.1180  data: 0.0006  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8327 (0.8603)  acc1: 75.0000 (77.6051)  acc5: 97.9167 (97.5796)  time: 0.1162  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1891 s / it)\n",
            "* Acc@1 77.605 Acc@5 97.580 loss 0.860\n",
            "Accuracy of the model on the 3925 test images: 77.6%\n",
            "Max accuracy: 77.61%\n",
            "Test:  [ 0/82]  eta: 0:02:04  loss: 2.8952 (2.8952)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 1.5206  data: 1.3640  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 3.0657 (3.0877)  acc1: 12.5000 (12.6894)  acc5: 91.6667 (90.9091)  time: 0.3229  data: 0.1988  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 3.0939 (3.2186)  acc1: 14.5833 (14.0873)  acc5: 91.6667 (88.8889)  time: 0.1788  data: 0.0438  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.8842 (3.7710)  acc1: 8.3333 (10.4839)  acc5: 79.1667 (77.1505)  time: 0.1713  data: 0.0126  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.5365 (3.9143)  acc1: 4.1667 (9.9085)  acc5: 62.5000 (74.0346)  time: 0.1689  data: 0.0115  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.3264 (4.0776)  acc1: 8.3333 (10.6209)  acc5: 62.5000 (70.9559)  time: 0.1676  data: 0.0178  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5633 (4.1942)  acc1: 2.0833 (9.1530)  acc5: 50.0000 (68.9208)  time: 0.1896  data: 0.0372  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.1930 (4.0794)  acc1: 2.0833 (12.4120)  acc5: 77.0833 (68.7500)  time: 0.1593  data: 0.0214  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.5088 (3.7135)  acc1: 54.1667 (19.9331)  acc5: 95.8333 (72.1965)  time: 0.1221  data: 0.0006  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3995 (3.6844)  acc1: 60.4167 (20.4841)  acc5: 95.8333 (72.3567)  time: 0.1197  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1861 s / it)\n",
            "* Acc@1 20.484 Acc@5 72.357 loss 3.684\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [60]  [  0/295]  eta: 0:10:53  lr: 0.001001  min_lr: 0.001001  loss: 2.4252 (2.4252)  weight_decay: 0.0500 (0.0500)  time: 2.2142  data: 1.8816  max mem: 3719\n",
            "Epoch: [60]  [ 10/295]  eta: 0:02:05  lr: 0.000998  min_lr: 0.000998  loss: 2.4111 (2.3747)  weight_decay: 0.0500 (0.0500)  time: 0.4413  data: 0.1732  max mem: 3719\n",
            "Epoch: [60]  [ 20/295]  eta: 0:01:38  lr: 0.000995  min_lr: 0.000995  loss: 2.4111 (2.4256)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0024  max mem: 3719\n",
            "Epoch: [60]  [ 30/295]  eta: 0:01:27  lr: 0.000992  min_lr: 0.000992  loss: 2.6090 (2.4395)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0027  max mem: 3719\n",
            "Epoch: [60]  [ 40/295]  eta: 0:01:20  lr: 0.000988  min_lr: 0.000988  loss: 2.5188 (2.4818)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0024  max mem: 3719\n",
            "Epoch: [60]  [ 50/295]  eta: 0:01:15  lr: 0.000986  min_lr: 0.000986  loss: 2.5025 (2.4490)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0013  max mem: 3719\n",
            "Epoch: [60]  [ 60/295]  eta: 0:01:10  lr: 0.000982  min_lr: 0.000982  loss: 2.3390 (2.4556)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0010  max mem: 3719\n",
            "Epoch: [60]  [ 70/295]  eta: 0:01:06  lr: 0.000980  min_lr: 0.000980  loss: 2.5527 (2.4747)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0010  max mem: 3719\n",
            "Epoch: [60]  [ 80/295]  eta: 0:01:02  lr: 0.000976  min_lr: 0.000976  loss: 2.4576 (2.4636)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0021  max mem: 3719\n",
            "Epoch: [60]  [ 90/295]  eta: 0:00:59  lr: 0.000974  min_lr: 0.000974  loss: 2.3822 (2.4676)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0026  max mem: 3719\n",
            "Epoch: [60]  [100/295]  eta: 0:00:56  lr: 0.000970  min_lr: 0.000970  loss: 2.3976 (2.4671)  weight_decay: 0.0500 (0.0500)  time: 0.2762  data: 0.0025  max mem: 3719\n",
            "Epoch: [60]  [110/295]  eta: 0:00:53  lr: 0.000967  min_lr: 0.000967  loss: 2.5428 (2.4723)  weight_decay: 0.0500 (0.0500)  time: 0.2760  data: 0.0023  max mem: 3719\n",
            "Epoch: [60]  [120/295]  eta: 0:00:49  lr: 0.000964  min_lr: 0.000964  loss: 2.5428 (2.4701)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0012  max mem: 3719\n",
            "Epoch: [60]  [130/295]  eta: 0:00:46  lr: 0.000961  min_lr: 0.000961  loss: 2.4036 (2.4689)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0006  max mem: 3719\n",
            "Epoch: [60]  [140/295]  eta: 0:00:43  lr: 0.000958  min_lr: 0.000958  loss: 2.3834 (2.4606)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0013  max mem: 3719\n",
            "Epoch: [60]  [150/295]  eta: 0:00:40  lr: 0.000955  min_lr: 0.000955  loss: 2.3507 (2.4612)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0013  max mem: 3719\n",
            "Epoch: [60]  [160/295]  eta: 0:00:37  lr: 0.000951  min_lr: 0.000951  loss: 2.4683 (2.4637)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0014  max mem: 3719\n",
            "Epoch: [60]  [170/295]  eta: 0:00:34  lr: 0.000949  min_lr: 0.000949  loss: 2.4683 (2.4627)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0019  max mem: 3719\n",
            "Epoch: [60]  [180/295]  eta: 0:00:31  lr: 0.000945  min_lr: 0.000945  loss: 2.5407 (2.4684)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0011  max mem: 3719\n",
            "Epoch: [60]  [190/295]  eta: 0:00:29  lr: 0.000943  min_lr: 0.000943  loss: 2.6440 (2.4749)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0008  max mem: 3719\n",
            "Epoch: [60]  [200/295]  eta: 0:00:26  lr: 0.000939  min_lr: 0.000939  loss: 2.4582 (2.4719)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0009  max mem: 3719\n",
            "Epoch: [60]  [210/295]  eta: 0:00:23  lr: 0.000937  min_lr: 0.000937  loss: 2.5262 (2.4773)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0009  max mem: 3719\n",
            "Epoch: [60]  [220/295]  eta: 0:00:20  lr: 0.000933  min_lr: 0.000933  loss: 2.6320 (2.4818)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0022  max mem: 3719\n",
            "Epoch: [60]  [230/295]  eta: 0:00:17  lr: 0.000931  min_lr: 0.000931  loss: 2.6442 (2.4835)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0039  max mem: 3719\n",
            "Epoch: [60]  [240/295]  eta: 0:00:15  lr: 0.000927  min_lr: 0.000927  loss: 2.3529 (2.4769)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0038  max mem: 3719\n",
            "Epoch: [60]  [250/295]  eta: 0:00:12  lr: 0.000925  min_lr: 0.000925  loss: 2.4473 (2.4833)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0021  max mem: 3719\n",
            "Epoch: [60]  [260/295]  eta: 0:00:09  lr: 0.000921  min_lr: 0.000921  loss: 2.6200 (2.4885)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0011  max mem: 3719\n",
            "Epoch: [60]  [270/295]  eta: 0:00:06  lr: 0.000919  min_lr: 0.000919  loss: 2.5561 (2.4911)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0011  max mem: 3719\n",
            "Epoch: [60]  [280/295]  eta: 0:00:04  lr: 0.000915  min_lr: 0.000915  loss: 2.4303 (2.4874)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0011  max mem: 3719\n",
            "Epoch: [60]  [290/295]  eta: 0:00:01  lr: 0.000913  min_lr: 0.000913  loss: 2.4303 (2.4850)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0006  max mem: 3719\n",
            "Epoch: [60]  [294/295]  eta: 0:00:00  lr: 0.000913  min_lr: 0.000913  loss: 2.4303 (2.4852)  weight_decay: 0.0500 (0.0500)  time: 0.2224  data: 0.0002  max mem: 3719\n",
            "Epoch: [60] Total time: 0:01:20 (0.2713 s / it)\n",
            "Averaged stats: lr: 0.000913  min_lr: 0.000913  loss: 2.4303 (2.4852)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:15  loss: 0.6813 (0.6813)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 2.3876  data: 2.2234  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 0.6696 (0.6634)  acc1: 89.5833 (87.5000)  acc5: 97.9167 (97.3485)  time: 0.3371  data: 0.2034  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.6182 (0.6362)  acc1: 89.5833 (88.1944)  acc5: 97.9167 (97.8175)  time: 0.1311  data: 0.0022  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6751 (0.8311)  acc1: 85.4167 (79.7043)  acc5: 97.9167 (97.1774)  time: 0.1279  data: 0.0024  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8103 (0.8092)  acc1: 79.1667 (80.5894)  acc5: 97.9167 (97.4594)  time: 0.1242  data: 0.0026  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7823 (0.8046)  acc1: 81.2500 (80.6373)  acc5: 97.9167 (97.5490)  time: 0.1223  data: 0.0035  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8231 (0.8071)  acc1: 79.1667 (80.1571)  acc5: 97.9167 (97.7459)  time: 0.1227  data: 0.0046  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.0319 (0.8578)  acc1: 66.6667 (77.9343)  acc5: 97.9167 (97.3885)  time: 0.1217  data: 0.0033  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0520 (0.8619)  acc1: 68.7500 (77.8807)  acc5: 95.8333 (97.2479)  time: 0.1191  data: 0.0007  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0520 (0.8645)  acc1: 68.7500 (77.8599)  acc5: 95.8333 (97.2229)  time: 0.1172  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1582 s / it)\n",
            "* Acc@1 77.860 Acc@5 97.223 loss 0.865\n",
            "Accuracy of the model on the 3925 test images: 77.9%\n",
            "Max accuracy: 77.86%\n",
            "Test:  [ 0/82]  eta: 0:03:34  loss: 2.8385 (2.8385)  acc1: 16.6667 (16.6667)  acc5: 89.5833 (89.5833)  time: 2.6118  data: 2.4536  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 3.0086 (3.0408)  acc1: 14.5833 (13.0682)  acc5: 91.6667 (91.0985)  time: 0.3715  data: 0.2459  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.0426 (3.1763)  acc1: 14.5833 (14.4841)  acc5: 91.6667 (89.4841)  time: 0.1484  data: 0.0133  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.8457 (3.7303)  acc1: 8.3333 (10.6855)  acc5: 79.1667 (77.3522)  time: 0.1451  data: 0.0010  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.4957 (3.8702)  acc1: 6.2500 (10.2134)  acc5: 64.5833 (74.2886)  time: 0.1523  data: 0.0129  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.2632 (4.0400)  acc1: 8.3333 (10.8660)  acc5: 64.5833 (70.9967)  time: 0.1632  data: 0.0304  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5071 (4.1541)  acc1: 2.0833 (9.3579)  acc5: 47.9167 (68.9891)  time: 0.1651  data: 0.0365  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.1425 (4.0389)  acc1: 2.0833 (12.6467)  acc5: 77.0833 (68.8967)  time: 0.1555  data: 0.0234  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4761 (3.6754)  acc1: 56.2500 (20.2161)  acc5: 95.8333 (72.3251)  time: 0.1419  data: 0.0159  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3688 (3.6465)  acc1: 60.4167 (20.7643)  acc5: 95.8333 (72.4841)  time: 0.1359  data: 0.0139  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1889 s / it)\n",
            "* Acc@1 20.764 Acc@5 72.484 loss 3.647\n",
            "Accuracy of the model EMA on 3925 test images: 20.8%\n",
            "Max EMA accuracy: 20.76%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [61]  [  0/295]  eta: 0:13:14  lr: 0.000911  min_lr: 0.000911  loss: 2.8399 (2.8399)  weight_decay: 0.0500 (0.0500)  time: 2.6939  data: 2.2000  max mem: 3719\n",
            "Epoch: [61]  [ 10/295]  eta: 0:02:17  lr: 0.000909  min_lr: 0.000909  loss: 2.4490 (2.4247)  weight_decay: 0.0500 (0.0500)  time: 0.4833  data: 0.2005  max mem: 3719\n",
            "Epoch: [61]  [ 20/295]  eta: 0:01:43  lr: 0.000905  min_lr: 0.000905  loss: 2.3881 (2.4340)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0004  max mem: 3719\n",
            "Epoch: [61]  [ 30/295]  eta: 0:01:30  lr: 0.000903  min_lr: 0.000903  loss: 2.4374 (2.4461)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0007  max mem: 3719\n",
            "Epoch: [61]  [ 40/295]  eta: 0:01:22  lr: 0.000899  min_lr: 0.000899  loss: 2.5361 (2.4906)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0008  max mem: 3719\n",
            "Epoch: [61]  [ 50/295]  eta: 0:01:16  lr: 0.000897  min_lr: 0.000897  loss: 2.5581 (2.4945)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0031  max mem: 3719\n",
            "Epoch: [61]  [ 60/295]  eta: 0:01:12  lr: 0.000894  min_lr: 0.000894  loss: 2.4846 (2.4849)  weight_decay: 0.0500 (0.0500)  time: 0.2741  data: 0.0034  max mem: 3719\n",
            "Epoch: [61]  [ 70/295]  eta: 0:01:07  lr: 0.000891  min_lr: 0.000891  loss: 2.5141 (2.4869)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0015  max mem: 3719\n",
            "Epoch: [61]  [ 80/295]  eta: 0:01:03  lr: 0.000888  min_lr: 0.000888  loss: 2.5527 (2.4874)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0016  max mem: 3719\n",
            "Epoch: [61]  [ 90/295]  eta: 0:01:00  lr: 0.000885  min_lr: 0.000885  loss: 2.4675 (2.4918)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0015  max mem: 3719\n",
            "Epoch: [61]  [100/295]  eta: 0:00:56  lr: 0.000882  min_lr: 0.000882  loss: 2.5555 (2.4935)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0023  max mem: 3719\n",
            "Epoch: [61]  [110/295]  eta: 0:00:53  lr: 0.000879  min_lr: 0.000879  loss: 2.5173 (2.4849)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0030  max mem: 3719\n",
            "Epoch: [61]  [120/295]  eta: 0:00:50  lr: 0.000876  min_lr: 0.000876  loss: 2.3624 (2.4757)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0036  max mem: 3719\n",
            "Epoch: [61]  [130/295]  eta: 0:00:47  lr: 0.000873  min_lr: 0.000873  loss: 2.3693 (2.4754)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0036  max mem: 3719\n",
            "Epoch: [61]  [140/295]  eta: 0:00:43  lr: 0.000870  min_lr: 0.000870  loss: 2.4518 (2.4710)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0021  max mem: 3719\n",
            "Epoch: [61]  [150/295]  eta: 0:00:40  lr: 0.000867  min_lr: 0.000867  loss: 2.4928 (2.4746)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0006  max mem: 3719\n",
            "Epoch: [61]  [160/295]  eta: 0:00:37  lr: 0.000864  min_lr: 0.000864  loss: 2.5418 (2.4781)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0008  max mem: 3719\n",
            "Epoch: [61]  [170/295]  eta: 0:00:35  lr: 0.000861  min_lr: 0.000861  loss: 2.4603 (2.4766)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0025  max mem: 3719\n",
            "Epoch: [61]  [180/295]  eta: 0:00:32  lr: 0.000858  min_lr: 0.000858  loss: 2.5500 (2.4768)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0029  max mem: 3719\n",
            "Epoch: [61]  [190/295]  eta: 0:00:29  lr: 0.000856  min_lr: 0.000856  loss: 2.6248 (2.4776)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0032  max mem: 3719\n",
            "Epoch: [61]  [200/295]  eta: 0:00:26  lr: 0.000852  min_lr: 0.000852  loss: 2.5730 (2.4818)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0027  max mem: 3719\n",
            "Epoch: [61]  [210/295]  eta: 0:00:23  lr: 0.000850  min_lr: 0.000850  loss: 2.6169 (2.4806)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0007  max mem: 3719\n",
            "Epoch: [61]  [220/295]  eta: 0:00:20  lr: 0.000846  min_lr: 0.000846  loss: 2.5773 (2.4790)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0007  max mem: 3719\n",
            "Epoch: [61]  [230/295]  eta: 0:00:17  lr: 0.000844  min_lr: 0.000844  loss: 2.5285 (2.4829)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0008  max mem: 3719\n",
            "Epoch: [61]  [240/295]  eta: 0:00:15  lr: 0.000840  min_lr: 0.000840  loss: 2.5285 (2.4815)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0014  max mem: 3719\n",
            "Epoch: [61]  [250/295]  eta: 0:00:12  lr: 0.000838  min_lr: 0.000838  loss: 2.5648 (2.4835)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0021  max mem: 3719\n",
            "Epoch: [61]  [260/295]  eta: 0:00:09  lr: 0.000835  min_lr: 0.000835  loss: 2.5648 (2.4837)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0020  max mem: 3719\n",
            "Epoch: [61]  [270/295]  eta: 0:00:06  lr: 0.000832  min_lr: 0.000832  loss: 2.4046 (2.4782)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0021  max mem: 3719\n",
            "Epoch: [61]  [280/295]  eta: 0:00:04  lr: 0.000829  min_lr: 0.000829  loss: 2.3036 (2.4744)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0013  max mem: 3719\n",
            "Epoch: [61]  [290/295]  eta: 0:00:01  lr: 0.000826  min_lr: 0.000826  loss: 2.4399 (2.4730)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0002  max mem: 3719\n",
            "Epoch: [61]  [294/295]  eta: 0:00:00  lr: 0.000826  min_lr: 0.000826  loss: 2.5498 (2.4740)  weight_decay: 0.0500 (0.0500)  time: 0.2199  data: 0.0002  max mem: 3719\n",
            "Epoch: [61] Total time: 0:01:20 (0.2726 s / it)\n",
            "Averaged stats: lr: 0.000826  min_lr: 0.000826  loss: 2.5498 (2.4740)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:06  loss: 0.6505 (0.6505)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.0114  data: 2.8173  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.6505 (0.7024)  acc1: 87.5000 (84.4697)  acc5: 97.9167 (97.7273)  time: 0.4032  data: 0.2602  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.6606 (0.7097)  acc1: 83.3333 (82.9365)  acc5: 97.9167 (97.6191)  time: 0.1324  data: 0.0032  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7578 (0.8230)  acc1: 75.0000 (78.1586)  acc5: 97.9167 (98.0511)  time: 0.1247  data: 0.0019  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7167 (0.7830)  acc1: 79.1667 (79.7764)  acc5: 100.0000 (98.1707)  time: 0.1247  data: 0.0026  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7091 (0.7960)  acc1: 83.3333 (79.1667)  acc5: 97.9167 (97.9984)  time: 0.1226  data: 0.0043  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8093 (0.7999)  acc1: 79.1667 (79.1325)  acc5: 97.9167 (97.9850)  time: 0.1236  data: 0.0054  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.7905 (0.8048)  acc1: 79.1667 (79.0200)  acc5: 97.9167 (97.7993)  time: 0.1220  data: 0.0032  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7561 (0.7928)  acc1: 79.1667 (79.3982)  acc5: 97.9167 (97.8395)  time: 0.1187  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7561 (0.7963)  acc1: 79.1667 (79.3376)  acc5: 97.9167 (97.7834)  time: 0.1170  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1648 s / it)\n",
            "* Acc@1 79.338 Acc@5 97.783 loss 0.796\n",
            "Accuracy of the model on the 3925 test images: 79.3%\n",
            "Max accuracy: 79.34%\n",
            "Test:  [ 0/82]  eta: 0:04:35  loss: 2.7898 (2.7898)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 3.3602  data: 3.1715  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 2.9590 (2.9989)  acc1: 14.5833 (13.4470)  acc5: 91.6667 (91.0985)  time: 0.4342  data: 0.2897  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.9978 (3.1377)  acc1: 14.5833 (14.7817)  acc5: 91.6667 (89.6825)  time: 0.1358  data: 0.0017  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.8053 (3.6925)  acc1: 8.3333 (11.0215)  acc5: 79.1667 (77.6210)  time: 0.1273  data: 0.0032  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.4361 (3.8298)  acc1: 6.2500 (10.5691)  acc5: 64.5833 (74.5427)  time: 0.1242  data: 0.0045  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.2201 (4.0059)  acc1: 10.4167 (11.0703)  acc5: 64.5833 (71.1193)  time: 0.1241  data: 0.0035  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.4588 (4.1182)  acc1: 2.0833 (9.5287)  acc5: 47.9167 (69.0574)  time: 0.1249  data: 0.0038  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.1026 (4.0020)  acc1: 2.0833 (12.7934)  acc5: 77.0833 (68.9554)  time: 0.1228  data: 0.0029  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4416 (3.6405)  acc1: 56.2500 (20.4218)  acc5: 95.8333 (72.3765)  time: 0.1199  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3383 (3.6118)  acc1: 60.4167 (20.9682)  acc5: 95.8333 (72.5350)  time: 0.1185  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1700 s / it)\n",
            "* Acc@1 20.968 Acc@5 72.535 loss 3.612\n",
            "Accuracy of the model EMA on 3925 test images: 21.0%\n",
            "Max EMA accuracy: 20.97%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [62]  [  0/295]  eta: 0:14:16  lr: 0.000825  min_lr: 0.000825  loss: 2.6906 (2.6906)  weight_decay: 0.0500 (0.0500)  time: 2.9036  data: 2.4266  max mem: 3719\n",
            "Epoch: [62]  [ 10/295]  eta: 0:02:40  lr: 0.000823  min_lr: 0.000823  loss: 2.5399 (2.5056)  weight_decay: 0.0500 (0.0500)  time: 0.5641  data: 0.2217  max mem: 3719\n",
            "Epoch: [62]  [ 20/295]  eta: 0:01:55  lr: 0.000819  min_lr: 0.000819  loss: 2.3971 (2.4299)  weight_decay: 0.0500 (0.0500)  time: 0.2972  data: 0.0008  max mem: 3719\n",
            "Epoch: [62]  [ 30/295]  eta: 0:01:38  lr: 0.000817  min_lr: 0.000817  loss: 2.5518 (2.4719)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0006  max mem: 3719\n",
            "Epoch: [62]  [ 40/295]  eta: 0:01:27  lr: 0.000814  min_lr: 0.000814  loss: 2.6547 (2.5092)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0008  max mem: 3719\n",
            "Epoch: [62]  [ 50/295]  eta: 0:01:20  lr: 0.000811  min_lr: 0.000811  loss: 2.5849 (2.4950)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0007  max mem: 3719\n",
            "Epoch: [62]  [ 60/295]  eta: 0:01:15  lr: 0.000808  min_lr: 0.000808  loss: 2.4158 (2.4942)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0018  max mem: 3719\n",
            "Epoch: [62]  [ 70/295]  eta: 0:01:10  lr: 0.000806  min_lr: 0.000806  loss: 2.5157 (2.4937)  weight_decay: 0.0500 (0.0500)  time: 0.2745  data: 0.0036  max mem: 3719\n",
            "Epoch: [62]  [ 80/295]  eta: 0:01:06  lr: 0.000802  min_lr: 0.000802  loss: 2.4782 (2.4887)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0036  max mem: 3719\n",
            "Epoch: [62]  [ 90/295]  eta: 0:01:02  lr: 0.000800  min_lr: 0.000800  loss: 2.4979 (2.5022)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0032  max mem: 3719\n",
            "Epoch: [62]  [100/295]  eta: 0:00:58  lr: 0.000796  min_lr: 0.000796  loss: 2.6173 (2.5142)  weight_decay: 0.0500 (0.0500)  time: 0.2758  data: 0.0036  max mem: 3719\n",
            "Epoch: [62]  [110/295]  eta: 0:00:55  lr: 0.000794  min_lr: 0.000794  loss: 2.5415 (2.5004)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0027  max mem: 3719\n",
            "Epoch: [62]  [120/295]  eta: 0:00:51  lr: 0.000791  min_lr: 0.000791  loss: 2.3357 (2.5021)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0023  max mem: 3719\n",
            "Epoch: [62]  [130/295]  eta: 0:00:48  lr: 0.000788  min_lr: 0.000788  loss: 2.3442 (2.4908)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0035  max mem: 3719\n",
            "Epoch: [62]  [140/295]  eta: 0:00:45  lr: 0.000785  min_lr: 0.000785  loss: 2.3442 (2.4856)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0029  max mem: 3719\n",
            "Epoch: [62]  [150/295]  eta: 0:00:42  lr: 0.000783  min_lr: 0.000783  loss: 2.5045 (2.4890)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0015  max mem: 3719\n",
            "Epoch: [62]  [160/295]  eta: 0:00:38  lr: 0.000779  min_lr: 0.000779  loss: 2.5498 (2.4872)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0008  max mem: 3719\n",
            "Epoch: [62]  [170/295]  eta: 0:00:35  lr: 0.000777  min_lr: 0.000777  loss: 2.4658 (2.4789)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0010  max mem: 3719\n",
            "Epoch: [62]  [180/295]  eta: 0:00:32  lr: 0.000774  min_lr: 0.000774  loss: 2.5038 (2.4821)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0016  max mem: 3719\n",
            "Epoch: [62]  [190/295]  eta: 0:00:29  lr: 0.000771  min_lr: 0.000771  loss: 2.4710 (2.4800)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0019  max mem: 3719\n",
            "Epoch: [62]  [200/295]  eta: 0:00:26  lr: 0.000768  min_lr: 0.000768  loss: 2.3516 (2.4773)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0018  max mem: 3719\n",
            "Epoch: [62]  [210/295]  eta: 0:00:24  lr: 0.000766  min_lr: 0.000766  loss: 2.4077 (2.4762)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0022  max mem: 3719\n",
            "Epoch: [62]  [220/295]  eta: 0:00:21  lr: 0.000762  min_lr: 0.000762  loss: 2.4077 (2.4763)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0025  max mem: 3719\n",
            "Epoch: [62]  [230/295]  eta: 0:00:18  lr: 0.000760  min_lr: 0.000760  loss: 2.4970 (2.4786)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0020  max mem: 3719\n",
            "Epoch: [62]  [240/295]  eta: 0:00:15  lr: 0.000757  min_lr: 0.000757  loss: 2.4880 (2.4782)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0015  max mem: 3719\n",
            "Epoch: [62]  [250/295]  eta: 0:00:12  lr: 0.000754  min_lr: 0.000754  loss: 2.4936 (2.4824)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0028  max mem: 3719\n",
            "Epoch: [62]  [260/295]  eta: 0:00:09  lr: 0.000751  min_lr: 0.000751  loss: 2.4794 (2.4768)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0033  max mem: 3719\n",
            "Epoch: [62]  [270/295]  eta: 0:00:06  lr: 0.000749  min_lr: 0.000749  loss: 2.3425 (2.4722)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0015  max mem: 3719\n",
            "Epoch: [62]  [280/295]  eta: 0:00:04  lr: 0.000746  min_lr: 0.000746  loss: 2.3640 (2.4703)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0007  max mem: 3719\n",
            "Epoch: [62]  [290/295]  eta: 0:00:01  lr: 0.000743  min_lr: 0.000743  loss: 2.4345 (2.4692)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0002  max mem: 3719\n",
            "Epoch: [62]  [294/295]  eta: 0:00:00  lr: 0.000743  min_lr: 0.000743  loss: 2.4345 (2.4674)  weight_decay: 0.0500 (0.0500)  time: 0.2195  data: 0.0002  max mem: 3719\n",
            "Epoch: [62] Total time: 0:01:21 (0.2756 s / it)\n",
            "Averaged stats: lr: 0.000743  min_lr: 0.000743  loss: 2.4345 (2.4674)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:59  loss: 0.5753 (0.5753)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.1857  data: 2.0241  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.5753 (0.6088)  acc1: 87.5000 (86.1742)  acc5: 97.9167 (97.7273)  time: 0.3735  data: 0.2229  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.5905 (0.6164)  acc1: 85.4167 (85.2183)  acc5: 97.9167 (98.1151)  time: 0.1789  data: 0.0291  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.7372 (0.7874)  acc1: 77.0833 (78.8979)  acc5: 97.9167 (97.8495)  time: 0.1717  data: 0.0233  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7887 (0.7698)  acc1: 79.1667 (80.1321)  acc5: 97.9167 (98.0691)  time: 0.1726  data: 0.0265  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7887 (0.8239)  acc1: 79.1667 (77.9003)  acc5: 97.9167 (97.9984)  time: 0.1468  data: 0.0117  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8402 (0.8207)  acc1: 75.0000 (78.2445)  acc5: 97.9167 (97.7801)  time: 0.1259  data: 0.0014  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8031 (0.8282)  acc1: 79.1667 (78.0223)  acc5: 95.8333 (97.6526)  time: 0.1229  data: 0.0007  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7602 (0.8054)  acc1: 79.1667 (78.8837)  acc5: 97.9167 (97.7881)  time: 0.1195  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7602 (0.8070)  acc1: 79.1667 (78.8535)  acc5: 97.9167 (97.7325)  time: 0.1183  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1784 s / it)\n",
            "* Acc@1 78.854 Acc@5 97.732 loss 0.807\n",
            "Accuracy of the model on the 3925 test images: 78.9%\n",
            "Max accuracy: 79.34%\n",
            "Test:  [ 0/82]  eta: 0:02:25  loss: 2.7436 (2.7436)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 1.7696  data: 1.6037  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.9111 (2.9586)  acc1: 12.5000 (13.4470)  acc5: 91.6667 (91.0985)  time: 0.2886  data: 0.1655  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.9557 (3.1002)  acc1: 12.5000 (14.9802)  acc5: 91.6667 (89.7817)  time: 0.1329  data: 0.0137  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.7648 (3.6555)  acc1: 8.3333 (11.1559)  acc5: 79.1667 (77.8226)  time: 0.1329  data: 0.0037  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.3753 (3.7896)  acc1: 6.2500 (10.7215)  acc5: 64.5833 (74.8476)  time: 0.1416  data: 0.0016  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.2261 (3.9719)  acc1: 8.3333 (10.9477)  acc5: 64.5833 (71.2827)  time: 0.1472  data: 0.0028  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.4189 (4.0837)  acc1: 2.0833 (9.3921)  acc5: 45.8333 (69.1940)  time: 0.1666  data: 0.0202  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.0724 (3.9671)  acc1: 2.0833 (12.7054)  acc5: 75.0000 (69.0434)  time: 0.1720  data: 0.0282  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4111 (3.6074)  acc1: 56.2500 (20.3961)  acc5: 95.8333 (72.4537)  time: 0.1445  data: 0.0129  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3117 (3.5788)  acc1: 64.5833 (20.9427)  acc5: 95.8333 (72.6115)  time: 0.1372  data: 0.0080  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1707 s / it)\n",
            "* Acc@1 20.943 Acc@5 72.611 loss 3.579\n",
            "Accuracy of the model EMA on 3925 test images: 20.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [63]  [  0/295]  eta: 0:08:44  lr: 0.000742  min_lr: 0.000742  loss: 2.7366 (2.7366)  weight_decay: 0.0500 (0.0500)  time: 1.7781  data: 1.3816  max mem: 3719\n",
            "Epoch: [63]  [ 10/295]  eta: 0:01:57  lr: 0.000740  min_lr: 0.000740  loss: 2.5111 (2.4549)  weight_decay: 0.0500 (0.0500)  time: 0.4122  data: 0.1278  max mem: 3719\n",
            "Epoch: [63]  [ 20/295]  eta: 0:01:34  lr: 0.000737  min_lr: 0.000737  loss: 2.4446 (2.4812)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0016  max mem: 3719\n",
            "Epoch: [63]  [ 30/295]  eta: 0:01:24  lr: 0.000734  min_lr: 0.000734  loss: 2.4572 (2.4812)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0010  max mem: 3719\n",
            "Epoch: [63]  [ 40/295]  eta: 0:01:18  lr: 0.000731  min_lr: 0.000731  loss: 2.4743 (2.4793)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0015  max mem: 3719\n",
            "Epoch: [63]  [ 50/295]  eta: 0:01:13  lr: 0.000729  min_lr: 0.000729  loss: 2.4743 (2.4666)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0021  max mem: 3719\n",
            "Epoch: [63]  [ 60/295]  eta: 0:01:09  lr: 0.000726  min_lr: 0.000726  loss: 2.4555 (2.4697)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0015  max mem: 3719\n",
            "Epoch: [63]  [ 70/295]  eta: 0:01:05  lr: 0.000723  min_lr: 0.000723  loss: 2.4555 (2.4507)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0009  max mem: 3719\n",
            "Epoch: [63]  [ 80/295]  eta: 0:01:01  lr: 0.000720  min_lr: 0.000720  loss: 2.4971 (2.4618)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0008  max mem: 3719\n",
            "Epoch: [63]  [ 90/295]  eta: 0:00:58  lr: 0.000718  min_lr: 0.000718  loss: 2.4411 (2.4577)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0014  max mem: 3719\n",
            "Epoch: [63]  [100/295]  eta: 0:00:55  lr: 0.000715  min_lr: 0.000715  loss: 2.4192 (2.4641)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0035  max mem: 3719\n",
            "Epoch: [63]  [110/295]  eta: 0:00:52  lr: 0.000712  min_lr: 0.000712  loss: 2.4628 (2.4563)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0056  max mem: 3719\n",
            "Epoch: [63]  [120/295]  eta: 0:00:49  lr: 0.000709  min_lr: 0.000709  loss: 2.4628 (2.4659)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0049  max mem: 3719\n",
            "Epoch: [63]  [130/295]  eta: 0:00:46  lr: 0.000707  min_lr: 0.000707  loss: 2.5132 (2.4596)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0023  max mem: 3719\n",
            "Epoch: [63]  [140/295]  eta: 0:00:43  lr: 0.000704  min_lr: 0.000704  loss: 2.5141 (2.4613)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0017  max mem: 3719\n",
            "Epoch: [63]  [150/295]  eta: 0:00:40  lr: 0.000701  min_lr: 0.000701  loss: 2.5185 (2.4595)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0017  max mem: 3719\n",
            "Epoch: [63]  [160/295]  eta: 0:00:37  lr: 0.000698  min_lr: 0.000698  loss: 2.3281 (2.4535)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0033  max mem: 3719\n",
            "Epoch: [63]  [170/295]  eta: 0:00:34  lr: 0.000696  min_lr: 0.000696  loss: 2.3281 (2.4526)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0047  max mem: 3719\n",
            "Epoch: [63]  [180/295]  eta: 0:00:31  lr: 0.000693  min_lr: 0.000693  loss: 2.5994 (2.4579)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0046  max mem: 3719\n",
            "Epoch: [63]  [190/295]  eta: 0:00:28  lr: 0.000691  min_lr: 0.000691  loss: 2.5906 (2.4598)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0032  max mem: 3719\n",
            "Epoch: [63]  [200/295]  eta: 0:00:26  lr: 0.000687  min_lr: 0.000687  loss: 2.4792 (2.4590)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0013  max mem: 3719\n",
            "Epoch: [63]  [210/295]  eta: 0:00:23  lr: 0.000685  min_lr: 0.000685  loss: 2.5532 (2.4639)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0015  max mem: 3719\n",
            "Epoch: [63]  [220/295]  eta: 0:00:20  lr: 0.000682  min_lr: 0.000682  loss: 2.5588 (2.4647)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0017  max mem: 3719\n",
            "Epoch: [63]  [230/295]  eta: 0:00:17  lr: 0.000680  min_lr: 0.000680  loss: 2.5443 (2.4683)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0036  max mem: 3719\n",
            "Epoch: [63]  [240/295]  eta: 0:00:15  lr: 0.000676  min_lr: 0.000676  loss: 2.5168 (2.4669)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0046  max mem: 3719\n",
            "Epoch: [63]  [250/295]  eta: 0:00:12  lr: 0.000674  min_lr: 0.000674  loss: 2.4409 (2.4618)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0034  max mem: 3719\n",
            "Epoch: [63]  [260/295]  eta: 0:00:09  lr: 0.000671  min_lr: 0.000671  loss: 2.4187 (2.4617)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0027  max mem: 3719\n",
            "Epoch: [63]  [270/295]  eta: 0:00:06  lr: 0.000669  min_lr: 0.000669  loss: 2.4278 (2.4599)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0022  max mem: 3719\n",
            "Epoch: [63]  [280/295]  eta: 0:00:04  lr: 0.000666  min_lr: 0.000666  loss: 2.4321 (2.4599)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0017  max mem: 3719\n",
            "Epoch: [63]  [290/295]  eta: 0:00:01  lr: 0.000664  min_lr: 0.000664  loss: 2.3590 (2.4537)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0006  max mem: 3719\n",
            "Epoch: [63]  [294/295]  eta: 0:00:00  lr: 0.000664  min_lr: 0.000664  loss: 2.3590 (2.4549)  weight_decay: 0.0500 (0.0500)  time: 0.2201  data: 0.0002  max mem: 3719\n",
            "Epoch: [63] Total time: 0:01:19 (0.2711 s / it)\n",
            "Averaged stats: lr: 0.000664  min_lr: 0.000664  loss: 2.3590 (2.4549)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:56  loss: 0.6069 (0.6069)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.1578  data: 1.9928  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 0.5645 (0.5991)  acc1: 89.5833 (87.1212)  acc5: 97.9167 (97.7273)  time: 0.3336  data: 0.2096  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5808 (0.6175)  acc1: 87.5000 (86.7064)  acc5: 97.9167 (98.1151)  time: 0.1369  data: 0.0165  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.7495 (0.7872)  acc1: 79.1667 (79.6371)  acc5: 97.9167 (97.9839)  time: 0.1221  data: 0.0014  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8676 (0.7849)  acc1: 77.0833 (80.2846)  acc5: 97.9167 (98.1707)  time: 0.1222  data: 0.0017  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7814 (0.7889)  acc1: 79.1667 (80.2696)  acc5: 97.9167 (98.1618)  time: 0.1237  data: 0.0030  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7516 (0.7909)  acc1: 81.2500 (80.1913)  acc5: 97.9167 (98.0191)  time: 0.1243  data: 0.0050  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8202 (0.8020)  acc1: 79.1667 (79.6362)  acc5: 97.9167 (97.9167)  time: 0.1215  data: 0.0032  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6720 (0.7717)  acc1: 85.4167 (80.7870)  acc5: 97.9167 (98.0453)  time: 0.1181  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6720 (0.7720)  acc1: 85.4167 (80.7643)  acc5: 97.9167 (97.9873)  time: 0.1160  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1573 s / it)\n",
            "* Acc@1 80.764 Acc@5 97.987 loss 0.772\n",
            "Accuracy of the model on the 3925 test images: 80.8%\n",
            "Max accuracy: 80.76%\n",
            "Test:  [ 0/82]  eta: 0:03:35  loss: 2.6981 (2.6981)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 2.6249  data: 2.4353  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 2.8628 (2.9180)  acc1: 12.5000 (13.6364)  acc5: 91.6667 (91.2879)  time: 0.3793  data: 0.2298  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 2.9095 (3.0627)  acc1: 12.5000 (14.9802)  acc5: 91.6667 (90.2778)  time: 0.1425  data: 0.0099  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.7265 (3.6178)  acc1: 8.3333 (11.1559)  acc5: 79.1667 (78.3602)  time: 0.1270  data: 0.0078  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.3093 (3.7480)  acc1: 6.2500 (10.7724)  acc5: 64.5833 (75.3049)  time: 0.1223  data: 0.0035  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.2331 (3.9363)  acc1: 10.4167 (10.9477)  acc5: 64.5833 (71.5278)  time: 0.1220  data: 0.0028  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.3720 (4.0466)  acc1: 2.0833 (9.3921)  acc5: 45.8333 (69.3648)  time: 0.1238  data: 0.0043  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.0263 (3.9300)  acc1: 2.0833 (12.8228)  acc5: 75.0000 (69.2195)  time: 0.1212  data: 0.0026  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3837 (3.5724)  acc1: 56.2500 (20.5247)  acc5: 95.8333 (72.6337)  time: 0.1181  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2878 (3.5441)  acc1: 64.5833 (21.0701)  acc5: 95.8333 (72.7898)  time: 0.1168  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1619 s / it)\n",
            "* Acc@1 21.070 Acc@5 72.790 loss 3.544\n",
            "Accuracy of the model EMA on 3925 test images: 21.1%\n",
            "Max EMA accuracy: 21.07%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [64]  [  0/295]  eta: 0:14:42  lr: 0.000663  min_lr: 0.000663  loss: 2.1369 (2.1369)  weight_decay: 0.0500 (0.0500)  time: 2.9915  data: 2.4905  max mem: 3719\n",
            "Epoch: [64]  [ 10/295]  eta: 0:02:36  lr: 0.000660  min_lr: 0.000660  loss: 2.4841 (2.3802)  weight_decay: 0.0500 (0.0500)  time: 0.5501  data: 0.2308  max mem: 3719\n",
            "Epoch: [64]  [ 20/295]  eta: 0:01:53  lr: 0.000657  min_lr: 0.000657  loss: 2.4841 (2.4513)  weight_decay: 0.0500 (0.0500)  time: 0.2843  data: 0.0031  max mem: 3719\n",
            "Epoch: [64]  [ 30/295]  eta: 0:01:36  lr: 0.000655  min_lr: 0.000655  loss: 2.4532 (2.4384)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0016  max mem: 3719\n",
            "Epoch: [64]  [ 40/295]  eta: 0:01:26  lr: 0.000652  min_lr: 0.000652  loss: 2.4951 (2.4306)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0014  max mem: 3719\n",
            "Epoch: [64]  [ 50/295]  eta: 0:01:19  lr: 0.000650  min_lr: 0.000650  loss: 2.2962 (2.4123)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0012  max mem: 3719\n",
            "Epoch: [64]  [ 60/295]  eta: 0:01:14  lr: 0.000647  min_lr: 0.000647  loss: 2.2917 (2.4139)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0018  max mem: 3719\n",
            "Epoch: [64]  [ 70/295]  eta: 0:01:10  lr: 0.000645  min_lr: 0.000645  loss: 2.4571 (2.4230)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0022  max mem: 3719\n",
            "Epoch: [64]  [ 80/295]  eta: 0:01:05  lr: 0.000641  min_lr: 0.000641  loss: 2.5459 (2.4344)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0023  max mem: 3719\n",
            "Epoch: [64]  [ 90/295]  eta: 0:01:02  lr: 0.000639  min_lr: 0.000639  loss: 2.5459 (2.4396)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0023  max mem: 3719\n",
            "Epoch: [64]  [100/295]  eta: 0:00:58  lr: 0.000636  min_lr: 0.000636  loss: 2.4576 (2.4463)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0021  max mem: 3719\n",
            "Epoch: [64]  [110/295]  eta: 0:00:54  lr: 0.000634  min_lr: 0.000634  loss: 2.4305 (2.4413)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0028  max mem: 3719\n",
            "Epoch: [64]  [120/295]  eta: 0:00:51  lr: 0.000631  min_lr: 0.000631  loss: 2.3276 (2.4364)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0041  max mem: 3719\n",
            "Epoch: [64]  [130/295]  eta: 0:00:48  lr: 0.000629  min_lr: 0.000629  loss: 2.4231 (2.4368)  weight_decay: 0.0500 (0.0500)  time: 0.2745  data: 0.0048  max mem: 3719\n",
            "Epoch: [64]  [140/295]  eta: 0:00:45  lr: 0.000626  min_lr: 0.000626  loss: 2.5686 (2.4429)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0029  max mem: 3719\n",
            "Epoch: [64]  [150/295]  eta: 0:00:41  lr: 0.000624  min_lr: 0.000624  loss: 2.4105 (2.4387)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0009  max mem: 3719\n",
            "Epoch: [64]  [160/295]  eta: 0:00:38  lr: 0.000620  min_lr: 0.000620  loss: 2.4105 (2.4400)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0009  max mem: 3719\n",
            "Epoch: [64]  [170/295]  eta: 0:00:35  lr: 0.000618  min_lr: 0.000618  loss: 2.4924 (2.4425)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0018  max mem: 3719\n",
            "Epoch: [64]  [180/295]  eta: 0:00:32  lr: 0.000615  min_lr: 0.000615  loss: 2.5339 (2.4470)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0014  max mem: 3719\n",
            "Epoch: [64]  [190/295]  eta: 0:00:29  lr: 0.000613  min_lr: 0.000613  loss: 2.4752 (2.4417)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0034  max mem: 3719\n",
            "Epoch: [64]  [200/295]  eta: 0:00:26  lr: 0.000610  min_lr: 0.000610  loss: 2.4092 (2.4414)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0053  max mem: 3719\n",
            "Epoch: [64]  [210/295]  eta: 0:00:23  lr: 0.000608  min_lr: 0.000608  loss: 2.5625 (2.4446)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0031  max mem: 3719\n",
            "Epoch: [64]  [220/295]  eta: 0:00:21  lr: 0.000605  min_lr: 0.000605  loss: 2.4638 (2.4398)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0024  max mem: 3719\n",
            "Epoch: [64]  [230/295]  eta: 0:00:18  lr: 0.000603  min_lr: 0.000603  loss: 2.4635 (2.4427)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0019  max mem: 3719\n",
            "Epoch: [64]  [240/295]  eta: 0:00:15  lr: 0.000600  min_lr: 0.000600  loss: 2.5316 (2.4410)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0018  max mem: 3719\n",
            "Epoch: [64]  [250/295]  eta: 0:00:12  lr: 0.000598  min_lr: 0.000598  loss: 2.3803 (2.4369)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0035  max mem: 3719\n",
            "Epoch: [64]  [260/295]  eta: 0:00:09  lr: 0.000595  min_lr: 0.000595  loss: 2.3966 (2.4397)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0051  max mem: 3719\n",
            "Epoch: [64]  [270/295]  eta: 0:00:06  lr: 0.000593  min_lr: 0.000593  loss: 2.4441 (2.4368)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0036  max mem: 3719\n",
            "Epoch: [64]  [280/295]  eta: 0:00:04  lr: 0.000590  min_lr: 0.000590  loss: 2.2968 (2.4337)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0009  max mem: 3719\n",
            "Epoch: [64]  [290/295]  eta: 0:00:01  lr: 0.000588  min_lr: 0.000588  loss: 2.5063 (2.4373)  weight_decay: 0.0500 (0.0500)  time: 0.2554  data: 0.0003  max mem: 3719\n",
            "Epoch: [64]  [294/295]  eta: 0:00:00  lr: 0.000588  min_lr: 0.000588  loss: 2.5063 (2.4373)  weight_decay: 0.0500 (0.0500)  time: 0.2178  data: 0.0003  max mem: 3719\n",
            "Epoch: [64] Total time: 0:01:21 (0.2747 s / it)\n",
            "Averaged stats: lr: 0.000588  min_lr: 0.000588  loss: 2.5063 (2.4373)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:10  loss: 0.5553 (0.5553)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 3.0534  data: 2.8844  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.5553 (0.5716)  acc1: 87.5000 (87.6894)  acc5: 97.9167 (98.4849)  time: 0.4391  data: 0.2907  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.5770 (0.6032)  acc1: 87.5000 (87.3016)  acc5: 97.9167 (98.4127)  time: 0.1778  data: 0.0258  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.7408 (0.8115)  acc1: 77.0833 (78.6962)  acc5: 97.9167 (98.1183)  time: 0.1600  data: 0.0112  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7986 (0.7881)  acc1: 77.0833 (79.9797)  acc5: 97.9167 (98.2215)  time: 0.1324  data: 0.0018  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6821 (0.7719)  acc1: 83.3333 (80.6373)  acc5: 100.0000 (98.3252)  time: 0.1247  data: 0.0030  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7246 (0.7804)  acc1: 81.2500 (80.4645)  acc5: 97.9167 (98.1557)  time: 0.1262  data: 0.0042  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.7776 (0.7888)  acc1: 79.1667 (80.2524)  acc5: 97.9167 (97.9460)  time: 0.1223  data: 0.0024  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7591 (0.7839)  acc1: 79.1667 (80.4270)  acc5: 97.9167 (97.9424)  time: 0.1187  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7591 (0.7885)  acc1: 79.1667 (80.3057)  acc5: 97.9167 (97.8854)  time: 0.1170  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1788 s / it)\n",
            "* Acc@1 80.306 Acc@5 97.885 loss 0.788\n",
            "Accuracy of the model on the 3925 test images: 80.3%\n",
            "Max accuracy: 80.76%\n",
            "Test:  [ 0/82]  eta: 0:02:48  loss: 2.6545 (2.6545)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 2.0510  data: 1.8628  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 2.8188 (2.8807)  acc1: 12.5000 (13.6364)  acc5: 91.6667 (91.6667)  time: 0.3160  data: 0.1727  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 2.8690 (3.0278)  acc1: 12.5000 (15.0794)  acc5: 91.6667 (90.9722)  time: 0.1545  data: 0.0143  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.6898 (3.5829)  acc1: 8.3333 (11.1559)  acc5: 81.2500 (78.8979)  time: 0.1913  data: 0.0437  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.2424 (3.7087)  acc1: 8.3333 (10.8740)  acc5: 64.5833 (75.8638)  time: 0.2135  data: 0.0594  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 4.2380 (3.9023)  acc1: 10.4167 (11.0294)  acc5: 64.5833 (71.9363)  time: 0.2072  data: 0.0478  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.3249 (4.0108)  acc1: 2.0833 (9.4604)  acc5: 45.8333 (69.7746)  time: 0.1934  data: 0.0252  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.9799 (3.8938)  acc1: 2.0833 (12.9401)  acc5: 77.0833 (69.6596)  time: 0.1721  data: 0.0084  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3544 (3.5384)  acc1: 58.3333 (20.6276)  acc5: 95.8333 (73.0195)  time: 0.1397  data: 0.0029  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2608 (3.5103)  acc1: 64.5833 (21.1720)  acc5: 95.8333 (73.1720)  time: 0.1366  data: 0.0029  max mem: 3719\n",
            "Test: Total time: 0:00:16 (0.2031 s / it)\n",
            "* Acc@1 21.172 Acc@5 73.172 loss 3.510\n",
            "Accuracy of the model EMA on 3925 test images: 21.2%\n",
            "Max EMA accuracy: 21.17%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [65]  [  0/295]  eta: 0:09:29  lr: 0.000587  min_lr: 0.000587  loss: 2.5238 (2.5238)  weight_decay: 0.0500 (0.0500)  time: 1.9298  data: 1.5165  max mem: 3719\n",
            "Epoch: [65]  [ 10/295]  eta: 0:02:00  lr: 0.000585  min_lr: 0.000585  loss: 2.5240 (2.5136)  weight_decay: 0.0500 (0.0500)  time: 0.4240  data: 0.1401  max mem: 3719\n",
            "Epoch: [65]  [ 20/295]  eta: 0:01:35  lr: 0.000582  min_lr: 0.000582  loss: 2.5306 (2.5384)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0015  max mem: 3719\n",
            "Epoch: [65]  [ 30/295]  eta: 0:01:25  lr: 0.000580  min_lr: 0.000580  loss: 2.5714 (2.5330)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0017  max mem: 3719\n",
            "Epoch: [65]  [ 40/295]  eta: 0:01:19  lr: 0.000577  min_lr: 0.000577  loss: 2.5354 (2.5519)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0024  max mem: 3719\n",
            "Epoch: [65]  [ 50/295]  eta: 0:01:14  lr: 0.000575  min_lr: 0.000575  loss: 2.5256 (2.5284)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0018  max mem: 3719\n",
            "Epoch: [65]  [ 60/295]  eta: 0:01:09  lr: 0.000572  min_lr: 0.000572  loss: 2.4100 (2.5179)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0016  max mem: 3719\n",
            "Epoch: [65]  [ 70/295]  eta: 0:01:05  lr: 0.000570  min_lr: 0.000570  loss: 2.5447 (2.5186)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0016  max mem: 3719\n",
            "Epoch: [65]  [ 80/295]  eta: 0:01:01  lr: 0.000567  min_lr: 0.000567  loss: 2.5342 (2.5024)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0012  max mem: 3719\n",
            "Epoch: [65]  [ 90/295]  eta: 0:00:58  lr: 0.000565  min_lr: 0.000565  loss: 2.4210 (2.4937)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0005  max mem: 3719\n",
            "Epoch: [65]  [100/295]  eta: 0:00:55  lr: 0.000562  min_lr: 0.000562  loss: 2.4690 (2.4860)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0016  max mem: 3719\n",
            "Epoch: [65]  [110/295]  eta: 0:00:52  lr: 0.000560  min_lr: 0.000560  loss: 2.4372 (2.4807)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0028  max mem: 3719\n",
            "Epoch: [65]  [120/295]  eta: 0:00:49  lr: 0.000557  min_lr: 0.000557  loss: 2.4291 (2.4750)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0021  max mem: 3719\n",
            "Epoch: [65]  [130/295]  eta: 0:00:46  lr: 0.000555  min_lr: 0.000555  loss: 2.4209 (2.4743)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0012  max mem: 3719\n",
            "Epoch: [65]  [140/295]  eta: 0:00:43  lr: 0.000552  min_lr: 0.000552  loss: 2.4372 (2.4718)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0010  max mem: 3719\n",
            "Epoch: [65]  [150/295]  eta: 0:00:40  lr: 0.000550  min_lr: 0.000550  loss: 2.4084 (2.4686)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0011  max mem: 3719\n",
            "Epoch: [65]  [160/295]  eta: 0:00:37  lr: 0.000547  min_lr: 0.000547  loss: 2.4780 (2.4674)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0013  max mem: 3719\n",
            "Epoch: [65]  [170/295]  eta: 0:00:34  lr: 0.000545  min_lr: 0.000545  loss: 2.5138 (2.4713)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0016  max mem: 3719\n",
            "Epoch: [65]  [180/295]  eta: 0:00:31  lr: 0.000542  min_lr: 0.000542  loss: 2.5756 (2.4753)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0014  max mem: 3719\n",
            "Epoch: [65]  [190/295]  eta: 0:00:28  lr: 0.000540  min_lr: 0.000540  loss: 2.6029 (2.4844)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0011  max mem: 3719\n",
            "Epoch: [65]  [200/295]  eta: 0:00:26  lr: 0.000537  min_lr: 0.000537  loss: 2.5471 (2.4707)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0008  max mem: 3719\n",
            "Epoch: [65]  [210/295]  eta: 0:00:23  lr: 0.000535  min_lr: 0.000535  loss: 2.3907 (2.4750)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0016  max mem: 3719\n",
            "Epoch: [65]  [220/295]  eta: 0:00:20  lr: 0.000532  min_lr: 0.000532  loss: 2.5346 (2.4739)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0023  max mem: 3719\n",
            "Epoch: [65]  [230/295]  eta: 0:00:17  lr: 0.000530  min_lr: 0.000530  loss: 2.4718 (2.4734)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0012  max mem: 3719\n",
            "Epoch: [65]  [240/295]  eta: 0:00:14  lr: 0.000527  min_lr: 0.000527  loss: 2.3856 (2.4681)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0014  max mem: 3719\n",
            "Epoch: [65]  [250/295]  eta: 0:00:12  lr: 0.000525  min_lr: 0.000525  loss: 2.3322 (2.4613)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0020  max mem: 3719\n",
            "Epoch: [65]  [260/295]  eta: 0:00:09  lr: 0.000522  min_lr: 0.000522  loss: 2.4635 (2.4611)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0016  max mem: 3719\n",
            "Epoch: [65]  [270/295]  eta: 0:00:06  lr: 0.000520  min_lr: 0.000520  loss: 2.5695 (2.4612)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0015  max mem: 3719\n",
            "Epoch: [65]  [280/295]  eta: 0:00:04  lr: 0.000517  min_lr: 0.000517  loss: 2.3605 (2.4588)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0012  max mem: 3719\n",
            "Epoch: [65]  [290/295]  eta: 0:00:01  lr: 0.000516  min_lr: 0.000516  loss: 2.4637 (2.4570)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0005  max mem: 3719\n",
            "Epoch: [65]  [294/295]  eta: 0:00:00  lr: 0.000516  min_lr: 0.000516  loss: 2.3654 (2.4567)  weight_decay: 0.0500 (0.0500)  time: 0.2236  data: 0.0002  max mem: 3719\n",
            "Epoch: [65] Total time: 0:01:19 (0.2698 s / it)\n",
            "Averaged stats: lr: 0.000516  min_lr: 0.000516  loss: 2.3654 (2.4567)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:38  loss: 0.5878 (0.5878)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 1.9322  data: 1.7668  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.5595 (0.5922)  acc1: 87.5000 (86.3636)  acc5: 97.9167 (98.1061)  time: 0.2865  data: 0.1616  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.5876 (0.6324)  acc1: 85.4167 (85.8135)  acc5: 97.9167 (98.1151)  time: 0.1223  data: 0.0023  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.7989 (0.8023)  acc1: 79.1667 (78.6962)  acc5: 97.9167 (98.1183)  time: 0.1229  data: 0.0031  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7688 (0.7754)  acc1: 79.1667 (80.0305)  acc5: 97.9167 (98.2724)  time: 0.1232  data: 0.0021  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7562 (0.7758)  acc1: 83.3333 (80.6373)  acc5: 100.0000 (98.1618)  time: 0.1268  data: 0.0052  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.6791 (0.7639)  acc1: 83.3333 (80.9768)  acc5: 97.9167 (98.2240)  time: 0.1270  data: 0.0061  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.7376 (0.7708)  acc1: 83.3333 (80.8392)  acc5: 97.9167 (98.2394)  time: 0.1216  data: 0.0018  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6953 (0.7585)  acc1: 79.1667 (81.2243)  acc5: 97.9167 (98.1996)  time: 0.1190  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6953 (0.7612)  acc1: 79.1667 (81.1210)  acc5: 97.9167 (98.1401)  time: 0.1175  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1515 s / it)\n",
            "* Acc@1 81.121 Acc@5 98.140 loss 0.761\n",
            "Accuracy of the model on the 3925 test images: 81.1%\n",
            "Max accuracy: 81.12%\n",
            "Test:  [ 0/82]  eta: 0:03:44  loss: 2.6115 (2.6115)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 2.7362  data: 2.5511  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 2.7756 (2.8436)  acc1: 12.5000 (14.0152)  acc5: 91.6667 (91.6667)  time: 0.3634  data: 0.2344  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 2.8389 (2.9930)  acc1: 14.5833 (15.4762)  acc5: 91.6667 (90.9722)  time: 0.1244  data: 0.0027  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 3.6515 (3.5487)  acc1: 8.3333 (11.4247)  acc5: 81.2500 (78.8979)  time: 0.1227  data: 0.0021  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.1786 (3.6703)  acc1: 8.3333 (11.0772)  acc5: 66.6667 (76.0163)  time: 0.1231  data: 0.0017  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.1786 (3.8695)  acc1: 10.4167 (11.1520)  acc5: 66.6667 (71.9363)  time: 0.1235  data: 0.0033  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2836 (3.9771)  acc1: 2.0833 (9.5628)  acc5: 45.8333 (69.7746)  time: 0.1223  data: 0.0051  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.9400 (3.8597)  acc1: 2.0833 (13.0575)  acc5: 75.0000 (69.6303)  time: 0.1205  data: 0.0031  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3261 (3.5064)  acc1: 58.3333 (20.7305)  acc5: 95.8333 (73.0453)  time: 0.1193  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2345 (3.4785)  acc1: 64.5833 (21.2739)  acc5: 95.8333 (73.1975)  time: 0.1171  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1615 s / it)\n",
            "* Acc@1 21.274 Acc@5 73.197 loss 3.478\n",
            "Accuracy of the model EMA on 3925 test images: 21.3%\n",
            "Max EMA accuracy: 21.27%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [66]  [  0/295]  eta: 0:14:38  lr: 0.000515  min_lr: 0.000515  loss: 2.7698 (2.7698)  weight_decay: 0.0500 (0.0500)  time: 2.9784  data: 2.2629  max mem: 3719\n",
            "Epoch: [66]  [ 10/295]  eta: 0:02:34  lr: 0.000513  min_lr: 0.000513  loss: 2.5593 (2.4328)  weight_decay: 0.0500 (0.0500)  time: 0.5405  data: 0.2070  max mem: 3719\n",
            "Epoch: [66]  [ 20/295]  eta: 0:01:52  lr: 0.000510  min_lr: 0.000510  loss: 2.3153 (2.3868)  weight_decay: 0.0500 (0.0500)  time: 0.2801  data: 0.0018  max mem: 3719\n",
            "Epoch: [66]  [ 30/295]  eta: 0:01:35  lr: 0.000508  min_lr: 0.000508  loss: 2.4171 (2.4089)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0015  max mem: 3719\n",
            "Epoch: [66]  [ 40/295]  eta: 0:01:25  lr: 0.000505  min_lr: 0.000505  loss: 2.3578 (2.3682)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0007  max mem: 3719\n",
            "Epoch: [66]  [ 50/295]  eta: 0:01:19  lr: 0.000503  min_lr: 0.000503  loss: 2.3349 (2.3881)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0008  max mem: 3719\n",
            "Epoch: [66]  [ 60/295]  eta: 0:01:14  lr: 0.000500  min_lr: 0.000500  loss: 2.5763 (2.3845)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0020  max mem: 3719\n",
            "Epoch: [66]  [ 70/295]  eta: 0:01:09  lr: 0.000498  min_lr: 0.000498  loss: 2.3742 (2.3846)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0021  max mem: 3719\n",
            "Epoch: [66]  [ 80/295]  eta: 0:01:05  lr: 0.000496  min_lr: 0.000496  loss: 2.3743 (2.3964)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0015  max mem: 3719\n",
            "Epoch: [66]  [ 90/295]  eta: 0:01:01  lr: 0.000494  min_lr: 0.000494  loss: 2.5521 (2.4090)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0014  max mem: 3719\n",
            "Epoch: [66]  [100/295]  eta: 0:00:57  lr: 0.000491  min_lr: 0.000491  loss: 2.5521 (2.4270)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0037  max mem: 3719\n",
            "Epoch: [66]  [110/295]  eta: 0:00:54  lr: 0.000489  min_lr: 0.000489  loss: 2.4629 (2.4130)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0051  max mem: 3719\n",
            "Epoch: [66]  [120/295]  eta: 0:00:51  lr: 0.000486  min_lr: 0.000486  loss: 2.2085 (2.4026)  weight_decay: 0.0500 (0.0500)  time: 0.2790  data: 0.0036  max mem: 3719\n",
            "Epoch: [66]  [130/295]  eta: 0:00:48  lr: 0.000484  min_lr: 0.000484  loss: 2.4260 (2.4078)  weight_decay: 0.0500 (0.0500)  time: 0.2812  data: 0.0026  max mem: 3719\n",
            "Epoch: [66]  [140/295]  eta: 0:00:45  lr: 0.000481  min_lr: 0.000481  loss: 2.5458 (2.4240)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0022  max mem: 3719\n",
            "Epoch: [66]  [150/295]  eta: 0:00:41  lr: 0.000480  min_lr: 0.000480  loss: 2.4865 (2.4190)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0022  max mem: 3719\n",
            "Epoch: [66]  [160/295]  eta: 0:00:38  lr: 0.000477  min_lr: 0.000477  loss: 2.4865 (2.4239)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0024  max mem: 3719\n",
            "Epoch: [66]  [170/295]  eta: 0:00:35  lr: 0.000475  min_lr: 0.000475  loss: 2.4979 (2.4210)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0019  max mem: 3719\n",
            "Epoch: [66]  [180/295]  eta: 0:00:32  lr: 0.000472  min_lr: 0.000472  loss: 2.4891 (2.4200)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0012  max mem: 3719\n",
            "Epoch: [66]  [190/295]  eta: 0:00:29  lr: 0.000470  min_lr: 0.000470  loss: 2.4414 (2.4178)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0027  max mem: 3719\n",
            "Epoch: [66]  [200/295]  eta: 0:00:26  lr: 0.000468  min_lr: 0.000468  loss: 2.3493 (2.4203)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0032  max mem: 3719\n",
            "Epoch: [66]  [210/295]  eta: 0:00:23  lr: 0.000466  min_lr: 0.000466  loss: 2.4999 (2.4254)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0027  max mem: 3719\n",
            "Epoch: [66]  [220/295]  eta: 0:00:21  lr: 0.000463  min_lr: 0.000463  loss: 2.4987 (2.4246)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0023  max mem: 3719\n",
            "Epoch: [66]  [230/295]  eta: 0:00:18  lr: 0.000461  min_lr: 0.000461  loss: 2.4588 (2.4286)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0010  max mem: 3719\n",
            "Epoch: [66]  [240/295]  eta: 0:00:15  lr: 0.000458  min_lr: 0.000458  loss: 2.4023 (2.4279)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0005  max mem: 3719\n",
            "Epoch: [66]  [250/295]  eta: 0:00:12  lr: 0.000457  min_lr: 0.000457  loss: 2.4640 (2.4324)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0021  max mem: 3719\n",
            "Epoch: [66]  [260/295]  eta: 0:00:09  lr: 0.000454  min_lr: 0.000454  loss: 2.4640 (2.4304)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0036  max mem: 3719\n",
            "Epoch: [66]  [270/295]  eta: 0:00:06  lr: 0.000452  min_lr: 0.000452  loss: 2.4246 (2.4338)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0024  max mem: 3719\n",
            "Epoch: [66]  [280/295]  eta: 0:00:04  lr: 0.000449  min_lr: 0.000449  loss: 2.5289 (2.4379)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0007  max mem: 3719\n",
            "Epoch: [66]  [290/295]  eta: 0:00:01  lr: 0.000447  min_lr: 0.000447  loss: 2.5490 (2.4423)  weight_decay: 0.0500 (0.0500)  time: 0.2568  data: 0.0002  max mem: 3719\n",
            "Epoch: [66]  [294/295]  eta: 0:00:00  lr: 0.000447  min_lr: 0.000447  loss: 2.5325 (2.4424)  weight_decay: 0.0500 (0.0500)  time: 0.2189  data: 0.0002  max mem: 3719\n",
            "Epoch: [66] Total time: 0:01:21 (0.2751 s / it)\n",
            "Averaged stats: lr: 0.000447  min_lr: 0.000447  loss: 2.5325 (2.4424)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:22  loss: 0.5576 (0.5576)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 1.7391  data: 1.5766  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5286 (0.5374)  acc1: 91.6667 (90.5303)  acc5: 97.9167 (98.4849)  time: 0.2938  data: 0.1556  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5447 (0.5775)  acc1: 91.6667 (89.2857)  acc5: 97.9167 (98.3135)  time: 0.1506  data: 0.0081  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6846 (0.8064)  acc1: 81.2500 (79.7715)  acc5: 97.9167 (97.9167)  time: 0.1614  data: 0.0152  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7338 (0.7733)  acc1: 81.2500 (81.1992)  acc5: 97.9167 (98.1707)  time: 0.1819  data: 0.0343  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7245 (0.7911)  acc1: 81.2500 (80.5556)  acc5: 97.9167 (98.1618)  time: 0.1807  data: 0.0264  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8292 (0.7964)  acc1: 77.0833 (80.3279)  acc5: 97.9167 (97.9850)  time: 0.1547  data: 0.0123  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8136 (0.8043)  acc1: 81.2500 (80.1350)  acc5: 97.9167 (97.8580)  time: 0.1319  data: 0.0065  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6892 (0.7865)  acc1: 81.2500 (80.6584)  acc5: 97.9167 (97.8909)  time: 0.1207  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6892 (0.7889)  acc1: 81.2500 (80.6115)  acc5: 97.9167 (97.8344)  time: 0.1193  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1755 s / it)\n",
            "* Acc@1 80.611 Acc@5 97.834 loss 0.789\n",
            "Accuracy of the model on the 3925 test images: 80.6%\n",
            "Max accuracy: 81.12%\n",
            "Test:  [ 0/82]  eta: 0:01:43  loss: 2.5687 (2.5687)  acc1: 16.6667 (16.6667)  acc5: 91.6667 (91.6667)  time: 1.2571  data: 1.1386  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.7320 (2.8058)  acc1: 14.5833 (14.3939)  acc5: 93.7500 (92.2349)  time: 0.2855  data: 0.1644  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.8128 (2.9578)  acc1: 14.5833 (15.4762)  acc5: 91.6667 (91.3691)  time: 0.1563  data: 0.0345  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.6105 (3.5139)  acc1: 10.4167 (11.4919)  acc5: 81.2500 (79.2339)  time: 0.1233  data: 0.0019  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.1152 (3.6316)  acc1: 8.3333 (11.2297)  acc5: 66.6667 (76.3211)  time: 0.1278  data: 0.0050  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.1152 (3.8359)  acc1: 10.4167 (11.1928)  acc5: 66.6667 (72.1405)  time: 0.1400  data: 0.0043  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2460 (3.9426)  acc1: 2.0833 (9.5970)  acc5: 45.8333 (69.9795)  time: 0.1435  data: 0.0011  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.8998 (3.8250)  acc1: 2.0833 (13.1749)  acc5: 72.9167 (69.7770)  time: 0.1447  data: 0.0010  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2969 (3.4739)  acc1: 60.4167 (20.8591)  acc5: 95.8333 (73.1739)  time: 0.1381  data: 0.0031  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2081 (3.4461)  acc1: 66.6667 (21.4013)  acc5: 95.8333 (73.3248)  time: 0.1352  data: 0.0031  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1610 s / it)\n",
            "* Acc@1 21.401 Acc@5 73.325 loss 3.446\n",
            "Accuracy of the model EMA on 3925 test images: 21.4%\n",
            "Max EMA accuracy: 21.40%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [67]  [  0/295]  eta: 0:07:57  lr: 0.000447  min_lr: 0.000447  loss: 2.6628 (2.6628)  weight_decay: 0.0500 (0.0500)  time: 1.6182  data: 1.2432  max mem: 3719\n",
            "Epoch: [67]  [ 10/295]  eta: 0:01:54  lr: 0.000445  min_lr: 0.000445  loss: 2.5058 (2.4517)  weight_decay: 0.0500 (0.0500)  time: 0.4005  data: 0.1217  max mem: 3719\n",
            "Epoch: [67]  [ 20/295]  eta: 0:01:32  lr: 0.000442  min_lr: 0.000442  loss: 2.4045 (2.4243)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0054  max mem: 3719\n",
            "Epoch: [67]  [ 30/295]  eta: 0:01:22  lr: 0.000440  min_lr: 0.000440  loss: 2.4506 (2.4340)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0022  max mem: 3719\n",
            "Epoch: [67]  [ 40/295]  eta: 0:01:17  lr: 0.000438  min_lr: 0.000438  loss: 2.5418 (2.4427)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0020  max mem: 3719\n",
            "Epoch: [67]  [ 50/295]  eta: 0:01:12  lr: 0.000436  min_lr: 0.000436  loss: 2.3726 (2.4258)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0022  max mem: 3719\n",
            "Epoch: [67]  [ 60/295]  eta: 0:01:08  lr: 0.000433  min_lr: 0.000433  loss: 2.3838 (2.4231)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0034  max mem: 3719\n",
            "Epoch: [67]  [ 70/295]  eta: 0:01:04  lr: 0.000431  min_lr: 0.000431  loss: 2.4549 (2.4359)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0027  max mem: 3719\n",
            "Epoch: [67]  [ 80/295]  eta: 0:01:01  lr: 0.000429  min_lr: 0.000429  loss: 2.5224 (2.4500)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0019  max mem: 3719\n",
            "Epoch: [67]  [ 90/295]  eta: 0:00:57  lr: 0.000427  min_lr: 0.000427  loss: 2.4962 (2.4491)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0022  max mem: 3719\n",
            "Epoch: [67]  [100/295]  eta: 0:00:54  lr: 0.000424  min_lr: 0.000424  loss: 2.4165 (2.4442)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0019  max mem: 3719\n",
            "Epoch: [67]  [110/295]  eta: 0:00:51  lr: 0.000423  min_lr: 0.000423  loss: 2.4588 (2.4459)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0018  max mem: 3719\n",
            "Epoch: [67]  [120/295]  eta: 0:00:48  lr: 0.000420  min_lr: 0.000420  loss: 2.4213 (2.4352)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0029  max mem: 3719\n",
            "Epoch: [67]  [130/295]  eta: 0:00:45  lr: 0.000418  min_lr: 0.000418  loss: 2.4213 (2.4429)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0029  max mem: 3719\n",
            "Epoch: [67]  [140/295]  eta: 0:00:42  lr: 0.000416  min_lr: 0.000416  loss: 2.5438 (2.4521)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0019  max mem: 3719\n",
            "Epoch: [67]  [150/295]  eta: 0:00:39  lr: 0.000414  min_lr: 0.000414  loss: 2.5793 (2.4553)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0016  max mem: 3719\n",
            "Epoch: [67]  [160/295]  eta: 0:00:37  lr: 0.000411  min_lr: 0.000411  loss: 2.4404 (2.4520)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0026  max mem: 3719\n",
            "Epoch: [67]  [170/295]  eta: 0:00:34  lr: 0.000409  min_lr: 0.000409  loss: 2.5023 (2.4569)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0027  max mem: 3719\n",
            "Epoch: [67]  [180/295]  eta: 0:00:31  lr: 0.000407  min_lr: 0.000407  loss: 2.3581 (2.4450)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0027  max mem: 3719\n",
            "Epoch: [67]  [190/295]  eta: 0:00:28  lr: 0.000405  min_lr: 0.000405  loss: 2.2784 (2.4426)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0030  max mem: 3719\n",
            "Epoch: [67]  [200/295]  eta: 0:00:25  lr: 0.000402  min_lr: 0.000402  loss: 2.2919 (2.4388)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0022  max mem: 3719\n",
            "Epoch: [67]  [210/295]  eta: 0:00:23  lr: 0.000401  min_lr: 0.000401  loss: 2.3287 (2.4404)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0011  max mem: 3719\n",
            "Epoch: [67]  [220/295]  eta: 0:00:20  lr: 0.000398  min_lr: 0.000398  loss: 2.5417 (2.4403)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0010  max mem: 3719\n",
            "Epoch: [67]  [230/295]  eta: 0:00:17  lr: 0.000396  min_lr: 0.000396  loss: 2.4466 (2.4375)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0040  max mem: 3719\n",
            "Epoch: [67]  [240/295]  eta: 0:00:14  lr: 0.000394  min_lr: 0.000394  loss: 2.4431 (2.4363)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0058  max mem: 3719\n",
            "Epoch: [67]  [250/295]  eta: 0:00:12  lr: 0.000392  min_lr: 0.000392  loss: 2.5139 (2.4413)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0033  max mem: 3719\n",
            "Epoch: [67]  [260/295]  eta: 0:00:09  lr: 0.000390  min_lr: 0.000390  loss: 2.5594 (2.4451)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0037  max mem: 3719\n",
            "Epoch: [67]  [270/295]  eta: 0:00:06  lr: 0.000388  min_lr: 0.000388  loss: 2.5012 (2.4421)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0056  max mem: 3719\n",
            "Epoch: [67]  [280/295]  eta: 0:00:04  lr: 0.000385  min_lr: 0.000385  loss: 2.4752 (2.4447)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0028  max mem: 3719\n",
            "Epoch: [67]  [290/295]  eta: 0:00:01  lr: 0.000384  min_lr: 0.000384  loss: 2.4822 (2.4455)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0003  max mem: 3719\n",
            "Epoch: [67]  [294/295]  eta: 0:00:00  lr: 0.000384  min_lr: 0.000384  loss: 2.4540 (2.4453)  weight_decay: 0.0500 (0.0500)  time: 0.2213  data: 0.0002  max mem: 3719\n",
            "Epoch: [67] Total time: 0:01:19 (0.2703 s / it)\n",
            "Averaged stats: lr: 0.000384  min_lr: 0.000384  loss: 2.4540 (2.4453)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:28  loss: 0.6255 (0.6255)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.5458  data: 2.3768  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 0.5554 (0.5918)  acc1: 91.6667 (88.6364)  acc5: 97.9167 (98.2955)  time: 0.3484  data: 0.2184  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5755 (0.6099)  acc1: 89.5833 (87.6984)  acc5: 100.0000 (98.3135)  time: 0.1250  data: 0.0024  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.7245 (0.8006)  acc1: 81.2500 (79.6371)  acc5: 97.9167 (97.9167)  time: 0.1214  data: 0.0022  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7229 (0.7652)  acc1: 83.3333 (81.3008)  acc5: 97.9167 (98.2215)  time: 0.1223  data: 0.0021  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6886 (0.7890)  acc1: 83.3333 (80.4330)  acc5: 97.9167 (98.0392)  time: 0.1236  data: 0.0035  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8384 (0.7891)  acc1: 77.0833 (80.2937)  acc5: 97.9167 (97.9167)  time: 0.1236  data: 0.0050  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8213 (0.8052)  acc1: 77.0833 (79.5775)  acc5: 97.9167 (97.7700)  time: 0.1200  data: 0.0026  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7165 (0.7841)  acc1: 81.2500 (80.5298)  acc5: 97.9167 (97.8395)  time: 0.1167  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7165 (0.7861)  acc1: 81.2500 (80.4586)  acc5: 97.9167 (97.7834)  time: 0.1155  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1590 s / it)\n",
            "* Acc@1 80.459 Acc@5 97.783 loss 0.786\n",
            "Accuracy of the model on the 3925 test images: 80.5%\n",
            "Max accuracy: 81.12%\n",
            "Test:  [ 0/82]  eta: 0:04:24  loss: 2.5211 (2.5211)  acc1: 18.7500 (18.7500)  acc5: 91.6667 (91.6667)  time: 3.2215  data: 3.0363  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 2.6836 (2.7651)  acc1: 14.5833 (14.5833)  acc5: 93.7500 (92.6136)  time: 0.4416  data: 0.2768  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 2.7904 (2.9218)  acc1: 16.6667 (15.8730)  acc5: 93.7500 (91.7659)  time: 0.1470  data: 0.0029  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.5721 (3.4788)  acc1: 10.4167 (11.6935)  acc5: 83.3333 (79.4355)  time: 0.1270  data: 0.0032  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.0499 (3.5920)  acc1: 8.3333 (11.5854)  acc5: 68.7500 (76.6768)  time: 0.1224  data: 0.0019  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.0499 (3.8012)  acc1: 10.4167 (11.4379)  acc5: 68.7500 (72.3448)  time: 0.1211  data: 0.0038  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2472 (3.9068)  acc1: 2.0833 (9.8019)  acc5: 45.8333 (70.1844)  time: 0.1235  data: 0.0072  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.8562 (3.7892)  acc1: 2.0833 (13.4096)  acc5: 72.9167 (69.9531)  time: 0.1224  data: 0.0052  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2694 (3.4404)  acc1: 60.4167 (21.1163)  acc5: 95.8333 (73.3539)  time: 0.1180  data: 0.0007  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1838 (3.4129)  acc1: 66.6667 (21.6561)  acc5: 95.8333 (73.5032)  time: 0.1164  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1696 s / it)\n",
            "* Acc@1 21.656 Acc@5 73.503 loss 3.413\n",
            "Accuracy of the model EMA on 3925 test images: 21.7%\n",
            "Max EMA accuracy: 21.66%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [68]  [  0/295]  eta: 0:14:22  lr: 0.000383  min_lr: 0.000383  loss: 2.7056 (2.7056)  weight_decay: 0.0500 (0.0500)  time: 2.9239  data: 2.3661  max mem: 3719\n",
            "Epoch: [68]  [ 10/295]  eta: 0:02:43  lr: 0.000381  min_lr: 0.000381  loss: 2.5621 (2.4494)  weight_decay: 0.0500 (0.0500)  time: 0.5722  data: 0.2163  max mem: 3719\n",
            "Epoch: [68]  [ 20/295]  eta: 0:01:57  lr: 0.000379  min_lr: 0.000379  loss: 2.4644 (2.4527)  weight_decay: 0.0500 (0.0500)  time: 0.3008  data: 0.0021  max mem: 3719\n",
            "Epoch: [68]  [ 30/295]  eta: 0:01:38  lr: 0.000377  min_lr: 0.000377  loss: 2.4644 (2.4262)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0021  max mem: 3719\n",
            "Epoch: [68]  [ 40/295]  eta: 0:01:28  lr: 0.000374  min_lr: 0.000374  loss: 2.4423 (2.4350)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0016  max mem: 3719\n",
            "Epoch: [68]  [ 50/295]  eta: 0:01:20  lr: 0.000373  min_lr: 0.000373  loss: 2.4423 (2.4146)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0015  max mem: 3719\n",
            "Epoch: [68]  [ 60/295]  eta: 0:01:15  lr: 0.000370  min_lr: 0.000370  loss: 2.3224 (2.3953)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0015  max mem: 3719\n",
            "Epoch: [68]  [ 70/295]  eta: 0:01:10  lr: 0.000369  min_lr: 0.000369  loss: 2.3224 (2.3992)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0032  max mem: 3719\n",
            "Epoch: [68]  [ 80/295]  eta: 0:01:06  lr: 0.000366  min_lr: 0.000366  loss: 2.4750 (2.3957)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0031  max mem: 3719\n",
            "Epoch: [68]  [ 90/295]  eta: 0:01:02  lr: 0.000365  min_lr: 0.000365  loss: 2.4279 (2.3889)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0014  max mem: 3719\n",
            "Epoch: [68]  [100/295]  eta: 0:00:58  lr: 0.000362  min_lr: 0.000362  loss: 2.3774 (2.3922)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0014  max mem: 3719\n",
            "Epoch: [68]  [110/295]  eta: 0:00:54  lr: 0.000360  min_lr: 0.000360  loss: 2.3774 (2.3885)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0016  max mem: 3719\n",
            "Epoch: [68]  [120/295]  eta: 0:00:51  lr: 0.000358  min_lr: 0.000358  loss: 2.5057 (2.4000)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0025  max mem: 3719\n",
            "Epoch: [68]  [130/295]  eta: 0:00:48  lr: 0.000356  min_lr: 0.000356  loss: 2.4573 (2.3976)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0032  max mem: 3719\n",
            "Epoch: [68]  [140/295]  eta: 0:00:45  lr: 0.000354  min_lr: 0.000354  loss: 2.4573 (2.4023)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0028  max mem: 3719\n",
            "Epoch: [68]  [150/295]  eta: 0:00:42  lr: 0.000352  min_lr: 0.000352  loss: 2.4700 (2.4015)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0026  max mem: 3719\n",
            "Epoch: [68]  [160/295]  eta: 0:00:38  lr: 0.000350  min_lr: 0.000350  loss: 2.3908 (2.4014)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0028  max mem: 3719\n",
            "Epoch: [68]  [170/295]  eta: 0:00:35  lr: 0.000348  min_lr: 0.000348  loss: 2.4060 (2.3954)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0031  max mem: 3719\n",
            "Epoch: [68]  [180/295]  eta: 0:00:32  lr: 0.000346  min_lr: 0.000346  loss: 2.3693 (2.3943)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0024  max mem: 3719\n",
            "Epoch: [68]  [190/295]  eta: 0:00:29  lr: 0.000344  min_lr: 0.000344  loss: 2.3706 (2.4003)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0033  max mem: 3719\n",
            "Epoch: [68]  [200/295]  eta: 0:00:26  lr: 0.000342  min_lr: 0.000342  loss: 2.4755 (2.4009)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0040  max mem: 3719\n",
            "Epoch: [68]  [210/295]  eta: 0:00:24  lr: 0.000340  min_lr: 0.000340  loss: 2.4755 (2.4018)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0023  max mem: 3719\n",
            "Epoch: [68]  [220/295]  eta: 0:00:21  lr: 0.000338  min_lr: 0.000338  loss: 2.3642 (2.3994)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0014  max mem: 3719\n",
            "Epoch: [68]  [230/295]  eta: 0:00:18  lr: 0.000336  min_lr: 0.000336  loss: 2.3642 (2.4001)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0017  max mem: 3719\n",
            "Epoch: [68]  [240/295]  eta: 0:00:15  lr: 0.000334  min_lr: 0.000334  loss: 2.4650 (2.4042)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0026  max mem: 3719\n",
            "Epoch: [68]  [250/295]  eta: 0:00:12  lr: 0.000332  min_lr: 0.000332  loss: 2.4650 (2.4070)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0040  max mem: 3719\n",
            "Epoch: [68]  [260/295]  eta: 0:00:09  lr: 0.000330  min_lr: 0.000330  loss: 2.4526 (2.4074)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0044  max mem: 3719\n",
            "Epoch: [68]  [270/295]  eta: 0:00:06  lr: 0.000328  min_lr: 0.000328  loss: 2.4041 (2.4064)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0034  max mem: 3719\n",
            "Epoch: [68]  [280/295]  eta: 0:00:04  lr: 0.000326  min_lr: 0.000326  loss: 2.3407 (2.4044)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0016  max mem: 3719\n",
            "Epoch: [68]  [290/295]  eta: 0:00:01  lr: 0.000324  min_lr: 0.000324  loss: 2.4064 (2.4055)  weight_decay: 0.0500 (0.0500)  time: 0.2550  data: 0.0002  max mem: 3719\n",
            "Epoch: [68]  [294/295]  eta: 0:00:00  lr: 0.000324  min_lr: 0.000324  loss: 2.4138 (2.4056)  weight_decay: 0.0500 (0.0500)  time: 0.2176  data: 0.0002  max mem: 3719\n",
            "Epoch: [68] Total time: 0:01:21 (0.2754 s / it)\n",
            "Averaged stats: lr: 0.000324  min_lr: 0.000324  loss: 2.4138 (2.4056)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:24  loss: 0.6042 (0.6042)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.4885  data: 2.3208  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.5418 (0.5587)  acc1: 89.5833 (88.8258)  acc5: 97.9167 (98.1061)  time: 0.3779  data: 0.2282  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.5410 (0.5613)  acc1: 89.5833 (88.7897)  acc5: 97.9167 (98.1151)  time: 0.1660  data: 0.0197  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6416 (0.7847)  acc1: 83.3333 (79.3683)  acc5: 97.9167 (97.7823)  time: 0.1661  data: 0.0231  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7522 (0.7624)  acc1: 81.2500 (80.6402)  acc5: 97.9167 (98.0183)  time: 0.1714  data: 0.0286  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7319 (0.7666)  acc1: 81.2500 (80.5556)  acc5: 100.0000 (98.2026)  time: 0.1489  data: 0.0170  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8057 (0.7788)  acc1: 81.2500 (80.0205)  acc5: 97.9167 (97.8825)  time: 0.1225  data: 0.0032  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8519 (0.7998)  acc1: 75.0000 (79.1960)  acc5: 95.8333 (97.5646)  time: 0.1218  data: 0.0023  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6923 (0.7741)  acc1: 83.3333 (80.1698)  acc5: 97.9167 (97.7109)  time: 0.1194  data: 0.0004  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6923 (0.7751)  acc1: 83.3333 (80.1529)  acc5: 97.9167 (97.6815)  time: 0.1182  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1780 s / it)\n",
            "* Acc@1 80.153 Acc@5 97.682 loss 0.775\n",
            "Accuracy of the model on the 3925 test images: 80.2%\n",
            "Max accuracy: 81.12%\n",
            "Test:  [ 0/82]  eta: 0:02:39  loss: 2.4747 (2.4747)  acc1: 18.7500 (18.7500)  acc5: 91.6667 (91.6667)  time: 1.9453  data: 1.7814  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.6473 (2.7251)  acc1: 16.6667 (14.7727)  acc5: 93.7500 (92.8030)  time: 0.2900  data: 0.1647  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.7674 (2.8860)  acc1: 16.6667 (16.0714)  acc5: 93.7500 (92.2619)  time: 0.1233  data: 0.0025  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.5347 (3.4429)  acc1: 10.4167 (11.8280)  acc5: 83.3333 (79.6371)  time: 0.1313  data: 0.0035  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.9900 (3.5529)  acc1: 10.4167 (11.7886)  acc5: 68.7500 (77.0833)  time: 0.1441  data: 0.0028  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.9900 (3.7668)  acc1: 10.4167 (11.6013)  acc5: 68.7500 (72.6307)  time: 0.1478  data: 0.0005  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2483 (3.8709)  acc1: 2.0833 (9.9385)  acc5: 45.8333 (70.3893)  time: 0.1571  data: 0.0103  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.8098 (3.7535)  acc1: 2.0833 (13.6150)  acc5: 72.9167 (70.1585)  time: 0.1871  data: 0.0439  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2439 (3.4072)  acc1: 60.4167 (21.2963)  acc5: 97.9167 (73.5340)  time: 0.1807  data: 0.0484  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1686 (3.3799)  acc1: 66.6667 (21.8344)  acc5: 97.9167 (73.6815)  time: 0.1781  data: 0.0484  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1817 s / it)\n",
            "* Acc@1 21.834 Acc@5 73.682 loss 3.380\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "Max EMA accuracy: 21.83%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [69]  [  0/295]  eta: 0:10:41  lr: 0.000324  min_lr: 0.000324  loss: 2.4256 (2.4256)  weight_decay: 0.0500 (0.0500)  time: 2.1746  data: 1.7560  max mem: 3719\n",
            "Epoch: [69]  [ 10/295]  eta: 0:02:07  lr: 0.000322  min_lr: 0.000322  loss: 2.5058 (2.5148)  weight_decay: 0.0500 (0.0500)  time: 0.4461  data: 0.1614  max mem: 3719\n",
            "Epoch: [69]  [ 20/295]  eta: 0:01:38  lr: 0.000320  min_lr: 0.000320  loss: 2.4232 (2.4171)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0022  max mem: 3719\n",
            "Epoch: [69]  [ 30/295]  eta: 0:01:27  lr: 0.000318  min_lr: 0.000318  loss: 2.4166 (2.4104)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0025  max mem: 3719\n",
            "Epoch: [69]  [ 40/295]  eta: 0:01:20  lr: 0.000316  min_lr: 0.000316  loss: 2.5124 (2.4138)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0017  max mem: 3719\n",
            "Epoch: [69]  [ 50/295]  eta: 0:01:15  lr: 0.000314  min_lr: 0.000314  loss: 2.4081 (2.4122)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0025  max mem: 3719\n",
            "Epoch: [69]  [ 60/295]  eta: 0:01:10  lr: 0.000312  min_lr: 0.000312  loss: 2.4362 (2.4233)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0027  max mem: 3719\n",
            "Epoch: [69]  [ 70/295]  eta: 0:01:06  lr: 0.000310  min_lr: 0.000310  loss: 2.5369 (2.4465)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0017  max mem: 3719\n",
            "Epoch: [69]  [ 80/295]  eta: 0:01:02  lr: 0.000308  min_lr: 0.000308  loss: 2.5767 (2.4552)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0021  max mem: 3719\n",
            "Epoch: [69]  [ 90/295]  eta: 0:00:59  lr: 0.000307  min_lr: 0.000307  loss: 2.4761 (2.4559)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0017  max mem: 3719\n",
            "Epoch: [69]  [100/295]  eta: 0:00:56  lr: 0.000304  min_lr: 0.000304  loss: 2.4754 (2.4545)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0024  max mem: 3719\n",
            "Epoch: [69]  [110/295]  eta: 0:00:53  lr: 0.000303  min_lr: 0.000303  loss: 2.5688 (2.4656)  weight_decay: 0.0500 (0.0500)  time: 0.2760  data: 0.0046  max mem: 3719\n",
            "Epoch: [69]  [120/295]  eta: 0:00:49  lr: 0.000301  min_lr: 0.000301  loss: 2.5082 (2.4580)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0034  max mem: 3719\n",
            "Epoch: [69]  [130/295]  eta: 0:00:46  lr: 0.000299  min_lr: 0.000299  loss: 2.4156 (2.4567)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0009  max mem: 3719\n",
            "Epoch: [69]  [140/295]  eta: 0:00:43  lr: 0.000297  min_lr: 0.000297  loss: 2.5056 (2.4588)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0005  max mem: 3719\n",
            "Epoch: [69]  [150/295]  eta: 0:00:40  lr: 0.000295  min_lr: 0.000295  loss: 2.5291 (2.4620)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0011  max mem: 3719\n",
            "Epoch: [69]  [160/295]  eta: 0:00:37  lr: 0.000293  min_lr: 0.000293  loss: 2.5291 (2.4670)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0029  max mem: 3719\n",
            "Epoch: [69]  [170/295]  eta: 0:00:34  lr: 0.000292  min_lr: 0.000292  loss: 2.4058 (2.4595)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0036  max mem: 3719\n",
            "Epoch: [69]  [180/295]  eta: 0:00:31  lr: 0.000289  min_lr: 0.000289  loss: 2.4058 (2.4599)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0028  max mem: 3719\n",
            "Epoch: [69]  [190/295]  eta: 0:00:29  lr: 0.000288  min_lr: 0.000288  loss: 2.4259 (2.4522)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0019  max mem: 3719\n",
            "Epoch: [69]  [200/295]  eta: 0:00:26  lr: 0.000286  min_lr: 0.000286  loss: 2.4259 (2.4499)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0019  max mem: 3719\n",
            "Epoch: [69]  [210/295]  eta: 0:00:23  lr: 0.000284  min_lr: 0.000284  loss: 2.5316 (2.4546)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0020  max mem: 3719\n",
            "Epoch: [69]  [220/295]  eta: 0:00:20  lr: 0.000282  min_lr: 0.000282  loss: 2.5222 (2.4548)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0013  max mem: 3719\n",
            "Epoch: [69]  [230/295]  eta: 0:00:17  lr: 0.000280  min_lr: 0.000280  loss: 2.4471 (2.4535)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0031  max mem: 3719\n",
            "Epoch: [69]  [240/295]  eta: 0:00:15  lr: 0.000278  min_lr: 0.000278  loss: 2.3209 (2.4444)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0048  max mem: 3719\n",
            "Epoch: [69]  [250/295]  eta: 0:00:12  lr: 0.000277  min_lr: 0.000277  loss: 2.3209 (2.4452)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0027  max mem: 3719\n",
            "Epoch: [69]  [260/295]  eta: 0:00:09  lr: 0.000275  min_lr: 0.000275  loss: 2.4873 (2.4461)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0014  max mem: 3719\n",
            "Epoch: [69]  [270/295]  eta: 0:00:06  lr: 0.000273  min_lr: 0.000273  loss: 2.5254 (2.4444)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0021  max mem: 3719\n",
            "Epoch: [69]  [280/295]  eta: 0:00:04  lr: 0.000271  min_lr: 0.000271  loss: 2.4505 (2.4457)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0017  max mem: 3719\n",
            "Epoch: [69]  [290/295]  eta: 0:00:01  lr: 0.000270  min_lr: 0.000270  loss: 2.4720 (2.4489)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0006  max mem: 3719\n",
            "Epoch: [69]  [294/295]  eta: 0:00:00  lr: 0.000270  min_lr: 0.000270  loss: 2.4720 (2.4488)  weight_decay: 0.0500 (0.0500)  time: 0.2215  data: 0.0003  max mem: 3719\n",
            "Epoch: [69] Total time: 0:01:19 (0.2708 s / it)\n",
            "Averaged stats: lr: 0.000270  min_lr: 0.000270  loss: 2.4720 (2.4488)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:29  loss: 0.5803 (0.5803)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 1.8240  data: 1.6623  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.5143 (0.5261)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (98.4849)  time: 0.3209  data: 0.1947  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5239 (0.5383)  acc1: 91.6667 (90.6746)  acc5: 100.0000 (98.6111)  time: 0.1470  data: 0.0250  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6452 (0.7098)  acc1: 87.5000 (83.0645)  acc5: 97.9167 (98.4543)  time: 0.1227  data: 0.0022  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8013 (0.7112)  acc1: 81.2500 (83.1809)  acc5: 97.9167 (98.5264)  time: 0.1235  data: 0.0030  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7948 (0.7330)  acc1: 81.2500 (82.5163)  acc5: 97.9167 (98.4477)  time: 0.1278  data: 0.0045  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8343 (0.7505)  acc1: 79.1667 (81.6257)  acc5: 97.9167 (98.2240)  time: 0.1278  data: 0.0048  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8765 (0.7766)  acc1: 75.0000 (80.7218)  acc5: 97.9167 (98.0047)  time: 0.1217  data: 0.0022  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7379 (0.7593)  acc1: 79.1667 (81.2500)  acc5: 97.9167 (98.0967)  time: 0.1183  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7379 (0.7614)  acc1: 79.1667 (81.1975)  acc5: 97.9167 (98.0637)  time: 0.1173  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1573 s / it)\n",
            "* Acc@1 81.197 Acc@5 98.064 loss 0.761\n",
            "Accuracy of the model on the 3925 test images: 81.2%\n",
            "Max accuracy: 81.20%\n",
            "Test:  [ 0/82]  eta: 0:03:50  loss: 2.4261 (2.4261)  acc1: 18.7500 (18.7500)  acc5: 91.6667 (91.6667)  time: 2.8096  data: 2.6362  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 2.6087 (2.6836)  acc1: 16.6667 (15.7197)  acc5: 93.7500 (92.9924)  time: 0.3867  data: 0.2522  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 2.7447 (2.8500)  acc1: 16.6667 (16.6667)  acc5: 93.7500 (92.4603)  time: 0.1345  data: 0.0093  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.4989 (3.4070)  acc1: 10.4167 (12.2312)  acc5: 83.3333 (79.7715)  time: 0.1238  data: 0.0034  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.9264 (3.5130)  acc1: 10.4167 (12.4492)  acc5: 70.8333 (77.2866)  time: 0.1228  data: 0.0020  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.9264 (3.7318)  acc1: 10.4167 (12.0915)  acc5: 70.8333 (72.7533)  time: 0.1223  data: 0.0025  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2496 (3.8338)  acc1: 2.0833 (10.3484)  acc5: 45.8333 (70.5601)  time: 0.1218  data: 0.0034  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.7614 (3.7165)  acc1: 2.0833 (14.0552)  acc5: 72.9167 (70.3639)  time: 0.1208  data: 0.0020  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2208 (3.3729)  acc1: 62.5000 (21.6821)  acc5: 97.9167 (73.7140)  time: 0.1195  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1533 (3.3458)  acc1: 66.6667 (22.2166)  acc5: 97.9167 (73.8599)  time: 0.1179  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1622 s / it)\n",
            "* Acc@1 22.217 Acc@5 73.860 loss 3.346\n",
            "Accuracy of the model EMA on 3925 test images: 22.2%\n",
            "Max EMA accuracy: 22.22%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [70]  [  0/295]  eta: 0:13:04  lr: 0.000269  min_lr: 0.000269  loss: 2.0514 (2.0514)  weight_decay: 0.0500 (0.0500)  time: 2.6596  data: 2.0706  max mem: 3719\n",
            "Epoch: [70]  [ 10/295]  eta: 0:02:29  lr: 0.000267  min_lr: 0.000267  loss: 2.5780 (2.4583)  weight_decay: 0.0500 (0.0500)  time: 0.5250  data: 0.1913  max mem: 3719\n",
            "Epoch: [70]  [ 20/295]  eta: 0:01:50  lr: 0.000265  min_lr: 0.000265  loss: 2.4371 (2.4394)  weight_decay: 0.0500 (0.0500)  time: 0.2880  data: 0.0032  max mem: 3719\n",
            "Epoch: [70]  [ 30/295]  eta: 0:01:34  lr: 0.000264  min_lr: 0.000264  loss: 2.3842 (2.4283)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0022  max mem: 3719\n",
            "Epoch: [70]  [ 40/295]  eta: 0:01:25  lr: 0.000262  min_lr: 0.000262  loss: 2.3088 (2.3915)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0008  max mem: 3719\n",
            "Epoch: [70]  [ 50/295]  eta: 0:01:18  lr: 0.000260  min_lr: 0.000260  loss: 2.3243 (2.3923)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0008  max mem: 3719\n",
            "Epoch: [70]  [ 60/295]  eta: 0:01:13  lr: 0.000258  min_lr: 0.000258  loss: 2.3265 (2.3932)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0023  max mem: 3719\n",
            "Epoch: [70]  [ 70/295]  eta: 0:01:09  lr: 0.000257  min_lr: 0.000257  loss: 2.3265 (2.3825)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0030  max mem: 3719\n",
            "Epoch: [70]  [ 80/295]  eta: 0:01:04  lr: 0.000255  min_lr: 0.000255  loss: 2.3540 (2.3818)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0023  max mem: 3719\n",
            "Epoch: [70]  [ 90/295]  eta: 0:01:01  lr: 0.000253  min_lr: 0.000253  loss: 2.5237 (2.3913)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0023  max mem: 3719\n",
            "Epoch: [70]  [100/295]  eta: 0:00:57  lr: 0.000251  min_lr: 0.000251  loss: 2.5460 (2.4028)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0034  max mem: 3719\n",
            "Epoch: [70]  [110/295]  eta: 0:00:54  lr: 0.000250  min_lr: 0.000250  loss: 2.5690 (2.4162)  weight_decay: 0.0500 (0.0500)  time: 0.2743  data: 0.0045  max mem: 3719\n",
            "Epoch: [70]  [120/295]  eta: 0:00:51  lr: 0.000248  min_lr: 0.000248  loss: 2.5687 (2.4201)  weight_decay: 0.0500 (0.0500)  time: 0.2819  data: 0.0051  max mem: 3719\n",
            "Epoch: [70]  [130/295]  eta: 0:00:48  lr: 0.000246  min_lr: 0.000246  loss: 2.4902 (2.4249)  weight_decay: 0.0500 (0.0500)  time: 0.2817  data: 0.0057  max mem: 3719\n",
            "Epoch: [70]  [140/295]  eta: 0:00:45  lr: 0.000244  min_lr: 0.000244  loss: 2.5512 (2.4239)  weight_decay: 0.0500 (0.0500)  time: 0.2745  data: 0.0036  max mem: 3719\n",
            "Epoch: [70]  [150/295]  eta: 0:00:41  lr: 0.000243  min_lr: 0.000243  loss: 2.4363 (2.4209)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0014  max mem: 3719\n",
            "Epoch: [70]  [160/295]  eta: 0:00:38  lr: 0.000241  min_lr: 0.000241  loss: 2.4363 (2.4241)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0014  max mem: 3719\n",
            "Epoch: [70]  [170/295]  eta: 0:00:35  lr: 0.000240  min_lr: 0.000240  loss: 2.5175 (2.4303)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0016  max mem: 3719\n",
            "Epoch: [70]  [180/295]  eta: 0:00:32  lr: 0.000238  min_lr: 0.000238  loss: 2.5143 (2.4356)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0017  max mem: 3719\n",
            "Epoch: [70]  [190/295]  eta: 0:00:29  lr: 0.000236  min_lr: 0.000236  loss: 2.5036 (2.4395)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0022  max mem: 3719\n",
            "Epoch: [70]  [200/295]  eta: 0:00:26  lr: 0.000234  min_lr: 0.000234  loss: 2.5186 (2.4435)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0037  max mem: 3719\n",
            "Epoch: [70]  [210/295]  eta: 0:00:23  lr: 0.000233  min_lr: 0.000233  loss: 2.4694 (2.4376)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0031  max mem: 3719\n",
            "Epoch: [70]  [220/295]  eta: 0:00:21  lr: 0.000231  min_lr: 0.000231  loss: 2.4362 (2.4399)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0014  max mem: 3719\n",
            "Epoch: [70]  [230/295]  eta: 0:00:18  lr: 0.000229  min_lr: 0.000229  loss: 2.5266 (2.4430)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0021  max mem: 3719\n",
            "Epoch: [70]  [240/295]  eta: 0:00:15  lr: 0.000227  min_lr: 0.000227  loss: 2.5511 (2.4439)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0029  max mem: 3719\n",
            "Epoch: [70]  [250/295]  eta: 0:00:12  lr: 0.000226  min_lr: 0.000226  loss: 2.4219 (2.4433)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0038  max mem: 3719\n",
            "Epoch: [70]  [260/295]  eta: 0:00:09  lr: 0.000224  min_lr: 0.000224  loss: 2.4023 (2.4376)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0047  max mem: 3719\n",
            "Epoch: [70]  [270/295]  eta: 0:00:06  lr: 0.000223  min_lr: 0.000223  loss: 2.3169 (2.4376)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0033  max mem: 3719\n",
            "Epoch: [70]  [280/295]  eta: 0:00:04  lr: 0.000221  min_lr: 0.000221  loss: 2.4252 (2.4351)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0016  max mem: 3719\n",
            "Epoch: [70]  [290/295]  eta: 0:00:01  lr: 0.000220  min_lr: 0.000220  loss: 2.3236 (2.4329)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0007  max mem: 3719\n",
            "Epoch: [70]  [294/295]  eta: 0:00:00  lr: 0.000220  min_lr: 0.000220  loss: 2.3236 (2.4332)  weight_decay: 0.0500 (0.0500)  time: 0.2201  data: 0.0002  max mem: 3719\n",
            "Epoch: [70] Total time: 0:01:21 (0.2749 s / it)\n",
            "Averaged stats: lr: 0.000220  min_lr: 0.000220  loss: 2.3236 (2.4332)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:39  loss: 0.5477 (0.5477)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 1.9455  data: 1.7726  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.4926 (0.5253)  acc1: 93.7500 (91.2879)  acc5: 97.9167 (98.1061)  time: 0.3275  data: 0.1806  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.5048 (0.5452)  acc1: 91.6667 (90.1786)  acc5: 100.0000 (98.5119)  time: 0.1678  data: 0.0251  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6538 (0.7635)  acc1: 85.4167 (80.7796)  acc5: 97.9167 (97.7823)  time: 0.1835  data: 0.0327  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.6823 (0.7352)  acc1: 83.3333 (81.9614)  acc5: 97.9167 (98.1199)  time: 0.1889  data: 0.0265  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6823 (0.7597)  acc1: 83.3333 (80.9232)  acc5: 100.0000 (98.0392)  time: 0.1617  data: 0.0098  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7821 (0.7571)  acc1: 79.1667 (81.0109)  acc5: 97.9167 (98.1216)  time: 0.1339  data: 0.0020  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.7999 (0.7766)  acc1: 79.1667 (80.1937)  acc5: 97.9167 (97.9460)  time: 0.1221  data: 0.0006  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7421 (0.7586)  acc1: 81.2500 (80.9671)  acc5: 97.9167 (97.9938)  time: 0.1191  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7421 (0.7602)  acc1: 81.2500 (80.9427)  acc5: 97.9167 (97.9363)  time: 0.1177  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1788 s / it)\n",
            "* Acc@1 80.943 Acc@5 97.936 loss 0.760\n",
            "Accuracy of the model on the 3925 test images: 80.9%\n",
            "Max accuracy: 81.20%\n",
            "Test:  [ 0/82]  eta: 0:02:34  loss: 2.3824 (2.3824)  acc1: 22.9167 (22.9167)  acc5: 93.7500 (93.7500)  time: 1.8863  data: 1.7277  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.5749 (2.6445)  acc1: 18.7500 (16.6667)  acc5: 93.7500 (93.3712)  time: 0.2847  data: 0.1578  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.7048 (2.8134)  acc1: 16.6667 (17.1627)  acc5: 93.7500 (92.9564)  time: 0.1238  data: 0.0016  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.4596 (3.3705)  acc1: 10.4167 (12.6344)  acc5: 87.5000 (80.1075)  time: 0.1234  data: 0.0024  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.8636 (3.4730)  acc1: 10.4167 (12.9573)  acc5: 70.8333 (77.6423)  time: 0.1396  data: 0.0020  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.8636 (3.6963)  acc1: 12.5000 (12.4592)  acc5: 70.8333 (72.9575)  time: 0.1494  data: 0.0021  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2489 (3.7961)  acc1: 2.0833 (10.6557)  acc5: 45.8333 (70.7309)  time: 0.1452  data: 0.0034  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.7140 (3.6794)  acc1: 2.0833 (14.2899)  acc5: 72.9167 (70.5106)  time: 0.1596  data: 0.0140  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1997 (3.3386)  acc1: 62.5000 (21.9393)  acc5: 97.9167 (73.8426)  time: 0.1468  data: 0.0120  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1395 (3.3118)  acc1: 68.7500 (22.4713)  acc5: 97.9167 (73.9873)  time: 0.1326  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1658 s / it)\n",
            "* Acc@1 22.471 Acc@5 73.987 loss 3.312\n",
            "Accuracy of the model EMA on 3925 test images: 22.5%\n",
            "Max EMA accuracy: 22.47%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [71]  [  0/295]  eta: 0:09:32  lr: 0.000219  min_lr: 0.000219  loss: 2.5380 (2.5380)  weight_decay: 0.0500 (0.0500)  time: 1.9392  data: 1.5397  max mem: 3719\n",
            "Epoch: [71]  [ 10/295]  eta: 0:02:01  lr: 0.000218  min_lr: 0.000218  loss: 2.4998 (2.3596)  weight_decay: 0.0500 (0.0500)  time: 0.4262  data: 0.1412  max mem: 3719\n",
            "Epoch: [71]  [ 20/295]  eta: 0:01:35  lr: 0.000216  min_lr: 0.000216  loss: 2.4998 (2.3871)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0011  max mem: 3719\n",
            "Epoch: [71]  [ 30/295]  eta: 0:01:25  lr: 0.000214  min_lr: 0.000214  loss: 2.4230 (2.3776)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0019  max mem: 3719\n",
            "Epoch: [71]  [ 40/295]  eta: 0:01:19  lr: 0.000212  min_lr: 0.000212  loss: 2.4507 (2.4043)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0035  max mem: 3719\n",
            "Epoch: [71]  [ 50/295]  eta: 0:01:13  lr: 0.000211  min_lr: 0.000211  loss: 2.5506 (2.4301)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0027  max mem: 3719\n",
            "Epoch: [71]  [ 60/295]  eta: 0:01:09  lr: 0.000209  min_lr: 0.000209  loss: 2.4718 (2.4121)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0012  max mem: 3719\n",
            "Epoch: [71]  [ 70/295]  eta: 0:01:05  lr: 0.000208  min_lr: 0.000208  loss: 2.4198 (2.4146)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0018  max mem: 3719\n",
            "Epoch: [71]  [ 80/295]  eta: 0:01:02  lr: 0.000206  min_lr: 0.000206  loss: 2.4135 (2.4118)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0023  max mem: 3719\n",
            "Epoch: [71]  [ 90/295]  eta: 0:00:58  lr: 0.000205  min_lr: 0.000205  loss: 2.3725 (2.4038)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0023  max mem: 3719\n",
            "Epoch: [71]  [100/295]  eta: 0:00:55  lr: 0.000203  min_lr: 0.000203  loss: 2.4345 (2.4038)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0034  max mem: 3719\n",
            "Epoch: [71]  [110/295]  eta: 0:00:52  lr: 0.000202  min_lr: 0.000202  loss: 2.4139 (2.4108)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0042  max mem: 3719\n",
            "Epoch: [71]  [120/295]  eta: 0:00:49  lr: 0.000200  min_lr: 0.000200  loss: 2.4975 (2.4200)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0029  max mem: 3719\n",
            "Epoch: [71]  [130/295]  eta: 0:00:46  lr: 0.000199  min_lr: 0.000199  loss: 2.4996 (2.4215)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0015  max mem: 3719\n",
            "Epoch: [71]  [140/295]  eta: 0:00:43  lr: 0.000197  min_lr: 0.000197  loss: 2.4805 (2.4298)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0016  max mem: 3719\n",
            "Epoch: [71]  [150/295]  eta: 0:00:40  lr: 0.000195  min_lr: 0.000195  loss: 2.4259 (2.4283)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0015  max mem: 3719\n",
            "Epoch: [71]  [160/295]  eta: 0:00:37  lr: 0.000194  min_lr: 0.000194  loss: 2.4259 (2.4335)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0015  max mem: 3719\n",
            "Epoch: [71]  [170/295]  eta: 0:00:34  lr: 0.000192  min_lr: 0.000192  loss: 2.5710 (2.4413)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0031  max mem: 3719\n",
            "Epoch: [71]  [180/295]  eta: 0:00:31  lr: 0.000191  min_lr: 0.000191  loss: 2.4591 (2.4394)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0035  max mem: 3719\n",
            "Epoch: [71]  [190/295]  eta: 0:00:28  lr: 0.000189  min_lr: 0.000189  loss: 2.4410 (2.4331)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0022  max mem: 3719\n",
            "Epoch: [71]  [200/295]  eta: 0:00:26  lr: 0.000188  min_lr: 0.000188  loss: 2.4678 (2.4304)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0017  max mem: 3719\n",
            "Epoch: [71]  [210/295]  eta: 0:00:23  lr: 0.000186  min_lr: 0.000186  loss: 2.4185 (2.4287)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0025  max mem: 3719\n",
            "Epoch: [71]  [220/295]  eta: 0:00:20  lr: 0.000185  min_lr: 0.000185  loss: 2.4647 (2.4358)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0036  max mem: 3719\n",
            "Epoch: [71]  [230/295]  eta: 0:00:17  lr: 0.000183  min_lr: 0.000183  loss: 2.5966 (2.4437)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0042  max mem: 3719\n",
            "Epoch: [71]  [240/295]  eta: 0:00:15  lr: 0.000182  min_lr: 0.000182  loss: 2.5327 (2.4434)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0038  max mem: 3719\n",
            "Epoch: [71]  [250/295]  eta: 0:00:12  lr: 0.000180  min_lr: 0.000180  loss: 2.5148 (2.4414)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0035  max mem: 3719\n",
            "Epoch: [71]  [260/295]  eta: 0:00:09  lr: 0.000179  min_lr: 0.000179  loss: 2.4630 (2.4394)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0043  max mem: 3719\n",
            "Epoch: [71]  [270/295]  eta: 0:00:06  lr: 0.000177  min_lr: 0.000177  loss: 2.4630 (2.4387)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0037  max mem: 3719\n",
            "Epoch: [71]  [280/295]  eta: 0:00:04  lr: 0.000176  min_lr: 0.000176  loss: 2.4972 (2.4378)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0017  max mem: 3719\n",
            "Epoch: [71]  [290/295]  eta: 0:00:01  lr: 0.000174  min_lr: 0.000174  loss: 2.4372 (2.4368)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0004  max mem: 3719\n",
            "Epoch: [71]  [294/295]  eta: 0:00:00  lr: 0.000174  min_lr: 0.000174  loss: 2.4372 (2.4366)  weight_decay: 0.0500 (0.0500)  time: 0.2223  data: 0.0002  max mem: 3719\n",
            "Epoch: [71] Total time: 0:01:20 (0.2717 s / it)\n",
            "Averaged stats: lr: 0.000174  min_lr: 0.000174  loss: 2.4372 (2.4366)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:05  loss: 0.5690 (0.5690)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 2.2564  data: 2.0885  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.5072 (0.5292)  acc1: 91.6667 (91.4773)  acc5: 97.9167 (98.4849)  time: 0.3186  data: 0.1914  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5145 (0.5530)  acc1: 89.5833 (90.2778)  acc5: 100.0000 (98.6111)  time: 0.1243  data: 0.0028  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6680 (0.7241)  acc1: 85.4167 (83.1317)  acc5: 97.9167 (98.5215)  time: 0.1294  data: 0.0035  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8186 (0.7285)  acc1: 77.0833 (82.8252)  acc5: 97.9167 (98.4756)  time: 0.1297  data: 0.0028  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7803 (0.7355)  acc1: 79.1667 (82.4346)  acc5: 97.9167 (98.4886)  time: 0.1239  data: 0.0029  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7803 (0.7420)  acc1: 79.1667 (81.9331)  acc5: 97.9167 (98.2582)  time: 0.1237  data: 0.0036  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9034 (0.7734)  acc1: 77.0833 (80.6338)  acc5: 97.9167 (97.9460)  time: 0.1212  data: 0.0020  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7246 (0.7518)  acc1: 79.1667 (81.4558)  acc5: 97.9167 (97.9938)  time: 0.1183  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7246 (0.7526)  acc1: 79.1667 (81.4268)  acc5: 97.9167 (97.9618)  time: 0.1167  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1570 s / it)\n",
            "* Acc@1 81.427 Acc@5 97.962 loss 0.753\n",
            "Accuracy of the model on the 3925 test images: 81.4%\n",
            "Max accuracy: 81.43%\n",
            "Test:  [ 0/82]  eta: 0:03:45  loss: 2.3365 (2.3365)  acc1: 22.9167 (22.9167)  acc5: 93.7500 (93.7500)  time: 2.7540  data: 2.5662  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 2.5384 (2.6033)  acc1: 18.7500 (17.2348)  acc5: 93.7500 (93.5606)  time: 0.3661  data: 0.2364  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 2.6722 (2.7757)  acc1: 16.6667 (17.2619)  acc5: 93.7500 (93.0556)  time: 0.1252  data: 0.0022  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 3.4177 (3.3331)  acc1: 10.4167 (12.7016)  acc5: 87.5000 (80.3091)  time: 0.1248  data: 0.0025  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.7987 (3.4319)  acc1: 10.4167 (13.3130)  acc5: 70.8333 (78.0488)  time: 0.1243  data: 0.0052  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.8092 (3.6596)  acc1: 12.5000 (12.7451)  acc5: 70.8333 (73.2843)  time: 0.1241  data: 0.0058  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2476 (3.7573)  acc1: 2.0833 (10.8948)  acc5: 45.8333 (71.0041)  time: 0.1241  data: 0.0047  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.6667 (3.6414)  acc1: 2.0833 (14.5246)  acc5: 72.9167 (70.7746)  time: 0.1198  data: 0.0021  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1805 (3.3036)  acc1: 64.5833 (22.1451)  acc5: 97.9167 (74.0741)  time: 0.1174  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1265 (3.2770)  acc1: 68.7500 (22.6752)  acc5: 97.9167 (74.2166)  time: 0.1159  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1619 s / it)\n",
            "* Acc@1 22.675 Acc@5 74.217 loss 3.277\n",
            "Accuracy of the model EMA on 3925 test images: 22.7%\n",
            "Max EMA accuracy: 22.68%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [72]  [  0/295]  eta: 0:15:20  lr: 0.000174  min_lr: 0.000174  loss: 2.1468 (2.1468)  weight_decay: 0.0500 (0.0500)  time: 3.1216  data: 2.6408  max mem: 3719\n",
            "Epoch: [72]  [ 10/295]  eta: 0:02:36  lr: 0.000173  min_lr: 0.000173  loss: 2.6063 (2.4506)  weight_decay: 0.0500 (0.0500)  time: 0.5480  data: 0.2421  max mem: 3719\n",
            "Epoch: [72]  [ 20/295]  eta: 0:01:53  lr: 0.000171  min_lr: 0.000171  loss: 2.6579 (2.5019)  weight_decay: 0.0500 (0.0500)  time: 0.2759  data: 0.0016  max mem: 3719\n",
            "Epoch: [72]  [ 30/295]  eta: 0:01:36  lr: 0.000170  min_lr: 0.000170  loss: 2.5526 (2.4860)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0007  max mem: 3719\n",
            "Epoch: [72]  [ 40/295]  eta: 0:01:26  lr: 0.000168  min_lr: 0.000168  loss: 2.5133 (2.4886)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0013  max mem: 3719\n",
            "Epoch: [72]  [ 50/295]  eta: 0:01:19  lr: 0.000167  min_lr: 0.000167  loss: 2.4778 (2.4652)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0013  max mem: 3719\n",
            "Epoch: [72]  [ 60/295]  eta: 0:01:14  lr: 0.000165  min_lr: 0.000165  loss: 2.3307 (2.4340)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0015  max mem: 3719\n",
            "Epoch: [72]  [ 70/295]  eta: 0:01:09  lr: 0.000164  min_lr: 0.000164  loss: 2.2564 (2.4209)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0021  max mem: 3719\n",
            "Epoch: [72]  [ 80/295]  eta: 0:01:05  lr: 0.000162  min_lr: 0.000162  loss: 2.3738 (2.4126)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0012  max mem: 3719\n",
            "Epoch: [72]  [ 90/295]  eta: 0:01:01  lr: 0.000161  min_lr: 0.000161  loss: 2.4542 (2.4214)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0014  max mem: 3719\n",
            "Epoch: [72]  [100/295]  eta: 0:00:57  lr: 0.000160  min_lr: 0.000160  loss: 2.3247 (2.4087)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0030  max mem: 3719\n",
            "Epoch: [72]  [110/295]  eta: 0:00:54  lr: 0.000158  min_lr: 0.000158  loss: 2.3247 (2.4095)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0037  max mem: 3719\n",
            "Epoch: [72]  [120/295]  eta: 0:00:51  lr: 0.000157  min_lr: 0.000157  loss: 2.4262 (2.4051)  weight_decay: 0.0500 (0.0500)  time: 0.2758  data: 0.0033  max mem: 3719\n",
            "Epoch: [72]  [130/295]  eta: 0:00:48  lr: 0.000156  min_lr: 0.000156  loss: 2.4273 (2.4020)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0029  max mem: 3719\n",
            "Epoch: [72]  [140/295]  eta: 0:00:44  lr: 0.000154  min_lr: 0.000154  loss: 2.4273 (2.4113)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0022  max mem: 3719\n",
            "Epoch: [72]  [150/295]  eta: 0:00:41  lr: 0.000153  min_lr: 0.000153  loss: 2.4554 (2.4121)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0013  max mem: 3719\n",
            "Epoch: [72]  [160/295]  eta: 0:00:38  lr: 0.000151  min_lr: 0.000151  loss: 2.4554 (2.4156)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0018  max mem: 3719\n",
            "Epoch: [72]  [170/295]  eta: 0:00:35  lr: 0.000150  min_lr: 0.000150  loss: 2.3916 (2.4058)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0031  max mem: 3719\n",
            "Epoch: [72]  [180/295]  eta: 0:00:32  lr: 0.000149  min_lr: 0.000149  loss: 2.2721 (2.4064)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0036  max mem: 3719\n",
            "Epoch: [72]  [190/295]  eta: 0:00:29  lr: 0.000147  min_lr: 0.000147  loss: 2.4958 (2.4066)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0032  max mem: 3719\n",
            "Epoch: [72]  [200/295]  eta: 0:00:26  lr: 0.000146  min_lr: 0.000146  loss: 2.4289 (2.4033)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0023  max mem: 3719\n",
            "Epoch: [72]  [210/295]  eta: 0:00:23  lr: 0.000145  min_lr: 0.000145  loss: 2.4042 (2.4009)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0015  max mem: 3719\n",
            "Epoch: [72]  [220/295]  eta: 0:00:21  lr: 0.000143  min_lr: 0.000143  loss: 2.4175 (2.4014)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0015  max mem: 3719\n",
            "Epoch: [72]  [230/295]  eta: 0:00:18  lr: 0.000142  min_lr: 0.000142  loss: 2.4784 (2.4032)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0025  max mem: 3719\n",
            "Epoch: [72]  [240/295]  eta: 0:00:15  lr: 0.000141  min_lr: 0.000141  loss: 2.4130 (2.4027)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0026  max mem: 3719\n",
            "Epoch: [72]  [250/295]  eta: 0:00:12  lr: 0.000140  min_lr: 0.000140  loss: 2.4954 (2.4120)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0035  max mem: 3719\n",
            "Epoch: [72]  [260/295]  eta: 0:00:09  lr: 0.000138  min_lr: 0.000138  loss: 2.5285 (2.4128)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0035  max mem: 3719\n",
            "Epoch: [72]  [270/295]  eta: 0:00:06  lr: 0.000137  min_lr: 0.000137  loss: 2.3741 (2.4092)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0018  max mem: 3719\n",
            "Epoch: [72]  [280/295]  eta: 0:00:04  lr: 0.000135  min_lr: 0.000135  loss: 2.3612 (2.4087)  weight_decay: 0.0500 (0.0500)  time: 0.2564  data: 0.0011  max mem: 3719\n",
            "Epoch: [72]  [290/295]  eta: 0:00:01  lr: 0.000134  min_lr: 0.000134  loss: 2.3544 (2.4077)  weight_decay: 0.0500 (0.0500)  time: 0.2552  data: 0.0004  max mem: 3719\n",
            "Epoch: [72]  [294/295]  eta: 0:00:00  lr: 0.000134  min_lr: 0.000134  loss: 2.3487 (2.4073)  weight_decay: 0.0500 (0.0500)  time: 0.2176  data: 0.0002  max mem: 3719\n",
            "Epoch: [72] Total time: 0:01:21 (0.2751 s / it)\n",
            "Averaged stats: lr: 0.000134  min_lr: 0.000134  loss: 2.3487 (2.4073)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:01  loss: 0.5712 (0.5712)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.9434  data: 2.7694  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 0.5038 (0.5326)  acc1: 91.6667 (90.1515)  acc5: 97.9167 (98.4849)  time: 0.4296  data: 0.2829  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.5063 (0.5628)  acc1: 87.5000 (88.3929)  acc5: 100.0000 (98.6111)  time: 0.1512  data: 0.0188  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6783 (0.7162)  acc1: 83.3333 (82.3253)  acc5: 100.0000 (98.6559)  time: 0.1231  data: 0.0044  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7399 (0.7022)  acc1: 81.2500 (83.0285)  acc5: 100.0000 (98.6789)  time: 0.1229  data: 0.0052  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7191 (0.7228)  acc1: 81.2500 (82.1895)  acc5: 100.0000 (98.6111)  time: 0.1242  data: 0.0044  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7881 (0.7260)  acc1: 79.1667 (81.8648)  acc5: 97.9167 (98.4973)  time: 0.1236  data: 0.0045  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8309 (0.7520)  acc1: 77.0833 (80.9272)  acc5: 97.9167 (98.2394)  time: 0.1206  data: 0.0030  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7130 (0.7335)  acc1: 83.3333 (81.7130)  acc5: 97.9167 (98.2510)  time: 0.1179  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7130 (0.7344)  acc1: 83.3333 (81.7070)  acc5: 97.9167 (98.2166)  time: 0.1165  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1685 s / it)\n",
            "* Acc@1 81.707 Acc@5 98.217 loss 0.734\n",
            "Accuracy of the model on the 3925 test images: 81.7%\n",
            "Max accuracy: 81.71%\n",
            "Test:  [ 0/82]  eta: 0:04:28  loss: 2.2940 (2.2940)  acc1: 22.9167 (22.9167)  acc5: 93.7500 (93.7500)  time: 3.2732  data: 3.0962  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 2.5060 (2.5660)  acc1: 18.7500 (17.4242)  acc5: 93.7500 (93.9394)  time: 0.4369  data: 0.2852  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 2.6497 (2.7426)  acc1: 16.6667 (17.7579)  acc5: 93.7500 (93.4524)  time: 0.1572  data: 0.0144  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.3816 (3.3004)  acc1: 10.4167 (13.1048)  acc5: 89.5833 (80.4436)  time: 0.1422  data: 0.0145  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 3.7390 (3.3953)  acc1: 10.4167 (13.8211)  acc5: 70.8333 (78.1504)  time: 0.1344  data: 0.0042  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.7505 (3.6268)  acc1: 12.5000 (13.1127)  acc5: 70.8333 (73.3660)  time: 0.1483  data: 0.0038  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.2446 (3.7225)  acc1: 2.0833 (11.2022)  acc5: 45.8333 (71.1749)  time: 0.1551  data: 0.0123  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.6252 (3.6068)  acc1: 2.0833 (14.7887)  acc5: 75.0000 (71.0094)  time: 0.1539  data: 0.0117  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1594 (3.2716)  acc1: 64.5833 (22.4280)  acc5: 97.9167 (74.2798)  time: 0.1341  data: 0.0013  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1143 (3.2453)  acc1: 70.8333 (22.9554)  acc5: 97.9167 (74.4459)  time: 0.1314  data: 0.0013  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1902 s / it)\n",
            "* Acc@1 22.955 Acc@5 74.446 loss 3.245\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "Max EMA accuracy: 22.96%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [73]  [  0/295]  eta: 0:14:42  lr: 0.000134  min_lr: 0.000134  loss: 2.4561 (2.4561)  weight_decay: 0.0500 (0.0500)  time: 2.9900  data: 2.2543  max mem: 3719\n",
            "Epoch: [73]  [ 10/295]  eta: 0:02:36  lr: 0.000133  min_lr: 0.000133  loss: 2.2265 (2.2526)  weight_decay: 0.0500 (0.0500)  time: 0.5481  data: 0.2077  max mem: 3719\n",
            "Epoch: [73]  [ 20/295]  eta: 0:01:53  lr: 0.000131  min_lr: 0.000131  loss: 2.3610 (2.3843)  weight_decay: 0.0500 (0.0500)  time: 0.2850  data: 0.0022  max mem: 3719\n",
            "Epoch: [73]  [ 30/295]  eta: 0:01:36  lr: 0.000130  min_lr: 0.000130  loss: 2.5012 (2.4141)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0012  max mem: 3719\n",
            "Epoch: [73]  [ 40/295]  eta: 0:01:26  lr: 0.000129  min_lr: 0.000129  loss: 2.4857 (2.4263)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0010  max mem: 3719\n",
            "Epoch: [73]  [ 50/295]  eta: 0:01:20  lr: 0.000128  min_lr: 0.000128  loss: 2.4544 (2.4293)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0010  max mem: 3719\n",
            "Epoch: [73]  [ 60/295]  eta: 0:01:15  lr: 0.000126  min_lr: 0.000126  loss: 2.4633 (2.4321)  weight_decay: 0.0500 (0.0500)  time: 0.2750  data: 0.0015  max mem: 3719\n",
            "Epoch: [73]  [ 70/295]  eta: 0:01:10  lr: 0.000125  min_lr: 0.000125  loss: 2.5397 (2.4525)  weight_decay: 0.0500 (0.0500)  time: 0.2746  data: 0.0027  max mem: 3719\n",
            "Epoch: [73]  [ 80/295]  eta: 0:01:06  lr: 0.000124  min_lr: 0.000124  loss: 2.4383 (2.4319)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0027  max mem: 3719\n",
            "Epoch: [73]  [ 90/295]  eta: 0:01:02  lr: 0.000123  min_lr: 0.000123  loss: 2.3970 (2.4388)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0019  max mem: 3719\n",
            "Epoch: [73]  [100/295]  eta: 0:00:58  lr: 0.000121  min_lr: 0.000121  loss: 2.3891 (2.4301)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0020  max mem: 3719\n",
            "Epoch: [73]  [110/295]  eta: 0:00:54  lr: 0.000120  min_lr: 0.000120  loss: 2.3699 (2.4281)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0019  max mem: 3719\n",
            "Epoch: [73]  [120/295]  eta: 0:00:51  lr: 0.000119  min_lr: 0.000119  loss: 2.3249 (2.4167)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0014  max mem: 3719\n",
            "Epoch: [73]  [130/295]  eta: 0:00:48  lr: 0.000118  min_lr: 0.000118  loss: 2.2832 (2.4129)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0028  max mem: 3719\n",
            "Epoch: [73]  [140/295]  eta: 0:00:45  lr: 0.000116  min_lr: 0.000116  loss: 2.5232 (2.4234)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0029  max mem: 3719\n",
            "Epoch: [73]  [150/295]  eta: 0:00:41  lr: 0.000115  min_lr: 0.000115  loss: 2.5544 (2.4270)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0008  max mem: 3719\n",
            "Epoch: [73]  [160/295]  eta: 0:00:38  lr: 0.000114  min_lr: 0.000114  loss: 2.5034 (2.4322)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0009  max mem: 3719\n",
            "Epoch: [73]  [170/295]  eta: 0:00:35  lr: 0.000113  min_lr: 0.000113  loss: 2.4613 (2.4306)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0010  max mem: 3719\n",
            "Epoch: [73]  [180/295]  eta: 0:00:32  lr: 0.000112  min_lr: 0.000112  loss: 2.4320 (2.4336)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0020  max mem: 3719\n",
            "Epoch: [73]  [190/295]  eta: 0:00:29  lr: 0.000111  min_lr: 0.000111  loss: 2.5962 (2.4378)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0022  max mem: 3719\n",
            "Epoch: [73]  [200/295]  eta: 0:00:26  lr: 0.000109  min_lr: 0.000109  loss: 2.6101 (2.4404)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0019  max mem: 3719\n",
            "Epoch: [73]  [210/295]  eta: 0:00:23  lr: 0.000108  min_lr: 0.000108  loss: 2.5126 (2.4341)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0020  max mem: 3719\n",
            "Epoch: [73]  [220/295]  eta: 0:00:21  lr: 0.000107  min_lr: 0.000107  loss: 2.3181 (2.4295)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0012  max mem: 3719\n",
            "Epoch: [73]  [230/295]  eta: 0:00:18  lr: 0.000106  min_lr: 0.000106  loss: 2.3933 (2.4302)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0013  max mem: 3719\n",
            "Epoch: [73]  [240/295]  eta: 0:00:15  lr: 0.000105  min_lr: 0.000105  loss: 2.5023 (2.4341)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0019  max mem: 3719\n",
            "Epoch: [73]  [250/295]  eta: 0:00:12  lr: 0.000104  min_lr: 0.000104  loss: 2.4323 (2.4290)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0021  max mem: 3719\n",
            "Epoch: [73]  [260/295]  eta: 0:00:09  lr: 0.000102  min_lr: 0.000102  loss: 2.3771 (2.4304)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0020  max mem: 3719\n",
            "Epoch: [73]  [270/295]  eta: 0:00:06  lr: 0.000102  min_lr: 0.000102  loss: 2.5299 (2.4324)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0019  max mem: 3719\n",
            "Epoch: [73]  [280/295]  eta: 0:00:04  lr: 0.000100  min_lr: 0.000100  loss: 2.4644 (2.4293)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0010  max mem: 3719\n",
            "Epoch: [73]  [290/295]  eta: 0:00:01  lr: 0.000099  min_lr: 0.000099  loss: 2.1929 (2.4237)  weight_decay: 0.0500 (0.0500)  time: 0.2561  data: 0.0002  max mem: 3719\n",
            "Epoch: [73]  [294/295]  eta: 0:00:00  lr: 0.000099  min_lr: 0.000099  loss: 2.1877 (2.4219)  weight_decay: 0.0500 (0.0500)  time: 0.2182  data: 0.0002  max mem: 3719\n",
            "Epoch: [73] Total time: 0:01:20 (0.2744 s / it)\n",
            "Averaged stats: lr: 0.000099  min_lr: 0.000099  loss: 2.1877 (2.4219)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:55  loss: 0.5852 (0.5852)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.8731  data: 2.6673  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 0.4991 (0.5399)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (98.2955)  time: 0.3980  data: 0.2605  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.5253 (0.5680)  acc1: 89.5833 (89.1865)  acc5: 100.0000 (98.4127)  time: 0.1666  data: 0.0255  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.7002 (0.7581)  acc1: 83.3333 (81.1156)  acc5: 97.9167 (98.0511)  time: 0.1586  data: 0.0205  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7018 (0.7269)  acc1: 83.3333 (82.1138)  acc5: 97.9167 (98.3232)  time: 0.1449  data: 0.0210  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6523 (0.7292)  acc1: 83.3333 (82.1078)  acc5: 100.0000 (98.3660)  time: 0.1382  data: 0.0179  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7723 (0.7299)  acc1: 83.3333 (82.0697)  acc5: 97.9167 (98.3265)  time: 0.1237  data: 0.0039  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8349 (0.7570)  acc1: 79.1667 (81.0446)  acc5: 97.9167 (98.1514)  time: 0.1233  data: 0.0023  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7666 (0.7422)  acc1: 81.2500 (81.6358)  acc5: 97.9167 (98.1739)  time: 0.1195  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7666 (0.7439)  acc1: 81.2500 (81.6051)  acc5: 97.9167 (98.1147)  time: 0.1172  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1761 s / it)\n",
            "* Acc@1 81.605 Acc@5 98.115 loss 0.744\n",
            "Accuracy of the model on the 3925 test images: 81.6%\n",
            "Max accuracy: 81.71%\n",
            "Test:  [ 0/82]  eta: 0:02:27  loss: 2.2501 (2.2501)  acc1: 22.9167 (22.9167)  acc5: 93.7500 (93.7500)  time: 1.8033  data: 1.6323  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 2.4712 (2.5278)  acc1: 18.7500 (17.9924)  acc5: 93.7500 (94.1288)  time: 0.3074  data: 0.1779  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 2.6264 (2.7091)  acc1: 18.7500 (18.2540)  acc5: 93.7500 (93.5516)  time: 0.1631  data: 0.0341  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.3467 (3.2666)  acc1: 10.4167 (13.4409)  acc5: 89.5833 (80.5108)  time: 0.1785  data: 0.0457  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.6785 (3.3577)  acc1: 10.4167 (14.1768)  acc5: 70.8333 (78.4553)  time: 0.1828  data: 0.0464  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.6908 (3.5926)  acc1: 12.5000 (13.3987)  acc5: 70.8333 (73.5703)  time: 0.1618  data: 0.0194  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.2395 (3.6860)  acc1: 4.1667 (11.5096)  acc5: 45.8333 (71.4139)  time: 0.1378  data: 0.0015  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.5826 (3.5706)  acc1: 2.0833 (15.0528)  acc5: 75.0000 (71.2148)  time: 0.1245  data: 0.0009  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1403 (3.2383)  acc1: 64.5833 (22.6852)  acc5: 97.9167 (74.4856)  time: 0.1204  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1015 (3.2123)  acc1: 70.8333 (23.2102)  acc5: 97.9167 (74.6497)  time: 0.1189  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1758 s / it)\n",
            "* Acc@1 23.210 Acc@5 74.650 loss 3.212\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "Max EMA accuracy: 23.21%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [74]  [  0/295]  eta: 0:09:39  lr: 0.000099  min_lr: 0.000099  loss: 2.0314 (2.0314)  weight_decay: 0.0500 (0.0500)  time: 1.9655  data: 1.4870  max mem: 3719\n",
            "Epoch: [74]  [ 10/295]  eta: 0:02:01  lr: 0.000098  min_lr: 0.000098  loss: 2.4583 (2.4402)  weight_decay: 0.0500 (0.0500)  time: 0.4264  data: 0.1356  max mem: 3719\n",
            "Epoch: [74]  [ 20/295]  eta: 0:01:37  lr: 0.000097  min_lr: 0.000097  loss: 2.4877 (2.4669)  weight_decay: 0.0500 (0.0500)  time: 0.2747  data: 0.0022  max mem: 3719\n",
            "Epoch: [74]  [ 30/295]  eta: 0:01:27  lr: 0.000096  min_lr: 0.000096  loss: 2.4591 (2.4496)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0040  max mem: 3719\n",
            "Epoch: [74]  [ 40/295]  eta: 0:01:20  lr: 0.000094  min_lr: 0.000094  loss: 2.4495 (2.4525)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0041  max mem: 3719\n",
            "Epoch: [74]  [ 50/295]  eta: 0:01:14  lr: 0.000094  min_lr: 0.000094  loss: 2.4495 (2.4410)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0025  max mem: 3719\n",
            "Epoch: [74]  [ 60/295]  eta: 0:01:09  lr: 0.000092  min_lr: 0.000092  loss: 2.3583 (2.4437)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0009  max mem: 3719\n",
            "Epoch: [74]  [ 70/295]  eta: 0:01:05  lr: 0.000091  min_lr: 0.000091  loss: 2.3791 (2.4363)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0016  max mem: 3719\n",
            "Epoch: [74]  [ 80/295]  eta: 0:01:02  lr: 0.000090  min_lr: 0.000090  loss: 2.4195 (2.4390)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0023  max mem: 3719\n",
            "Epoch: [74]  [ 90/295]  eta: 0:00:58  lr: 0.000089  min_lr: 0.000089  loss: 2.3863 (2.4248)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0024  max mem: 3719\n",
            "Epoch: [74]  [100/295]  eta: 0:00:56  lr: 0.000088  min_lr: 0.000088  loss: 2.4183 (2.4262)  weight_decay: 0.0500 (0.0500)  time: 0.2780  data: 0.0048  max mem: 3719\n",
            "Epoch: [74]  [110/295]  eta: 0:00:52  lr: 0.000087  min_lr: 0.000087  loss: 2.4311 (2.4259)  weight_decay: 0.0500 (0.0500)  time: 0.2789  data: 0.0059  max mem: 3719\n",
            "Epoch: [74]  [120/295]  eta: 0:00:49  lr: 0.000086  min_lr: 0.000086  loss: 2.4311 (2.4251)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0039  max mem: 3719\n",
            "Epoch: [74]  [130/295]  eta: 0:00:46  lr: 0.000085  min_lr: 0.000085  loss: 2.4384 (2.4254)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0023  max mem: 3719\n",
            "Epoch: [74]  [140/295]  eta: 0:00:43  lr: 0.000084  min_lr: 0.000084  loss: 2.4667 (2.4299)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0017  max mem: 3719\n",
            "Epoch: [74]  [150/295]  eta: 0:00:40  lr: 0.000083  min_lr: 0.000083  loss: 2.5176 (2.4330)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0032  max mem: 3719\n",
            "Epoch: [74]  [160/295]  eta: 0:00:37  lr: 0.000082  min_lr: 0.000082  loss: 2.4107 (2.4239)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0050  max mem: 3719\n",
            "Epoch: [74]  [170/295]  eta: 0:00:34  lr: 0.000081  min_lr: 0.000081  loss: 2.3281 (2.4215)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0049  max mem: 3719\n",
            "Epoch: [74]  [180/295]  eta: 0:00:31  lr: 0.000080  min_lr: 0.000080  loss: 2.5280 (2.4213)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0034  max mem: 3719\n",
            "Epoch: [74]  [190/295]  eta: 0:00:29  lr: 0.000079  min_lr: 0.000079  loss: 2.4267 (2.4170)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0030  max mem: 3719\n",
            "Epoch: [74]  [200/295]  eta: 0:00:26  lr: 0.000078  min_lr: 0.000078  loss: 2.2853 (2.4110)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0018  max mem: 3719\n",
            "Epoch: [74]  [210/295]  eta: 0:00:23  lr: 0.000077  min_lr: 0.000077  loss: 2.3492 (2.4137)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0014  max mem: 3719\n",
            "Epoch: [74]  [220/295]  eta: 0:00:20  lr: 0.000076  min_lr: 0.000076  loss: 2.4132 (2.4137)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0046  max mem: 3719\n",
            "Epoch: [74]  [230/295]  eta: 0:00:17  lr: 0.000075  min_lr: 0.000075  loss: 2.3542 (2.4148)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0050  max mem: 3719\n",
            "Epoch: [74]  [240/295]  eta: 0:00:15  lr: 0.000074  min_lr: 0.000074  loss: 2.4858 (2.4182)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0019  max mem: 3719\n",
            "Epoch: [74]  [250/295]  eta: 0:00:12  lr: 0.000073  min_lr: 0.000073  loss: 2.5568 (2.4213)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0010  max mem: 3719\n",
            "Epoch: [74]  [260/295]  eta: 0:00:09  lr: 0.000072  min_lr: 0.000072  loss: 2.5200 (2.4236)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0015  max mem: 3719\n",
            "Epoch: [74]  [270/295]  eta: 0:00:06  lr: 0.000071  min_lr: 0.000071  loss: 2.4016 (2.4182)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0026  max mem: 3719\n",
            "Epoch: [74]  [280/295]  eta: 0:00:04  lr: 0.000070  min_lr: 0.000070  loss: 2.4016 (2.4177)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0021  max mem: 3719\n",
            "Epoch: [74]  [290/295]  eta: 0:00:01  lr: 0.000070  min_lr: 0.000070  loss: 2.4246 (2.4200)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0003  max mem: 3719\n",
            "Epoch: [74]  [294/295]  eta: 0:00:00  lr: 0.000070  min_lr: 0.000070  loss: 2.4246 (2.4210)  weight_decay: 0.0500 (0.0500)  time: 0.2219  data: 0.0003  max mem: 3719\n",
            "Epoch: [74] Total time: 0:01:19 (0.2711 s / it)\n",
            "Averaged stats: lr: 0.000070  min_lr: 0.000070  loss: 2.4246 (2.4210)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:35  loss: 0.5927 (0.5927)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 1.8934  data: 1.7269  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5053 (0.5334)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (98.4849)  time: 0.2919  data: 0.1672  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5153 (0.5475)  acc1: 91.6667 (90.4762)  acc5: 100.0000 (98.7103)  time: 0.1275  data: 0.0072  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6594 (0.7500)  acc1: 87.5000 (81.7204)  acc5: 97.9167 (98.2527)  time: 0.1247  data: 0.0032  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.6960 (0.7227)  acc1: 83.3333 (82.7236)  acc5: 97.9167 (98.4756)  time: 0.1251  data: 0.0033  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6844 (0.7254)  acc1: 81.2500 (82.5572)  acc5: 100.0000 (98.5294)  time: 0.1239  data: 0.0047  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7578 (0.7385)  acc1: 81.2500 (82.1380)  acc5: 97.9167 (98.3607)  time: 0.1303  data: 0.0050  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8678 (0.7629)  acc1: 77.0833 (81.0739)  acc5: 97.9167 (98.1514)  time: 0.1324  data: 0.0021  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7309 (0.7449)  acc1: 81.2500 (81.7901)  acc5: 97.9167 (98.1739)  time: 0.1233  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7309 (0.7466)  acc1: 81.2500 (81.7834)  acc5: 97.9167 (98.1147)  time: 0.1213  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1548 s / it)\n",
            "* Acc@1 81.783 Acc@5 98.115 loss 0.747\n",
            "Accuracy of the model on the 3925 test images: 81.8%\n",
            "Max accuracy: 81.78%\n",
            "Test:  [ 0/82]  eta: 0:02:39  loss: 2.2056 (2.2056)  acc1: 27.0833 (27.0833)  acc5: 93.7500 (93.7500)  time: 1.9499  data: 1.7854  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.4339 (2.4887)  acc1: 18.7500 (19.6970)  acc5: 93.7500 (94.3182)  time: 0.2939  data: 0.1644  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.6015 (2.6742)  acc1: 18.7500 (19.2460)  acc5: 93.7500 (93.8492)  time: 0.1251  data: 0.0022  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.3103 (3.2318)  acc1: 10.4167 (14.1129)  acc5: 89.5833 (80.7124)  time: 0.1240  data: 0.0020  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.6172 (3.3190)  acc1: 10.4167 (14.8882)  acc5: 72.9167 (78.8110)  time: 0.1249  data: 0.0037  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.6335 (3.5573)  acc1: 12.5000 (13.8480)  acc5: 72.9167 (73.8154)  time: 0.1219  data: 0.0040  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2339 (3.6482)  acc1: 4.1667 (11.8852)  acc5: 45.8333 (71.6189)  time: 0.1215  data: 0.0032  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.5377 (3.5333)  acc1: 2.0833 (15.3756)  acc5: 75.0000 (71.4202)  time: 0.1213  data: 0.0023  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1220 (3.2041)  acc1: 64.5833 (22.9681)  acc5: 97.9167 (74.6914)  time: 0.1191  data: 0.0004  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0896 (3.1784)  acc1: 70.8333 (23.4904)  acc5: 97.9167 (74.8535)  time: 0.1170  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1516 s / it)\n",
            "* Acc@1 23.490 Acc@5 74.854 loss 3.178\n",
            "Accuracy of the model EMA on 3925 test images: 23.5%\n",
            "Max EMA accuracy: 23.49%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [75]  [  0/295]  eta: 0:11:36  lr: 0.000069  min_lr: 0.000069  loss: 2.4761 (2.4761)  weight_decay: 0.0500 (0.0500)  time: 2.3593  data: 2.0087  max mem: 3719\n",
            "Epoch: [75]  [ 10/295]  eta: 0:02:12  lr: 0.000068  min_lr: 0.000068  loss: 2.4761 (2.4458)  weight_decay: 0.0500 (0.0500)  time: 0.4646  data: 0.1853  max mem: 3719\n",
            "Epoch: [75]  [ 20/295]  eta: 0:01:41  lr: 0.000067  min_lr: 0.000067  loss: 2.4129 (2.4076)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0024  max mem: 3719\n",
            "Epoch: [75]  [ 30/295]  eta: 0:01:28  lr: 0.000067  min_lr: 0.000067  loss: 2.3845 (2.4212)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0014  max mem: 3719\n",
            "Epoch: [75]  [ 40/295]  eta: 0:01:20  lr: 0.000065  min_lr: 0.000065  loss: 2.5111 (2.4436)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0013  max mem: 3719\n",
            "Epoch: [75]  [ 50/295]  eta: 0:01:15  lr: 0.000065  min_lr: 0.000065  loss: 2.5474 (2.4271)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0017  max mem: 3719\n",
            "Epoch: [75]  [ 60/295]  eta: 0:01:11  lr: 0.000064  min_lr: 0.000064  loss: 2.3962 (2.4214)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0027  max mem: 3719\n",
            "Epoch: [75]  [ 70/295]  eta: 0:01:06  lr: 0.000063  min_lr: 0.000063  loss: 2.4971 (2.4377)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0024  max mem: 3719\n",
            "Epoch: [75]  [ 80/295]  eta: 0:01:03  lr: 0.000062  min_lr: 0.000062  loss: 2.5272 (2.4335)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0007  max mem: 3719\n",
            "Epoch: [75]  [ 90/295]  eta: 0:00:59  lr: 0.000061  min_lr: 0.000061  loss: 2.4888 (2.4344)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0011  max mem: 3719\n",
            "Epoch: [75]  [100/295]  eta: 0:00:56  lr: 0.000060  min_lr: 0.000060  loss: 2.4297 (2.4307)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0022  max mem: 3719\n",
            "Epoch: [75]  [110/295]  eta: 0:00:52  lr: 0.000059  min_lr: 0.000059  loss: 2.4372 (2.4290)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0034  max mem: 3719\n",
            "Epoch: [75]  [120/295]  eta: 0:00:49  lr: 0.000058  min_lr: 0.000058  loss: 2.3292 (2.4069)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0050  max mem: 3719\n",
            "Epoch: [75]  [130/295]  eta: 0:00:46  lr: 0.000058  min_lr: 0.000058  loss: 2.3089 (2.3984)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0048  max mem: 3719\n",
            "Epoch: [75]  [140/295]  eta: 0:00:43  lr: 0.000057  min_lr: 0.000057  loss: 2.3987 (2.3970)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0034  max mem: 3719\n",
            "Epoch: [75]  [150/295]  eta: 0:00:40  lr: 0.000056  min_lr: 0.000056  loss: 2.4402 (2.4015)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0028  max mem: 3719\n",
            "Epoch: [75]  [160/295]  eta: 0:00:37  lr: 0.000055  min_lr: 0.000055  loss: 2.5600 (2.4058)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0017  max mem: 3719\n",
            "Epoch: [75]  [170/295]  eta: 0:00:34  lr: 0.000054  min_lr: 0.000054  loss: 2.5984 (2.4089)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0025  max mem: 3719\n",
            "Epoch: [75]  [180/295]  eta: 0:00:31  lr: 0.000053  min_lr: 0.000053  loss: 2.3294 (2.4064)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0044  max mem: 3719\n",
            "Epoch: [75]  [190/295]  eta: 0:00:29  lr: 0.000053  min_lr: 0.000053  loss: 2.3276 (2.4050)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0045  max mem: 3719\n",
            "Epoch: [75]  [200/295]  eta: 0:00:26  lr: 0.000052  min_lr: 0.000052  loss: 2.3649 (2.4043)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0026  max mem: 3719\n",
            "Epoch: [75]  [210/295]  eta: 0:00:23  lr: 0.000051  min_lr: 0.000051  loss: 2.3120 (2.4010)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0010  max mem: 3719\n",
            "Epoch: [75]  [220/295]  eta: 0:00:20  lr: 0.000050  min_lr: 0.000050  loss: 2.4764 (2.4046)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0024  max mem: 3719\n",
            "Epoch: [75]  [230/295]  eta: 0:00:17  lr: 0.000050  min_lr: 0.000050  loss: 2.6090 (2.4063)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0037  max mem: 3719\n",
            "Epoch: [75]  [240/295]  eta: 0:00:15  lr: 0.000049  min_lr: 0.000049  loss: 2.3724 (2.4023)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0043  max mem: 3719\n",
            "Epoch: [75]  [250/295]  eta: 0:00:12  lr: 0.000048  min_lr: 0.000048  loss: 2.3737 (2.4048)  weight_decay: 0.0500 (0.0500)  time: 0.2759  data: 0.0057  max mem: 3719\n",
            "Epoch: [75]  [260/295]  eta: 0:00:09  lr: 0.000047  min_lr: 0.000047  loss: 2.4731 (2.4079)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0059  max mem: 3719\n",
            "Epoch: [75]  [270/295]  eta: 0:00:06  lr: 0.000047  min_lr: 0.000047  loss: 2.3241 (2.4030)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0050  max mem: 3719\n",
            "Epoch: [75]  [280/295]  eta: 0:00:04  lr: 0.000046  min_lr: 0.000046  loss: 2.3375 (2.4043)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0027  max mem: 3719\n",
            "Epoch: [75]  [290/295]  eta: 0:00:01  lr: 0.000045  min_lr: 0.000045  loss: 2.4629 (2.4046)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0002  max mem: 3719\n",
            "Epoch: [75]  [294/295]  eta: 0:00:00  lr: 0.000045  min_lr: 0.000045  loss: 2.4386 (2.4041)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0002  max mem: 3719\n",
            "Epoch: [75] Total time: 0:01:20 (0.2719 s / it)\n",
            "Averaged stats: lr: 0.000045  min_lr: 0.000045  loss: 2.4386 (2.4041)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:12  loss: 0.5845 (0.5845)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 1.6134  data: 1.4520  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.5064 (0.5383)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (98.4849)  time: 0.2862  data: 0.1508  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5146 (0.5562)  acc1: 91.6667 (90.1786)  acc5: 100.0000 (98.7103)  time: 0.1649  data: 0.0282  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.6850 (0.7267)  acc1: 85.4167 (82.3925)  acc5: 100.0000 (98.6559)  time: 0.1767  data: 0.0343  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7148 (0.7041)  acc1: 83.3333 (83.3333)  acc5: 100.0000 (98.7297)  time: 0.1768  data: 0.0344  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6848 (0.7130)  acc1: 83.3333 (82.9657)  acc5: 100.0000 (98.7337)  time: 0.1718  data: 0.0296  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7711 (0.7220)  acc1: 79.1667 (82.5478)  acc5: 97.9167 (98.4973)  time: 0.1505  data: 0.0185  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8545 (0.7488)  acc1: 79.1667 (81.6021)  acc5: 97.9167 (98.2981)  time: 0.1267  data: 0.0070  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7653 (0.7338)  acc1: 83.3333 (82.1502)  acc5: 97.9167 (98.2768)  time: 0.1191  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7653 (0.7357)  acc1: 83.3333 (82.1147)  acc5: 97.9167 (98.2420)  time: 0.1179  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1748 s / it)\n",
            "* Acc@1 82.115 Acc@5 98.242 loss 0.736\n",
            "Accuracy of the model on the 3925 test images: 82.1%\n",
            "Max accuracy: 82.11%\n",
            "Test:  [ 0/82]  eta: 0:02:17  loss: 2.1604 (2.1604)  acc1: 27.0833 (27.0833)  acc5: 93.7500 (93.7500)  time: 1.6816  data: 1.5176  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.3897 (2.4490)  acc1: 20.8333 (20.2652)  acc5: 95.8333 (94.6970)  time: 0.2939  data: 0.1691  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.5795 (2.6396)  acc1: 18.7500 (19.7421)  acc5: 93.7500 (94.1468)  time: 0.1389  data: 0.0185  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.2735 (3.1973)  acc1: 12.5000 (14.5161)  acc5: 89.5833 (80.8468)  time: 0.1310  data: 0.0024  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.5563 (3.2806)  acc1: 12.5000 (15.2439)  acc5: 72.9167 (78.9126)  time: 0.1457  data: 0.0016  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.5934 (3.5223)  acc1: 12.5000 (14.0931)  acc5: 72.9167 (73.8562)  time: 0.1506  data: 0.0010  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2282 (3.6106)  acc1: 4.1667 (12.0902)  acc5: 45.8333 (71.7555)  time: 0.1632  data: 0.0195  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.4929 (3.4962)  acc1: 2.0833 (15.6103)  acc5: 75.0000 (71.5669)  time: 0.1739  data: 0.0349  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1045 (3.1701)  acc1: 64.5833 (23.1739)  acc5: 97.9167 (74.8200)  time: 0.1442  data: 0.0159  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0782 (3.1446)  acc1: 70.8333 (23.6943)  acc5: 97.9167 (74.9809)  time: 0.1399  data: 0.0157  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1710 s / it)\n",
            "* Acc@1 23.694 Acc@5 74.981 loss 3.145\n",
            "Accuracy of the model EMA on 3925 test images: 23.7%\n",
            "Max EMA accuracy: 23.69%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [76]  [  0/295]  eta: 0:08:23  lr: 0.000045  min_lr: 0.000045  loss: 2.5293 (2.5293)  weight_decay: 0.0500 (0.0500)  time: 1.7057  data: 1.2761  max mem: 3719\n",
            "Epoch: [76]  [ 10/295]  eta: 0:01:57  lr: 0.000044  min_lr: 0.000044  loss: 2.4144 (2.3629)  weight_decay: 0.0500 (0.0500)  time: 0.4129  data: 0.1171  max mem: 3719\n",
            "Epoch: [76]  [ 20/295]  eta: 0:01:33  lr: 0.000043  min_lr: 0.000043  loss: 2.3977 (2.4251)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0020  max mem: 3719\n",
            "Epoch: [76]  [ 30/295]  eta: 0:01:24  lr: 0.000043  min_lr: 0.000043  loss: 2.3977 (2.4169)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0035  max mem: 3719\n",
            "Epoch: [76]  [ 40/295]  eta: 0:01:18  lr: 0.000042  min_lr: 0.000042  loss: 2.4668 (2.4445)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0032  max mem: 3719\n",
            "Epoch: [76]  [ 50/295]  eta: 0:01:13  lr: 0.000041  min_lr: 0.000041  loss: 2.4773 (2.4536)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0028  max mem: 3719\n",
            "Epoch: [76]  [ 60/295]  eta: 0:01:09  lr: 0.000040  min_lr: 0.000040  loss: 2.4773 (2.4292)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0024  max mem: 3719\n",
            "Epoch: [76]  [ 70/295]  eta: 0:01:05  lr: 0.000040  min_lr: 0.000040  loss: 2.4844 (2.4407)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0015  max mem: 3719\n",
            "Epoch: [76]  [ 80/295]  eta: 0:01:01  lr: 0.000039  min_lr: 0.000039  loss: 2.4276 (2.4257)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0021  max mem: 3719\n",
            "Epoch: [76]  [ 90/295]  eta: 0:00:58  lr: 0.000038  min_lr: 0.000038  loss: 2.4133 (2.4272)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0024  max mem: 3719\n",
            "Epoch: [76]  [100/295]  eta: 0:00:55  lr: 0.000038  min_lr: 0.000038  loss: 2.5142 (2.4306)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0036  max mem: 3719\n",
            "Epoch: [76]  [110/295]  eta: 0:00:52  lr: 0.000037  min_lr: 0.000037  loss: 2.5010 (2.4263)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0036  max mem: 3719\n",
            "Epoch: [76]  [120/295]  eta: 0:00:48  lr: 0.000036  min_lr: 0.000036  loss: 2.3536 (2.4283)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0017  max mem: 3719\n",
            "Epoch: [76]  [130/295]  eta: 0:00:45  lr: 0.000036  min_lr: 0.000036  loss: 2.3293 (2.4165)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0021  max mem: 3719\n",
            "Epoch: [76]  [140/295]  eta: 0:00:42  lr: 0.000035  min_lr: 0.000035  loss: 2.3095 (2.4128)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0023  max mem: 3719\n",
            "Epoch: [76]  [150/295]  eta: 0:00:40  lr: 0.000034  min_lr: 0.000034  loss: 2.3906 (2.4095)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0023  max mem: 3719\n",
            "Epoch: [76]  [160/295]  eta: 0:00:37  lr: 0.000034  min_lr: 0.000034  loss: 2.3092 (2.4069)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0038  max mem: 3719\n",
            "Epoch: [76]  [170/295]  eta: 0:00:34  lr: 0.000033  min_lr: 0.000033  loss: 2.3092 (2.4036)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0041  max mem: 3719\n",
            "Epoch: [76]  [180/295]  eta: 0:00:31  lr: 0.000032  min_lr: 0.000032  loss: 2.3743 (2.4019)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0036  max mem: 3719\n",
            "Epoch: [76]  [190/295]  eta: 0:00:28  lr: 0.000032  min_lr: 0.000032  loss: 2.3386 (2.3916)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0028  max mem: 3719\n",
            "Epoch: [76]  [200/295]  eta: 0:00:25  lr: 0.000031  min_lr: 0.000031  loss: 2.3597 (2.3941)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0020  max mem: 3719\n",
            "Epoch: [76]  [210/295]  eta: 0:00:23  lr: 0.000031  min_lr: 0.000031  loss: 2.4851 (2.3967)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0021  max mem: 3719\n",
            "Epoch: [76]  [220/295]  eta: 0:00:20  lr: 0.000030  min_lr: 0.000030  loss: 2.3557 (2.3934)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0034  max mem: 3719\n",
            "Epoch: [76]  [230/295]  eta: 0:00:17  lr: 0.000029  min_lr: 0.000029  loss: 2.3040 (2.3901)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0042  max mem: 3719\n",
            "Epoch: [76]  [240/295]  eta: 0:00:14  lr: 0.000029  min_lr: 0.000029  loss: 2.2468 (2.3866)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0028  max mem: 3719\n",
            "Epoch: [76]  [250/295]  eta: 0:00:12  lr: 0.000028  min_lr: 0.000028  loss: 2.3570 (2.3844)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0010  max mem: 3719\n",
            "Epoch: [76]  [260/295]  eta: 0:00:09  lr: 0.000027  min_lr: 0.000027  loss: 2.4206 (2.3858)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0010  max mem: 3719\n",
            "Epoch: [76]  [270/295]  eta: 0:00:06  lr: 0.000027  min_lr: 0.000027  loss: 2.4220 (2.3867)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0021  max mem: 3719\n",
            "Epoch: [76]  [280/295]  eta: 0:00:04  lr: 0.000026  min_lr: 0.000026  loss: 2.4980 (2.3916)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0015  max mem: 3719\n",
            "Epoch: [76]  [290/295]  eta: 0:00:01  lr: 0.000026  min_lr: 0.000026  loss: 2.4854 (2.3888)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0002  max mem: 3719\n",
            "Epoch: [76]  [294/295]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 2.4854 (2.3905)  weight_decay: 0.0500 (0.0500)  time: 0.2231  data: 0.0002  max mem: 3719\n",
            "Epoch: [76] Total time: 0:01:19 (0.2695 s / it)\n",
            "Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 2.4854 (2.3905)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:23  loss: 0.6072 (0.6072)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 1.7537  data: 1.5807  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.5261 (0.5383)  acc1: 91.6667 (89.9621)  acc5: 97.9167 (98.4849)  time: 0.2860  data: 0.1544  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.5261 (0.5413)  acc1: 91.6667 (90.3770)  acc5: 100.0000 (98.6111)  time: 0.1297  data: 0.0068  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6389 (0.7231)  acc1: 83.3333 (82.4597)  acc5: 100.0000 (98.4543)  time: 0.1229  data: 0.0034  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7320 (0.7043)  acc1: 83.3333 (83.2825)  acc5: 100.0000 (98.5772)  time: 0.1256  data: 0.0050  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6895 (0.7133)  acc1: 83.3333 (82.9657)  acc5: 100.0000 (98.5703)  time: 0.1239  data: 0.0041  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7677 (0.7240)  acc1: 81.2500 (82.4795)  acc5: 97.9167 (98.3607)  time: 0.1228  data: 0.0035  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8698 (0.7503)  acc1: 77.0833 (81.4261)  acc5: 97.9167 (98.1808)  time: 0.1211  data: 0.0020  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7339 (0.7321)  acc1: 81.2500 (81.9959)  acc5: 97.9167 (98.1996)  time: 0.1179  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7339 (0.7338)  acc1: 81.2500 (81.9873)  acc5: 97.9167 (98.1656)  time: 0.1164  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1509 s / it)\n",
            "* Acc@1 81.987 Acc@5 98.166 loss 0.734\n",
            "Accuracy of the model on the 3925 test images: 82.0%\n",
            "Max accuracy: 82.11%\n",
            "Test:  [ 0/82]  eta: 0:03:36  loss: 2.1156 (2.1156)  acc1: 27.0833 (27.0833)  acc5: 93.7500 (93.7500)  time: 2.6421  data: 2.4891  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 2.3457 (2.4093)  acc1: 20.8333 (20.4545)  acc5: 95.8333 (94.5076)  time: 0.3690  data: 0.2388  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 2.5580 (2.6051)  acc1: 18.7500 (19.7421)  acc5: 93.7500 (94.1468)  time: 0.1350  data: 0.0117  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.2367 (3.1629)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (80.7796)  time: 0.1327  data: 0.0055  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.4969 (3.2427)  acc1: 12.5000 (15.2947)  acc5: 72.9167 (79.0142)  time: 0.1522  data: 0.0201  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.5526 (3.4873)  acc1: 12.5000 (13.9706)  acc5: 72.9167 (73.8971)  time: 0.1652  data: 0.0310  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.2212 (3.5731)  acc1: 4.1667 (12.0219)  acc5: 45.8333 (71.8921)  time: 0.1562  data: 0.0217  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.4475 (3.4594)  acc1: 2.0833 (15.5516)  acc5: 75.0000 (71.6843)  time: 0.1508  data: 0.0259  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0891 (3.1365)  acc1: 64.5833 (23.1481)  acc5: 97.9167 (74.9228)  time: 0.1348  data: 0.0158  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0668 (3.1113)  acc1: 70.8333 (23.6688)  acc5: 97.9167 (75.0828)  time: 0.1252  data: 0.0071  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1820 s / it)\n",
            "* Acc@1 23.669 Acc@5 75.083 loss 3.111\n",
            "Accuracy of the model EMA on 3925 test images: 23.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [77]  [  0/295]  eta: 0:14:38  lr: 0.000026  min_lr: 0.000026  loss: 2.6027 (2.6027)  weight_decay: 0.0500 (0.0500)  time: 2.9767  data: 2.4748  max mem: 3719\n",
            "Epoch: [77]  [ 10/295]  eta: 0:02:32  lr: 0.000025  min_lr: 0.000025  loss: 2.4991 (2.4514)  weight_decay: 0.0500 (0.0500)  time: 0.5361  data: 0.2275  max mem: 3719\n",
            "Epoch: [77]  [ 20/295]  eta: 0:01:51  lr: 0.000025  min_lr: 0.000025  loss: 2.4991 (2.4764)  weight_decay: 0.0500 (0.0500)  time: 0.2780  data: 0.0019  max mem: 3719\n",
            "Epoch: [77]  [ 30/295]  eta: 0:01:35  lr: 0.000024  min_lr: 0.000024  loss: 2.4855 (2.4697)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0010  max mem: 3719\n",
            "Epoch: [77]  [ 40/295]  eta: 0:01:25  lr: 0.000023  min_lr: 0.000023  loss: 2.4084 (2.4457)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0013  max mem: 3719\n",
            "Epoch: [77]  [ 50/295]  eta: 0:01:19  lr: 0.000023  min_lr: 0.000023  loss: 2.3578 (2.4311)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0009  max mem: 3719\n",
            "Epoch: [77]  [ 60/295]  eta: 0:01:14  lr: 0.000022  min_lr: 0.000022  loss: 2.3660 (2.4267)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0018  max mem: 3719\n",
            "Epoch: [77]  [ 70/295]  eta: 0:01:09  lr: 0.000022  min_lr: 0.000022  loss: 2.3299 (2.3941)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0028  max mem: 3719\n",
            "Epoch: [77]  [ 80/295]  eta: 0:01:05  lr: 0.000021  min_lr: 0.000021  loss: 2.3311 (2.4017)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0020  max mem: 3719\n",
            "Epoch: [77]  [ 90/295]  eta: 0:01:01  lr: 0.000021  min_lr: 0.000021  loss: 2.4082 (2.3980)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0016  max mem: 3719\n",
            "Epoch: [77]  [100/295]  eta: 0:00:57  lr: 0.000020  min_lr: 0.000020  loss: 2.4447 (2.4055)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0010  max mem: 3719\n",
            "Epoch: [77]  [110/295]  eta: 0:00:54  lr: 0.000020  min_lr: 0.000020  loss: 2.4301 (2.3951)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0017  max mem: 3719\n",
            "Epoch: [77]  [120/295]  eta: 0:00:50  lr: 0.000019  min_lr: 0.000019  loss: 2.3206 (2.3895)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0036  max mem: 3719\n",
            "Epoch: [77]  [130/295]  eta: 0:00:47  lr: 0.000019  min_lr: 0.000019  loss: 2.4020 (2.3914)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0055  max mem: 3719\n",
            "Epoch: [77]  [140/295]  eta: 0:00:44  lr: 0.000018  min_lr: 0.000018  loss: 2.5111 (2.3922)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0043  max mem: 3719\n",
            "Epoch: [77]  [150/295]  eta: 0:00:41  lr: 0.000018  min_lr: 0.000018  loss: 2.4721 (2.3943)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0026  max mem: 3719\n",
            "Epoch: [77]  [160/295]  eta: 0:00:38  lr: 0.000017  min_lr: 0.000017  loss: 2.3056 (2.3870)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0030  max mem: 3719\n",
            "Epoch: [77]  [170/295]  eta: 0:00:35  lr: 0.000017  min_lr: 0.000017  loss: 2.2535 (2.3856)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0026  max mem: 3719\n",
            "Epoch: [77]  [180/295]  eta: 0:00:32  lr: 0.000017  min_lr: 0.000017  loss: 2.3269 (2.3813)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0042  max mem: 3719\n",
            "Epoch: [77]  [190/295]  eta: 0:00:29  lr: 0.000016  min_lr: 0.000016  loss: 2.3269 (2.3865)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0051  max mem: 3719\n",
            "Epoch: [77]  [200/295]  eta: 0:00:26  lr: 0.000016  min_lr: 0.000016  loss: 2.3769 (2.3852)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0032  max mem: 3719\n",
            "Epoch: [77]  [210/295]  eta: 0:00:23  lr: 0.000015  min_lr: 0.000015  loss: 2.2118 (2.3810)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0015  max mem: 3719\n",
            "Epoch: [77]  [220/295]  eta: 0:00:20  lr: 0.000015  min_lr: 0.000015  loss: 2.4217 (2.3897)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0014  max mem: 3719\n",
            "Epoch: [77]  [230/295]  eta: 0:00:18  lr: 0.000014  min_lr: 0.000014  loss: 2.4958 (2.3951)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0023  max mem: 3719\n",
            "Epoch: [77]  [240/295]  eta: 0:00:15  lr: 0.000014  min_lr: 0.000014  loss: 2.4674 (2.4003)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0033  max mem: 3719\n",
            "Epoch: [77]  [250/295]  eta: 0:00:12  lr: 0.000014  min_lr: 0.000014  loss: 2.4674 (2.4024)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0032  max mem: 3719\n",
            "Epoch: [77]  [260/295]  eta: 0:00:09  lr: 0.000013  min_lr: 0.000013  loss: 2.3987 (2.3962)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0017  max mem: 3719\n",
            "Epoch: [77]  [270/295]  eta: 0:00:06  lr: 0.000013  min_lr: 0.000013  loss: 2.3462 (2.3961)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0022  max mem: 3719\n",
            "Epoch: [77]  [280/295]  eta: 0:00:04  lr: 0.000012  min_lr: 0.000012  loss: 2.3861 (2.3978)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0023  max mem: 3719\n",
            "Epoch: [77]  [290/295]  eta: 0:00:01  lr: 0.000012  min_lr: 0.000012  loss: 2.5060 (2.3998)  weight_decay: 0.0500 (0.0500)  time: 0.2563  data: 0.0005  max mem: 3719\n",
            "Epoch: [77]  [294/295]  eta: 0:00:00  lr: 0.000012  min_lr: 0.000012  loss: 2.5090 (2.4005)  weight_decay: 0.0500 (0.0500)  time: 0.2187  data: 0.0002  max mem: 3719\n",
            "Epoch: [77] Total time: 0:01:20 (0.2736 s / it)\n",
            "Averaged stats: lr: 0.000012  min_lr: 0.000012  loss: 2.5090 (2.4005)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:18  loss: 0.5933 (0.5933)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 3.1491  data: 2.9577  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.5121 (0.5354)  acc1: 91.6667 (90.3409)  acc5: 97.9167 (98.4849)  time: 0.4430  data: 0.2977  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.5147 (0.5490)  acc1: 91.6667 (89.9802)  acc5: 100.0000 (98.6111)  time: 0.1589  data: 0.0194  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.6677 (0.7252)  acc1: 85.4167 (82.5269)  acc5: 100.0000 (98.6559)  time: 0.1546  data: 0.0088  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7266 (0.7048)  acc1: 83.3333 (83.4858)  acc5: 100.0000 (98.7297)  time: 0.1435  data: 0.0068  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6906 (0.7101)  acc1: 83.3333 (83.3333)  acc5: 100.0000 (98.6928)  time: 0.1232  data: 0.0034  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7514 (0.7212)  acc1: 81.2500 (82.7527)  acc5: 97.9167 (98.4631)  time: 0.1238  data: 0.0042  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8750 (0.7490)  acc1: 77.0833 (81.6021)  acc5: 97.9167 (98.2688)  time: 0.1213  data: 0.0027  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7353 (0.7312)  acc1: 83.3333 (82.2788)  acc5: 97.9167 (98.2768)  time: 0.1181  data: 0.0004  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7353 (0.7329)  acc1: 83.3333 (82.2675)  acc5: 97.9167 (98.2420)  time: 0.1166  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1780 s / it)\n",
            "* Acc@1 82.268 Acc@5 98.242 loss 0.733\n",
            "Accuracy of the model on the 3925 test images: 82.3%\n",
            "Max accuracy: 82.27%\n",
            "Test:  [ 0/82]  eta: 0:03:54  loss: 2.0715 (2.0715)  acc1: 27.0833 (27.0833)  acc5: 93.7500 (93.7500)  time: 2.8651  data: 2.7084  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 2.3024 (2.3701)  acc1: 20.8333 (21.2121)  acc5: 95.8333 (95.0758)  time: 0.4434  data: 0.2951  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 2.5365 (2.5710)  acc1: 18.7500 (20.2381)  acc5: 93.7500 (94.6429)  time: 0.1783  data: 0.0345  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 3.2001 (3.1289)  acc1: 14.5833 (14.9194)  acc5: 89.5833 (81.1156)  time: 0.1604  data: 0.0194  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 3.4387 (3.2053)  acc1: 12.5000 (15.4980)  acc5: 72.9167 (79.2683)  time: 0.1434  data: 0.0133  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.5127 (3.4527)  acc1: 12.5000 (14.0931)  acc5: 72.9167 (74.1422)  time: 0.1222  data: 0.0024  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.2128 (3.5361)  acc1: 4.1667 (12.1585)  acc5: 45.8333 (72.0970)  time: 0.1230  data: 0.0049  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.4032 (3.4231)  acc1: 2.0833 (15.6984)  acc5: 75.0000 (71.8603)  time: 0.1220  data: 0.0042  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0741 (3.1033)  acc1: 64.5833 (23.2767)  acc5: 97.9167 (75.1029)  time: 0.1202  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0560 (3.0784)  acc1: 70.8333 (23.7962)  acc5: 97.9167 (75.2611)  time: 0.1182  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1797 s / it)\n",
            "* Acc@1 23.796 Acc@5 75.261 loss 3.078\n",
            "Accuracy of the model EMA on 3925 test images: 23.8%\n",
            "Max EMA accuracy: 23.80%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [78]  [  0/295]  eta: 0:08:11  lr: 0.000012  min_lr: 0.000012  loss: 2.4782 (2.4782)  weight_decay: 0.0500 (0.0500)  time: 1.6657  data: 1.2970  max mem: 3719\n",
            "Epoch: [78]  [ 10/295]  eta: 0:02:14  lr: 0.000012  min_lr: 0.000012  loss: 2.4186 (2.3633)  weight_decay: 0.0500 (0.0500)  time: 0.4705  data: 0.1378  max mem: 3719\n",
            "Epoch: [78]  [ 20/295]  eta: 0:01:43  lr: 0.000011  min_lr: 0.000011  loss: 2.3392 (2.3274)  weight_decay: 0.0500 (0.0500)  time: 0.3128  data: 0.0133  max mem: 3719\n",
            "Epoch: [78]  [ 30/295]  eta: 0:01:30  lr: 0.000011  min_lr: 0.000011  loss: 2.3392 (2.3456)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0052  max mem: 3719\n",
            "Epoch: [78]  [ 40/295]  eta: 0:01:22  lr: 0.000011  min_lr: 0.000011  loss: 2.4389 (2.3569)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0038  max mem: 3719\n",
            "Epoch: [78]  [ 50/295]  eta: 0:01:16  lr: 0.000010  min_lr: 0.000010  loss: 2.3444 (2.3537)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0012  max mem: 3719\n",
            "Epoch: [78]  [ 60/295]  eta: 0:01:11  lr: 0.000010  min_lr: 0.000010  loss: 2.3444 (2.3550)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0012  max mem: 3719\n",
            "Epoch: [78]  [ 70/295]  eta: 0:01:07  lr: 0.000010  min_lr: 0.000010  loss: 2.4855 (2.3834)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0028  max mem: 3719\n",
            "Epoch: [78]  [ 80/295]  eta: 0:01:03  lr: 0.000009  min_lr: 0.000009  loss: 2.5008 (2.3675)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0028  max mem: 3719\n",
            "Epoch: [78]  [ 90/295]  eta: 0:01:00  lr: 0.000009  min_lr: 0.000009  loss: 2.2808 (2.3741)  weight_decay: 0.0500 (0.0500)  time: 0.2769  data: 0.0033  max mem: 3719\n",
            "Epoch: [78]  [100/295]  eta: 0:00:57  lr: 0.000009  min_lr: 0.000009  loss: 2.4718 (2.3723)  weight_decay: 0.0500 (0.0500)  time: 0.2749  data: 0.0047  max mem: 3719\n",
            "Epoch: [78]  [110/295]  eta: 0:00:53  lr: 0.000008  min_lr: 0.000008  loss: 2.4438 (2.3782)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0040  max mem: 3719\n",
            "Epoch: [78]  [120/295]  eta: 0:00:50  lr: 0.000008  min_lr: 0.000008  loss: 2.4359 (2.3814)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0025  max mem: 3719\n",
            "Epoch: [78]  [130/295]  eta: 0:00:47  lr: 0.000008  min_lr: 0.000008  loss: 2.4365 (2.3908)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0017  max mem: 3719\n",
            "Epoch: [78]  [140/295]  eta: 0:00:44  lr: 0.000007  min_lr: 0.000007  loss: 2.4406 (2.3938)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0018  max mem: 3719\n",
            "Epoch: [78]  [150/295]  eta: 0:00:41  lr: 0.000007  min_lr: 0.000007  loss: 2.4406 (2.3948)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0034  max mem: 3719\n",
            "Epoch: [78]  [160/295]  eta: 0:00:38  lr: 0.000007  min_lr: 0.000007  loss: 2.3870 (2.3902)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0036  max mem: 3719\n",
            "Epoch: [78]  [170/295]  eta: 0:00:35  lr: 0.000007  min_lr: 0.000007  loss: 2.3424 (2.3881)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0020  max mem: 3719\n",
            "Epoch: [78]  [180/295]  eta: 0:00:32  lr: 0.000006  min_lr: 0.000006  loss: 2.4158 (2.3932)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0015  max mem: 3719\n",
            "Epoch: [78]  [190/295]  eta: 0:00:29  lr: 0.000006  min_lr: 0.000006  loss: 2.4934 (2.3961)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0018  max mem: 3719\n",
            "Epoch: [78]  [200/295]  eta: 0:00:26  lr: 0.000006  min_lr: 0.000006  loss: 2.4934 (2.3993)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0024  max mem: 3719\n",
            "Epoch: [78]  [210/295]  eta: 0:00:23  lr: 0.000006  min_lr: 0.000006  loss: 2.4798 (2.4005)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0027  max mem: 3719\n",
            "Epoch: [78]  [220/295]  eta: 0:00:20  lr: 0.000005  min_lr: 0.000005  loss: 2.4847 (2.4067)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0034  max mem: 3719\n",
            "Epoch: [78]  [230/295]  eta: 0:00:17  lr: 0.000005  min_lr: 0.000005  loss: 2.4823 (2.4056)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0034  max mem: 3719\n",
            "Epoch: [78]  [240/295]  eta: 0:00:15  lr: 0.000005  min_lr: 0.000005  loss: 2.4021 (2.4036)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0020  max mem: 3719\n",
            "Epoch: [78]  [250/295]  eta: 0:00:12  lr: 0.000005  min_lr: 0.000005  loss: 2.3979 (2.4041)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0013  max mem: 3719\n",
            "Epoch: [78]  [260/295]  eta: 0:00:09  lr: 0.000004  min_lr: 0.000004  loss: 2.3280 (2.4014)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0020  max mem: 3719\n",
            "Epoch: [78]  [270/295]  eta: 0:00:06  lr: 0.000004  min_lr: 0.000004  loss: 2.2982 (2.4023)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0036  max mem: 3719\n",
            "Epoch: [78]  [280/295]  eta: 0:00:04  lr: 0.000004  min_lr: 0.000004  loss: 2.4708 (2.4008)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0033  max mem: 3719\n",
            "Epoch: [78]  [290/295]  eta: 0:00:01  lr: 0.000004  min_lr: 0.000004  loss: 2.4260 (2.4010)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0011  max mem: 3719\n",
            "Epoch: [78]  [294/295]  eta: 0:00:00  lr: 0.000004  min_lr: 0.000004  loss: 2.4124 (2.4006)  weight_decay: 0.0500 (0.0500)  time: 0.2197  data: 0.0002  max mem: 3719\n",
            "Epoch: [78] Total time: 0:01:20 (0.2720 s / it)\n",
            "Averaged stats: lr: 0.000004  min_lr: 0.000004  loss: 2.4124 (2.4006)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:50  loss: 0.5922 (0.5922)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.0817  data: 1.9107  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5108 (0.5346)  acc1: 91.6667 (90.3409)  acc5: 97.9167 (98.4849)  time: 0.3012  data: 0.1772  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5181 (0.5477)  acc1: 91.6667 (90.1786)  acc5: 100.0000 (98.6111)  time: 0.1242  data: 0.0042  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6622 (0.7262)  acc1: 85.4167 (82.3925)  acc5: 100.0000 (98.5215)  time: 0.1285  data: 0.0052  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7229 (0.7048)  acc1: 83.3333 (83.4350)  acc5: 100.0000 (98.6281)  time: 0.1387  data: 0.0060  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6858 (0.7113)  acc1: 83.3333 (83.2108)  acc5: 100.0000 (98.6111)  time: 0.1468  data: 0.0042  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7579 (0.7224)  acc1: 81.2500 (82.6503)  acc5: 97.9167 (98.3948)  time: 0.1520  data: 0.0013  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8735 (0.7490)  acc1: 77.0833 (81.6315)  acc5: 97.9167 (98.2101)  time: 0.1500  data: 0.0002  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7497 (0.7317)  acc1: 81.2500 (82.2274)  acc5: 97.9167 (98.2253)  time: 0.1310  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7497 (0.7335)  acc1: 81.2500 (82.2166)  acc5: 97.9167 (98.1911)  time: 0.1293  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1653 s / it)\n",
            "* Acc@1 82.217 Acc@5 98.191 loss 0.733\n",
            "Accuracy of the model on the 3925 test images: 82.2%\n",
            "Max accuracy: 82.27%\n",
            "Test:  [ 0/82]  eta: 0:02:45  loss: 2.0276 (2.0276)  acc1: 27.0833 (27.0833)  acc5: 93.7500 (93.7500)  time: 2.0146  data: 1.8519  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.2592 (2.3310)  acc1: 20.8333 (21.5909)  acc5: 95.8333 (95.0758)  time: 0.2995  data: 0.1710  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.5192 (2.5367)  acc1: 20.8333 (20.7341)  acc5: 93.7500 (94.6429)  time: 0.1243  data: 0.0030  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.1635 (3.0948)  acc1: 14.5833 (15.3898)  acc5: 89.5833 (81.2500)  time: 0.1239  data: 0.0039  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.3812 (3.1678)  acc1: 12.5000 (16.1585)  acc5: 75.0000 (79.6240)  time: 0.1286  data: 0.0041  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.4720 (3.4177)  acc1: 12.5000 (14.5833)  acc5: 75.0000 (74.3873)  time: 0.1270  data: 0.0032  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2028 (3.4987)  acc1: 4.1667 (12.6708)  acc5: 47.9167 (72.3702)  time: 0.1231  data: 0.0033  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.3583 (3.3865)  acc1: 2.0833 (16.1678)  acc5: 75.0000 (72.1244)  time: 0.1213  data: 0.0020  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0600 (3.0700)  acc1: 64.5833 (23.6883)  acc5: 97.9167 (75.3344)  time: 0.1199  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0458 (3.0453)  acc1: 70.8333 (24.2293)  acc5: 97.9167 (75.4904)  time: 0.1183  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1543 s / it)\n",
            "* Acc@1 24.229 Acc@5 75.490 loss 3.045\n",
            "Accuracy of the model EMA on 3925 test images: 24.2%\n",
            "Max EMA accuracy: 24.23%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [79]  [  0/295]  eta: 0:11:30  lr: 0.000004  min_lr: 0.000004  loss: 2.5431 (2.5431)  weight_decay: 0.0500 (0.0500)  time: 2.3417  data: 1.9133  max mem: 3719\n",
            "Epoch: [79]  [ 10/295]  eta: 0:02:12  lr: 0.000004  min_lr: 0.000004  loss: 2.3593 (2.2826)  weight_decay: 0.0500 (0.0500)  time: 0.4634  data: 0.1754  max mem: 3719\n",
            "Epoch: [79]  [ 20/295]  eta: 0:01:41  lr: 0.000003  min_lr: 0.000003  loss: 2.2986 (2.2875)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0012  max mem: 3719\n",
            "Epoch: [79]  [ 30/295]  eta: 0:01:28  lr: 0.000003  min_lr: 0.000003  loss: 2.3112 (2.3243)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0009  max mem: 3719\n",
            "Epoch: [79]  [ 40/295]  eta: 0:01:20  lr: 0.000003  min_lr: 0.000003  loss: 2.3739 (2.3467)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0017  max mem: 3719\n",
            "Epoch: [79]  [ 50/295]  eta: 0:01:15  lr: 0.000003  min_lr: 0.000003  loss: 2.3297 (2.3337)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0033  max mem: 3719\n",
            "Epoch: [79]  [ 60/295]  eta: 0:01:10  lr: 0.000003  min_lr: 0.000003  loss: 2.3234 (2.3134)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0030  max mem: 3719\n",
            "Epoch: [79]  [ 70/295]  eta: 0:01:06  lr: 0.000003  min_lr: 0.000003  loss: 2.2471 (2.3107)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0022  max mem: 3719\n",
            "Epoch: [79]  [ 80/295]  eta: 0:01:02  lr: 0.000002  min_lr: 0.000002  loss: 2.2619 (2.3145)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0015  max mem: 3719\n",
            "Epoch: [79]  [ 90/295]  eta: 0:00:59  lr: 0.000002  min_lr: 0.000002  loss: 2.4212 (2.3307)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0016  max mem: 3719\n",
            "Epoch: [79]  [100/295]  eta: 0:00:55  lr: 0.000002  min_lr: 0.000002  loss: 2.4629 (2.3370)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0027  max mem: 3719\n",
            "Epoch: [79]  [110/295]  eta: 0:00:52  lr: 0.000002  min_lr: 0.000002  loss: 2.4207 (2.3393)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0046  max mem: 3719\n",
            "Epoch: [79]  [120/295]  eta: 0:00:49  lr: 0.000002  min_lr: 0.000002  loss: 2.3620 (2.3436)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0059  max mem: 3719\n",
            "Epoch: [79]  [130/295]  eta: 0:00:46  lr: 0.000002  min_lr: 0.000002  loss: 2.4920 (2.3500)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0042  max mem: 3719\n",
            "Epoch: [79]  [140/295]  eta: 0:00:43  lr: 0.000002  min_lr: 0.000002  loss: 2.5088 (2.3597)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0028  max mem: 3719\n",
            "Epoch: [79]  [150/295]  eta: 0:00:40  lr: 0.000002  min_lr: 0.000002  loss: 2.4414 (2.3591)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0022  max mem: 3719\n",
            "Epoch: [79]  [160/295]  eta: 0:00:37  lr: 0.000002  min_lr: 0.000002  loss: 2.3730 (2.3512)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0014  max mem: 3719\n",
            "Epoch: [79]  [170/295]  eta: 0:00:34  lr: 0.000001  min_lr: 0.000001  loss: 2.3312 (2.3524)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0029  max mem: 3719\n",
            "Epoch: [79]  [180/295]  eta: 0:00:31  lr: 0.000001  min_lr: 0.000001  loss: 2.3748 (2.3543)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0050  max mem: 3719\n",
            "Epoch: [79]  [190/295]  eta: 0:00:29  lr: 0.000001  min_lr: 0.000001  loss: 2.2794 (2.3451)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0031  max mem: 3719\n",
            "Epoch: [79]  [200/295]  eta: 0:00:26  lr: 0.000001  min_lr: 0.000001  loss: 2.1343 (2.3439)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0010  max mem: 3719\n",
            "Epoch: [79]  [210/295]  eta: 0:00:23  lr: 0.000001  min_lr: 0.000001  loss: 2.4791 (2.3497)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0011  max mem: 3719\n",
            "Epoch: [79]  [220/295]  eta: 0:00:20  lr: 0.000001  min_lr: 0.000001  loss: 2.4465 (2.3515)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0019  max mem: 3719\n",
            "Epoch: [79]  [230/295]  eta: 0:00:17  lr: 0.000001  min_lr: 0.000001  loss: 2.3896 (2.3553)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0042  max mem: 3719\n",
            "Epoch: [79]  [240/295]  eta: 0:00:15  lr: 0.000001  min_lr: 0.000001  loss: 2.2985 (2.3532)  weight_decay: 0.0500 (0.0500)  time: 0.2762  data: 0.0046  max mem: 3719\n",
            "Epoch: [79]  [250/295]  eta: 0:00:12  lr: 0.000001  min_lr: 0.000001  loss: 2.4706 (2.3619)  weight_decay: 0.0500 (0.0500)  time: 0.2784  data: 0.0036  max mem: 3719\n",
            "Epoch: [79]  [260/295]  eta: 0:00:09  lr: 0.000001  min_lr: 0.000001  loss: 2.4538 (2.3569)  weight_decay: 0.0500 (0.0500)  time: 0.2754  data: 0.0040  max mem: 3719\n",
            "Epoch: [79]  [270/295]  eta: 0:00:06  lr: 0.000001  min_lr: 0.000001  loss: 2.4244 (2.3627)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0034  max mem: 3719\n",
            "Epoch: [79]  [280/295]  eta: 0:00:04  lr: 0.000001  min_lr: 0.000001  loss: 2.4429 (2.3618)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0015  max mem: 3719\n",
            "Epoch: [79]  [290/295]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000001  loss: 2.4553 (2.3675)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0002  max mem: 3719\n",
            "Epoch: [79]  [294/295]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.3805 (2.3674)  weight_decay: 0.0500 (0.0500)  time: 0.2201  data: 0.0002  max mem: 3719\n",
            "Epoch: [79] Total time: 0:01:20 (0.2719 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.3805 (2.3674)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:53  loss: 0.5894 (0.5894)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.1190  data: 1.8674  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 0.5086 (0.5317)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (98.4849)  time: 0.3395  data: 0.1845  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.5162 (0.5459)  acc1: 91.6667 (90.3770)  acc5: 100.0000 (98.6111)  time: 0.1976  data: 0.0433  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6643 (0.7241)  acc1: 85.4167 (82.5941)  acc5: 100.0000 (98.5215)  time: 0.1915  data: 0.0358  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7219 (0.7029)  acc1: 83.3333 (83.4858)  acc5: 100.0000 (98.6281)  time: 0.1584  data: 0.0170  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6842 (0.7102)  acc1: 83.3333 (83.2516)  acc5: 100.0000 (98.6111)  time: 0.1576  data: 0.0300  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7613 (0.7209)  acc1: 81.2500 (82.6844)  acc5: 97.9167 (98.3948)  time: 0.1384  data: 0.0161  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8700 (0.7478)  acc1: 77.0833 (81.6021)  acc5: 97.9167 (98.2101)  time: 0.1241  data: 0.0027  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7508 (0.7307)  acc1: 81.2500 (82.2016)  acc5: 97.9167 (98.2253)  time: 0.1187  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7508 (0.7325)  acc1: 81.2500 (82.1911)  acc5: 97.9167 (98.1911)  time: 0.1170  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1818 s / it)\n",
            "* Acc@1 82.191 Acc@5 98.191 loss 0.732\n",
            "Accuracy of the model on the 3925 test images: 82.2%\n",
            "Max accuracy: 82.27%\n",
            "Test:  [ 0/82]  eta: 0:02:35  loss: 1.9842 (1.9842)  acc1: 27.0833 (27.0833)  acc5: 93.7500 (93.7500)  time: 1.8911  data: 1.7237  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.2166 (2.2924)  acc1: 22.9167 (22.1591)  acc5: 95.8333 (95.2652)  time: 0.2817  data: 0.1575  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.5036 (2.5028)  acc1: 20.8333 (21.0317)  acc5: 93.7500 (94.7421)  time: 0.1221  data: 0.0016  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.1273 (3.0609)  acc1: 14.5833 (15.5914)  acc5: 89.5833 (81.3844)  time: 0.1345  data: 0.0019  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.3244 (3.1307)  acc1: 12.5000 (16.3618)  acc5: 75.0000 (79.8781)  time: 0.1470  data: 0.0019  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.4311 (3.3829)  acc1: 12.5000 (14.7467)  acc5: 75.0000 (74.5915)  time: 0.1597  data: 0.0161  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.1919 (3.4615)  acc1: 4.1667 (12.8757)  acc5: 47.9167 (72.6776)  time: 0.1655  data: 0.0236  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.3134 (3.3501)  acc1: 2.0833 (16.3439)  acc5: 77.0833 (72.4178)  time: 0.1481  data: 0.0087  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0464 (3.0369)  acc1: 64.5833 (23.8426)  acc5: 97.9167 (75.5916)  time: 0.1277  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0359 (3.0125)  acc1: 70.8333 (24.3822)  acc5: 97.9167 (75.7452)  time: 0.1249  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1664 s / it)\n",
            "* Acc@1 24.382 Acc@5 75.745 loss 3.012\n",
            "Accuracy of the model EMA on 3925 test images: 24.4%\n",
            "Max EMA accuracy: 24.38%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/result_tiny)... Done. 12.2s\n",
            "Training time 0:56:18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▂▁▃▃▂▄▄▄▄▄▅▆▅▇▇▇▇▇▆▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema ▁▁▁▁▂▁▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▆▆▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▂▁▃▃▃▃▅▃▅▅▄▆▆▇▆█▆▆▆▇▇▇█▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema ▁▁▂▂▂▂▃▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss ▇█▆▅▇▅▅▅▅▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss ▇█▇▇▇▆▆▆▆▅▅▅▄▄▃▄▄▄▂▄▃▃▂▃▃▂▂▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr ██▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr ██▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss ▇▅▄█▇▆▆▇▄▄▆▆▆▇▆▂▅▄▇▇▆▄▄▅▇▇▇▇▇▆▅▇▅▅▇▅▄▄▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 82.19109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema 24.38217\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 98.19108\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema 75.74522\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.73248\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema 3.01248\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 2.36741\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 5839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 2.3351\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 79\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 28589128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mupbeat-shape-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/m3kel4es\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230305_005228-m3kel4es/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python main.py --model convnext_tiny --eval true \\\n",
        "                --resume /content/result_tiny/checkpoint-best.pth \\\n",
        "                --input_size 160 --drop_path 0.1 \\\n",
        "                --data_path /content/imagenette2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc-P0Dw5Parc",
        "outputId": "e0fdd6b5-b118-4c64-94f5-bb3af9cb9267"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny/checkpoint-best.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7f5fff503b80>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f5fff491eb0>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f5fff50e100>\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 147\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 2940\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny/checkpoint-best.pth\n",
            "With optim & sched!\n",
            "Eval only mode\n",
            "Test:  [ 0/41]  eta: 0:05:58  loss: 0.5212 (0.5212)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 8.7382  data: 3.6831  max mem: 2077\n",
            "Test:  [10/41]  eta: 0:00:30  loss: 0.5480 (0.5560)  acc1: 89.5833 (89.7727)  acc5: 97.9167 (98.5795)  time: 0.9991  data: 0.3366  max mem: 2077\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.5927 (0.7024)  acc1: 87.5000 (83.5317)  acc5: 98.9583 (98.7103)  time: 0.2327  data: 0.0038  max mem: 2077\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6791 (0.7300)  acc1: 82.2917 (82.3925)  acc5: 97.9167 (98.4207)  time: 0.2321  data: 0.0030  max mem: 2077\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7213 (0.7324)  acc1: 81.2500 (82.2675)  acc5: 97.9167 (98.2420)  time: 0.2271  data: 0.0002  max mem: 2077\n",
            "Test: Total time: 0:00:18 (0.4532 s / it)\n",
            "* Acc@1 82.268 Acc@5 98.242 loss 0.732\n",
            "Accuracy of the network on 3925 test images: 82.26752%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acc@1 after 80 epochs: 82.268"
      ],
      "metadata": {
        "id": "4zhqr6wiXeyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/result_tiny\n",
        "%cd /content/ConvNeXt\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_tiny \\\n",
        "                                    --resume /content/result_tiny/checkpoint-79.pth \\\n",
        "                                    --epochs 100 \\\n",
        "                                    --start_epoch 80 \\\n",
        "                                    --batch_size 32 \\\n",
        "                                    --lr 4e-3 \\\n",
        "                                    --update_freq 4 \\\n",
        "                                    --model_ema true \\\n",
        "                                    --model_ema_eval true \\\n",
        "                                    --aa original \\\n",
        "                                    --drop_path 0.1 \\\n",
        "                                    --opt adamw \\\n",
        "                                    --train_interpolation bicubic \\\n",
        "                                    --input_size 160 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --output_dir /content/result_tiny \\\n",
        "                                    --log_dir /content/result_tiny \\\n",
        "                                    --enable_wandb true --wandb_ckpt true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFWACzAFd8O2",
        "outputId": "a1d18c92-6f68-4b2f-935e-fe1755a432cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt\n",
            "| distributed init (rank 0): env://, gpu 0\n",
            "Namespace(aa='original', auto_resume=True, batch_size=32, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_backend='nccl', dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=True, drop_path=0.1, enable_wandb=True, epochs=100, eval=False, eval_data_path=None, finetune='', gpu=0, head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=0, log_dir='/content/result_tiny', lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=True, model_ema_decay=0.9999, model_ema_eval=True, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/content/result_tiny', pin_mem=True, project='convnext', rank=0, recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny/checkpoint-79.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=80, train_interpolation='bicubic', update_freq=4, use_amp=False, wandb_ckpt=True, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.AutoAugment object at 0x7fe6ea6fc7f0>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7fe6ea683430>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fe6ea700130>\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlolikgiovi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ConvNeXt/wandb/run-20230305_015215-pua791sp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolished-disco-18\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/pua791sp\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Using EMA with decay = 0.99990000\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 128\n",
            "Update frequent = 4\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 73\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 1460\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny/checkpoint-79.pth\n",
            "With optim & sched!\n",
            "Start training for 100 epochs\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [80]  [  0/295]  eta: 0:16:47  lr: 0.000587  min_lr: 0.000587  loss: 2.7625 (2.7625)  weight_decay: 0.0500 (0.0500)  time: 3.4143  data: 1.9461  max mem: 3719\n",
            "Epoch: [80]  [ 10/295]  eta: 0:02:32  lr: 0.000585  min_lr: 0.000585  loss: 2.5617 (2.5472)  weight_decay: 0.0500 (0.0500)  time: 0.5363  data: 0.1772  max mem: 3719\n",
            "Epoch: [80]  [ 20/295]  eta: 0:01:50  lr: 0.000583  min_lr: 0.000583  loss: 2.4894 (2.4912)  weight_decay: 0.0500 (0.0500)  time: 0.2504  data: 0.0005  max mem: 3719\n",
            "Epoch: [80]  [ 30/295]  eta: 0:01:34  lr: 0.000581  min_lr: 0.000581  loss: 2.3481 (2.4608)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0009  max mem: 3719\n",
            "Epoch: [80]  [ 40/295]  eta: 0:01:25  lr: 0.000579  min_lr: 0.000579  loss: 2.4443 (2.4546)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0014  max mem: 3719\n",
            "Epoch: [80]  [ 50/295]  eta: 0:01:18  lr: 0.000578  min_lr: 0.000578  loss: 2.4279 (2.4185)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0010  max mem: 3719\n",
            "Epoch: [80]  [ 60/295]  eta: 0:01:12  lr: 0.000575  min_lr: 0.000575  loss: 2.3220 (2.4211)  weight_decay: 0.0500 (0.0500)  time: 0.2562  data: 0.0008  max mem: 3719\n",
            "Epoch: [80]  [ 70/295]  eta: 0:01:07  lr: 0.000574  min_lr: 0.000574  loss: 2.4774 (2.4208)  weight_decay: 0.0500 (0.0500)  time: 0.2540  data: 0.0011  max mem: 3719\n",
            "Epoch: [80]  [ 80/295]  eta: 0:01:03  lr: 0.000572  min_lr: 0.000572  loss: 2.4667 (2.4076)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0012  max mem: 3719\n",
            "Epoch: [80]  [ 90/295]  eta: 0:00:59  lr: 0.000570  min_lr: 0.000570  loss: 2.3468 (2.4117)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0020  max mem: 3719\n",
            "Epoch: [80]  [100/295]  eta: 0:00:56  lr: 0.000568  min_lr: 0.000568  loss: 2.5479 (2.4303)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0031  max mem: 3719\n",
            "Epoch: [80]  [110/295]  eta: 0:00:53  lr: 0.000566  min_lr: 0.000566  loss: 2.5479 (2.4297)  weight_decay: 0.0500 (0.0500)  time: 0.2779  data: 0.0042  max mem: 3719\n",
            "Epoch: [80]  [120/295]  eta: 0:00:50  lr: 0.000564  min_lr: 0.000564  loss: 2.4722 (2.4382)  weight_decay: 0.0500 (0.0500)  time: 0.2785  data: 0.0043  max mem: 3719\n",
            "Epoch: [80]  [130/295]  eta: 0:00:47  lr: 0.000563  min_lr: 0.000563  loss: 2.5116 (2.4413)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0023  max mem: 3719\n",
            "Epoch: [80]  [140/295]  eta: 0:00:44  lr: 0.000560  min_lr: 0.000560  loss: 2.4249 (2.4388)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0007  max mem: 3719\n",
            "Epoch: [80]  [150/295]  eta: 0:00:41  lr: 0.000559  min_lr: 0.000559  loss: 2.4870 (2.4465)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0009  max mem: 3719\n",
            "Epoch: [80]  [160/295]  eta: 0:00:38  lr: 0.000557  min_lr: 0.000557  loss: 2.5176 (2.4523)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0010  max mem: 3719\n",
            "Epoch: [80]  [170/295]  eta: 0:00:35  lr: 0.000555  min_lr: 0.000555  loss: 2.4121 (2.4467)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0010  max mem: 3719\n",
            "Epoch: [80]  [180/295]  eta: 0:00:32  lr: 0.000553  min_lr: 0.000553  loss: 2.3578 (2.4411)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0018  max mem: 3719\n",
            "Epoch: [80]  [190/295]  eta: 0:00:29  lr: 0.000551  min_lr: 0.000551  loss: 2.3578 (2.4371)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0026  max mem: 3719\n",
            "Epoch: [80]  [200/295]  eta: 0:00:26  lr: 0.000549  min_lr: 0.000549  loss: 2.2936 (2.4341)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0027  max mem: 3719\n",
            "Epoch: [80]  [210/295]  eta: 0:00:23  lr: 0.000548  min_lr: 0.000548  loss: 2.3792 (2.4320)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0020  max mem: 3719\n",
            "Epoch: [80]  [220/295]  eta: 0:00:20  lr: 0.000545  min_lr: 0.000545  loss: 2.4172 (2.4292)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0010  max mem: 3719\n",
            "Epoch: [80]  [230/295]  eta: 0:00:18  lr: 0.000544  min_lr: 0.000544  loss: 2.4574 (2.4335)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0017  max mem: 3719\n",
            "Epoch: [80]  [240/295]  eta: 0:00:15  lr: 0.000542  min_lr: 0.000542  loss: 2.4521 (2.4306)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0024  max mem: 3719\n",
            "Epoch: [80]  [250/295]  eta: 0:00:12  lr: 0.000540  min_lr: 0.000540  loss: 2.2919 (2.4246)  weight_decay: 0.0500 (0.0500)  time: 0.2757  data: 0.0029  max mem: 3719\n",
            "Epoch: [80]  [260/295]  eta: 0:00:09  lr: 0.000538  min_lr: 0.000538  loss: 2.2081 (2.4179)  weight_decay: 0.0500 (0.0500)  time: 0.2743  data: 0.0033  max mem: 3719\n",
            "Epoch: [80]  [270/295]  eta: 0:00:06  lr: 0.000537  min_lr: 0.000537  loss: 2.3886 (2.4178)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0020  max mem: 3719\n",
            "Epoch: [80]  [280/295]  eta: 0:00:04  lr: 0.000534  min_lr: 0.000534  loss: 2.4329 (2.4213)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0008  max mem: 3719\n",
            "Epoch: [80]  [290/295]  eta: 0:00:01  lr: 0.000533  min_lr: 0.000533  loss: 2.4329 (2.4203)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0002  max mem: 3719\n",
            "Epoch: [80]  [294/295]  eta: 0:00:00  lr: 0.000533  min_lr: 0.000533  loss: 2.5031 (2.4215)  weight_decay: 0.0500 (0.0500)  time: 0.2207  data: 0.0002  max mem: 3719\n",
            "Epoch: [80] Total time: 0:01:21 (0.2753 s / it)\n",
            "Averaged stats: lr: 0.000533  min_lr: 0.000533  loss: 2.5031 (2.4215)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:35  loss: 0.5038 (0.5038)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 3.3594  data: 2.9025  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:33  loss: 0.4957 (0.5399)  acc1: 91.6667 (89.2045)  acc5: 97.9167 (98.1061)  time: 0.4689  data: 0.2676  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:20  loss: 0.5378 (0.5714)  acc1: 89.5833 (88.2937)  acc5: 97.9167 (98.2143)  time: 0.1708  data: 0.0043  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.7172 (0.7730)  acc1: 83.3333 (80.4436)  acc5: 97.9167 (97.7151)  time: 0.1469  data: 0.0034  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.6669 (0.7310)  acc1: 83.3333 (81.8089)  acc5: 97.9167 (98.0691)  time: 0.1318  data: 0.0045  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6278 (0.7441)  acc1: 81.2500 (81.4543)  acc5: 97.9167 (97.8758)  time: 0.1397  data: 0.0158  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8137 (0.7581)  acc1: 79.1667 (80.7377)  acc5: 97.9167 (97.8142)  time: 0.1355  data: 0.0137  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8640 (0.7822)  acc1: 75.0000 (79.5481)  acc5: 97.9167 (97.5939)  time: 0.1199  data: 0.0014  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6566 (0.7545)  acc1: 83.3333 (80.6584)  acc5: 97.9167 (97.7109)  time: 0.1164  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6566 (0.7550)  acc1: 83.3333 (80.6369)  acc5: 97.9167 (97.6815)  time: 0.1182  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1835 s / it)\n",
            "* Acc@1 80.637 Acc@5 97.682 loss 0.755\n",
            "Accuracy of the model on the 3925 test images: 80.6%\n",
            "Max accuracy: 80.64%\n",
            "Test:  [ 0/82]  eta: 0:04:15  loss: 1.9445 (1.9445)  acc1: 27.0833 (27.0833)  acc5: 93.7500 (93.7500)  time: 3.1201  data: 2.9510  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 2.1772 (2.2567)  acc1: 25.0000 (23.6742)  acc5: 95.8333 (95.6439)  time: 0.4456  data: 0.2956  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 2.4912 (2.4715)  acc1: 20.8333 (21.9246)  acc5: 93.7500 (94.9405)  time: 0.1782  data: 0.0421  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 3.0918 (3.0297)  acc1: 12.5000 (16.2634)  acc5: 89.5833 (81.5860)  time: 0.1623  data: 0.0288  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 3.2682 (3.0956)  acc1: 12.5000 (17.0224)  acc5: 75.0000 (80.1829)  time: 0.1585  data: 0.0199  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.3914 (3.3498)  acc1: 12.5000 (15.1961)  acc5: 72.9167 (74.7958)  time: 0.1484  data: 0.0193  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.1807 (3.4260)  acc1: 6.2500 (13.3197)  acc5: 47.9167 (72.8484)  time: 0.1232  data: 0.0026  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.2695 (3.3156)  acc1: 2.0833 (16.7254)  acc5: 77.0833 (72.5646)  time: 0.1193  data: 0.0018  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0338 (3.0054)  acc1: 64.5833 (24.2027)  acc5: 97.9167 (75.7202)  time: 0.1178  data: 0.0004  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0257 (2.9812)  acc1: 70.8333 (24.7389)  acc5: 97.9167 (75.8726)  time: 0.1165  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1854 s / it)\n",
            "* Acc@1 24.739 Acc@5 75.873 loss 2.981\n",
            "Accuracy of the model EMA on 3925 test images: 24.7%\n",
            "Max EMA accuracy: 24.74%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [81]  [  0/295]  eta: 0:10:00  lr: 0.000532  min_lr: 0.000532  loss: 2.1504 (2.1504)  weight_decay: 0.0500 (0.0500)  time: 2.0361  data: 1.6234  max mem: 3719\n",
            "Epoch: [81]  [ 10/295]  eta: 0:02:05  lr: 0.000531  min_lr: 0.000531  loss: 2.5523 (2.5002)  weight_decay: 0.0500 (0.0500)  time: 0.4405  data: 0.1488  max mem: 3719\n",
            "Epoch: [81]  [ 20/295]  eta: 0:01:39  lr: 0.000529  min_lr: 0.000529  loss: 2.5222 (2.4621)  weight_decay: 0.0500 (0.0500)  time: 0.2776  data: 0.0008  max mem: 3719\n",
            "Epoch: [81]  [ 30/295]  eta: 0:01:27  lr: 0.000527  min_lr: 0.000527  loss: 2.5580 (2.4906)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0005  max mem: 3719\n",
            "Epoch: [81]  [ 40/295]  eta: 0:01:20  lr: 0.000525  min_lr: 0.000525  loss: 2.5580 (2.5011)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0008  max mem: 3719\n",
            "Epoch: [81]  [ 50/295]  eta: 0:01:14  lr: 0.000523  min_lr: 0.000523  loss: 2.3335 (2.4688)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0010  max mem: 3719\n",
            "Epoch: [81]  [ 60/295]  eta: 0:01:10  lr: 0.000521  min_lr: 0.000521  loss: 2.4496 (2.4851)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0010  max mem: 3719\n",
            "Epoch: [81]  [ 70/295]  eta: 0:01:06  lr: 0.000520  min_lr: 0.000520  loss: 2.4726 (2.4687)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0011  max mem: 3719\n",
            "Epoch: [81]  [ 80/295]  eta: 0:01:02  lr: 0.000518  min_lr: 0.000518  loss: 2.4457 (2.4629)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0009  max mem: 3719\n",
            "Epoch: [81]  [ 90/295]  eta: 0:00:59  lr: 0.000516  min_lr: 0.000516  loss: 2.5136 (2.4568)  weight_decay: 0.0500 (0.0500)  time: 0.2790  data: 0.0012  max mem: 3719\n",
            "Epoch: [81]  [100/295]  eta: 0:00:56  lr: 0.000514  min_lr: 0.000514  loss: 2.3692 (2.4362)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0032  max mem: 3719\n",
            "Epoch: [81]  [110/295]  eta: 0:00:53  lr: 0.000513  min_lr: 0.000513  loss: 2.3692 (2.4414)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0030  max mem: 3719\n",
            "Epoch: [81]  [120/295]  eta: 0:00:49  lr: 0.000511  min_lr: 0.000511  loss: 2.4420 (2.4395)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0014  max mem: 3719\n",
            "Epoch: [81]  [130/295]  eta: 0:00:46  lr: 0.000509  min_lr: 0.000509  loss: 2.5166 (2.4359)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0015  max mem: 3719\n",
            "Epoch: [81]  [140/295]  eta: 0:00:43  lr: 0.000507  min_lr: 0.000507  loss: 2.4817 (2.4358)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0013  max mem: 3719\n",
            "Epoch: [81]  [150/295]  eta: 0:00:40  lr: 0.000505  min_lr: 0.000505  loss: 2.4230 (2.4327)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0028  max mem: 3719\n",
            "Epoch: [81]  [160/295]  eta: 0:00:37  lr: 0.000503  min_lr: 0.000503  loss: 2.3844 (2.4280)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0034  max mem: 3719\n",
            "Epoch: [81]  [170/295]  eta: 0:00:34  lr: 0.000502  min_lr: 0.000502  loss: 2.3561 (2.4249)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0014  max mem: 3719\n",
            "Epoch: [81]  [180/295]  eta: 0:00:32  lr: 0.000500  min_lr: 0.000500  loss: 2.2367 (2.4139)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0007  max mem: 3719\n",
            "Epoch: [81]  [190/295]  eta: 0:00:29  lr: 0.000498  min_lr: 0.000498  loss: 2.2236 (2.4075)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0015  max mem: 3719\n",
            "Epoch: [81]  [200/295]  eta: 0:00:26  lr: 0.000496  min_lr: 0.000496  loss: 2.2527 (2.4022)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0018  max mem: 3719\n",
            "Epoch: [81]  [210/295]  eta: 0:00:23  lr: 0.000495  min_lr: 0.000495  loss: 2.4617 (2.4109)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0047  max mem: 3719\n",
            "Epoch: [81]  [220/295]  eta: 0:00:20  lr: 0.000493  min_lr: 0.000493  loss: 2.4653 (2.4087)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0060  max mem: 3719\n",
            "Epoch: [81]  [230/295]  eta: 0:00:17  lr: 0.000491  min_lr: 0.000491  loss: 2.3810 (2.4097)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0028  max mem: 3719\n",
            "Epoch: [81]  [240/295]  eta: 0:00:15  lr: 0.000489  min_lr: 0.000489  loss: 2.6069 (2.4180)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0012  max mem: 3719\n",
            "Epoch: [81]  [250/295]  eta: 0:00:12  lr: 0.000488  min_lr: 0.000488  loss: 2.6605 (2.4269)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0022  max mem: 3719\n",
            "Epoch: [81]  [260/295]  eta: 0:00:09  lr: 0.000486  min_lr: 0.000486  loss: 2.5095 (2.4289)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0024  max mem: 3719\n",
            "Epoch: [81]  [270/295]  eta: 0:00:06  lr: 0.000484  min_lr: 0.000484  loss: 2.4451 (2.4265)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0020  max mem: 3719\n",
            "Epoch: [81]  [280/295]  eta: 0:00:04  lr: 0.000482  min_lr: 0.000482  loss: 2.4634 (2.4277)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0015  max mem: 3719\n",
            "Epoch: [81]  [290/295]  eta: 0:00:01  lr: 0.000481  min_lr: 0.000481  loss: 2.3445 (2.4260)  weight_decay: 0.0500 (0.0500)  time: 0.2563  data: 0.0002  max mem: 3719\n",
            "Epoch: [81]  [294/295]  eta: 0:00:00  lr: 0.000481  min_lr: 0.000481  loss: 2.3237 (2.4248)  weight_decay: 0.0500 (0.0500)  time: 0.2191  data: 0.0002  max mem: 3719\n",
            "Epoch: [81] Total time: 0:01:20 (0.2730 s / it)\n",
            "Averaged stats: lr: 0.000481  min_lr: 0.000481  loss: 2.3237 (2.4248)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:10  loss: 0.6145 (0.6145)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.0509  data: 2.8744  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.5473 (0.5680)  acc1: 91.6667 (89.0152)  acc5: 97.9167 (98.1061)  time: 0.4053  data: 0.2690  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.5473 (0.5933)  acc1: 87.5000 (88.2937)  acc5: 97.9167 (98.1151)  time: 0.1343  data: 0.0047  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7400 (0.7348)  acc1: 81.2500 (82.1237)  acc5: 100.0000 (98.4543)  time: 0.1264  data: 0.0020  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7978 (0.7273)  acc1: 79.1667 (82.5203)  acc5: 100.0000 (98.4756)  time: 0.1262  data: 0.0031  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7474 (0.7482)  acc1: 81.2500 (81.7402)  acc5: 97.9167 (98.4069)  time: 0.1261  data: 0.0028  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7831 (0.7547)  acc1: 77.0833 (81.2158)  acc5: 97.9167 (98.2924)  time: 0.1259  data: 0.0035  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8339 (0.7775)  acc1: 77.0833 (80.3991)  acc5: 97.9167 (98.1221)  time: 0.1235  data: 0.0024  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7218 (0.7535)  acc1: 81.2500 (81.2243)  acc5: 97.9167 (98.1482)  time: 0.1191  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7218 (0.7543)  acc1: 81.2500 (81.1720)  acc5: 97.9167 (98.1147)  time: 0.1172  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1689 s / it)\n",
            "* Acc@1 81.172 Acc@5 98.115 loss 0.754\n",
            "Accuracy of the model on the 3925 test images: 81.2%\n",
            "Max accuracy: 81.17%\n",
            "Test:  [ 0/82]  eta: 0:03:04  loss: 1.9033 (1.9033)  acc1: 31.2500 (31.2500)  acc5: 93.7500 (93.7500)  time: 2.2522  data: 2.0891  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 2.1364 (2.2201)  acc1: 25.0000 (24.0530)  acc5: 97.9167 (96.0227)  time: 0.4051  data: 0.2552  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.4762 (2.4394)  acc1: 20.8333 (22.5198)  acc5: 95.8333 (95.2381)  time: 0.1798  data: 0.0449  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.0558 (2.9975)  acc1: 12.5000 (16.8683)  acc5: 89.5833 (81.9892)  time: 0.1317  data: 0.0119  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.2114 (3.0598)  acc1: 12.5000 (17.4797)  acc5: 77.0833 (80.5894)  time: 0.1236  data: 0.0048  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.3520 (3.3161)  acc1: 12.5000 (15.5637)  acc5: 72.9167 (75.1226)  time: 0.1257  data: 0.0044  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.1689 (3.3899)  acc1: 6.2500 (13.6954)  acc5: 47.9167 (73.1216)  time: 0.1273  data: 0.0063  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.2257 (3.2802)  acc1: 4.1667 (17.0775)  acc5: 77.0833 (72.8580)  time: 0.1235  data: 0.0038  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0212 (2.9732)  acc1: 64.5833 (24.5370)  acc5: 97.9167 (75.9774)  time: 0.1205  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0162 (2.9493)  acc1: 70.8333 (25.0701)  acc5: 97.9167 (76.1274)  time: 0.1188  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1688 s / it)\n",
            "* Acc@1 25.070 Acc@5 76.127 loss 2.949\n",
            "Accuracy of the model EMA on 3925 test images: 25.1%\n",
            "Max EMA accuracy: 25.07%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [82]  [  0/295]  eta: 0:23:43  lr: 0.000480  min_lr: 0.000480  loss: 2.0111 (2.0111)  weight_decay: 0.0500 (0.0500)  time: 4.8249  data: 3.4343  max mem: 3719\n",
            "Epoch: [82]  [ 10/295]  eta: 0:03:15  lr: 0.000479  min_lr: 0.000479  loss: 2.2743 (2.3505)  weight_decay: 0.0500 (0.0500)  time: 0.6846  data: 0.3130  max mem: 3719\n",
            "Epoch: [82]  [ 20/295]  eta: 0:02:13  lr: 0.000477  min_lr: 0.000477  loss: 2.4362 (2.4110)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0012  max mem: 3719\n",
            "Epoch: [82]  [ 30/295]  eta: 0:01:49  lr: 0.000475  min_lr: 0.000475  loss: 2.3597 (2.3658)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0011  max mem: 3719\n",
            "Epoch: [82]  [ 40/295]  eta: 0:01:35  lr: 0.000473  min_lr: 0.000473  loss: 2.3316 (2.3618)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0005  max mem: 3719\n",
            "Epoch: [82]  [ 50/295]  eta: 0:01:26  lr: 0.000472  min_lr: 0.000472  loss: 2.4443 (2.3859)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0007  max mem: 3719\n",
            "Epoch: [82]  [ 60/295]  eta: 0:01:20  lr: 0.000470  min_lr: 0.000470  loss: 2.4360 (2.3873)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0006  max mem: 3719\n",
            "Epoch: [82]  [ 70/295]  eta: 0:01:14  lr: 0.000468  min_lr: 0.000468  loss: 2.3616 (2.3795)  weight_decay: 0.0500 (0.0500)  time: 0.2754  data: 0.0006  max mem: 3719\n",
            "Epoch: [82]  [ 80/295]  eta: 0:01:09  lr: 0.000466  min_lr: 0.000466  loss: 2.2536 (2.3643)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0012  max mem: 3719\n",
            "Epoch: [82]  [ 90/295]  eta: 0:01:05  lr: 0.000465  min_lr: 0.000465  loss: 2.2311 (2.3651)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0012  max mem: 3719\n",
            "Epoch: [82]  [100/295]  eta: 0:01:00  lr: 0.000463  min_lr: 0.000463  loss: 2.3979 (2.3751)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0007  max mem: 3719\n",
            "Epoch: [82]  [110/295]  eta: 0:00:56  lr: 0.000461  min_lr: 0.000461  loss: 2.4451 (2.3706)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0013  max mem: 3719\n",
            "Epoch: [82]  [120/295]  eta: 0:00:53  lr: 0.000459  min_lr: 0.000459  loss: 2.4892 (2.3774)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0016  max mem: 3719\n",
            "Epoch: [82]  [130/295]  eta: 0:00:49  lr: 0.000458  min_lr: 0.000458  loss: 2.5328 (2.3805)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0016  max mem: 3719\n",
            "Epoch: [82]  [140/295]  eta: 0:00:46  lr: 0.000456  min_lr: 0.000456  loss: 2.5040 (2.3887)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0017  max mem: 3719\n",
            "Epoch: [82]  [150/295]  eta: 0:00:43  lr: 0.000455  min_lr: 0.000455  loss: 2.5645 (2.3960)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0015  max mem: 3719\n",
            "Epoch: [82]  [160/295]  eta: 0:00:39  lr: 0.000452  min_lr: 0.000452  loss: 2.5645 (2.3997)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0011  max mem: 3719\n",
            "Epoch: [82]  [170/295]  eta: 0:00:36  lr: 0.000451  min_lr: 0.000451  loss: 2.4909 (2.4035)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0007  max mem: 3719\n",
            "Epoch: [82]  [180/295]  eta: 0:00:33  lr: 0.000449  min_lr: 0.000449  loss: 2.4611 (2.4053)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0006  max mem: 3719\n",
            "Epoch: [82]  [190/295]  eta: 0:00:30  lr: 0.000448  min_lr: 0.000448  loss: 2.4037 (2.4059)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0017  max mem: 3719\n",
            "Epoch: [82]  [200/295]  eta: 0:00:27  lr: 0.000446  min_lr: 0.000446  loss: 2.4741 (2.4085)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0029  max mem: 3719\n",
            "Epoch: [82]  [210/295]  eta: 0:00:24  lr: 0.000444  min_lr: 0.000444  loss: 2.5424 (2.4120)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0022  max mem: 3719\n",
            "Epoch: [82]  [220/295]  eta: 0:00:21  lr: 0.000442  min_lr: 0.000442  loss: 2.5279 (2.4156)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0018  max mem: 3719\n",
            "Epoch: [82]  [230/295]  eta: 0:00:18  lr: 0.000441  min_lr: 0.000441  loss: 2.4115 (2.4139)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0017  max mem: 3719\n",
            "Epoch: [82]  [240/295]  eta: 0:00:15  lr: 0.000439  min_lr: 0.000439  loss: 2.4042 (2.4135)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0014  max mem: 3719\n",
            "Epoch: [82]  [250/295]  eta: 0:00:12  lr: 0.000438  min_lr: 0.000438  loss: 2.3415 (2.4091)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0018  max mem: 3719\n",
            "Epoch: [82]  [260/295]  eta: 0:00:09  lr: 0.000436  min_lr: 0.000436  loss: 2.3355 (2.4092)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0023  max mem: 3719\n",
            "Epoch: [82]  [270/295]  eta: 0:00:07  lr: 0.000434  min_lr: 0.000434  loss: 2.3201 (2.4115)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0025  max mem: 3719\n",
            "Epoch: [82]  [280/295]  eta: 0:00:04  lr: 0.000432  min_lr: 0.000432  loss: 2.3224 (2.4092)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0015  max mem: 3719\n",
            "Epoch: [82]  [290/295]  eta: 0:00:01  lr: 0.000431  min_lr: 0.000431  loss: 2.3224 (2.4047)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0003  max mem: 3719\n",
            "Epoch: [82]  [294/295]  eta: 0:00:00  lr: 0.000431  min_lr: 0.000431  loss: 2.1824 (2.4036)  weight_decay: 0.0500 (0.0500)  time: 0.2202  data: 0.0002  max mem: 3719\n",
            "Epoch: [82] Total time: 0:01:22 (0.2797 s / it)\n",
            "Averaged stats: lr: 0.000431  min_lr: 0.000431  loss: 2.1824 (2.4036)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:11  loss: 0.5078 (0.5078)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 1.5983  data: 1.4325  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.4836 (0.4984)  acc1: 91.6667 (90.5303)  acc5: 97.9167 (98.4849)  time: 0.2989  data: 0.1611  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5147 (0.5598)  acc1: 91.6667 (88.4921)  acc5: 97.9167 (98.6111)  time: 0.1563  data: 0.0191  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.6885 (0.7521)  acc1: 75.0000 (80.4436)  acc5: 97.9167 (98.5215)  time: 0.1796  data: 0.0360  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.6361 (0.7013)  acc1: 81.2500 (82.4187)  acc5: 97.9167 (98.6281)  time: 0.2117  data: 0.0583  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.6390 (0.7514)  acc1: 85.4167 (80.5964)  acc5: 97.9167 (98.2843)  time: 0.2145  data: 0.0494  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7179 (0.7439)  acc1: 79.1667 (80.7036)  acc5: 97.9167 (98.2240)  time: 0.2214  data: 0.0566  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.7179 (0.7514)  acc1: 79.1667 (80.6338)  acc5: 97.9167 (98.0047)  time: 0.1996  data: 0.0368  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6341 (0.7292)  acc1: 83.3333 (81.4043)  acc5: 97.9167 (98.0710)  time: 0.1514  data: 0.0086  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6341 (0.7305)  acc1: 83.3333 (81.3503)  acc5: 97.9167 (98.0382)  time: 0.1433  data: 0.0034  max mem: 3719\n",
            "Test: Total time: 0:00:16 (0.2073 s / it)\n",
            "* Acc@1 81.350 Acc@5 98.038 loss 0.731\n",
            "Accuracy of the model on the 3925 test images: 81.4%\n",
            "Max accuracy: 81.35%\n",
            "Test:  [ 0/82]  eta: 0:02:43  loss: 1.8629 (1.8629)  acc1: 31.2500 (31.2500)  acc5: 93.7500 (93.7500)  time: 1.9983  data: 1.8360  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.0964 (2.1839)  acc1: 25.0000 (24.8106)  acc5: 97.9167 (96.2121)  time: 0.2976  data: 0.1722  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.4641 (2.4075)  acc1: 25.0000 (23.2143)  acc5: 95.8333 (95.6349)  time: 0.1251  data: 0.0037  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.0192 (2.9651)  acc1: 14.5833 (17.4059)  acc5: 89.5833 (82.3925)  time: 0.1230  data: 0.0032  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.1499 (3.0229)  acc1: 12.5000 (17.9878)  acc5: 77.0833 (81.2500)  time: 0.1245  data: 0.0048  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.3105 (3.2804)  acc1: 12.5000 (15.8905)  acc5: 72.9167 (75.6944)  time: 0.1335  data: 0.0048  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.1505 (3.3519)  acc1: 4.1667 (13.9686)  acc5: 47.9167 (73.7022)  time: 0.1430  data: 0.0025  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.1799 (3.2434)  acc1: 4.1667 (17.3709)  acc5: 79.1667 (73.3568)  time: 0.1406  data: 0.0014  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0093 (2.9398)  acc1: 66.6667 (24.7942)  acc5: 97.9167 (76.4403)  time: 0.1282  data: 0.0013  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0072 (2.9162)  acc1: 70.8333 (25.3248)  acc5: 97.9167 (76.5860)  time: 0.1228  data: 0.0013  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1599 s / it)\n",
            "* Acc@1 25.325 Acc@5 76.586 loss 2.916\n",
            "Accuracy of the model EMA on 3925 test images: 25.3%\n",
            "Max EMA accuracy: 25.32%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [83]  [  0/295]  eta: 0:11:06  lr: 0.000430  min_lr: 0.000430  loss: 1.9355 (1.9355)  weight_decay: 0.0500 (0.0500)  time: 2.2586  data: 1.8358  max mem: 3719\n",
            "Epoch: [83]  [ 10/295]  eta: 0:02:07  lr: 0.000429  min_lr: 0.000429  loss: 2.5905 (2.5109)  weight_decay: 0.0500 (0.0500)  time: 0.4458  data: 0.1672  max mem: 3719\n",
            "Epoch: [83]  [ 20/295]  eta: 0:01:38  lr: 0.000427  min_lr: 0.000427  loss: 2.5572 (2.4998)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0005  max mem: 3719\n",
            "Epoch: [83]  [ 30/295]  eta: 0:01:26  lr: 0.000426  min_lr: 0.000426  loss: 2.4743 (2.4733)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0005  max mem: 3719\n",
            "Epoch: [83]  [ 40/295]  eta: 0:01:20  lr: 0.000424  min_lr: 0.000424  loss: 2.4071 (2.4685)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0011  max mem: 3719\n",
            "Epoch: [83]  [ 50/295]  eta: 0:01:14  lr: 0.000422  min_lr: 0.000422  loss: 2.3802 (2.4453)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0016  max mem: 3719\n",
            "Epoch: [83]  [ 60/295]  eta: 0:01:10  lr: 0.000420  min_lr: 0.000420  loss: 2.4596 (2.4480)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0014  max mem: 3719\n",
            "Epoch: [83]  [ 70/295]  eta: 0:01:06  lr: 0.000419  min_lr: 0.000419  loss: 2.5217 (2.4523)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0016  max mem: 3719\n",
            "Epoch: [83]  [ 80/295]  eta: 0:01:02  lr: 0.000417  min_lr: 0.000417  loss: 2.5429 (2.4637)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0019  max mem: 3719\n",
            "Epoch: [83]  [ 90/295]  eta: 0:00:59  lr: 0.000416  min_lr: 0.000416  loss: 2.5211 (2.4633)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0020  max mem: 3719\n",
            "Epoch: [83]  [100/295]  eta: 0:00:55  lr: 0.000414  min_lr: 0.000414  loss: 2.3863 (2.4579)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0019  max mem: 3719\n",
            "Epoch: [83]  [110/295]  eta: 0:00:52  lr: 0.000412  min_lr: 0.000412  loss: 2.4889 (2.4533)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0013  max mem: 3719\n",
            "Epoch: [83]  [120/295]  eta: 0:00:49  lr: 0.000410  min_lr: 0.000410  loss: 2.3882 (2.4447)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0016  max mem: 3719\n",
            "Epoch: [83]  [130/295]  eta: 0:00:46  lr: 0.000409  min_lr: 0.000409  loss: 2.3882 (2.4462)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0017  max mem: 3719\n",
            "Epoch: [83]  [140/295]  eta: 0:00:43  lr: 0.000407  min_lr: 0.000407  loss: 2.5005 (2.4564)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0009  max mem: 3719\n",
            "Epoch: [83]  [150/295]  eta: 0:00:40  lr: 0.000406  min_lr: 0.000406  loss: 2.5332 (2.4596)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0007  max mem: 3719\n",
            "Epoch: [83]  [160/295]  eta: 0:00:37  lr: 0.000404  min_lr: 0.000404  loss: 2.4908 (2.4544)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0012  max mem: 3719\n",
            "Epoch: [83]  [170/295]  eta: 0:00:34  lr: 0.000403  min_lr: 0.000403  loss: 2.4251 (2.4516)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0022  max mem: 3719\n",
            "Epoch: [83]  [180/295]  eta: 0:00:31  lr: 0.000401  min_lr: 0.000401  loss: 2.4167 (2.4503)  weight_decay: 0.0500 (0.0500)  time: 0.2746  data: 0.0034  max mem: 3719\n",
            "Epoch: [83]  [190/295]  eta: 0:00:29  lr: 0.000399  min_lr: 0.000399  loss: 2.4890 (2.4552)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0026  max mem: 3719\n",
            "Epoch: [83]  [200/295]  eta: 0:00:26  lr: 0.000398  min_lr: 0.000398  loss: 2.4734 (2.4566)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0007  max mem: 3719\n",
            "Epoch: [83]  [210/295]  eta: 0:00:23  lr: 0.000396  min_lr: 0.000396  loss: 2.4505 (2.4538)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0003  max mem: 3719\n",
            "Epoch: [83]  [220/295]  eta: 0:00:20  lr: 0.000394  min_lr: 0.000394  loss: 2.4133 (2.4528)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0009  max mem: 3719\n",
            "Epoch: [83]  [230/295]  eta: 0:00:17  lr: 0.000393  min_lr: 0.000393  loss: 2.4113 (2.4533)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0026  max mem: 3719\n",
            "Epoch: [83]  [240/295]  eta: 0:00:15  lr: 0.000391  min_lr: 0.000391  loss: 2.4625 (2.4516)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0044  max mem: 3719\n",
            "Epoch: [83]  [250/295]  eta: 0:00:12  lr: 0.000390  min_lr: 0.000390  loss: 2.4707 (2.4532)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0043  max mem: 3719\n",
            "Epoch: [83]  [260/295]  eta: 0:00:09  lr: 0.000388  min_lr: 0.000388  loss: 2.4707 (2.4515)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0033  max mem: 3719\n",
            "Epoch: [83]  [270/295]  eta: 0:00:06  lr: 0.000387  min_lr: 0.000387  loss: 2.5283 (2.4494)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0019  max mem: 3719\n",
            "Epoch: [83]  [280/295]  eta: 0:00:04  lr: 0.000385  min_lr: 0.000385  loss: 2.2874 (2.4437)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0006  max mem: 3719\n",
            "Epoch: [83]  [290/295]  eta: 0:00:01  lr: 0.000384  min_lr: 0.000384  loss: 2.4432 (2.4465)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0003  max mem: 3719\n",
            "Epoch: [83]  [294/295]  eta: 0:00:00  lr: 0.000384  min_lr: 0.000384  loss: 2.4432 (2.4447)  weight_decay: 0.0500 (0.0500)  time: 0.2199  data: 0.0002  max mem: 3719\n",
            "Epoch: [83] Total time: 0:01:20 (0.2712 s / it)\n",
            "Averaged stats: lr: 0.000384  min_lr: 0.000384  loss: 2.4432 (2.4447)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:49  loss: 0.6054 (0.6054)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 2.7928  data: 2.6270  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.5696 (0.5923)  acc1: 91.6667 (88.8258)  acc5: 97.9167 (97.7273)  time: 0.4318  data: 0.2797  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.5491 (0.5983)  acc1: 89.5833 (88.5913)  acc5: 97.9167 (98.1151)  time: 0.1668  data: 0.0245  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6657 (0.7912)  acc1: 85.4167 (80.3091)  acc5: 97.9167 (97.5806)  time: 0.1320  data: 0.0039  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.6563 (0.7404)  acc1: 83.3333 (81.8089)  acc5: 97.9167 (97.9167)  time: 0.1257  data: 0.0030  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6286 (0.7383)  acc1: 83.3333 (81.7402)  acc5: 100.0000 (98.0392)  time: 0.1238  data: 0.0038  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7658 (0.7421)  acc1: 79.1667 (81.5574)  acc5: 97.9167 (98.0874)  time: 0.1231  data: 0.0053  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8004 (0.7602)  acc1: 79.1667 (80.7805)  acc5: 97.9167 (97.9460)  time: 0.1211  data: 0.0029  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7365 (0.7444)  acc1: 81.2500 (81.3014)  acc5: 97.9167 (97.9681)  time: 0.1182  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7365 (0.7463)  acc1: 81.2500 (81.2484)  acc5: 97.9167 (97.9108)  time: 0.1168  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1709 s / it)\n",
            "* Acc@1 81.248 Acc@5 97.911 loss 0.746\n",
            "Accuracy of the model on the 3925 test images: 81.2%\n",
            "Max accuracy: 81.35%\n",
            "Test:  [ 0/82]  eta: 0:04:31  loss: 1.8235 (1.8235)  acc1: 33.3333 (33.3333)  acc5: 93.7500 (93.7500)  time: 3.3060  data: 3.1358  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:33  loss: 2.0566 (2.1483)  acc1: 27.0833 (25.9470)  acc5: 97.9167 (96.2121)  time: 0.4613  data: 0.3252  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 2.4498 (2.3763)  acc1: 25.0000 (23.7103)  acc5: 95.8333 (95.7341)  time: 0.1675  data: 0.0326  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 2.9851 (2.9334)  acc1: 14.5833 (17.7419)  acc5: 89.5833 (82.5269)  time: 0.1569  data: 0.0186  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 3.0941 (2.9876)  acc1: 12.5000 (18.3943)  acc5: 77.0833 (81.4024)  time: 0.1405  data: 0.0101  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.2686 (3.2463)  acc1: 12.5000 (16.2582)  acc5: 72.9167 (75.8170)  time: 0.1247  data: 0.0039  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.1331 (3.3152)  acc1: 6.2500 (14.3443)  acc5: 47.9167 (73.9413)  time: 0.1243  data: 0.0039  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.1341 (3.2077)  acc1: 4.1667 (17.7230)  acc5: 79.1667 (73.5622)  time: 0.1231  data: 0.0031  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9975 (2.9075)  acc1: 66.6667 (25.1029)  acc5: 97.9167 (76.6204)  time: 0.1206  data: 0.0011  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9975 (2.8842)  acc1: 70.8333 (25.6306)  acc5: 97.9167 (76.7643)  time: 0.1190  data: 0.0006  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1812 s / it)\n",
            "* Acc@1 25.631 Acc@5 76.764 loss 2.884\n",
            "Accuracy of the model EMA on 3925 test images: 25.6%\n",
            "Max EMA accuracy: 25.63%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [84]  [  0/295]  eta: 0:09:59  lr: 0.000383  min_lr: 0.000383  loss: 2.5746 (2.5746)  weight_decay: 0.0500 (0.0500)  time: 2.0330  data: 1.6839  max mem: 3719\n",
            "Epoch: [84]  [ 10/295]  eta: 0:02:10  lr: 0.000382  min_lr: 0.000382  loss: 2.1992 (2.2233)  weight_decay: 0.0500 (0.0500)  time: 0.4582  data: 0.1541  max mem: 3719\n",
            "Epoch: [84]  [ 20/295]  eta: 0:01:42  lr: 0.000380  min_lr: 0.000380  loss: 2.1830 (2.2429)  weight_decay: 0.0500 (0.0500)  time: 0.2891  data: 0.0012  max mem: 3719\n",
            "Epoch: [84]  [ 30/295]  eta: 0:01:30  lr: 0.000378  min_lr: 0.000378  loss: 2.2989 (2.3019)  weight_decay: 0.0500 (0.0500)  time: 0.2775  data: 0.0009  max mem: 3719\n",
            "Epoch: [84]  [ 40/295]  eta: 0:01:23  lr: 0.000377  min_lr: 0.000377  loss: 2.4431 (2.3566)  weight_decay: 0.0500 (0.0500)  time: 0.2771  data: 0.0008  max mem: 3719\n",
            "Epoch: [84]  [ 50/295]  eta: 0:01:16  lr: 0.000375  min_lr: 0.000375  loss: 2.5215 (2.3753)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0008  max mem: 3719\n",
            "Epoch: [84]  [ 60/295]  eta: 0:01:11  lr: 0.000373  min_lr: 0.000373  loss: 2.4556 (2.3712)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0009  max mem: 3719\n",
            "Epoch: [84]  [ 70/295]  eta: 0:01:07  lr: 0.000372  min_lr: 0.000372  loss: 2.2097 (2.3568)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0017  max mem: 3719\n",
            "Epoch: [84]  [ 80/295]  eta: 0:01:03  lr: 0.000370  min_lr: 0.000370  loss: 2.4754 (2.3790)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0016  max mem: 3719\n",
            "Epoch: [84]  [ 90/295]  eta: 0:01:00  lr: 0.000369  min_lr: 0.000369  loss: 2.5790 (2.3930)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0011  max mem: 3719\n",
            "Epoch: [84]  [100/295]  eta: 0:00:56  lr: 0.000367  min_lr: 0.000367  loss: 2.4005 (2.3860)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0013  max mem: 3719\n",
            "Epoch: [84]  [110/295]  eta: 0:00:53  lr: 0.000366  min_lr: 0.000366  loss: 2.3746 (2.3861)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0011  max mem: 3719\n",
            "Epoch: [84]  [120/295]  eta: 0:00:50  lr: 0.000364  min_lr: 0.000364  loss: 2.3608 (2.3744)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0007  max mem: 3719\n",
            "Epoch: [84]  [130/295]  eta: 0:00:46  lr: 0.000363  min_lr: 0.000363  loss: 2.4045 (2.3862)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0009  max mem: 3719\n",
            "Epoch: [84]  [140/295]  eta: 0:00:43  lr: 0.000361  min_lr: 0.000361  loss: 2.5757 (2.3978)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0009  max mem: 3719\n",
            "Epoch: [84]  [150/295]  eta: 0:00:41  lr: 0.000360  min_lr: 0.000360  loss: 2.5337 (2.4047)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0026  max mem: 3719\n",
            "Epoch: [84]  [160/295]  eta: 0:00:38  lr: 0.000358  min_lr: 0.000358  loss: 2.4522 (2.4066)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0033  max mem: 3719\n",
            "Epoch: [84]  [170/295]  eta: 0:00:35  lr: 0.000357  min_lr: 0.000357  loss: 2.3880 (2.4094)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0024  max mem: 3719\n",
            "Epoch: [84]  [180/295]  eta: 0:00:32  lr: 0.000355  min_lr: 0.000355  loss: 2.5100 (2.4105)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0020  max mem: 3719\n",
            "Epoch: [84]  [190/295]  eta: 0:00:29  lr: 0.000354  min_lr: 0.000354  loss: 2.4228 (2.4067)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0020  max mem: 3719\n",
            "Epoch: [84]  [200/295]  eta: 0:00:26  lr: 0.000352  min_lr: 0.000352  loss: 2.3666 (2.4098)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0023  max mem: 3719\n",
            "Epoch: [84]  [210/295]  eta: 0:00:23  lr: 0.000351  min_lr: 0.000351  loss: 2.3929 (2.4086)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0026  max mem: 3719\n",
            "Epoch: [84]  [220/295]  eta: 0:00:20  lr: 0.000349  min_lr: 0.000349  loss: 2.3829 (2.4059)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0030  max mem: 3719\n",
            "Epoch: [84]  [230/295]  eta: 0:00:17  lr: 0.000348  min_lr: 0.000348  loss: 2.4203 (2.4096)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0026  max mem: 3719\n",
            "Epoch: [84]  [240/295]  eta: 0:00:15  lr: 0.000346  min_lr: 0.000346  loss: 2.5338 (2.4123)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0016  max mem: 3719\n",
            "Epoch: [84]  [250/295]  eta: 0:00:12  lr: 0.000345  min_lr: 0.000345  loss: 2.4461 (2.4119)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0011  max mem: 3719\n",
            "Epoch: [84]  [260/295]  eta: 0:00:09  lr: 0.000343  min_lr: 0.000343  loss: 2.4442 (2.4103)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0012  max mem: 3719\n",
            "Epoch: [84]  [270/295]  eta: 0:00:06  lr: 0.000342  min_lr: 0.000342  loss: 2.3140 (2.4082)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0020  max mem: 3719\n",
            "Epoch: [84]  [280/295]  eta: 0:00:04  lr: 0.000340  min_lr: 0.000340  loss: 2.3788 (2.4073)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0022  max mem: 3719\n",
            "Epoch: [84]  [290/295]  eta: 0:00:01  lr: 0.000339  min_lr: 0.000339  loss: 2.4524 (2.4101)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0010  max mem: 3719\n",
            "Epoch: [84]  [294/295]  eta: 0:00:00  lr: 0.000339  min_lr: 0.000339  loss: 2.4964 (2.4110)  weight_decay: 0.0500 (0.0500)  time: 0.2207  data: 0.0002  max mem: 3719\n",
            "Epoch: [84] Total time: 0:01:20 (0.2719 s / it)\n",
            "Averaged stats: lr: 0.000339  min_lr: 0.000339  loss: 2.4964 (2.4110)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:25  loss: 0.6611 (0.6611)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.5015  data: 2.3422  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 0.5812 (0.6243)  acc1: 89.5833 (87.3106)  acc5: 97.9167 (97.7273)  time: 0.3410  data: 0.2157  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5719 (0.5932)  acc1: 89.5833 (88.6905)  acc5: 97.9167 (98.3135)  time: 0.1248  data: 0.0055  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.5997 (0.7497)  acc1: 87.5000 (81.7204)  acc5: 100.0000 (98.1855)  time: 0.1245  data: 0.0055  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7217 (0.7242)  acc1: 81.2500 (82.2663)  acc5: 100.0000 (98.4248)  time: 0.1244  data: 0.0031  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6580 (0.7249)  acc1: 81.2500 (82.1895)  acc5: 100.0000 (98.4886)  time: 0.1444  data: 0.0039  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7756 (0.7392)  acc1: 81.2500 (81.5232)  acc5: 100.0000 (98.3607)  time: 0.1527  data: 0.0029  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8860 (0.7663)  acc1: 72.9167 (80.2817)  acc5: 97.9167 (98.1808)  time: 0.1412  data: 0.0005  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7139 (0.7433)  acc1: 81.2500 (81.2243)  acc5: 97.9167 (98.1739)  time: 0.1299  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7139 (0.7444)  acc1: 81.2500 (81.1975)  acc5: 97.9167 (98.1147)  time: 0.1290  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1674 s / it)\n",
            "* Acc@1 81.197 Acc@5 98.115 loss 0.744\n",
            "Accuracy of the model on the 3925 test images: 81.2%\n",
            "Max accuracy: 81.35%\n",
            "Test:  [ 0/82]  eta: 0:01:42  loss: 1.7845 (1.7845)  acc1: 35.4167 (35.4167)  acc5: 93.7500 (93.7500)  time: 1.2511  data: 1.1438  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 2.0184 (2.1129)  acc1: 27.0833 (27.0833)  acc5: 97.9167 (96.4015)  time: 0.3170  data: 0.1975  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 2.4180 (2.3456)  acc1: 27.0833 (24.4048)  acc5: 95.8333 (95.7341)  time: 0.1749  data: 0.0551  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.9501 (2.9029)  acc1: 14.5833 (18.3468)  acc5: 89.5833 (82.4597)  time: 0.1259  data: 0.0063  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.0392 (2.9537)  acc1: 12.5000 (19.0041)  acc5: 79.1667 (81.6057)  time: 0.1233  data: 0.0045  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.2271 (3.2139)  acc1: 12.5000 (16.7484)  acc5: 70.8333 (75.8987)  time: 0.1220  data: 0.0032  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.1195 (3.2801)  acc1: 4.1667 (14.7883)  acc5: 47.9167 (74.0437)  time: 0.1230  data: 0.0035  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.0904 (3.1735)  acc1: 4.1667 (18.1631)  acc5: 79.1667 (73.7089)  time: 0.1217  data: 0.0023  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9879 (2.8764)  acc1: 68.7500 (25.5144)  acc5: 97.9167 (76.7490)  time: 0.1201  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9879 (2.8534)  acc1: 70.8333 (26.0382)  acc5: 97.9167 (76.8917)  time: 0.1187  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1559 s / it)\n",
            "* Acc@1 26.038 Acc@5 76.892 loss 2.853\n",
            "Accuracy of the model EMA on 3925 test images: 26.0%\n",
            "Max EMA accuracy: 26.04%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [85]  [  0/295]  eta: 0:10:57  lr: 0.000338  min_lr: 0.000338  loss: 2.5593 (2.5593)  weight_decay: 0.0500 (0.0500)  time: 2.2302  data: 1.8466  max mem: 3719\n",
            "Epoch: [85]  [ 10/295]  eta: 0:02:09  lr: 0.000337  min_lr: 0.000337  loss: 2.5214 (2.4481)  weight_decay: 0.0500 (0.0500)  time: 0.4536  data: 0.1693  max mem: 3719\n",
            "Epoch: [85]  [ 20/295]  eta: 0:01:39  lr: 0.000335  min_lr: 0.000335  loss: 2.5214 (2.4414)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0010  max mem: 3719\n",
            "Epoch: [85]  [ 30/295]  eta: 0:01:27  lr: 0.000334  min_lr: 0.000334  loss: 2.4573 (2.4038)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0004  max mem: 3719\n",
            "Epoch: [85]  [ 40/295]  eta: 0:01:20  lr: 0.000332  min_lr: 0.000332  loss: 2.3265 (2.3807)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0004  max mem: 3719\n",
            "Epoch: [85]  [ 50/295]  eta: 0:01:14  lr: 0.000331  min_lr: 0.000331  loss: 2.5130 (2.4117)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0007  max mem: 3719\n",
            "Epoch: [85]  [ 60/295]  eta: 0:01:10  lr: 0.000329  min_lr: 0.000329  loss: 2.3539 (2.3840)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0013  max mem: 3719\n",
            "Epoch: [85]  [ 70/295]  eta: 0:01:06  lr: 0.000328  min_lr: 0.000328  loss: 2.2113 (2.3818)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0015  max mem: 3719\n",
            "Epoch: [85]  [ 80/295]  eta: 0:01:02  lr: 0.000326  min_lr: 0.000326  loss: 2.2113 (2.3717)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0016  max mem: 3719\n",
            "Epoch: [85]  [ 90/295]  eta: 0:00:59  lr: 0.000325  min_lr: 0.000325  loss: 2.2693 (2.3786)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0015  max mem: 3719\n",
            "Epoch: [85]  [100/295]  eta: 0:00:55  lr: 0.000323  min_lr: 0.000323  loss: 2.4280 (2.3737)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0011  max mem: 3719\n",
            "Epoch: [85]  [110/295]  eta: 0:00:52  lr: 0.000322  min_lr: 0.000322  loss: 2.3047 (2.3730)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0020  max mem: 3719\n",
            "Epoch: [85]  [120/295]  eta: 0:00:49  lr: 0.000320  min_lr: 0.000320  loss: 2.5226 (2.3838)  weight_decay: 0.0500 (0.0500)  time: 0.2750  data: 0.0033  max mem: 3719\n",
            "Epoch: [85]  [130/295]  eta: 0:00:46  lr: 0.000319  min_lr: 0.000319  loss: 2.3047 (2.3668)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0026  max mem: 3719\n",
            "Epoch: [85]  [140/295]  eta: 0:00:43  lr: 0.000317  min_lr: 0.000317  loss: 2.2387 (2.3658)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0011  max mem: 3719\n",
            "Epoch: [85]  [150/295]  eta: 0:00:40  lr: 0.000316  min_lr: 0.000316  loss: 2.4759 (2.3790)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0010  max mem: 3719\n",
            "Epoch: [85]  [160/295]  eta: 0:00:37  lr: 0.000314  min_lr: 0.000314  loss: 2.4759 (2.3813)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0014  max mem: 3719\n",
            "Epoch: [85]  [170/295]  eta: 0:00:34  lr: 0.000313  min_lr: 0.000313  loss: 2.4456 (2.3840)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0011  max mem: 3719\n",
            "Epoch: [85]  [180/295]  eta: 0:00:31  lr: 0.000312  min_lr: 0.000312  loss: 2.2852 (2.3783)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0025  max mem: 3719\n",
            "Epoch: [85]  [190/295]  eta: 0:00:29  lr: 0.000310  min_lr: 0.000310  loss: 2.2661 (2.3763)  weight_decay: 0.0500 (0.0500)  time: 0.2754  data: 0.0041  max mem: 3719\n",
            "Epoch: [85]  [200/295]  eta: 0:00:26  lr: 0.000309  min_lr: 0.000309  loss: 2.4048 (2.3800)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0036  max mem: 3719\n",
            "Epoch: [85]  [210/295]  eta: 0:00:23  lr: 0.000308  min_lr: 0.000308  loss: 2.4293 (2.3832)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0028  max mem: 3719\n",
            "Epoch: [85]  [220/295]  eta: 0:00:20  lr: 0.000306  min_lr: 0.000306  loss: 2.3629 (2.3826)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0013  max mem: 3719\n",
            "Epoch: [85]  [230/295]  eta: 0:00:17  lr: 0.000305  min_lr: 0.000305  loss: 2.2810 (2.3769)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0006  max mem: 3719\n",
            "Epoch: [85]  [240/295]  eta: 0:00:15  lr: 0.000303  min_lr: 0.000303  loss: 2.4188 (2.3801)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0013  max mem: 3719\n",
            "Epoch: [85]  [250/295]  eta: 0:00:12  lr: 0.000302  min_lr: 0.000302  loss: 2.4394 (2.3783)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0016  max mem: 3719\n",
            "Epoch: [85]  [260/295]  eta: 0:00:09  lr: 0.000300  min_lr: 0.000300  loss: 2.3766 (2.3812)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0027  max mem: 3719\n",
            "Epoch: [85]  [270/295]  eta: 0:00:06  lr: 0.000299  min_lr: 0.000299  loss: 2.4214 (2.3833)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0035  max mem: 3719\n",
            "Epoch: [85]  [280/295]  eta: 0:00:04  lr: 0.000297  min_lr: 0.000297  loss: 2.3726 (2.3850)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0016  max mem: 3719\n",
            "Epoch: [85]  [290/295]  eta: 0:00:01  lr: 0.000296  min_lr: 0.000296  loss: 2.4727 (2.3888)  weight_decay: 0.0500 (0.0500)  time: 0.2570  data: 0.0002  max mem: 3719\n",
            "Epoch: [85]  [294/295]  eta: 0:00:00  lr: 0.000296  min_lr: 0.000296  loss: 2.4727 (2.3904)  weight_decay: 0.0500 (0.0500)  time: 0.2194  data: 0.0002  max mem: 3719\n",
            "Epoch: [85] Total time: 0:01:19 (0.2710 s / it)\n",
            "Averaged stats: lr: 0.000296  min_lr: 0.000296  loss: 2.4727 (2.3904)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:25  loss: 0.4884 (0.4884)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 1.7701  data: 1.5996  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.4679 (0.5049)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (97.9167)  time: 0.3817  data: 0.2369  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.4919 (0.5403)  acc1: 91.6667 (89.3849)  acc5: 100.0000 (98.4127)  time: 0.2228  data: 0.0726  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.6383 (0.7228)  acc1: 85.4167 (81.7876)  acc5: 100.0000 (98.2527)  time: 0.1899  data: 0.0344  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7293 (0.7071)  acc1: 79.1667 (82.2154)  acc5: 100.0000 (98.4756)  time: 0.1674  data: 0.0150  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7202 (0.7123)  acc1: 81.2500 (82.1078)  acc5: 100.0000 (98.4886)  time: 0.1410  data: 0.0047  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7636 (0.7191)  acc1: 81.2500 (82.0697)  acc5: 97.9167 (98.4631)  time: 0.1244  data: 0.0028  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8123 (0.7387)  acc1: 81.2500 (81.2793)  acc5: 97.9167 (98.2394)  time: 0.1238  data: 0.0037  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7197 (0.7219)  acc1: 83.3333 (82.0216)  acc5: 97.9167 (98.1996)  time: 0.1206  data: 0.0028  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7197 (0.7239)  acc1: 83.3333 (82.0127)  acc5: 97.9167 (98.1656)  time: 0.1190  data: 0.0028  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1823 s / it)\n",
            "* Acc@1 82.013 Acc@5 98.166 loss 0.724\n",
            "Accuracy of the model on the 3925 test images: 82.0%\n",
            "Max accuracy: 82.01%\n",
            "Test:  [ 0/82]  eta: 0:02:37  loss: 1.7474 (1.7474)  acc1: 35.4167 (35.4167)  acc5: 91.6667 (91.6667)  time: 1.9259  data: 1.7341  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 1.9815 (2.0794)  acc1: 27.0833 (27.6515)  acc5: 97.9167 (96.4015)  time: 0.3026  data: 0.1609  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.3860 (2.3157)  acc1: 27.0833 (25.0000)  acc5: 95.8333 (95.7341)  time: 0.1402  data: 0.0021  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.9158 (2.8731)  acc1: 14.5833 (18.9516)  acc5: 89.5833 (82.5941)  time: 0.1547  data: 0.0167  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.9848 (2.9204)  acc1: 14.5833 (19.7663)  acc5: 79.1667 (81.8598)  time: 0.1695  data: 0.0317  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.1857 (3.1817)  acc1: 12.5000 (17.4020)  acc5: 70.8333 (76.1029)  time: 0.1593  data: 0.0216  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.1043 (3.2453)  acc1: 4.1667 (15.4372)  acc5: 47.9167 (74.3511)  time: 0.1449  data: 0.0099  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.0467 (3.1395)  acc1: 4.1667 (18.7500)  acc5: 79.1667 (74.0317)  time: 0.1382  data: 0.0086  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9761 (2.8457)  acc1: 68.7500 (26.0545)  acc5: 97.9167 (77.0062)  time: 0.1274  data: 0.0050  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9761 (2.8230)  acc1: 70.8333 (26.5732)  acc5: 97.9167 (77.1210)  time: 0.1247  data: 0.0049  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1719 s / it)\n",
            "* Acc@1 26.573 Acc@5 77.121 loss 2.823\n",
            "Accuracy of the model EMA on 3925 test images: 26.6%\n",
            "Max EMA accuracy: 26.57%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [86]  [  0/295]  eta: 0:10:13  lr: 0.000296  min_lr: 0.000296  loss: 2.4011 (2.4011)  weight_decay: 0.0500 (0.0500)  time: 2.0797  data: 1.6995  max mem: 3719\n",
            "Epoch: [86]  [ 10/295]  eta: 0:02:05  lr: 0.000295  min_lr: 0.000295  loss: 2.2723 (2.3507)  weight_decay: 0.0500 (0.0500)  time: 0.4418  data: 0.1552  max mem: 3719\n",
            "Epoch: [86]  [ 20/295]  eta: 0:01:39  lr: 0.000293  min_lr: 0.000293  loss: 2.4553 (2.3907)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0010  max mem: 3719\n",
            "Epoch: [86]  [ 30/295]  eta: 0:01:27  lr: 0.000292  min_lr: 0.000292  loss: 2.4553 (2.4110)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0013  max mem: 3719\n",
            "Epoch: [86]  [ 40/295]  eta: 0:01:20  lr: 0.000290  min_lr: 0.000290  loss: 2.3434 (2.3879)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0012  max mem: 3719\n",
            "Epoch: [86]  [ 50/295]  eta: 0:01:15  lr: 0.000289  min_lr: 0.000289  loss: 2.2141 (2.3747)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0010  max mem: 3719\n",
            "Epoch: [86]  [ 60/295]  eta: 0:01:10  lr: 0.000287  min_lr: 0.000287  loss: 2.5305 (2.4175)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0014  max mem: 3719\n",
            "Epoch: [86]  [ 70/295]  eta: 0:01:06  lr: 0.000286  min_lr: 0.000286  loss: 2.6263 (2.4303)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0015  max mem: 3719\n",
            "Epoch: [86]  [ 80/295]  eta: 0:01:02  lr: 0.000285  min_lr: 0.000285  loss: 2.4995 (2.4305)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0009  max mem: 3719\n",
            "Epoch: [86]  [ 90/295]  eta: 0:00:59  lr: 0.000283  min_lr: 0.000283  loss: 2.3799 (2.4231)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0004  max mem: 3719\n",
            "Epoch: [86]  [100/295]  eta: 0:00:56  lr: 0.000282  min_lr: 0.000282  loss: 2.3868 (2.4165)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0012  max mem: 3719\n",
            "Epoch: [86]  [110/295]  eta: 0:00:52  lr: 0.000281  min_lr: 0.000281  loss: 2.4666 (2.4206)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0016  max mem: 3719\n",
            "Epoch: [86]  [120/295]  eta: 0:00:49  lr: 0.000279  min_lr: 0.000279  loss: 2.4030 (2.4125)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0013  max mem: 3719\n",
            "Epoch: [86]  [130/295]  eta: 0:00:46  lr: 0.000278  min_lr: 0.000278  loss: 2.2805 (2.4058)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0014  max mem: 3719\n",
            "Epoch: [86]  [140/295]  eta: 0:00:43  lr: 0.000276  min_lr: 0.000276  loss: 2.4775 (2.4153)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0013  max mem: 3719\n",
            "Epoch: [86]  [150/295]  eta: 0:00:40  lr: 0.000275  min_lr: 0.000275  loss: 2.4527 (2.4121)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0017  max mem: 3719\n",
            "Epoch: [86]  [160/295]  eta: 0:00:37  lr: 0.000274  min_lr: 0.000274  loss: 2.4064 (2.4143)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0015  max mem: 3719\n",
            "Epoch: [86]  [170/295]  eta: 0:00:34  lr: 0.000272  min_lr: 0.000272  loss: 2.4092 (2.4139)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0011  max mem: 3719\n",
            "Epoch: [86]  [180/295]  eta: 0:00:31  lr: 0.000271  min_lr: 0.000271  loss: 2.4092 (2.4099)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0012  max mem: 3719\n",
            "Epoch: [86]  [190/295]  eta: 0:00:28  lr: 0.000270  min_lr: 0.000270  loss: 2.2869 (2.4012)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0019  max mem: 3719\n",
            "Epoch: [86]  [200/295]  eta: 0:00:26  lr: 0.000268  min_lr: 0.000268  loss: 2.3265 (2.4025)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0027  max mem: 3719\n",
            "Epoch: [86]  [210/295]  eta: 0:00:23  lr: 0.000267  min_lr: 0.000267  loss: 2.3236 (2.3964)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0026  max mem: 3719\n",
            "Epoch: [86]  [220/295]  eta: 0:00:20  lr: 0.000265  min_lr: 0.000265  loss: 2.2486 (2.3953)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0032  max mem: 3719\n",
            "Epoch: [86]  [230/295]  eta: 0:00:17  lr: 0.000264  min_lr: 0.000264  loss: 2.4194 (2.3979)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0026  max mem: 3719\n",
            "Epoch: [86]  [240/295]  eta: 0:00:15  lr: 0.000263  min_lr: 0.000263  loss: 2.4194 (2.4001)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0013  max mem: 3719\n",
            "Epoch: [86]  [250/295]  eta: 0:00:12  lr: 0.000262  min_lr: 0.000262  loss: 2.4210 (2.4023)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0009  max mem: 3719\n",
            "Epoch: [86]  [260/295]  eta: 0:00:09  lr: 0.000260  min_lr: 0.000260  loss: 2.5097 (2.4079)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0007  max mem: 3719\n",
            "Epoch: [86]  [270/295]  eta: 0:00:06  lr: 0.000259  min_lr: 0.000259  loss: 2.5280 (2.4062)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0016  max mem: 3719\n",
            "Epoch: [86]  [280/295]  eta: 0:00:04  lr: 0.000258  min_lr: 0.000258  loss: 2.5427 (2.4105)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0016  max mem: 3719\n",
            "Epoch: [86]  [290/295]  eta: 0:00:01  lr: 0.000256  min_lr: 0.000256  loss: 2.5427 (2.4132)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0004  max mem: 3719\n",
            "Epoch: [86]  [294/295]  eta: 0:00:00  lr: 0.000256  min_lr: 0.000256  loss: 2.5289 (2.4122)  weight_decay: 0.0500 (0.0500)  time: 0.2220  data: 0.0002  max mem: 3719\n",
            "Epoch: [86] Total time: 0:01:19 (0.2702 s / it)\n",
            "Averaged stats: lr: 0.000256  min_lr: 0.000256  loss: 2.5289 (2.4122)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:02  loss: 0.5764 (0.5764)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 1.4881  data: 1.3213  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.5553 (0.5524)  acc1: 89.5833 (88.6364)  acc5: 100.0000 (98.4849)  time: 0.3104  data: 0.1795  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5235 (0.5582)  acc1: 89.5833 (89.8810)  acc5: 100.0000 (98.5119)  time: 0.1610  data: 0.0335  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6703 (0.7207)  acc1: 87.5000 (82.9973)  acc5: 97.9167 (98.3871)  time: 0.1366  data: 0.0029  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7838 (0.7162)  acc1: 81.2500 (83.4858)  acc5: 97.9167 (98.5264)  time: 0.1431  data: 0.0028  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7446 (0.7205)  acc1: 83.3333 (83.4150)  acc5: 100.0000 (98.5294)  time: 0.1573  data: 0.0017  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7752 (0.7369)  acc1: 81.2500 (82.7869)  acc5: 97.9167 (98.3607)  time: 0.1718  data: 0.0034  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8508 (0.7576)  acc1: 77.0833 (81.7488)  acc5: 97.9167 (98.1514)  time: 0.1807  data: 0.0259  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6738 (0.7414)  acc1: 81.2500 (82.3560)  acc5: 97.9167 (98.1996)  time: 0.1544  data: 0.0234  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6738 (0.7433)  acc1: 81.2500 (82.3185)  acc5: 97.9167 (98.1656)  time: 0.1499  data: 0.0224  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1818 s / it)\n",
            "* Acc@1 82.318 Acc@5 98.166 loss 0.743\n",
            "Accuracy of the model on the 3925 test images: 82.3%\n",
            "Max accuracy: 82.32%\n",
            "Test:  [ 0/82]  eta: 0:04:06  loss: 1.7097 (1.7097)  acc1: 37.5000 (37.5000)  acc5: 91.6667 (91.6667)  time: 3.0091  data: 2.8450  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 1.9444 (2.0454)  acc1: 29.1667 (28.9773)  acc5: 97.9167 (96.4015)  time: 0.4105  data: 0.2774  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.3649 (2.2854)  acc1: 27.0833 (25.6944)  acc5: 95.8333 (95.6349)  time: 0.1380  data: 0.0114  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.8820 (2.8430)  acc1: 14.5833 (19.4220)  acc5: 89.5833 (82.5941)  time: 0.1244  data: 0.0018  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.9417 (2.8868)  acc1: 14.5833 (20.2236)  acc5: 77.0833 (82.0630)  time: 0.1259  data: 0.0041  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.1445 (3.1491)  acc1: 10.4167 (17.6471)  acc5: 72.9167 (76.3480)  time: 0.1253  data: 0.0042  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.0895 (3.2102)  acc1: 4.1667 (15.7787)  acc5: 47.9167 (74.7609)  time: 0.1222  data: 0.0033  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.0028 (3.1054)  acc1: 6.2500 (19.1315)  acc5: 79.1667 (74.4131)  time: 0.1208  data: 0.0027  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9651 (2.8147)  acc1: 68.7500 (26.3889)  acc5: 97.9167 (77.3405)  time: 0.1191  data: 0.0004  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9651 (2.7923)  acc1: 70.8333 (26.9045)  acc5: 97.9167 (77.4777)  time: 0.1175  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1695 s / it)\n",
            "* Acc@1 26.904 Acc@5 77.478 loss 2.792\n",
            "Accuracy of the model EMA on 3925 test images: 26.9%\n",
            "Max EMA accuracy: 26.90%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [87]  [  0/295]  eta: 0:13:31  lr: 0.000256  min_lr: 0.000256  loss: 2.6480 (2.6480)  weight_decay: 0.0500 (0.0500)  time: 2.7497  data: 2.1808  max mem: 3719\n",
            "Epoch: [87]  [ 10/295]  eta: 0:02:23  lr: 0.000255  min_lr: 0.000255  loss: 2.3992 (2.3415)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.1991  max mem: 3719\n",
            "Epoch: [87]  [ 20/295]  eta: 0:01:46  lr: 0.000253  min_lr: 0.000253  loss: 2.4943 (2.4387)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0013  max mem: 3719\n",
            "Epoch: [87]  [ 30/295]  eta: 0:01:32  lr: 0.000252  min_lr: 0.000252  loss: 2.5288 (2.4363)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0013  max mem: 3719\n",
            "Epoch: [87]  [ 40/295]  eta: 0:01:23  lr: 0.000251  min_lr: 0.000251  loss: 2.4110 (2.4252)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0008  max mem: 3719\n",
            "Epoch: [87]  [ 50/295]  eta: 0:01:17  lr: 0.000250  min_lr: 0.000250  loss: 2.2982 (2.3963)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0008  max mem: 3719\n",
            "Epoch: [87]  [ 60/295]  eta: 0:01:12  lr: 0.000248  min_lr: 0.000248  loss: 2.3550 (2.3959)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0008  max mem: 3719\n",
            "Epoch: [87]  [ 70/295]  eta: 0:01:08  lr: 0.000247  min_lr: 0.000247  loss: 2.4919 (2.4074)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0005  max mem: 3719\n",
            "Epoch: [87]  [ 80/295]  eta: 0:01:04  lr: 0.000246  min_lr: 0.000246  loss: 2.4285 (2.3884)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0008  max mem: 3719\n",
            "Epoch: [87]  [ 90/295]  eta: 0:01:00  lr: 0.000245  min_lr: 0.000245  loss: 2.2338 (2.3720)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0012  max mem: 3719\n",
            "Epoch: [87]  [100/295]  eta: 0:00:56  lr: 0.000243  min_lr: 0.000243  loss: 2.2741 (2.3802)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0017  max mem: 3719\n",
            "Epoch: [87]  [110/295]  eta: 0:00:53  lr: 0.000242  min_lr: 0.000242  loss: 2.4115 (2.3840)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0023  max mem: 3719\n",
            "Epoch: [87]  [120/295]  eta: 0:00:50  lr: 0.000240  min_lr: 0.000240  loss: 2.2990 (2.3663)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0024  max mem: 3719\n",
            "Epoch: [87]  [130/295]  eta: 0:00:47  lr: 0.000239  min_lr: 0.000239  loss: 2.2569 (2.3694)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0015  max mem: 3719\n",
            "Epoch: [87]  [140/295]  eta: 0:00:44  lr: 0.000238  min_lr: 0.000238  loss: 2.4564 (2.3738)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0009  max mem: 3719\n",
            "Epoch: [87]  [150/295]  eta: 0:00:40  lr: 0.000237  min_lr: 0.000237  loss: 2.4393 (2.3763)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0015  max mem: 3719\n",
            "Epoch: [87]  [160/295]  eta: 0:00:37  lr: 0.000235  min_lr: 0.000235  loss: 2.4393 (2.3738)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0014  max mem: 3719\n",
            "Epoch: [87]  [170/295]  eta: 0:00:35  lr: 0.000234  min_lr: 0.000234  loss: 2.3740 (2.3710)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0013  max mem: 3719\n",
            "Epoch: [87]  [180/295]  eta: 0:00:32  lr: 0.000233  min_lr: 0.000233  loss: 2.4874 (2.3775)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0023  max mem: 3719\n",
            "Epoch: [87]  [190/295]  eta: 0:00:29  lr: 0.000232  min_lr: 0.000232  loss: 2.5255 (2.3836)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0026  max mem: 3719\n",
            "Epoch: [87]  [200/295]  eta: 0:00:26  lr: 0.000230  min_lr: 0.000230  loss: 2.5142 (2.3885)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0014  max mem: 3719\n",
            "Epoch: [87]  [210/295]  eta: 0:00:23  lr: 0.000229  min_lr: 0.000229  loss: 2.3712 (2.3845)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0011  max mem: 3719\n",
            "Epoch: [87]  [220/295]  eta: 0:00:20  lr: 0.000228  min_lr: 0.000228  loss: 2.3712 (2.3843)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0013  max mem: 3719\n",
            "Epoch: [87]  [230/295]  eta: 0:00:17  lr: 0.000227  min_lr: 0.000227  loss: 2.4956 (2.3882)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0017  max mem: 3719\n",
            "Epoch: [87]  [240/295]  eta: 0:00:15  lr: 0.000225  min_lr: 0.000225  loss: 2.4297 (2.3867)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0020  max mem: 3719\n",
            "Epoch: [87]  [250/295]  eta: 0:00:12  lr: 0.000224  min_lr: 0.000224  loss: 2.3591 (2.3882)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0014  max mem: 3719\n",
            "Epoch: [87]  [260/295]  eta: 0:00:09  lr: 0.000223  min_lr: 0.000223  loss: 2.4857 (2.3905)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0009  max mem: 3719\n",
            "Epoch: [87]  [270/295]  eta: 0:00:06  lr: 0.000222  min_lr: 0.000222  loss: 2.4779 (2.3861)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0009  max mem: 3719\n",
            "Epoch: [87]  [280/295]  eta: 0:00:04  lr: 0.000220  min_lr: 0.000220  loss: 2.4873 (2.3936)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0007  max mem: 3719\n",
            "Epoch: [87]  [290/295]  eta: 0:00:01  lr: 0.000219  min_lr: 0.000219  loss: 2.5153 (2.3939)  weight_decay: 0.0500 (0.0500)  time: 0.2569  data: 0.0002  max mem: 3719\n",
            "Epoch: [87]  [294/295]  eta: 0:00:00  lr: 0.000219  min_lr: 0.000219  loss: 2.5014 (2.3942)  weight_decay: 0.0500 (0.0500)  time: 0.2199  data: 0.0002  max mem: 3719\n",
            "Epoch: [87] Total time: 0:01:20 (0.2727 s / it)\n",
            "Averaged stats: lr: 0.000219  min_lr: 0.000219  loss: 2.5014 (2.3942)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:37  loss: 0.5919 (0.5919)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 2.6532  data: 2.4892  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.5341 (0.5282)  acc1: 93.7500 (91.2879)  acc5: 100.0000 (98.4848)  time: 0.4117  data: 0.2681  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.5164 (0.5295)  acc1: 93.7500 (91.3691)  acc5: 100.0000 (98.7103)  time: 0.1589  data: 0.0242  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.5867 (0.7260)  acc1: 83.3333 (82.9973)  acc5: 97.9167 (98.4543)  time: 0.1293  data: 0.0032  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.6775 (0.6994)  acc1: 83.3333 (83.9939)  acc5: 100.0000 (98.6789)  time: 0.1267  data: 0.0036  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6661 (0.7136)  acc1: 83.3333 (83.2516)  acc5: 100.0000 (98.5294)  time: 0.1248  data: 0.0040  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7515 (0.7179)  acc1: 79.1667 (82.9235)  acc5: 97.9167 (98.4973)  time: 0.1229  data: 0.0045  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8389 (0.7386)  acc1: 79.1667 (81.8955)  acc5: 97.9167 (98.3275)  time: 0.1202  data: 0.0022  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6898 (0.7213)  acc1: 83.3333 (82.6389)  acc5: 97.9167 (98.2768)  time: 0.1187  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6898 (0.7235)  acc1: 83.3333 (82.5987)  acc5: 97.9167 (98.2166)  time: 0.1174  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1683 s / it)\n",
            "* Acc@1 82.599 Acc@5 98.217 loss 0.723\n",
            "Accuracy of the model on the 3925 test images: 82.6%\n",
            "Max accuracy: 82.60%\n",
            "Test:  [ 0/82]  eta: 0:04:22  loss: 1.6737 (1.6737)  acc1: 41.6667 (41.6667)  acc5: 91.6667 (91.6667)  time: 3.2042  data: 3.0221  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:33  loss: 1.9083 (2.0118)  acc1: 29.1667 (29.9242)  acc5: 97.9167 (96.4015)  time: 0.4600  data: 0.2806  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 2.3450 (2.2544)  acc1: 27.0833 (26.1905)  acc5: 95.8333 (95.5357)  time: 0.1557  data: 0.0043  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 2.8451 (2.8126)  acc1: 16.6667 (19.9597)  acc5: 89.5833 (82.5941)  time: 0.1250  data: 0.0037  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.9105 (2.8536)  acc1: 16.6667 (20.7825)  acc5: 77.0833 (82.2154)  time: 0.1224  data: 0.0041  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.1056 (3.1172)  acc1: 10.4167 (18.1373)  acc5: 70.8333 (76.4297)  time: 0.1235  data: 0.0036  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.0756 (3.1761)  acc1: 4.1667 (16.2227)  acc5: 47.9167 (74.8975)  time: 0.1249  data: 0.0033  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.9613 (3.0724)  acc1: 6.2500 (19.6009)  acc5: 79.1667 (74.5012)  time: 0.1212  data: 0.0014  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9569 (2.7849)  acc1: 68.7500 (26.8004)  acc5: 97.9167 (77.4177)  time: 0.1196  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9569 (2.7627)  acc1: 70.8333 (27.3121)  acc5: 97.9167 (77.5287)  time: 0.1181  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1726 s / it)\n",
            "* Acc@1 27.312 Acc@5 77.529 loss 2.763\n",
            "Accuracy of the model EMA on 3925 test images: 27.3%\n",
            "Max EMA accuracy: 27.31%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [88]  [  0/295]  eta: 0:13:52  lr: 0.000219  min_lr: 0.000219  loss: 2.4630 (2.4630)  weight_decay: 0.0500 (0.0500)  time: 2.8223  data: 2.1818  max mem: 3719\n",
            "Epoch: [88]  [ 10/295]  eta: 0:02:35  lr: 0.000218  min_lr: 0.000218  loss: 2.5232 (2.5294)  weight_decay: 0.0500 (0.0500)  time: 0.5446  data: 0.2000  max mem: 3719\n",
            "Epoch: [88]  [ 20/295]  eta: 0:01:52  lr: 0.000216  min_lr: 0.000216  loss: 2.5232 (2.5016)  weight_decay: 0.0500 (0.0500)  time: 0.2902  data: 0.0014  max mem: 3719\n",
            "Epoch: [88]  [ 30/295]  eta: 0:01:36  lr: 0.000216  min_lr: 0.000216  loss: 2.3794 (2.4374)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0008  max mem: 3719\n",
            "Epoch: [88]  [ 40/295]  eta: 0:01:27  lr: 0.000214  min_lr: 0.000214  loss: 2.2984 (2.4061)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0009  max mem: 3719\n",
            "Epoch: [88]  [ 50/295]  eta: 0:01:20  lr: 0.000213  min_lr: 0.000213  loss: 2.3220 (2.3965)  weight_decay: 0.0500 (0.0500)  time: 0.2782  data: 0.0012  max mem: 3719\n",
            "Epoch: [88]  [ 60/295]  eta: 0:01:15  lr: 0.000212  min_lr: 0.000212  loss: 2.4324 (2.4126)  weight_decay: 0.0500 (0.0500)  time: 0.2797  data: 0.0015  max mem: 3719\n",
            "Epoch: [88]  [ 70/295]  eta: 0:01:10  lr: 0.000211  min_lr: 0.000211  loss: 2.4919 (2.4148)  weight_decay: 0.0500 (0.0500)  time: 0.2764  data: 0.0012  max mem: 3719\n",
            "Epoch: [88]  [ 80/295]  eta: 0:01:06  lr: 0.000209  min_lr: 0.000209  loss: 2.3322 (2.4071)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0016  max mem: 3719\n",
            "Epoch: [88]  [ 90/295]  eta: 0:01:02  lr: 0.000208  min_lr: 0.000208  loss: 2.3726 (2.4161)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0016  max mem: 3719\n",
            "Epoch: [88]  [100/295]  eta: 0:00:58  lr: 0.000207  min_lr: 0.000207  loss: 2.3540 (2.4016)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0011  max mem: 3719\n",
            "Epoch: [88]  [110/295]  eta: 0:00:54  lr: 0.000206  min_lr: 0.000206  loss: 2.3730 (2.4002)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0011  max mem: 3719\n",
            "Epoch: [88]  [120/295]  eta: 0:00:51  lr: 0.000205  min_lr: 0.000205  loss: 2.4720 (2.3993)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0016  max mem: 3719\n",
            "Epoch: [88]  [130/295]  eta: 0:00:48  lr: 0.000204  min_lr: 0.000204  loss: 2.5060 (2.4082)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0024  max mem: 3719\n",
            "Epoch: [88]  [140/295]  eta: 0:00:45  lr: 0.000202  min_lr: 0.000202  loss: 2.4549 (2.4110)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0025  max mem: 3719\n",
            "Epoch: [88]  [150/295]  eta: 0:00:41  lr: 0.000201  min_lr: 0.000201  loss: 2.4225 (2.4113)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0016  max mem: 3719\n",
            "Epoch: [88]  [160/295]  eta: 0:00:38  lr: 0.000200  min_lr: 0.000200  loss: 2.3216 (2.4075)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0006  max mem: 3719\n",
            "Epoch: [88]  [170/295]  eta: 0:00:35  lr: 0.000199  min_lr: 0.000199  loss: 2.4622 (2.4075)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0011  max mem: 3719\n",
            "Epoch: [88]  [180/295]  eta: 0:00:32  lr: 0.000197  min_lr: 0.000197  loss: 2.4780 (2.4067)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0010  max mem: 3719\n",
            "Epoch: [88]  [190/295]  eta: 0:00:29  lr: 0.000197  min_lr: 0.000197  loss: 2.3919 (2.4013)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0015  max mem: 3719\n",
            "Epoch: [88]  [200/295]  eta: 0:00:26  lr: 0.000195  min_lr: 0.000195  loss: 2.1373 (2.3895)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0028  max mem: 3719\n",
            "Epoch: [88]  [210/295]  eta: 0:00:23  lr: 0.000194  min_lr: 0.000194  loss: 2.2118 (2.3901)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0031  max mem: 3719\n",
            "Epoch: [88]  [220/295]  eta: 0:00:21  lr: 0.000193  min_lr: 0.000193  loss: 2.4001 (2.3850)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0026  max mem: 3719\n",
            "Epoch: [88]  [230/295]  eta: 0:00:18  lr: 0.000192  min_lr: 0.000192  loss: 2.4284 (2.3885)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0018  max mem: 3719\n",
            "Epoch: [88]  [240/295]  eta: 0:00:15  lr: 0.000191  min_lr: 0.000191  loss: 2.5257 (2.3945)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0021  max mem: 3719\n",
            "Epoch: [88]  [250/295]  eta: 0:00:12  lr: 0.000190  min_lr: 0.000190  loss: 2.5257 (2.3925)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0027  max mem: 3719\n",
            "Epoch: [88]  [260/295]  eta: 0:00:09  lr: 0.000188  min_lr: 0.000188  loss: 2.4488 (2.3958)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0022  max mem: 3719\n",
            "Epoch: [88]  [270/295]  eta: 0:00:06  lr: 0.000187  min_lr: 0.000187  loss: 2.4716 (2.4005)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0019  max mem: 3719\n",
            "Epoch: [88]  [280/295]  eta: 0:00:04  lr: 0.000186  min_lr: 0.000186  loss: 2.5037 (2.4035)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0014  max mem: 3719\n",
            "Epoch: [88]  [290/295]  eta: 0:00:01  lr: 0.000185  min_lr: 0.000185  loss: 2.5388 (2.4086)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0007  max mem: 3719\n",
            "Epoch: [88]  [294/295]  eta: 0:00:00  lr: 0.000185  min_lr: 0.000185  loss: 2.5391 (2.4095)  weight_decay: 0.0500 (0.0500)  time: 0.2195  data: 0.0002  max mem: 3719\n",
            "Epoch: [88] Total time: 0:01:21 (0.2748 s / it)\n",
            "Averaged stats: lr: 0.000185  min_lr: 0.000185  loss: 2.5391 (2.4095)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:39  loss: 0.5719 (0.5719)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.6808  data: 2.5192  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.5365 (0.5585)  acc1: 91.6667 (89.9621)  acc5: 100.0000 (98.4849)  time: 0.4148  data: 0.2750  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.5300 (0.5586)  acc1: 91.6667 (90.1786)  acc5: 100.0000 (98.8095)  time: 0.2003  data: 0.0435  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 0.6562 (0.7388)  acc1: 87.5000 (82.1237)  acc5: 97.9167 (98.4543)  time: 0.1939  data: 0.0224  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.8119 (0.7355)  acc1: 77.0833 (81.9106)  acc5: 97.9167 (98.4248)  time: 0.1537  data: 0.0054  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7272 (0.7235)  acc1: 81.2500 (82.2712)  acc5: 100.0000 (98.4477)  time: 0.1275  data: 0.0033  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7056 (0.7330)  acc1: 83.3333 (81.5232)  acc5: 97.9167 (98.3607)  time: 0.1239  data: 0.0039  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8875 (0.7609)  acc1: 75.0000 (80.4577)  acc5: 97.9167 (98.0927)  time: 0.1220  data: 0.0024  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6609 (0.7347)  acc1: 83.3333 (81.5072)  acc5: 97.9167 (98.1739)  time: 0.1188  data: 0.0007  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6609 (0.7353)  acc1: 83.3333 (81.4777)  acc5: 97.9167 (98.1401)  time: 0.1170  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1843 s / it)\n",
            "* Acc@1 81.478 Acc@5 98.140 loss 0.735\n",
            "Accuracy of the model on the 3925 test images: 81.5%\n",
            "Max accuracy: 82.60%\n",
            "Test:  [ 0/82]  eta: 0:02:48  loss: 1.6365 (1.6365)  acc1: 41.6667 (41.6667)  acc5: 93.7500 (93.7500)  time: 2.0585  data: 1.8896  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 1.8714 (1.9766)  acc1: 31.2500 (30.1136)  acc5: 97.9167 (96.5909)  time: 0.2992  data: 0.1741  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.3245 (2.2226)  acc1: 27.0833 (26.3889)  acc5: 95.8333 (95.7341)  time: 0.1294  data: 0.0027  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.8065 (2.7816)  acc1: 16.6667 (20.2285)  acc5: 89.5833 (82.7285)  time: 0.1545  data: 0.0182  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.8607 (2.8196)  acc1: 18.7500 (21.3923)  acc5: 77.0833 (82.4187)  time: 0.1733  data: 0.0354  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.0657 (3.0842)  acc1: 10.4167 (18.5866)  acc5: 70.8333 (76.5523)  time: 0.1690  data: 0.0196  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.0585 (3.1409)  acc1: 6.2500 (16.7691)  acc5: 47.9167 (75.0342)  time: 0.1544  data: 0.0023  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.9186 (3.0386)  acc1: 8.3333 (20.1878)  acc5: 79.1667 (74.7359)  time: 0.1362  data: 0.0015  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9494 (2.7544)  acc1: 68.7500 (27.3405)  acc5: 97.9167 (77.6235)  time: 0.1244  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9494 (2.7325)  acc1: 70.8333 (27.8471)  acc5: 97.9167 (77.7325)  time: 0.1229  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1732 s / it)\n",
            "* Acc@1 27.847 Acc@5 77.732 loss 2.732\n",
            "Accuracy of the model EMA on 3925 test images: 27.8%\n",
            "Max EMA accuracy: 27.85%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [89]  [  0/295]  eta: 0:09:25  lr: 0.000185  min_lr: 0.000185  loss: 2.3580 (2.3580)  weight_decay: 0.0500 (0.0500)  time: 1.9164  data: 1.5133  max mem: 3719\n",
            "Epoch: [89]  [ 10/295]  eta: 0:02:01  lr: 0.000184  min_lr: 0.000184  loss: 2.3580 (2.3022)  weight_decay: 0.0500 (0.0500)  time: 0.4257  data: 0.1421  max mem: 3719\n",
            "Epoch: [89]  [ 20/295]  eta: 0:01:36  lr: 0.000182  min_lr: 0.000182  loss: 2.5027 (2.4243)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0030  max mem: 3719\n",
            "Epoch: [89]  [ 30/295]  eta: 0:01:25  lr: 0.000182  min_lr: 0.000182  loss: 2.5586 (2.4553)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0013  max mem: 3719\n",
            "Epoch: [89]  [ 40/295]  eta: 0:01:19  lr: 0.000180  min_lr: 0.000180  loss: 2.4415 (2.4252)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0013  max mem: 3719\n",
            "Epoch: [89]  [ 50/295]  eta: 0:01:13  lr: 0.000179  min_lr: 0.000179  loss: 2.3057 (2.3986)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0014  max mem: 3719\n",
            "Epoch: [89]  [ 60/295]  eta: 0:01:09  lr: 0.000178  min_lr: 0.000178  loss: 2.3057 (2.3999)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0015  max mem: 3719\n",
            "Epoch: [89]  [ 70/295]  eta: 0:01:05  lr: 0.000177  min_lr: 0.000177  loss: 2.3057 (2.3710)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0011  max mem: 3719\n",
            "Epoch: [89]  [ 80/295]  eta: 0:01:01  lr: 0.000176  min_lr: 0.000176  loss: 2.3280 (2.3902)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0016  max mem: 3719\n",
            "Epoch: [89]  [ 90/295]  eta: 0:00:58  lr: 0.000175  min_lr: 0.000175  loss: 2.4840 (2.3875)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0017  max mem: 3719\n",
            "Epoch: [89]  [100/295]  eta: 0:00:55  lr: 0.000174  min_lr: 0.000174  loss: 2.4452 (2.3915)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0011  max mem: 3719\n",
            "Epoch: [89]  [110/295]  eta: 0:00:52  lr: 0.000173  min_lr: 0.000173  loss: 2.3600 (2.3794)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0018  max mem: 3719\n",
            "Epoch: [89]  [120/295]  eta: 0:00:49  lr: 0.000171  min_lr: 0.000171  loss: 2.2699 (2.3778)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0022  max mem: 3719\n",
            "Epoch: [89]  [130/295]  eta: 0:00:46  lr: 0.000171  min_lr: 0.000171  loss: 2.2783 (2.3715)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0013  max mem: 3719\n",
            "Epoch: [89]  [140/295]  eta: 0:00:43  lr: 0.000169  min_lr: 0.000169  loss: 2.3653 (2.3772)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0005  max mem: 3719\n",
            "Epoch: [89]  [150/295]  eta: 0:00:40  lr: 0.000168  min_lr: 0.000168  loss: 2.4859 (2.3757)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0015  max mem: 3719\n",
            "Epoch: [89]  [160/295]  eta: 0:00:37  lr: 0.000167  min_lr: 0.000167  loss: 2.4648 (2.3824)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0021  max mem: 3719\n",
            "Epoch: [89]  [170/295]  eta: 0:00:34  lr: 0.000166  min_lr: 0.000166  loss: 2.4067 (2.3741)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0025  max mem: 3719\n",
            "Epoch: [89]  [180/295]  eta: 0:00:31  lr: 0.000165  min_lr: 0.000165  loss: 2.3741 (2.3792)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0034  max mem: 3719\n",
            "Epoch: [89]  [190/295]  eta: 0:00:28  lr: 0.000164  min_lr: 0.000164  loss: 2.3235 (2.3758)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0032  max mem: 3719\n",
            "Epoch: [89]  [200/295]  eta: 0:00:26  lr: 0.000163  min_lr: 0.000163  loss: 2.2204 (2.3709)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0019  max mem: 3719\n",
            "Epoch: [89]  [210/295]  eta: 0:00:23  lr: 0.000162  min_lr: 0.000162  loss: 2.2646 (2.3727)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0012  max mem: 3719\n",
            "Epoch: [89]  [220/295]  eta: 0:00:20  lr: 0.000161  min_lr: 0.000161  loss: 2.5021 (2.3748)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0011  max mem: 3719\n",
            "Epoch: [89]  [230/295]  eta: 0:00:17  lr: 0.000160  min_lr: 0.000160  loss: 2.3763 (2.3712)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0011  max mem: 3719\n",
            "Epoch: [89]  [240/295]  eta: 0:00:15  lr: 0.000159  min_lr: 0.000159  loss: 2.4630 (2.3733)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0018  max mem: 3719\n",
            "Epoch: [89]  [250/295]  eta: 0:00:12  lr: 0.000158  min_lr: 0.000158  loss: 2.4312 (2.3681)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0017  max mem: 3719\n",
            "Epoch: [89]  [260/295]  eta: 0:00:09  lr: 0.000157  min_lr: 0.000157  loss: 2.3044 (2.3685)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0010  max mem: 3719\n",
            "Epoch: [89]  [270/295]  eta: 0:00:06  lr: 0.000156  min_lr: 0.000156  loss: 2.3928 (2.3720)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0016  max mem: 3719\n",
            "Epoch: [89]  [280/295]  eta: 0:00:04  lr: 0.000154  min_lr: 0.000154  loss: 2.5007 (2.3760)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0015  max mem: 3719\n",
            "Epoch: [89]  [290/295]  eta: 0:00:01  lr: 0.000154  min_lr: 0.000154  loss: 2.4474 (2.3699)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0005  max mem: 3719\n",
            "Epoch: [89]  [294/295]  eta: 0:00:00  lr: 0.000154  min_lr: 0.000154  loss: 2.4474 (2.3705)  weight_decay: 0.0500 (0.0500)  time: 0.2223  data: 0.0001  max mem: 3719\n",
            "Epoch: [89] Total time: 0:01:19 (0.2699 s / it)\n",
            "Averaged stats: lr: 0.000154  min_lr: 0.000154  loss: 2.4474 (2.3705)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:31  loss: 0.5304 (0.5304)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 1.8527  data: 1.6776  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.5044 (0.5085)  acc1: 91.6667 (91.2879)  acc5: 97.9167 (98.4849)  time: 0.2829  data: 0.1551  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.4975 (0.5142)  acc1: 91.6667 (91.2698)  acc5: 100.0000 (98.5119)  time: 0.1247  data: 0.0026  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6200 (0.6856)  acc1: 87.5000 (83.9382)  acc5: 97.9167 (98.3871)  time: 0.1266  data: 0.0024  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7466 (0.6834)  acc1: 83.3333 (84.0447)  acc5: 97.9167 (98.5772)  time: 0.1278  data: 0.0031  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7249 (0.6920)  acc1: 83.3333 (83.6601)  acc5: 100.0000 (98.6111)  time: 0.1239  data: 0.0025  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7286 (0.7032)  acc1: 81.2500 (83.0601)  acc5: 100.0000 (98.3948)  time: 0.1267  data: 0.0031  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8779 (0.7308)  acc1: 77.0833 (81.9836)  acc5: 95.8333 (98.0634)  time: 0.1300  data: 0.0037  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7377 (0.7155)  acc1: 83.3333 (82.6389)  acc5: 95.8333 (98.0195)  time: 0.1233  data: 0.0013  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7377 (0.7180)  acc1: 83.3333 (82.5987)  acc5: 95.8333 (97.9873)  time: 0.1205  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1539 s / it)\n",
            "* Acc@1 82.599 Acc@5 97.987 loss 0.718\n",
            "Accuracy of the model on the 3925 test images: 82.6%\n",
            "Max accuracy: 82.60%\n",
            "Test:  [ 0/82]  eta: 0:03:03  loss: 1.6009 (1.6009)  acc1: 41.6667 (41.6667)  acc5: 93.7500 (93.7500)  time: 2.2374  data: 2.0581  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 1.8363 (1.9440)  acc1: 31.2500 (31.2500)  acc5: 97.9167 (96.7803)  time: 0.3160  data: 0.1893  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.2921 (2.1932)  acc1: 27.0833 (27.1825)  acc5: 95.8333 (95.8333)  time: 0.1232  data: 0.0024  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.7723 (2.7520)  acc1: 18.7500 (20.8333)  acc5: 89.5833 (82.9301)  time: 0.1222  data: 0.0029  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.8141 (2.7874)  acc1: 18.7500 (22.0020)  acc5: 77.0833 (82.6728)  time: 0.1235  data: 0.0049  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.0256 (3.0528)  acc1: 12.5000 (19.1176)  acc5: 70.8333 (76.7565)  time: 0.1230  data: 0.0053  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.0424 (3.1072)  acc1: 6.2500 (17.2814)  acc5: 47.9167 (75.2049)  time: 0.1217  data: 0.0034  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.8762 (3.0060)  acc1: 8.3333 (20.7160)  acc5: 79.1667 (75.0000)  time: 0.1205  data: 0.0014  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9413 (2.7250)  acc1: 68.7500 (27.8292)  acc5: 97.9167 (77.8549)  time: 0.1185  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9413 (2.7034)  acc1: 70.8333 (28.2803)  acc5: 97.9167 (77.9618)  time: 0.1172  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1544 s / it)\n",
            "* Acc@1 28.280 Acc@5 77.962 loss 2.703\n",
            "Accuracy of the model EMA on 3925 test images: 28.3%\n",
            "Max EMA accuracy: 28.28%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [90]  [  0/295]  eta: 0:12:35  lr: 0.000153  min_lr: 0.000153  loss: 2.3762 (2.3762)  weight_decay: 0.0500 (0.0500)  time: 2.5595  data: 2.1392  max mem: 3719\n",
            "Epoch: [90]  [ 10/295]  eta: 0:02:16  lr: 0.000152  min_lr: 0.000152  loss: 2.3762 (2.3835)  weight_decay: 0.0500 (0.0500)  time: 0.4773  data: 0.1959  max mem: 3719\n",
            "Epoch: [90]  [ 20/295]  eta: 0:01:43  lr: 0.000151  min_lr: 0.000151  loss: 2.3221 (2.3818)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0009  max mem: 3719\n",
            "Epoch: [90]  [ 30/295]  eta: 0:01:29  lr: 0.000150  min_lr: 0.000150  loss: 2.3221 (2.3615)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0006  max mem: 3719\n",
            "Epoch: [90]  [ 40/295]  eta: 0:01:21  lr: 0.000149  min_lr: 0.000149  loss: 2.4430 (2.4073)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0007  max mem: 3719\n",
            "Epoch: [90]  [ 50/295]  eta: 0:01:16  lr: 0.000148  min_lr: 0.000148  loss: 2.4430 (2.3785)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0007  max mem: 3719\n",
            "Epoch: [90]  [ 60/295]  eta: 0:01:11  lr: 0.000147  min_lr: 0.000147  loss: 2.2020 (2.3780)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0009  max mem: 3719\n",
            "Epoch: [90]  [ 70/295]  eta: 0:01:07  lr: 0.000146  min_lr: 0.000146  loss: 2.5000 (2.3868)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0008  max mem: 3719\n",
            "Epoch: [90]  [ 80/295]  eta: 0:01:03  lr: 0.000145  min_lr: 0.000145  loss: 2.4450 (2.3865)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0006  max mem: 3719\n",
            "Epoch: [90]  [ 90/295]  eta: 0:00:59  lr: 0.000144  min_lr: 0.000144  loss: 2.4450 (2.3836)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0009  max mem: 3719\n",
            "Epoch: [90]  [100/295]  eta: 0:00:56  lr: 0.000143  min_lr: 0.000143  loss: 2.4471 (2.3793)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0011  max mem: 3719\n",
            "Epoch: [90]  [110/295]  eta: 0:00:53  lr: 0.000142  min_lr: 0.000142  loss: 2.4123 (2.3828)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0010  max mem: 3719\n",
            "Epoch: [90]  [120/295]  eta: 0:00:50  lr: 0.000141  min_lr: 0.000141  loss: 2.3579 (2.3745)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0019  max mem: 3719\n",
            "Epoch: [90]  [130/295]  eta: 0:00:46  lr: 0.000140  min_lr: 0.000140  loss: 2.2554 (2.3724)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0014  max mem: 3719\n",
            "Epoch: [90]  [140/295]  eta: 0:00:43  lr: 0.000139  min_lr: 0.000139  loss: 2.3129 (2.3702)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0009  max mem: 3719\n",
            "Epoch: [90]  [150/295]  eta: 0:00:40  lr: 0.000138  min_lr: 0.000138  loss: 2.3156 (2.3690)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0009  max mem: 3719\n",
            "Epoch: [90]  [160/295]  eta: 0:00:37  lr: 0.000137  min_lr: 0.000137  loss: 2.4570 (2.3727)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0007  max mem: 3719\n",
            "Epoch: [90]  [170/295]  eta: 0:00:34  lr: 0.000136  min_lr: 0.000136  loss: 2.3958 (2.3680)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0010  max mem: 3719\n",
            "Epoch: [90]  [180/295]  eta: 0:00:32  lr: 0.000135  min_lr: 0.000135  loss: 2.3573 (2.3735)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0035  max mem: 3719\n",
            "Epoch: [90]  [190/295]  eta: 0:00:29  lr: 0.000134  min_lr: 0.000134  loss: 2.5047 (2.3780)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0040  max mem: 3719\n",
            "Epoch: [90]  [200/295]  eta: 0:00:26  lr: 0.000133  min_lr: 0.000133  loss: 2.4515 (2.3754)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0018  max mem: 3719\n",
            "Epoch: [90]  [210/295]  eta: 0:00:23  lr: 0.000133  min_lr: 0.000133  loss: 2.4515 (2.3838)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0013  max mem: 3719\n",
            "Epoch: [90]  [220/295]  eta: 0:00:20  lr: 0.000131  min_lr: 0.000131  loss: 2.5402 (2.3866)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0010  max mem: 3719\n",
            "Epoch: [90]  [230/295]  eta: 0:00:17  lr: 0.000131  min_lr: 0.000131  loss: 2.5030 (2.3876)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0014  max mem: 3719\n",
            "Epoch: [90]  [240/295]  eta: 0:00:15  lr: 0.000129  min_lr: 0.000129  loss: 2.2859 (2.3788)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0024  max mem: 3719\n",
            "Epoch: [90]  [250/295]  eta: 0:00:12  lr: 0.000129  min_lr: 0.000129  loss: 2.3427 (2.3883)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0022  max mem: 3719\n",
            "Epoch: [90]  [260/295]  eta: 0:00:09  lr: 0.000128  min_lr: 0.000128  loss: 2.5016 (2.3907)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0015  max mem: 3719\n",
            "Epoch: [90]  [270/295]  eta: 0:00:06  lr: 0.000127  min_lr: 0.000127  loss: 2.3717 (2.3881)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0012  max mem: 3719\n",
            "Epoch: [90]  [280/295]  eta: 0:00:04  lr: 0.000126  min_lr: 0.000126  loss: 2.2888 (2.3836)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0007  max mem: 3719\n",
            "Epoch: [90]  [290/295]  eta: 0:00:01  lr: 0.000125  min_lr: 0.000125  loss: 2.3618 (2.3811)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0003  max mem: 3719\n",
            "Epoch: [90]  [294/295]  eta: 0:00:00  lr: 0.000125  min_lr: 0.000125  loss: 2.3029 (2.3808)  weight_decay: 0.0500 (0.0500)  time: 0.2195  data: 0.0001  max mem: 3719\n",
            "Epoch: [90] Total time: 0:01:20 (0.2716 s / it)\n",
            "Averaged stats: lr: 0.000125  min_lr: 0.000125  loss: 2.3029 (2.3808)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:32  loss: 0.5636 (0.5636)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 2.5970  data: 2.4333  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.5087 (0.5141)  acc1: 91.6667 (91.2879)  acc5: 97.9167 (98.4849)  time: 0.3723  data: 0.2481  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.4831 (0.5182)  acc1: 91.6667 (91.0714)  acc5: 100.0000 (98.5119)  time: 0.1522  data: 0.0161  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.6415 (0.7093)  acc1: 87.5000 (83.5349)  acc5: 97.9167 (98.3199)  time: 0.1475  data: 0.0015  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.6792 (0.6892)  acc1: 83.3333 (83.9939)  acc5: 97.9167 (98.4756)  time: 0.1481  data: 0.0041  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6790 (0.6941)  acc1: 83.3333 (83.7827)  acc5: 100.0000 (98.4886)  time: 0.1591  data: 0.0191  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7599 (0.7033)  acc1: 83.3333 (83.4358)  acc5: 97.9167 (98.3948)  time: 0.1631  data: 0.0332  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.7865 (0.7230)  acc1: 81.2500 (82.6585)  acc5: 97.9167 (98.1221)  time: 0.1619  data: 0.0321  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6918 (0.7082)  acc1: 85.4167 (83.3076)  acc5: 97.9167 (98.0967)  time: 0.1396  data: 0.0150  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6918 (0.7105)  acc1: 85.4167 (83.2611)  acc5: 97.9167 (98.0637)  time: 0.1362  data: 0.0150  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1877 s / it)\n",
            "* Acc@1 83.261 Acc@5 98.064 loss 0.711\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.26%\n",
            "Test:  [ 0/82]  eta: 0:03:07  loss: 1.5656 (1.5656)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 2.2890  data: 2.1089  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 1.8012 (1.9116)  acc1: 33.3333 (32.5758)  acc5: 97.9167 (96.7803)  time: 0.3225  data: 0.1933  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 2.2608 (2.1647)  acc1: 27.0833 (28.2738)  acc5: 95.8333 (95.7341)  time: 0.1254  data: 0.0018  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.7385 (2.7232)  acc1: 18.7500 (21.6398)  acc5: 89.5833 (82.9301)  time: 0.1248  data: 0.0035  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.7664 (2.7555)  acc1: 18.7500 (22.6626)  acc5: 77.0833 (82.8760)  time: 0.1241  data: 0.0037  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.9898 (3.0216)  acc1: 10.4167 (19.6487)  acc5: 70.8333 (76.9608)  time: 0.1247  data: 0.0045  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.0241 (3.0742)  acc1: 6.2500 (17.7937)  acc5: 47.9167 (75.4440)  time: 0.1251  data: 0.0063  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.8382 (2.9741)  acc1: 8.3333 (21.1854)  acc5: 79.1667 (75.2054)  time: 0.1225  data: 0.0030  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9328 (2.6962)  acc1: 70.8333 (28.2665)  acc5: 97.9167 (78.0350)  time: 0.1202  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9328 (2.6748)  acc1: 70.8333 (28.7134)  acc5: 97.9167 (78.1401)  time: 0.1182  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1575 s / it)\n",
            "* Acc@1 28.713 Acc@5 78.140 loss 2.675\n",
            "Accuracy of the model EMA on 3925 test images: 28.7%\n",
            "Max EMA accuracy: 28.71%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [91]  [  0/295]  eta: 0:13:32  lr: 0.000125  min_lr: 0.000125  loss: 2.5793 (2.5793)  weight_decay: 0.0500 (0.0500)  time: 2.7547  data: 2.2144  max mem: 3719\n",
            "Epoch: [91]  [ 10/295]  eta: 0:02:22  lr: 0.000124  min_lr: 0.000124  loss: 2.3245 (2.2775)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.2032  max mem: 3719\n",
            "Epoch: [91]  [ 20/295]  eta: 0:01:46  lr: 0.000123  min_lr: 0.000123  loss: 2.3245 (2.3491)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0014  max mem: 3719\n",
            "Epoch: [91]  [ 30/295]  eta: 0:01:31  lr: 0.000122  min_lr: 0.000122  loss: 2.4403 (2.3531)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0011  max mem: 3719\n",
            "Epoch: [91]  [ 40/295]  eta: 0:01:23  lr: 0.000121  min_lr: 0.000121  loss: 2.4813 (2.3622)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0014  max mem: 3719\n",
            "Epoch: [91]  [ 50/295]  eta: 0:01:17  lr: 0.000120  min_lr: 0.000120  loss: 2.4813 (2.3751)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0026  max mem: 3719\n",
            "Epoch: [91]  [ 60/295]  eta: 0:01:12  lr: 0.000119  min_lr: 0.000119  loss: 2.4494 (2.3745)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0020  max mem: 3719\n",
            "Epoch: [91]  [ 70/295]  eta: 0:01:08  lr: 0.000118  min_lr: 0.000118  loss: 2.4697 (2.3810)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0015  max mem: 3719\n",
            "Epoch: [91]  [ 80/295]  eta: 0:01:04  lr: 0.000117  min_lr: 0.000117  loss: 2.4419 (2.3809)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0023  max mem: 3719\n",
            "Epoch: [91]  [ 90/295]  eta: 0:01:00  lr: 0.000117  min_lr: 0.000117  loss: 2.3865 (2.3847)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0026  max mem: 3719\n",
            "Epoch: [91]  [100/295]  eta: 0:00:56  lr: 0.000115  min_lr: 0.000115  loss: 2.3865 (2.3763)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0022  max mem: 3719\n",
            "Epoch: [91]  [110/295]  eta: 0:00:53  lr: 0.000115  min_lr: 0.000115  loss: 2.4434 (2.3776)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0028  max mem: 3719\n",
            "Epoch: [91]  [120/295]  eta: 0:00:50  lr: 0.000114  min_lr: 0.000114  loss: 2.3658 (2.3734)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0037  max mem: 3719\n",
            "Epoch: [91]  [130/295]  eta: 0:00:47  lr: 0.000113  min_lr: 0.000113  loss: 2.3658 (2.3751)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0024  max mem: 3719\n",
            "Epoch: [91]  [140/295]  eta: 0:00:44  lr: 0.000112  min_lr: 0.000112  loss: 2.2516 (2.3599)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0023  max mem: 3719\n",
            "Epoch: [91]  [150/295]  eta: 0:00:41  lr: 0.000111  min_lr: 0.000111  loss: 2.2567 (2.3645)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0021  max mem: 3719\n",
            "Epoch: [91]  [160/295]  eta: 0:00:38  lr: 0.000110  min_lr: 0.000110  loss: 2.4369 (2.3645)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0019  max mem: 3719\n",
            "Epoch: [91]  [170/295]  eta: 0:00:35  lr: 0.000109  min_lr: 0.000109  loss: 2.3219 (2.3618)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0026  max mem: 3719\n",
            "Epoch: [91]  [180/295]  eta: 0:00:32  lr: 0.000108  min_lr: 0.000108  loss: 2.3219 (2.3643)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0043  max mem: 3719\n",
            "Epoch: [91]  [190/295]  eta: 0:00:29  lr: 0.000108  min_lr: 0.000108  loss: 2.5303 (2.3668)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0032  max mem: 3719\n",
            "Epoch: [91]  [200/295]  eta: 0:00:26  lr: 0.000107  min_lr: 0.000107  loss: 2.4175 (2.3665)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0013  max mem: 3719\n",
            "Epoch: [91]  [210/295]  eta: 0:00:23  lr: 0.000106  min_lr: 0.000106  loss: 2.4458 (2.3697)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0013  max mem: 3719\n",
            "Epoch: [91]  [220/295]  eta: 0:00:20  lr: 0.000105  min_lr: 0.000105  loss: 2.5021 (2.3703)  weight_decay: 0.0500 (0.0500)  time: 0.2579  data: 0.0010  max mem: 3719\n",
            "Epoch: [91]  [230/295]  eta: 0:00:17  lr: 0.000104  min_lr: 0.000104  loss: 2.4819 (2.3772)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0014  max mem: 3719\n",
            "Epoch: [91]  [240/295]  eta: 0:00:15  lr: 0.000103  min_lr: 0.000103  loss: 2.4375 (2.3752)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0021  max mem: 3719\n",
            "Epoch: [91]  [250/295]  eta: 0:00:12  lr: 0.000103  min_lr: 0.000103  loss: 2.4272 (2.3796)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0036  max mem: 3719\n",
            "Epoch: [91]  [260/295]  eta: 0:00:09  lr: 0.000102  min_lr: 0.000102  loss: 2.4272 (2.3781)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0034  max mem: 3719\n",
            "Epoch: [91]  [270/295]  eta: 0:00:06  lr: 0.000101  min_lr: 0.000101  loss: 2.2788 (2.3730)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0016  max mem: 3719\n",
            "Epoch: [91]  [280/295]  eta: 0:00:04  lr: 0.000100  min_lr: 0.000100  loss: 2.2788 (2.3707)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0008  max mem: 3719\n",
            "Epoch: [91]  [290/295]  eta: 0:00:01  lr: 0.000099  min_lr: 0.000099  loss: 2.4333 (2.3692)  weight_decay: 0.0500 (0.0500)  time: 0.2570  data: 0.0003  max mem: 3719\n",
            "Epoch: [91]  [294/295]  eta: 0:00:00  lr: 0.000099  min_lr: 0.000099  loss: 2.4439 (2.3696)  weight_decay: 0.0500 (0.0500)  time: 0.2194  data: 0.0002  max mem: 3719\n",
            "Epoch: [91] Total time: 0:01:20 (0.2727 s / it)\n",
            "Averaged stats: lr: 0.000099  min_lr: 0.000099  loss: 2.4439 (2.3696)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:22  loss: 0.5732 (0.5732)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 3.2025  data: 3.0293  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 0.5128 (0.5349)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (97.9167)  time: 0.4091  data: 0.2775  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.5026 (0.5402)  acc1: 91.6667 (90.2778)  acc5: 97.9167 (98.2143)  time: 0.1256  data: 0.0040  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.6478 (0.7017)  acc1: 85.4167 (83.1989)  acc5: 100.0000 (98.3199)  time: 0.1237  data: 0.0042  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.6952 (0.6833)  acc1: 83.3333 (83.8923)  acc5: 100.0000 (98.4756)  time: 0.1248  data: 0.0037  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6714 (0.6827)  acc1: 83.3333 (83.8235)  acc5: 100.0000 (98.5703)  time: 0.1237  data: 0.0044  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7305 (0.6879)  acc1: 83.3333 (83.5383)  acc5: 100.0000 (98.3607)  time: 0.1231  data: 0.0045  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.7992 (0.7148)  acc1: 79.1667 (82.4531)  acc5: 97.9167 (98.0927)  time: 0.1212  data: 0.0032  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7206 (0.7004)  acc1: 83.3333 (83.0247)  acc5: 97.9167 (98.1481)  time: 0.1191  data: 0.0008  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7206 (0.7024)  acc1: 83.3333 (82.9809)  acc5: 97.9167 (98.1147)  time: 0.1168  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1661 s / it)\n",
            "* Acc@1 82.981 Acc@5 98.115 loss 0.702\n",
            "Accuracy of the model on the 3925 test images: 83.0%\n",
            "Max accuracy: 83.26%\n",
            "Test:  [ 0/82]  eta: 0:03:47  loss: 1.5303 (1.5303)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 2.7750  data: 2.6098  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 1.7665 (1.8789)  acc1: 35.4167 (32.9545)  acc5: 97.9167 (96.7803)  time: 0.4005  data: 0.2659  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.2287 (2.1362)  acc1: 27.0833 (28.4722)  acc5: 95.8333 (95.7341)  time: 0.1603  data: 0.0289  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 2.7038 (2.6944)  acc1: 18.7500 (21.8414)  acc5: 89.5833 (82.9301)  time: 0.1449  data: 0.0156  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.7186 (2.7235)  acc1: 18.7500 (22.9167)  acc5: 77.0833 (82.9268)  time: 0.1352  data: 0.0101  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 2.9526 (2.9902)  acc1: 10.4167 (19.8529)  acc5: 70.8333 (77.0016)  time: 0.1314  data: 0.0097  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.0050 (3.0409)  acc1: 8.3333 (18.1011)  acc5: 47.9167 (75.5123)  time: 0.1252  data: 0.0038  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.7995 (2.9421)  acc1: 10.4167 (21.5376)  acc5: 79.1667 (75.3228)  time: 0.1227  data: 0.0019  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9249 (2.6673)  acc1: 70.8333 (28.6008)  acc5: 97.9167 (78.1379)  time: 0.1203  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9249 (2.6462)  acc1: 70.8333 (29.0446)  acc5: 97.9167 (78.2420)  time: 0.1187  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1720 s / it)\n",
            "* Acc@1 29.045 Acc@5 78.242 loss 2.646\n",
            "Accuracy of the model EMA on 3925 test images: 29.0%\n",
            "Max EMA accuracy: 29.04%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [92]  [  0/295]  eta: 0:13:13  lr: 0.000099  min_lr: 0.000099  loss: 2.5870 (2.5870)  weight_decay: 0.0500 (0.0500)  time: 2.6891  data: 2.1863  max mem: 3719\n",
            "Epoch: [92]  [ 10/295]  eta: 0:02:30  lr: 0.000098  min_lr: 0.000098  loss: 2.5506 (2.4050)  weight_decay: 0.0500 (0.0500)  time: 0.5298  data: 0.2028  max mem: 3719\n",
            "Epoch: [92]  [ 20/295]  eta: 0:01:53  lr: 0.000097  min_lr: 0.000097  loss: 2.4155 (2.3387)  weight_decay: 0.0500 (0.0500)  time: 0.2985  data: 0.0039  max mem: 3719\n",
            "Epoch: [92]  [ 30/295]  eta: 0:01:36  lr: 0.000097  min_lr: 0.000097  loss: 2.4155 (2.3695)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0022  max mem: 3719\n",
            "Epoch: [92]  [ 40/295]  eta: 0:01:27  lr: 0.000096  min_lr: 0.000096  loss: 2.5067 (2.3943)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0017  max mem: 3719\n",
            "Epoch: [92]  [ 50/295]  eta: 0:01:20  lr: 0.000095  min_lr: 0.000095  loss: 2.4773 (2.3964)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0031  max mem: 3719\n",
            "Epoch: [92]  [ 60/295]  eta: 0:01:14  lr: 0.000094  min_lr: 0.000094  loss: 2.3550 (2.4004)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0028  max mem: 3719\n",
            "Epoch: [92]  [ 70/295]  eta: 0:01:10  lr: 0.000093  min_lr: 0.000093  loss: 2.4246 (2.4096)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0023  max mem: 3719\n",
            "Epoch: [92]  [ 80/295]  eta: 0:01:05  lr: 0.000092  min_lr: 0.000092  loss: 2.3623 (2.4089)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0034  max mem: 3719\n",
            "Epoch: [92]  [ 90/295]  eta: 0:01:01  lr: 0.000092  min_lr: 0.000092  loss: 2.4845 (2.4275)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0030  max mem: 3719\n",
            "Epoch: [92]  [100/295]  eta: 0:00:58  lr: 0.000091  min_lr: 0.000091  loss: 2.5128 (2.4333)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0019  max mem: 3719\n",
            "Epoch: [92]  [110/295]  eta: 0:00:54  lr: 0.000090  min_lr: 0.000090  loss: 2.4209 (2.4224)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0023  max mem: 3719\n",
            "Epoch: [92]  [120/295]  eta: 0:00:51  lr: 0.000089  min_lr: 0.000089  loss: 2.2896 (2.4188)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0031  max mem: 3719\n",
            "Epoch: [92]  [130/295]  eta: 0:00:47  lr: 0.000089  min_lr: 0.000089  loss: 2.2939 (2.4065)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0032  max mem: 3719\n",
            "Epoch: [92]  [140/295]  eta: 0:00:44  lr: 0.000088  min_lr: 0.000088  loss: 2.2580 (2.3945)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0035  max mem: 3719\n",
            "Epoch: [92]  [150/295]  eta: 0:00:41  lr: 0.000087  min_lr: 0.000087  loss: 2.3487 (2.3987)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0025  max mem: 3719\n",
            "Epoch: [92]  [160/295]  eta: 0:00:38  lr: 0.000086  min_lr: 0.000086  loss: 2.4580 (2.3993)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0013  max mem: 3719\n",
            "Epoch: [92]  [170/295]  eta: 0:00:35  lr: 0.000085  min_lr: 0.000085  loss: 2.3508 (2.3926)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0023  max mem: 3719\n",
            "Epoch: [92]  [180/295]  eta: 0:00:32  lr: 0.000084  min_lr: 0.000084  loss: 2.3338 (2.3923)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0025  max mem: 3719\n",
            "Epoch: [92]  [190/295]  eta: 0:00:29  lr: 0.000084  min_lr: 0.000084  loss: 2.3490 (2.3902)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0034  max mem: 3719\n",
            "Epoch: [92]  [200/295]  eta: 0:00:26  lr: 0.000083  min_lr: 0.000083  loss: 2.3202 (2.3854)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0043  max mem: 3719\n",
            "Epoch: [92]  [210/295]  eta: 0:00:23  lr: 0.000082  min_lr: 0.000082  loss: 2.3764 (2.3868)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0025  max mem: 3719\n",
            "Epoch: [92]  [220/295]  eta: 0:00:20  lr: 0.000081  min_lr: 0.000081  loss: 2.3764 (2.3875)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0013  max mem: 3719\n",
            "Epoch: [92]  [230/295]  eta: 0:00:18  lr: 0.000081  min_lr: 0.000081  loss: 2.4691 (2.3913)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0020  max mem: 3719\n",
            "Epoch: [92]  [240/295]  eta: 0:00:15  lr: 0.000080  min_lr: 0.000080  loss: 2.4330 (2.3910)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0020  max mem: 3719\n",
            "Epoch: [92]  [250/295]  eta: 0:00:12  lr: 0.000079  min_lr: 0.000079  loss: 2.4268 (2.3925)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0034  max mem: 3719\n",
            "Epoch: [92]  [260/295]  eta: 0:00:09  lr: 0.000078  min_lr: 0.000078  loss: 2.4008 (2.3880)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0041  max mem: 3719\n",
            "Epoch: [92]  [270/295]  eta: 0:00:06  lr: 0.000078  min_lr: 0.000078  loss: 2.2552 (2.3839)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0023  max mem: 3719\n",
            "Epoch: [92]  [280/295]  eta: 0:00:04  lr: 0.000077  min_lr: 0.000077  loss: 2.3649 (2.3820)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0014  max mem: 3719\n",
            "Epoch: [92]  [290/295]  eta: 0:00:01  lr: 0.000076  min_lr: 0.000076  loss: 2.3942 (2.3835)  weight_decay: 0.0500 (0.0500)  time: 0.2565  data: 0.0003  max mem: 3719\n",
            "Epoch: [92]  [294/295]  eta: 0:00:00  lr: 0.000076  min_lr: 0.000076  loss: 2.3942 (2.3820)  weight_decay: 0.0500 (0.0500)  time: 0.2186  data: 0.0003  max mem: 3719\n",
            "Epoch: [92] Total time: 0:01:20 (0.2740 s / it)\n",
            "Averaged stats: lr: 0.000076  min_lr: 0.000076  loss: 2.3942 (2.3820)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:14  loss: 0.5539 (0.5539)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.3673  data: 2.1889  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.5187 (0.5192)  acc1: 91.6667 (90.1515)  acc5: 97.9167 (98.2955)  time: 0.3844  data: 0.2387  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.5187 (0.5316)  acc1: 91.6667 (89.6825)  acc5: 100.0000 (98.5119)  time: 0.1860  data: 0.0404  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6455 (0.6931)  acc1: 87.5000 (83.1989)  acc5: 100.0000 (98.6559)  time: 0.1707  data: 0.0206  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.6771 (0.6702)  acc1: 83.3333 (84.0955)  acc5: 100.0000 (98.7297)  time: 0.1480  data: 0.0040  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6588 (0.6783)  acc1: 83.3333 (83.8235)  acc5: 100.0000 (98.7745)  time: 0.1342  data: 0.0042  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7457 (0.6873)  acc1: 81.2500 (83.3675)  acc5: 100.0000 (98.5997)  time: 0.1256  data: 0.0034  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.7917 (0.7083)  acc1: 81.2500 (82.5704)  acc5: 97.9167 (98.2981)  time: 0.1214  data: 0.0012  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6782 (0.6937)  acc1: 85.4167 (83.2819)  acc5: 97.9167 (98.2510)  time: 0.1189  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6782 (0.6963)  acc1: 85.4167 (83.2357)  acc5: 97.9167 (98.2166)  time: 0.1173  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1765 s / it)\n",
            "* Acc@1 83.236 Acc@5 98.217 loss 0.696\n",
            "Accuracy of the model on the 3925 test images: 83.2%\n",
            "Max accuracy: 83.26%\n",
            "Test:  [ 0/82]  eta: 0:02:26  loss: 1.4963 (1.4963)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 1.7918  data: 1.6187  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.7332 (1.8472)  acc1: 35.4167 (33.3333)  acc5: 97.9167 (96.7803)  time: 0.2878  data: 0.1627  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.1973 (2.1080)  acc1: 27.0833 (28.9683)  acc5: 95.8333 (96.0317)  time: 0.1298  data: 0.0098  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.6696 (2.6656)  acc1: 18.7500 (22.3790)  acc5: 91.6667 (83.0645)  time: 0.1255  data: 0.0035  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.6719 (2.6918)  acc1: 18.7500 (23.4756)  acc5: 77.0833 (83.0793)  time: 0.1343  data: 0.0038  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.9131 (2.9588)  acc1: 12.5000 (20.4248)  acc5: 70.8333 (77.1242)  time: 0.1437  data: 0.0023  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.9857 (3.0073)  acc1: 8.3333 (18.7158)  acc5: 47.9167 (75.7172)  time: 0.1432  data: 0.0014  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.7587 (2.9097)  acc1: 10.4167 (22.0657)  acc5: 79.1667 (75.5282)  time: 0.1435  data: 0.0081  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9180 (2.6381)  acc1: 70.8333 (29.1152)  acc5: 97.9167 (78.3179)  time: 0.1345  data: 0.0075  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9180 (2.6174)  acc1: 70.8333 (29.5541)  acc5: 97.9167 (78.4204)  time: 0.1340  data: 0.0074  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1609 s / it)\n",
            "* Acc@1 29.554 Acc@5 78.420 loss 2.617\n",
            "Accuracy of the model EMA on 3925 test images: 29.6%\n",
            "Max EMA accuracy: 29.55%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [93]  [  0/295]  eta: 0:07:46  lr: 0.000076  min_lr: 0.000076  loss: 2.5243 (2.5243)  weight_decay: 0.0500 (0.0500)  time: 1.5803  data: 1.2361  max mem: 3719\n",
            "Epoch: [93]  [ 10/295]  eta: 0:01:56  lr: 0.000075  min_lr: 0.000075  loss: 2.4868 (2.3620)  weight_decay: 0.0500 (0.0500)  time: 0.4071  data: 0.1140  max mem: 3719\n",
            "Epoch: [93]  [ 20/295]  eta: 0:01:32  lr: 0.000075  min_lr: 0.000075  loss: 2.5004 (2.4356)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0017  max mem: 3719\n",
            "Epoch: [93]  [ 30/295]  eta: 0:01:23  lr: 0.000074  min_lr: 0.000074  loss: 2.5225 (2.4411)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0019  max mem: 3719\n",
            "Epoch: [93]  [ 40/295]  eta: 0:01:17  lr: 0.000073  min_lr: 0.000073  loss: 2.3712 (2.4319)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0025  max mem: 3719\n",
            "Epoch: [93]  [ 50/295]  eta: 0:01:12  lr: 0.000073  min_lr: 0.000073  loss: 2.3209 (2.3954)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0029  max mem: 3719\n",
            "Epoch: [93]  [ 60/295]  eta: 0:01:08  lr: 0.000072  min_lr: 0.000072  loss: 2.2575 (2.3954)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0018  max mem: 3719\n",
            "Epoch: [93]  [ 70/295]  eta: 0:01:04  lr: 0.000071  min_lr: 0.000071  loss: 2.3218 (2.3765)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0008  max mem: 3719\n",
            "Epoch: [93]  [ 80/295]  eta: 0:01:01  lr: 0.000070  min_lr: 0.000070  loss: 2.4434 (2.3881)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0014  max mem: 3719\n",
            "Epoch: [93]  [ 90/295]  eta: 0:00:57  lr: 0.000070  min_lr: 0.000070  loss: 2.2982 (2.3787)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0018  max mem: 3719\n",
            "Epoch: [93]  [100/295]  eta: 0:00:54  lr: 0.000069  min_lr: 0.000069  loss: 2.2865 (2.3852)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0025  max mem: 3719\n",
            "Epoch: [93]  [110/295]  eta: 0:00:51  lr: 0.000068  min_lr: 0.000068  loss: 2.4438 (2.3826)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0025  max mem: 3719\n",
            "Epoch: [93]  [120/295]  eta: 0:00:48  lr: 0.000068  min_lr: 0.000068  loss: 2.4438 (2.3896)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0017  max mem: 3719\n",
            "Epoch: [93]  [130/295]  eta: 0:00:45  lr: 0.000067  min_lr: 0.000067  loss: 2.4295 (2.3815)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0018  max mem: 3719\n",
            "Epoch: [93]  [140/295]  eta: 0:00:42  lr: 0.000066  min_lr: 0.000066  loss: 2.3807 (2.3795)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0017  max mem: 3719\n",
            "Epoch: [93]  [150/295]  eta: 0:00:40  lr: 0.000066  min_lr: 0.000066  loss: 2.3176 (2.3730)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0016  max mem: 3719\n",
            "Epoch: [93]  [160/295]  eta: 0:00:37  lr: 0.000065  min_lr: 0.000065  loss: 2.3176 (2.3733)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0026  max mem: 3719\n",
            "Epoch: [93]  [170/295]  eta: 0:00:34  lr: 0.000064  min_lr: 0.000064  loss: 2.3408 (2.3690)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0031  max mem: 3719\n",
            "Epoch: [93]  [180/295]  eta: 0:00:31  lr: 0.000063  min_lr: 0.000063  loss: 2.4203 (2.3713)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0034  max mem: 3719\n",
            "Epoch: [93]  [190/295]  eta: 0:00:28  lr: 0.000063  min_lr: 0.000063  loss: 2.4229 (2.3718)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0039  max mem: 3719\n",
            "Epoch: [93]  [200/295]  eta: 0:00:26  lr: 0.000062  min_lr: 0.000062  loss: 2.3317 (2.3649)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0032  max mem: 3719\n",
            "Epoch: [93]  [210/295]  eta: 0:00:23  lr: 0.000062  min_lr: 0.000062  loss: 2.4314 (2.3740)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0023  max mem: 3719\n",
            "Epoch: [93]  [220/295]  eta: 0:00:20  lr: 0.000061  min_lr: 0.000061  loss: 2.5292 (2.3726)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0021  max mem: 3719\n",
            "Epoch: [93]  [230/295]  eta: 0:00:17  lr: 0.000060  min_lr: 0.000060  loss: 2.4703 (2.3774)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0024  max mem: 3719\n",
            "Epoch: [93]  [240/295]  eta: 0:00:15  lr: 0.000060  min_lr: 0.000060  loss: 2.4125 (2.3753)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0018  max mem: 3719\n",
            "Epoch: [93]  [250/295]  eta: 0:00:12  lr: 0.000059  min_lr: 0.000059  loss: 2.2974 (2.3694)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0008  max mem: 3719\n",
            "Epoch: [93]  [260/295]  eta: 0:00:09  lr: 0.000058  min_lr: 0.000058  loss: 2.2974 (2.3680)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0016  max mem: 3719\n",
            "Epoch: [93]  [270/295]  eta: 0:00:06  lr: 0.000058  min_lr: 0.000058  loss: 2.3567 (2.3630)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0016  max mem: 3719\n",
            "Epoch: [93]  [280/295]  eta: 0:00:04  lr: 0.000057  min_lr: 0.000057  loss: 2.4095 (2.3660)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0008  max mem: 3719\n",
            "Epoch: [93]  [290/295]  eta: 0:00:01  lr: 0.000056  min_lr: 0.000056  loss: 2.3484 (2.3606)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0006  max mem: 3719\n",
            "Epoch: [93]  [294/295]  eta: 0:00:00  lr: 0.000056  min_lr: 0.000056  loss: 2.3484 (2.3618)  weight_decay: 0.0500 (0.0500)  time: 0.2225  data: 0.0002  max mem: 3719\n",
            "Epoch: [93] Total time: 0:01:19 (0.2703 s / it)\n",
            "Averaged stats: lr: 0.000056  min_lr: 0.000056  loss: 2.3484 (2.3618)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:52  loss: 0.5459 (0.5459)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 2.1032  data: 1.9352  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.4974 (0.5168)  acc1: 91.6667 (90.3409)  acc5: 100.0000 (98.6742)  time: 0.3025  data: 0.1791  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.4986 (0.5317)  acc1: 91.6667 (89.9802)  acc5: 100.0000 (98.7103)  time: 0.1227  data: 0.0044  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6535 (0.6948)  acc1: 85.4167 (83.1317)  acc5: 97.9167 (98.5887)  time: 0.1263  data: 0.0043  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.6759 (0.6748)  acc1: 83.3333 (83.8923)  acc5: 97.9167 (98.6281)  time: 0.1284  data: 0.0057  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6628 (0.6826)  acc1: 83.3333 (83.3742)  acc5: 100.0000 (98.6520)  time: 0.1260  data: 0.0069  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7160 (0.6893)  acc1: 79.1667 (82.9577)  acc5: 100.0000 (98.5314)  time: 0.1225  data: 0.0043  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8218 (0.7111)  acc1: 77.0833 (82.1009)  acc5: 97.9167 (98.3275)  time: 0.1198  data: 0.0019  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6580 (0.6944)  acc1: 83.3333 (82.9733)  acc5: 97.9167 (98.3025)  time: 0.1187  data: 0.0006  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6580 (0.6966)  acc1: 83.3333 (82.9299)  acc5: 97.9167 (98.2675)  time: 0.1173  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1546 s / it)\n",
            "* Acc@1 82.930 Acc@5 98.268 loss 0.697\n",
            "Accuracy of the model on the 3925 test images: 82.9%\n",
            "Max accuracy: 83.26%\n",
            "Test:  [ 0/82]  eta: 0:03:17  loss: 1.4622 (1.4622)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 2.4037  data: 2.2392  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 1.6999 (1.8158)  acc1: 35.4167 (34.2803)  acc5: 97.9167 (96.7803)  time: 0.3823  data: 0.2481  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 2.1669 (2.0799)  acc1: 27.0833 (29.4643)  acc5: 95.8333 (96.1310)  time: 0.1526  data: 0.0260  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.6361 (2.6370)  acc1: 18.7500 (22.8495)  acc5: 91.6667 (83.1989)  time: 0.1254  data: 0.0031  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.6267 (2.6605)  acc1: 18.7500 (23.9329)  acc5: 77.0833 (83.2825)  time: 0.1267  data: 0.0035  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.8736 (2.9277)  acc1: 12.5000 (20.8742)  acc5: 70.8333 (77.2876)  time: 0.1267  data: 0.0044  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.9664 (2.9741)  acc1: 10.4167 (19.1598)  acc5: 47.9167 (76.0587)  time: 0.1240  data: 0.0047  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.7180 (2.8777)  acc1: 10.4167 (22.5059)  acc5: 81.2500 (75.9096)  time: 0.1217  data: 0.0026  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9106 (2.6093)  acc1: 70.8333 (29.4753)  acc5: 97.9167 (78.6523)  time: 0.1202  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9106 (2.5888)  acc1: 72.9167 (29.9108)  acc5: 97.9167 (78.7516)  time: 0.1182  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1630 s / it)\n",
            "* Acc@1 29.911 Acc@5 78.752 loss 2.589\n",
            "Accuracy of the model EMA on 3925 test images: 29.9%\n",
            "Max EMA accuracy: 29.91%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [94]  [  0/295]  eta: 0:13:24  lr: 0.000056  min_lr: 0.000056  loss: 2.0323 (2.0323)  weight_decay: 0.0500 (0.0500)  time: 2.7257  data: 2.0477  max mem: 3719\n",
            "Epoch: [94]  [ 10/295]  eta: 0:02:34  lr: 0.000056  min_lr: 0.000056  loss: 2.3952 (2.3387)  weight_decay: 0.0500 (0.0500)  time: 0.5438  data: 0.1873  max mem: 3719\n",
            "Epoch: [94]  [ 20/295]  eta: 0:01:52  lr: 0.000055  min_lr: 0.000055  loss: 2.3952 (2.3790)  weight_decay: 0.0500 (0.0500)  time: 0.2930  data: 0.0009  max mem: 3719\n",
            "Epoch: [94]  [ 30/295]  eta: 0:01:35  lr: 0.000055  min_lr: 0.000055  loss: 2.4043 (2.3808)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0010  max mem: 3719\n",
            "Epoch: [94]  [ 40/295]  eta: 0:01:26  lr: 0.000054  min_lr: 0.000054  loss: 2.4043 (2.3865)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0010  max mem: 3719\n",
            "Epoch: [94]  [ 50/295]  eta: 0:01:19  lr: 0.000053  min_lr: 0.000053  loss: 2.4013 (2.3630)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0008  max mem: 3719\n",
            "Epoch: [94]  [ 60/295]  eta: 0:01:13  lr: 0.000053  min_lr: 0.000053  loss: 2.3468 (2.3569)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0017  max mem: 3719\n",
            "Epoch: [94]  [ 70/295]  eta: 0:01:09  lr: 0.000052  min_lr: 0.000052  loss: 2.3739 (2.3639)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0026  max mem: 3719\n",
            "Epoch: [94]  [ 80/295]  eta: 0:01:05  lr: 0.000051  min_lr: 0.000051  loss: 2.3951 (2.3654)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0020  max mem: 3719\n",
            "Epoch: [94]  [ 90/295]  eta: 0:01:01  lr: 0.000051  min_lr: 0.000051  loss: 2.4177 (2.3586)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0009  max mem: 3719\n",
            "Epoch: [94]  [100/295]  eta: 0:00:57  lr: 0.000050  min_lr: 0.000050  loss: 2.4343 (2.3639)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0008  max mem: 3719\n",
            "Epoch: [94]  [110/295]  eta: 0:00:54  lr: 0.000050  min_lr: 0.000050  loss: 2.3570 (2.3501)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0019  max mem: 3719\n",
            "Epoch: [94]  [120/295]  eta: 0:00:51  lr: 0.000049  min_lr: 0.000049  loss: 2.1810 (2.3486)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0035  max mem: 3719\n",
            "Epoch: [94]  [130/295]  eta: 0:00:47  lr: 0.000048  min_lr: 0.000048  loss: 2.3658 (2.3543)  weight_decay: 0.0500 (0.0500)  time: 0.2743  data: 0.0029  max mem: 3719\n",
            "Epoch: [94]  [140/295]  eta: 0:00:44  lr: 0.000048  min_lr: 0.000048  loss: 2.4743 (2.3598)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0020  max mem: 3719\n",
            "Epoch: [94]  [150/295]  eta: 0:00:41  lr: 0.000047  min_lr: 0.000047  loss: 2.4710 (2.3571)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0017  max mem: 3719\n",
            "Epoch: [94]  [160/295]  eta: 0:00:38  lr: 0.000047  min_lr: 0.000047  loss: 2.4712 (2.3647)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0013  max mem: 3719\n",
            "Epoch: [94]  [170/295]  eta: 0:00:35  lr: 0.000046  min_lr: 0.000046  loss: 2.5435 (2.3701)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0010  max mem: 3719\n",
            "Epoch: [94]  [180/295]  eta: 0:00:32  lr: 0.000046  min_lr: 0.000046  loss: 2.5135 (2.3729)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0017  max mem: 3719\n",
            "Epoch: [94]  [190/295]  eta: 0:00:29  lr: 0.000045  min_lr: 0.000045  loss: 2.4418 (2.3698)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0019  max mem: 3719\n",
            "Epoch: [94]  [200/295]  eta: 0:00:26  lr: 0.000044  min_lr: 0.000044  loss: 2.3229 (2.3657)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0017  max mem: 3719\n",
            "Epoch: [94]  [210/295]  eta: 0:00:23  lr: 0.000044  min_lr: 0.000044  loss: 2.3486 (2.3671)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0016  max mem: 3719\n",
            "Epoch: [94]  [220/295]  eta: 0:00:20  lr: 0.000043  min_lr: 0.000043  loss: 2.4150 (2.3656)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0009  max mem: 3719\n",
            "Epoch: [94]  [230/295]  eta: 0:00:18  lr: 0.000043  min_lr: 0.000043  loss: 2.4086 (2.3680)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0012  max mem: 3719\n",
            "Epoch: [94]  [240/295]  eta: 0:00:15  lr: 0.000042  min_lr: 0.000042  loss: 2.3596 (2.3628)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0023  max mem: 3719\n",
            "Epoch: [94]  [250/295]  eta: 0:00:12  lr: 0.000042  min_lr: 0.000042  loss: 2.2307 (2.3579)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0035  max mem: 3719\n",
            "Epoch: [94]  [260/295]  eta: 0:00:09  lr: 0.000041  min_lr: 0.000041  loss: 2.3813 (2.3635)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0039  max mem: 3719\n",
            "Epoch: [94]  [270/295]  eta: 0:00:06  lr: 0.000041  min_lr: 0.000041  loss: 2.4654 (2.3613)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0036  max mem: 3719\n",
            "Epoch: [94]  [280/295]  eta: 0:00:04  lr: 0.000040  min_lr: 0.000040  loss: 2.4200 (2.3613)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0017  max mem: 3719\n",
            "Epoch: [94]  [290/295]  eta: 0:00:01  lr: 0.000040  min_lr: 0.000040  loss: 2.4414 (2.3623)  weight_decay: 0.0500 (0.0500)  time: 0.2565  data: 0.0002  max mem: 3719\n",
            "Epoch: [94]  [294/295]  eta: 0:00:00  lr: 0.000040  min_lr: 0.000040  loss: 2.4414 (2.3621)  weight_decay: 0.0500 (0.0500)  time: 0.2187  data: 0.0002  max mem: 3719\n",
            "Epoch: [94] Total time: 0:01:20 (0.2738 s / it)\n",
            "Averaged stats: lr: 0.000040  min_lr: 0.000040  loss: 2.4414 (2.3621)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:41  loss: 0.5305 (0.5305)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 3.4306  data: 3.1333  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 0.4802 (0.4937)  acc1: 91.6667 (91.4773)  acc5: 97.9167 (98.4849)  time: 0.4501  data: 0.2852  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.4802 (0.5107)  acc1: 91.6667 (91.5675)  acc5: 100.0000 (98.5119)  time: 0.1555  data: 0.0016  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.6485 (0.6706)  acc1: 85.4167 (84.9462)  acc5: 100.0000 (98.5887)  time: 0.1490  data: 0.0017  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7243 (0.6633)  acc1: 83.3333 (85.1118)  acc5: 100.0000 (98.6789)  time: 0.1470  data: 0.0007  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6939 (0.6758)  acc1: 83.3333 (84.3137)  acc5: 100.0000 (98.6928)  time: 0.1506  data: 0.0019  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7539 (0.6849)  acc1: 79.1667 (83.7773)  acc5: 100.0000 (98.4631)  time: 0.1582  data: 0.0207  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8123 (0.7087)  acc1: 79.1667 (82.8345)  acc5: 97.9167 (98.2101)  time: 0.1735  data: 0.0363  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6976 (0.6945)  acc1: 85.4167 (83.4362)  acc5: 97.9167 (98.1996)  time: 0.1472  data: 0.0172  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6976 (0.6966)  acc1: 85.4167 (83.3885)  acc5: 97.9167 (98.1656)  time: 0.1439  data: 0.0151  max mem: 3719\n",
            "Test: Total time: 0:00:16 (0.1970 s / it)\n",
            "* Acc@1 83.389 Acc@5 98.166 loss 0.697\n",
            "Accuracy of the model on the 3925 test images: 83.4%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/82]  eta: 0:04:24  loss: 1.4278 (1.4278)  acc1: 45.8333 (45.8333)  acc5: 93.7500 (93.7500)  time: 3.2279  data: 3.0665  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 1.6661 (1.7839)  acc1: 35.4167 (36.1742)  acc5: 97.9167 (96.7803)  time: 0.4137  data: 0.2823  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.1368 (2.0515)  acc1: 29.1667 (30.5556)  acc5: 95.8333 (96.1310)  time: 0.1301  data: 0.0043  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.6027 (2.6083)  acc1: 20.8333 (23.7231)  acc5: 91.6667 (83.3333)  time: 0.1262  data: 0.0045  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.5823 (2.6293)  acc1: 18.7500 (24.6951)  acc5: 81.2500 (83.4858)  time: 0.1237  data: 0.0033  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.8340 (2.8965)  acc1: 12.5000 (21.4869)  acc5: 70.8333 (77.4918)  time: 0.1225  data: 0.0027  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.9277 (2.9408)  acc1: 10.4167 (19.7063)  acc5: 47.9167 (76.3661)  time: 0.1231  data: 0.0041  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.6772 (2.8457)  acc1: 10.4167 (22.9754)  acc5: 81.2500 (76.2031)  time: 0.1218  data: 0.0029  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9038 (2.5805)  acc1: 72.9167 (29.9126)  acc5: 97.9167 (78.9095)  time: 0.1190  data: 0.0004  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9038 (2.5603)  acc1: 72.9167 (30.3440)  acc5: 97.9167 (79.0064)  time: 0.1176  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1664 s / it)\n",
            "* Acc@1 30.344 Acc@5 79.006 loss 2.560\n",
            "Accuracy of the model EMA on 3925 test images: 30.3%\n",
            "Max EMA accuracy: 30.34%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [95]  [  0/295]  eta: 0:15:36  lr: 0.000039  min_lr: 0.000039  loss: 2.6674 (2.6674)  weight_decay: 0.0500 (0.0500)  time: 3.1746  data: 2.6798  max mem: 3719\n",
            "Epoch: [95]  [ 10/295]  eta: 0:02:38  lr: 0.000039  min_lr: 0.000039  loss: 2.4418 (2.3732)  weight_decay: 0.0500 (0.0500)  time: 0.5579  data: 0.2455  max mem: 3719\n",
            "Epoch: [95]  [ 20/295]  eta: 0:01:55  lr: 0.000038  min_lr: 0.000038  loss: 2.4157 (2.4037)  weight_decay: 0.0500 (0.0500)  time: 0.2807  data: 0.0016  max mem: 3719\n",
            "Epoch: [95]  [ 30/295]  eta: 0:01:37  lr: 0.000038  min_lr: 0.000038  loss: 2.4728 (2.4504)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0010  max mem: 3719\n",
            "Epoch: [95]  [ 40/295]  eta: 0:01:27  lr: 0.000037  min_lr: 0.000037  loss: 2.5245 (2.4748)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0011  max mem: 3719\n",
            "Epoch: [95]  [ 50/295]  eta: 0:01:20  lr: 0.000037  min_lr: 0.000037  loss: 2.5115 (2.4603)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0013  max mem: 3719\n",
            "Epoch: [95]  [ 60/295]  eta: 0:01:15  lr: 0.000036  min_lr: 0.000036  loss: 2.4276 (2.4405)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0018  max mem: 3719\n",
            "Epoch: [95]  [ 70/295]  eta: 0:01:10  lr: 0.000036  min_lr: 0.000036  loss: 2.4630 (2.4461)  weight_decay: 0.0500 (0.0500)  time: 0.2756  data: 0.0018  max mem: 3719\n",
            "Epoch: [95]  [ 80/295]  eta: 0:01:06  lr: 0.000035  min_lr: 0.000035  loss: 2.4504 (2.4334)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0009  max mem: 3719\n",
            "Epoch: [95]  [ 90/295]  eta: 0:01:02  lr: 0.000035  min_lr: 0.000035  loss: 2.4022 (2.4309)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0004  max mem: 3719\n",
            "Epoch: [95]  [100/295]  eta: 0:00:58  lr: 0.000034  min_lr: 0.000034  loss: 2.4539 (2.4286)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0007  max mem: 3719\n",
            "Epoch: [95]  [110/295]  eta: 0:00:54  lr: 0.000034  min_lr: 0.000034  loss: 2.3448 (2.4228)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0010  max mem: 3719\n",
            "Epoch: [95]  [120/295]  eta: 0:00:51  lr: 0.000033  min_lr: 0.000033  loss: 2.3448 (2.4206)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0013  max mem: 3719\n",
            "Epoch: [95]  [130/295]  eta: 0:00:48  lr: 0.000033  min_lr: 0.000033  loss: 2.3776 (2.4134)  weight_decay: 0.0500 (0.0500)  time: 0.2745  data: 0.0023  max mem: 3719\n",
            "Epoch: [95]  [140/295]  eta: 0:00:45  lr: 0.000032  min_lr: 0.000032  loss: 2.3776 (2.4069)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0021  max mem: 3719\n",
            "Epoch: [95]  [150/295]  eta: 0:00:41  lr: 0.000032  min_lr: 0.000032  loss: 2.3461 (2.4009)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0011  max mem: 3719\n",
            "Epoch: [95]  [160/295]  eta: 0:00:38  lr: 0.000031  min_lr: 0.000031  loss: 2.3411 (2.3993)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0010  max mem: 3719\n",
            "Epoch: [95]  [170/295]  eta: 0:00:35  lr: 0.000031  min_lr: 0.000031  loss: 2.4099 (2.4039)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0015  max mem: 3719\n",
            "Epoch: [95]  [180/295]  eta: 0:00:32  lr: 0.000031  min_lr: 0.000031  loss: 2.4358 (2.4070)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0024  max mem: 3719\n",
            "Epoch: [95]  [190/295]  eta: 0:00:29  lr: 0.000030  min_lr: 0.000030  loss: 2.4401 (2.4131)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0029  max mem: 3719\n",
            "Epoch: [95]  [200/295]  eta: 0:00:26  lr: 0.000030  min_lr: 0.000030  loss: 2.5421 (2.4081)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0018  max mem: 3719\n",
            "Epoch: [95]  [210/295]  eta: 0:00:23  lr: 0.000029  min_lr: 0.000029  loss: 2.4439 (2.4131)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0015  max mem: 3719\n",
            "Epoch: [95]  [220/295]  eta: 0:00:21  lr: 0.000029  min_lr: 0.000029  loss: 2.4201 (2.4115)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0023  max mem: 3719\n",
            "Epoch: [95]  [230/295]  eta: 0:00:18  lr: 0.000028  min_lr: 0.000028  loss: 2.3553 (2.4088)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0014  max mem: 3719\n",
            "Epoch: [95]  [240/295]  eta: 0:00:15  lr: 0.000028  min_lr: 0.000028  loss: 2.2800 (2.4043)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0020  max mem: 3719\n",
            "Epoch: [95]  [250/295]  eta: 0:00:12  lr: 0.000028  min_lr: 0.000028  loss: 2.1824 (2.3963)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0036  max mem: 3719\n",
            "Epoch: [95]  [260/295]  eta: 0:00:09  lr: 0.000027  min_lr: 0.000027  loss: 2.2422 (2.3945)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0024  max mem: 3719\n",
            "Epoch: [95]  [270/295]  eta: 0:00:06  lr: 0.000027  min_lr: 0.000027  loss: 2.4831 (2.3932)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0010  max mem: 3719\n",
            "Epoch: [95]  [280/295]  eta: 0:00:04  lr: 0.000026  min_lr: 0.000026  loss: 2.3809 (2.3912)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0005  max mem: 3719\n",
            "Epoch: [95]  [290/295]  eta: 0:00:01  lr: 0.000026  min_lr: 0.000026  loss: 2.2725 (2.3879)  weight_decay: 0.0500 (0.0500)  time: 0.2568  data: 0.0003  max mem: 3719\n",
            "Epoch: [95]  [294/295]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 2.2725 (2.3879)  weight_decay: 0.0500 (0.0500)  time: 0.2186  data: 0.0002  max mem: 3719\n",
            "Epoch: [95] Total time: 0:01:21 (0.2749 s / it)\n",
            "Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 2.2725 (2.3879)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:02  loss: 0.5537 (0.5537)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 2.9617  data: 2.7726  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 0.4894 (0.5021)  acc1: 91.6667 (90.9091)  acc5: 100.0000 (98.8636)  time: 0.4305  data: 0.2532  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.4894 (0.5169)  acc1: 91.6667 (90.8730)  acc5: 100.0000 (98.8095)  time: 0.1896  data: 0.0049  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.6475 (0.6892)  acc1: 87.5000 (83.7366)  acc5: 100.0000 (98.7231)  time: 0.1676  data: 0.0071  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.6863 (0.6714)  acc1: 83.3333 (84.4512)  acc5: 100.0000 (98.7297)  time: 0.1294  data: 0.0040  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6628 (0.6785)  acc1: 83.3333 (84.0686)  acc5: 100.0000 (98.7337)  time: 0.1239  data: 0.0029  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7385 (0.6856)  acc1: 81.2500 (83.7090)  acc5: 100.0000 (98.5656)  time: 0.1226  data: 0.0026  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8206 (0.7097)  acc1: 79.1667 (82.7171)  acc5: 97.9167 (98.2981)  time: 0.1213  data: 0.0011  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6988 (0.6965)  acc1: 85.4167 (83.3848)  acc5: 97.9167 (98.2768)  time: 0.1195  data: 0.0003  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6988 (0.6990)  acc1: 85.4167 (83.3376)  acc5: 97.9167 (98.2420)  time: 0.1182  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1802 s / it)\n",
            "* Acc@1 83.338 Acc@5 98.242 loss 0.699\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/82]  eta: 0:02:35  loss: 1.3952 (1.3952)  acc1: 47.9167 (47.9167)  acc5: 93.7500 (93.7500)  time: 1.9004  data: 1.7375  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 1.6342 (1.7536)  acc1: 37.5000 (36.7424)  acc5: 97.9167 (97.1591)  time: 0.3133  data: 0.1794  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 2.1074 (2.0238)  acc1: 29.1667 (31.0516)  acc5: 95.8333 (96.4286)  time: 0.1608  data: 0.0273  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.5699 (2.5798)  acc1: 20.8333 (24.0591)  acc5: 91.6667 (83.6022)  time: 0.1713  data: 0.0332  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.5396 (2.5985)  acc1: 18.7500 (25.0508)  acc5: 81.2500 (83.7398)  time: 0.1639  data: 0.0286  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 2.7941 (2.8657)  acc1: 12.5000 (21.7729)  acc5: 70.8333 (77.6961)  time: 0.1542  data: 0.0215  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 3.8793 (2.9077)  acc1: 10.4167 (20.1503)  acc5: 47.9167 (76.5710)  time: 0.1436  data: 0.0114  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.6362 (2.8138)  acc1: 14.5833 (23.3568)  acc5: 81.2500 (76.4378)  time: 0.1266  data: 0.0009  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8972 (2.5519)  acc1: 72.9167 (30.2212)  acc5: 97.9167 (79.1409)  time: 0.1213  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8972 (2.5320)  acc1: 72.9167 (30.6497)  acc5: 97.9167 (79.2357)  time: 0.1195  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1737 s / it)\n",
            "* Acc@1 30.650 Acc@5 79.236 loss 2.532\n",
            "Accuracy of the model EMA on 3925 test images: 30.6%\n",
            "Max EMA accuracy: 30.65%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [96]  [  0/295]  eta: 0:10:52  lr: 0.000026  min_lr: 0.000026  loss: 2.4664 (2.4664)  weight_decay: 0.0500 (0.0500)  time: 2.2106  data: 1.8196  max mem: 3719\n",
            "Epoch: [96]  [ 10/295]  eta: 0:02:05  lr: 0.000025  min_lr: 0.000025  loss: 2.4814 (2.4217)  weight_decay: 0.0500 (0.0500)  time: 0.4406  data: 0.1680  max mem: 3719\n",
            "Epoch: [96]  [ 20/295]  eta: 0:01:39  lr: 0.000025  min_lr: 0.000025  loss: 2.3927 (2.3340)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0020  max mem: 3719\n",
            "Epoch: [96]  [ 30/295]  eta: 0:01:27  lr: 0.000024  min_lr: 0.000024  loss: 2.4138 (2.3475)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0011  max mem: 3719\n",
            "Epoch: [96]  [ 40/295]  eta: 0:01:20  lr: 0.000024  min_lr: 0.000024  loss: 2.3984 (2.3314)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0015  max mem: 3719\n",
            "Epoch: [96]  [ 50/295]  eta: 0:01:15  lr: 0.000024  min_lr: 0.000024  loss: 2.3646 (2.3331)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0016  max mem: 3719\n",
            "Epoch: [96]  [ 60/295]  eta: 0:01:10  lr: 0.000023  min_lr: 0.000023  loss: 2.3905 (2.3383)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0013  max mem: 3719\n",
            "Epoch: [96]  [ 70/295]  eta: 0:01:06  lr: 0.000023  min_lr: 0.000023  loss: 2.3439 (2.3318)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0025  max mem: 3719\n",
            "Epoch: [96]  [ 80/295]  eta: 0:01:03  lr: 0.000022  min_lr: 0.000022  loss: 2.3660 (2.3486)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0029  max mem: 3719\n",
            "Epoch: [96]  [ 90/295]  eta: 0:00:59  lr: 0.000022  min_lr: 0.000022  loss: 2.3915 (2.3533)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0024  max mem: 3719\n",
            "Epoch: [96]  [100/295]  eta: 0:00:56  lr: 0.000022  min_lr: 0.000022  loss: 2.4181 (2.3678)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0024  max mem: 3719\n",
            "Epoch: [96]  [110/295]  eta: 0:00:52  lr: 0.000021  min_lr: 0.000021  loss: 2.3994 (2.3545)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0016  max mem: 3719\n",
            "Epoch: [96]  [120/295]  eta: 0:00:49  lr: 0.000021  min_lr: 0.000021  loss: 2.1491 (2.3464)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0015  max mem: 3719\n",
            "Epoch: [96]  [130/295]  eta: 0:00:46  lr: 0.000021  min_lr: 0.000021  loss: 2.2069 (2.3423)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0022  max mem: 3719\n",
            "Epoch: [96]  [140/295]  eta: 0:00:43  lr: 0.000020  min_lr: 0.000020  loss: 2.4100 (2.3544)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0026  max mem: 3719\n",
            "Epoch: [96]  [150/295]  eta: 0:00:40  lr: 0.000020  min_lr: 0.000020  loss: 2.4160 (2.3516)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0021  max mem: 3719\n",
            "Epoch: [96]  [160/295]  eta: 0:00:37  lr: 0.000019  min_lr: 0.000019  loss: 2.3639 (2.3523)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0023  max mem: 3719\n",
            "Epoch: [96]  [170/295]  eta: 0:00:34  lr: 0.000019  min_lr: 0.000019  loss: 2.4134 (2.3542)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0017  max mem: 3719\n",
            "Epoch: [96]  [180/295]  eta: 0:00:31  lr: 0.000019  min_lr: 0.000019  loss: 2.3512 (2.3528)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0005  max mem: 3719\n",
            "Epoch: [96]  [190/295]  eta: 0:00:29  lr: 0.000018  min_lr: 0.000018  loss: 2.3651 (2.3545)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0005  max mem: 3719\n",
            "Epoch: [96]  [200/295]  eta: 0:00:26  lr: 0.000018  min_lr: 0.000018  loss: 2.3864 (2.3561)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0008  max mem: 3719\n",
            "Epoch: [96]  [210/295]  eta: 0:00:23  lr: 0.000018  min_lr: 0.000018  loss: 2.4720 (2.3618)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0017  max mem: 3719\n",
            "Epoch: [96]  [220/295]  eta: 0:00:20  lr: 0.000017  min_lr: 0.000017  loss: 2.4583 (2.3646)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0018  max mem: 3719\n",
            "Epoch: [96]  [230/295]  eta: 0:00:17  lr: 0.000017  min_lr: 0.000017  loss: 2.4186 (2.3651)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0018  max mem: 3719\n",
            "Epoch: [96]  [240/295]  eta: 0:00:15  lr: 0.000017  min_lr: 0.000017  loss: 2.4106 (2.3650)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0015  max mem: 3719\n",
            "Epoch: [96]  [250/295]  eta: 0:00:12  lr: 0.000016  min_lr: 0.000016  loss: 2.4278 (2.3673)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0014  max mem: 3719\n",
            "Epoch: [96]  [260/295]  eta: 0:00:09  lr: 0.000016  min_lr: 0.000016  loss: 2.2845 (2.3608)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0018  max mem: 3719\n",
            "Epoch: [96]  [270/295]  eta: 0:00:06  lr: 0.000016  min_lr: 0.000016  loss: 2.3026 (2.3651)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0025  max mem: 3719\n",
            "Epoch: [96]  [280/295]  eta: 0:00:04  lr: 0.000015  min_lr: 0.000015  loss: 2.4050 (2.3646)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0030  max mem: 3719\n",
            "Epoch: [96]  [290/295]  eta: 0:00:01  lr: 0.000015  min_lr: 0.000015  loss: 2.4858 (2.3690)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0015  max mem: 3719\n",
            "Epoch: [96]  [294/295]  eta: 0:00:00  lr: 0.000015  min_lr: 0.000015  loss: 2.5035 (2.3701)  weight_decay: 0.0500 (0.0500)  time: 0.2215  data: 0.0002  max mem: 3719\n",
            "Epoch: [96] Total time: 0:01:19 (0.2707 s / it)\n",
            "Averaged stats: lr: 0.000015  min_lr: 0.000015  loss: 2.5035 (2.3701)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:16  loss: 0.5589 (0.5589)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 1.6622  data: 1.4921  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.4918 (0.5122)  acc1: 91.6667 (90.9091)  acc5: 100.0000 (98.6742)  time: 0.2979  data: 0.1723  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.4918 (0.5210)  acc1: 91.6667 (90.9722)  acc5: 100.0000 (98.8095)  time: 0.1420  data: 0.0207  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6323 (0.6896)  acc1: 87.5000 (83.8710)  acc5: 100.0000 (98.7231)  time: 0.1227  data: 0.0014  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7006 (0.6739)  acc1: 83.3333 (84.3496)  acc5: 100.0000 (98.7805)  time: 0.1247  data: 0.0024  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6752 (0.6755)  acc1: 85.4167 (84.1095)  acc5: 100.0000 (98.8154)  time: 0.1326  data: 0.0032  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7243 (0.6871)  acc1: 81.2500 (83.6407)  acc5: 100.0000 (98.7022)  time: 0.1453  data: 0.0018  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8331 (0.7121)  acc1: 79.1667 (82.5704)  acc5: 97.9167 (98.4155)  time: 0.1453  data: 0.0003  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7001 (0.6957)  acc1: 85.4167 (83.3076)  acc5: 97.9167 (98.3796)  time: 0.1286  data: 0.0002  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7001 (0.6977)  acc1: 85.4167 (83.2611)  acc5: 97.9167 (98.3440)  time: 0.1246  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1605 s / it)\n",
            "* Acc@1 83.261 Acc@5 98.344 loss 0.698\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/82]  eta: 0:02:32  loss: 1.3624 (1.3624)  acc1: 47.9167 (47.9167)  acc5: 93.7500 (93.7500)  time: 1.8597  data: 1.6888  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.6021 (1.7229)  acc1: 39.5833 (37.6894)  acc5: 97.9167 (97.3485)  time: 0.2845  data: 0.1595  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.0776 (1.9958)  acc1: 29.1667 (31.8452)  acc5: 97.9167 (96.6270)  time: 0.1256  data: 0.0059  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.5362 (2.5511)  acc1: 20.8333 (24.7312)  acc5: 91.6667 (83.9382)  time: 0.1234  data: 0.0047  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 2.4970 (2.5676)  acc1: 18.7500 (25.6098)  acc5: 81.2500 (83.9939)  time: 0.1230  data: 0.0049  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.7539 (2.8346)  acc1: 12.5000 (22.1814)  acc5: 70.8333 (77.8595)  time: 0.1229  data: 0.0039  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.8310 (2.8744)  acc1: 10.4167 (20.6284)  acc5: 47.9167 (76.8101)  time: 0.1239  data: 0.0031  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 2.5950 (2.7819)  acc1: 14.5833 (23.7676)  acc5: 81.2500 (76.7312)  time: 0.1219  data: 0.0021  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8911 (2.5232)  acc1: 72.9167 (30.6070)  acc5: 97.9167 (79.3982)  time: 0.1186  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8911 (2.5036)  acc1: 72.9167 (31.0318)  acc5: 97.9167 (79.4904)  time: 0.1173  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:12 (0.1510 s / it)\n",
            "* Acc@1 31.032 Acc@5 79.490 loss 2.504\n",
            "Accuracy of the model EMA on 3925 test images: 31.0%\n",
            "Max EMA accuracy: 31.03%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [97]  [  0/295]  eta: 0:12:40  lr: 0.000015  min_lr: 0.000015  loss: 2.3362 (2.3362)  weight_decay: 0.0500 (0.0500)  time: 2.5772  data: 2.2271  max mem: 3719\n",
            "Epoch: [97]  [ 10/295]  eta: 0:02:16  lr: 0.000015  min_lr: 0.000015  loss: 2.3862 (2.4529)  weight_decay: 0.0500 (0.0500)  time: 0.4788  data: 0.2041  max mem: 3719\n",
            "Epoch: [97]  [ 20/295]  eta: 0:01:43  lr: 0.000014  min_lr: 0.000014  loss: 2.3298 (2.3490)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0011  max mem: 3719\n",
            "Epoch: [97]  [ 30/295]  eta: 0:01:29  lr: 0.000014  min_lr: 0.000014  loss: 2.3491 (2.3560)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0008  max mem: 3719\n",
            "Epoch: [97]  [ 40/295]  eta: 0:01:22  lr: 0.000014  min_lr: 0.000014  loss: 2.3775 (2.3734)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0022  max mem: 3719\n",
            "Epoch: [97]  [ 50/295]  eta: 0:01:16  lr: 0.000013  min_lr: 0.000013  loss: 2.2678 (2.3547)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0025  max mem: 3719\n",
            "Epoch: [97]  [ 60/295]  eta: 0:01:11  lr: 0.000013  min_lr: 0.000013  loss: 2.3118 (2.3532)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0014  max mem: 3719\n",
            "Epoch: [97]  [ 70/295]  eta: 0:01:07  lr: 0.000013  min_lr: 0.000013  loss: 2.3671 (2.3626)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0010  max mem: 3719\n",
            "Epoch: [97]  [ 80/295]  eta: 0:01:03  lr: 0.000012  min_lr: 0.000012  loss: 2.3657 (2.3678)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0012  max mem: 3719\n",
            "Epoch: [97]  [ 90/295]  eta: 0:00:59  lr: 0.000012  min_lr: 0.000012  loss: 2.3961 (2.3760)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0015  max mem: 3719\n",
            "Epoch: [97]  [100/295]  eta: 0:00:56  lr: 0.000012  min_lr: 0.000012  loss: 2.3750 (2.3719)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0018  max mem: 3719\n",
            "Epoch: [97]  [110/295]  eta: 0:00:53  lr: 0.000012  min_lr: 0.000012  loss: 2.3236 (2.3748)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0028  max mem: 3719\n",
            "Epoch: [97]  [120/295]  eta: 0:00:50  lr: 0.000011  min_lr: 0.000011  loss: 2.2989 (2.3586)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0035  max mem: 3719\n",
            "Epoch: [97]  [130/295]  eta: 0:00:46  lr: 0.000011  min_lr: 0.000011  loss: 2.3237 (2.3674)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0026  max mem: 3719\n",
            "Epoch: [97]  [140/295]  eta: 0:00:43  lr: 0.000011  min_lr: 0.000011  loss: 2.5181 (2.3753)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0011  max mem: 3719\n",
            "Epoch: [97]  [150/295]  eta: 0:00:40  lr: 0.000011  min_lr: 0.000011  loss: 2.4927 (2.3826)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0014  max mem: 3719\n",
            "Epoch: [97]  [160/295]  eta: 0:00:37  lr: 0.000010  min_lr: 0.000010  loss: 2.4644 (2.3799)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0024  max mem: 3719\n",
            "Epoch: [97]  [170/295]  eta: 0:00:34  lr: 0.000010  min_lr: 0.000010  loss: 2.4635 (2.3822)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0031  max mem: 3719\n",
            "Epoch: [97]  [180/295]  eta: 0:00:32  lr: 0.000010  min_lr: 0.000010  loss: 2.2667 (2.3679)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0027  max mem: 3719\n",
            "Epoch: [97]  [190/295]  eta: 0:00:29  lr: 0.000010  min_lr: 0.000010  loss: 2.2594 (2.3668)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0032  max mem: 3719\n",
            "Epoch: [97]  [200/295]  eta: 0:00:26  lr: 0.000009  min_lr: 0.000009  loss: 2.4189 (2.3662)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0033  max mem: 3719\n",
            "Epoch: [97]  [210/295]  eta: 0:00:23  lr: 0.000009  min_lr: 0.000009  loss: 2.3471 (2.3661)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0019  max mem: 3719\n",
            "Epoch: [97]  [220/295]  eta: 0:00:20  lr: 0.000009  min_lr: 0.000009  loss: 2.4227 (2.3664)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0022  max mem: 3719\n",
            "Epoch: [97]  [230/295]  eta: 0:00:17  lr: 0.000009  min_lr: 0.000009  loss: 2.4269 (2.3650)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0032  max mem: 3719\n",
            "Epoch: [97]  [240/295]  eta: 0:00:15  lr: 0.000008  min_lr: 0.000008  loss: 2.4602 (2.3699)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0025  max mem: 3719\n",
            "Epoch: [97]  [250/295]  eta: 0:00:12  lr: 0.000008  min_lr: 0.000008  loss: 2.5238 (2.3732)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0012  max mem: 3719\n",
            "Epoch: [97]  [260/295]  eta: 0:00:09  lr: 0.000008  min_lr: 0.000008  loss: 2.5238 (2.3781)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0008  max mem: 3719\n",
            "Epoch: [97]  [270/295]  eta: 0:00:06  lr: 0.000008  min_lr: 0.000008  loss: 2.5218 (2.3762)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0008  max mem: 3719\n",
            "Epoch: [97]  [280/295]  eta: 0:00:04  lr: 0.000007  min_lr: 0.000007  loss: 2.5218 (2.3802)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0012  max mem: 3719\n",
            "Epoch: [97]  [290/295]  eta: 0:00:01  lr: 0.000007  min_lr: 0.000007  loss: 2.4913 (2.3816)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0008  max mem: 3719\n",
            "Epoch: [97]  [294/295]  eta: 0:00:00  lr: 0.000007  min_lr: 0.000007  loss: 2.4913 (2.3805)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0002  max mem: 3719\n",
            "Epoch: [97] Total time: 0:01:20 (0.2723 s / it)\n",
            "Averaged stats: lr: 0.000007  min_lr: 0.000007  loss: 2.4913 (2.3805)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:32  loss: 0.5479 (0.5479)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 3.3240  data: 3.0425  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 0.4892 (0.5081)  acc1: 91.6667 (91.0985)  acc5: 100.0000 (98.8636)  time: 0.4491  data: 0.2895  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.4892 (0.5174)  acc1: 91.6667 (91.2698)  acc5: 100.0000 (98.8095)  time: 0.1484  data: 0.0087  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6278 (0.6886)  acc1: 87.5000 (83.9382)  acc5: 100.0000 (98.7231)  time: 0.1294  data: 0.0030  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.6962 (0.6727)  acc1: 83.3333 (84.4004)  acc5: 100.0000 (98.7297)  time: 0.1242  data: 0.0044  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6675 (0.6800)  acc1: 83.3333 (83.9461)  acc5: 100.0000 (98.7337)  time: 0.1247  data: 0.0042  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7555 (0.6909)  acc1: 81.2500 (83.5383)  acc5: 100.0000 (98.6339)  time: 0.1237  data: 0.0035  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8215 (0.7144)  acc1: 79.1667 (82.5704)  acc5: 97.9167 (98.3862)  time: 0.1210  data: 0.0028  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6953 (0.6974)  acc1: 85.4167 (83.3076)  acc5: 97.9167 (98.3539)  time: 0.1188  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6953 (0.6992)  acc1: 85.4167 (83.2611)  acc5: 97.9167 (98.3185)  time: 0.1174  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1721 s / it)\n",
            "* Acc@1 83.261 Acc@5 98.318 loss 0.699\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/82]  eta: 0:02:33  loss: 1.3307 (1.3307)  acc1: 47.9167 (47.9167)  acc5: 93.7500 (93.7500)  time: 1.8756  data: 1.7117  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 1.5713 (1.6931)  acc1: 39.5833 (38.2576)  acc5: 97.9167 (97.3485)  time: 0.2990  data: 0.1699  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 2.0524 (1.9683)  acc1: 31.2500 (32.4405)  acc5: 97.9167 (96.7262)  time: 0.1535  data: 0.0252  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.5028 (2.5229)  acc1: 20.8333 (25.2688)  acc5: 91.6667 (84.2742)  time: 0.1846  data: 0.0491  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.4553 (2.5373)  acc1: 18.7500 (26.2703)  acc5: 81.2500 (84.2988)  time: 0.1697  data: 0.0353  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 2.7153 (2.8040)  acc1: 12.5000 (22.8350)  acc5: 70.8333 (78.1046)  time: 0.1556  data: 0.0208  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 3.7838 (2.8419)  acc1: 10.4167 (21.3456)  acc5: 50.0000 (77.1175)  time: 0.1523  data: 0.0197  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.5556 (2.7506)  acc1: 16.6667 (24.4425)  acc5: 83.3333 (77.0833)  time: 0.1248  data: 0.0025  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8822 (2.4952)  acc1: 72.9167 (31.2500)  acc5: 97.9167 (79.7068)  time: 0.1202  data: 0.0001  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8822 (2.4759)  acc1: 72.9167 (31.6688)  acc5: 97.9167 (79.7962)  time: 0.1189  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:14 (0.1747 s / it)\n",
            "* Acc@1 31.669 Acc@5 79.796 loss 2.476\n",
            "Accuracy of the model EMA on 3925 test images: 31.7%\n",
            "Max EMA accuracy: 31.67%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [98]  [  0/295]  eta: 0:09:51  lr: 0.000007  min_lr: 0.000007  loss: 2.4300 (2.4300)  weight_decay: 0.0500 (0.0500)  time: 2.0039  data: 1.6671  max mem: 3719\n",
            "Epoch: [98]  [ 10/295]  eta: 0:02:00  lr: 0.000007  min_lr: 0.000007  loss: 2.4905 (2.4146)  weight_decay: 0.0500 (0.0500)  time: 0.4236  data: 0.1537  max mem: 3719\n",
            "Epoch: [98]  [ 20/295]  eta: 0:01:36  lr: 0.000007  min_lr: 0.000007  loss: 2.5144 (2.4625)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0022  max mem: 3719\n",
            "Epoch: [98]  [ 30/295]  eta: 0:01:25  lr: 0.000007  min_lr: 0.000007  loss: 2.4962 (2.4420)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0013  max mem: 3719\n",
            "Epoch: [98]  [ 40/295]  eta: 0:01:18  lr: 0.000006  min_lr: 0.000006  loss: 2.4497 (2.4455)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0018  max mem: 3719\n",
            "Epoch: [98]  [ 50/295]  eta: 0:01:13  lr: 0.000006  min_lr: 0.000006  loss: 2.4313 (2.4241)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0022  max mem: 3719\n",
            "Epoch: [98]  [ 60/295]  eta: 0:01:09  lr: 0.000006  min_lr: 0.000006  loss: 2.3694 (2.4260)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0011  max mem: 3719\n",
            "Epoch: [98]  [ 70/295]  eta: 0:01:05  lr: 0.000006  min_lr: 0.000006  loss: 2.3225 (2.4135)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0009  max mem: 3719\n",
            "Epoch: [98]  [ 80/295]  eta: 0:01:01  lr: 0.000006  min_lr: 0.000006  loss: 2.2893 (2.3959)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0019  max mem: 3719\n",
            "Epoch: [98]  [ 90/295]  eta: 0:00:58  lr: 0.000005  min_lr: 0.000005  loss: 2.3222 (2.3927)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0039  max mem: 3719\n",
            "Epoch: [98]  [100/295]  eta: 0:00:55  lr: 0.000005  min_lr: 0.000005  loss: 2.4176 (2.3960)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0032  max mem: 3719\n",
            "Epoch: [98]  [110/295]  eta: 0:00:52  lr: 0.000005  min_lr: 0.000005  loss: 2.4176 (2.3814)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0013  max mem: 3719\n",
            "Epoch: [98]  [120/295]  eta: 0:00:49  lr: 0.000005  min_lr: 0.000005  loss: 2.3806 (2.3848)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0011  max mem: 3719\n",
            "Epoch: [98]  [130/295]  eta: 0:00:46  lr: 0.000005  min_lr: 0.000005  loss: 2.2932 (2.3753)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0018  max mem: 3719\n",
            "Epoch: [98]  [140/295]  eta: 0:00:43  lr: 0.000005  min_lr: 0.000005  loss: 2.3939 (2.3778)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0022  max mem: 3719\n",
            "Epoch: [98]  [150/295]  eta: 0:00:40  lr: 0.000004  min_lr: 0.000004  loss: 2.4189 (2.3739)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0024  max mem: 3719\n",
            "Epoch: [98]  [160/295]  eta: 0:00:37  lr: 0.000004  min_lr: 0.000004  loss: 2.4382 (2.3718)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0020  max mem: 3719\n",
            "Epoch: [98]  [170/295]  eta: 0:00:34  lr: 0.000004  min_lr: 0.000004  loss: 2.4028 (2.3655)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0018  max mem: 3719\n",
            "Epoch: [98]  [180/295]  eta: 0:00:31  lr: 0.000004  min_lr: 0.000004  loss: 2.3410 (2.3635)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0022  max mem: 3719\n",
            "Epoch: [98]  [190/295]  eta: 0:00:28  lr: 0.000004  min_lr: 0.000004  loss: 2.3410 (2.3626)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0022  max mem: 3719\n",
            "Epoch: [98]  [200/295]  eta: 0:00:26  lr: 0.000004  min_lr: 0.000004  loss: 2.2976 (2.3614)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0015  max mem: 3719\n",
            "Epoch: [98]  [210/295]  eta: 0:00:23  lr: 0.000004  min_lr: 0.000004  loss: 2.2545 (2.3577)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0021  max mem: 3719\n",
            "Epoch: [98]  [220/295]  eta: 0:00:20  lr: 0.000003  min_lr: 0.000003  loss: 2.3045 (2.3564)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0034  max mem: 3719\n",
            "Epoch: [98]  [230/295]  eta: 0:00:17  lr: 0.000003  min_lr: 0.000003  loss: 2.4181 (2.3604)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0025  max mem: 3719\n",
            "Epoch: [98]  [240/295]  eta: 0:00:15  lr: 0.000003  min_lr: 0.000003  loss: 2.4511 (2.3625)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0016  max mem: 3719\n",
            "Epoch: [98]  [250/295]  eta: 0:00:12  lr: 0.000003  min_lr: 0.000003  loss: 2.4849 (2.3664)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0011  max mem: 3719\n",
            "Epoch: [98]  [260/295]  eta: 0:00:09  lr: 0.000003  min_lr: 0.000003  loss: 2.4551 (2.3661)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0020  max mem: 3719\n",
            "Epoch: [98]  [270/295]  eta: 0:00:06  lr: 0.000003  min_lr: 0.000003  loss: 2.3280 (2.3616)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0034  max mem: 3719\n",
            "Epoch: [98]  [280/295]  eta: 0:00:04  lr: 0.000003  min_lr: 0.000003  loss: 2.3280 (2.3615)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0020  max mem: 3719\n",
            "Epoch: [98]  [290/295]  eta: 0:00:01  lr: 0.000003  min_lr: 0.000003  loss: 2.3514 (2.3641)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0002  max mem: 3719\n",
            "Epoch: [98]  [294/295]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000003  loss: 2.4557 (2.3645)  weight_decay: 0.0500 (0.0500)  time: 0.2220  data: 0.0002  max mem: 3719\n",
            "Epoch: [98] Total time: 0:01:19 (0.2699 s / it)\n",
            "Averaged stats: lr: 0.000003  min_lr: 0.000003  loss: 2.4557 (2.3645)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:54  loss: 0.5583 (0.5583)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 2.1246  data: 1.9480  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.4980 (0.5141)  acc1: 91.6667 (90.7197)  acc5: 100.0000 (98.8636)  time: 0.3059  data: 0.1811  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.4952 (0.5201)  acc1: 91.6667 (91.0714)  acc5: 100.0000 (98.9087)  time: 0.1225  data: 0.0038  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6273 (0.6886)  acc1: 87.5000 (83.8710)  acc5: 100.0000 (98.7903)  time: 0.1217  data: 0.0040  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.6913 (0.6721)  acc1: 83.3333 (84.3496)  acc5: 100.0000 (98.7805)  time: 0.1242  data: 0.0057  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6640 (0.6782)  acc1: 83.3333 (83.9869)  acc5: 100.0000 (98.7745)  time: 0.1292  data: 0.0039  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7492 (0.6897)  acc1: 81.2500 (83.4699)  acc5: 100.0000 (98.6339)  time: 0.1407  data: 0.0022  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8299 (0.7141)  acc1: 79.1667 (82.4531)  acc5: 97.9167 (98.3862)  time: 0.1394  data: 0.0019  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6986 (0.6971)  acc1: 85.4167 (83.1790)  acc5: 97.9167 (98.3539)  time: 0.1243  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6986 (0.6991)  acc1: 85.4167 (83.1338)  acc5: 97.9167 (98.3185)  time: 0.1214  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1592 s / it)\n",
            "* Acc@1 83.134 Acc@5 98.318 loss 0.699\n",
            "Accuracy of the model on the 3925 test images: 83.1%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/82]  eta: 0:02:47  loss: 1.2999 (1.2999)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 2.0399  data: 1.8779  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 1.5412 (1.6641)  acc1: 41.6667 (38.8258)  acc5: 97.9167 (97.3485)  time: 0.3020  data: 0.1711  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.0331 (1.9414)  acc1: 31.2500 (32.8373)  acc5: 97.9167 (96.8254)  time: 0.1291  data: 0.0015  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.4700 (2.4951)  acc1: 20.8333 (25.6048)  acc5: 91.6667 (84.4086)  time: 0.1358  data: 0.0024  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.4229 (2.5073)  acc1: 18.7500 (26.6260)  acc5: 81.2500 (84.5528)  time: 0.1391  data: 0.0014  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.6770 (2.7739)  acc1: 12.5000 (23.1618)  acc5: 70.8333 (78.3905)  time: 0.1596  data: 0.0216  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 3.7369 (2.8097)  acc1: 10.4167 (21.7896)  acc5: 52.0833 (77.5273)  time: 0.1910  data: 0.0418  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.5166 (2.7197)  acc1: 18.7500 (24.8239)  acc5: 83.3333 (77.4648)  time: 0.1916  data: 0.0327  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8730 (2.4675)  acc1: 72.9167 (31.6101)  acc5: 97.9167 (80.0412)  time: 0.1647  data: 0.0250  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8730 (2.4484)  acc1: 75.0000 (32.0255)  acc5: 97.9167 (80.1274)  time: 0.1568  data: 0.0249  max mem: 3719\n",
            "Test: Total time: 0:00:15 (0.1864 s / it)\n",
            "* Acc@1 32.025 Acc@5 80.127 loss 2.448\n",
            "Accuracy of the model EMA on 3925 test images: 32.0%\n",
            "Max EMA accuracy: 32.03%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [99]  [  0/295]  eta: 0:12:49  lr: 0.000003  min_lr: 0.000003  loss: 2.5627 (2.5627)  weight_decay: 0.0500 (0.0500)  time: 2.6070  data: 2.2246  max mem: 3719\n",
            "Epoch: [99]  [ 10/295]  eta: 0:02:15  lr: 0.000002  min_lr: 0.000002  loss: 2.5133 (2.4979)  weight_decay: 0.0500 (0.0500)  time: 0.4742  data: 0.2042  max mem: 3719\n",
            "Epoch: [99]  [ 20/295]  eta: 0:01:42  lr: 0.000002  min_lr: 0.000002  loss: 2.4661 (2.4383)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0015  max mem: 3719\n",
            "Epoch: [99]  [ 30/295]  eta: 0:01:29  lr: 0.000002  min_lr: 0.000002  loss: 2.3778 (2.4312)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0011  max mem: 3719\n",
            "Epoch: [99]  [ 40/295]  eta: 0:01:21  lr: 0.000002  min_lr: 0.000002  loss: 2.4770 (2.4253)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0014  max mem: 3719\n",
            "Epoch: [99]  [ 50/295]  eta: 0:01:16  lr: 0.000002  min_lr: 0.000002  loss: 2.5024 (2.4340)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0014  max mem: 3719\n",
            "Epoch: [99]  [ 60/295]  eta: 0:01:11  lr: 0.000002  min_lr: 0.000002  loss: 2.4502 (2.4264)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0009  max mem: 3719\n",
            "Epoch: [99]  [ 70/295]  eta: 0:01:07  lr: 0.000002  min_lr: 0.000002  loss: 2.5140 (2.4446)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0006  max mem: 3719\n",
            "Epoch: [99]  [ 80/295]  eta: 0:01:03  lr: 0.000002  min_lr: 0.000002  loss: 2.4921 (2.4438)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0008  max mem: 3719\n",
            "Epoch: [99]  [ 90/295]  eta: 0:00:59  lr: 0.000002  min_lr: 0.000002  loss: 2.3972 (2.4385)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0009  max mem: 3719\n",
            "Epoch: [99]  [100/295]  eta: 0:00:56  lr: 0.000002  min_lr: 0.000002  loss: 2.3755 (2.4307)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0017  max mem: 3719\n",
            "Epoch: [99]  [110/295]  eta: 0:00:53  lr: 0.000002  min_lr: 0.000002  loss: 2.5345 (2.4451)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0028  max mem: 3719\n",
            "Epoch: [99]  [120/295]  eta: 0:00:50  lr: 0.000002  min_lr: 0.000002  loss: 2.4975 (2.4364)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0032  max mem: 3719\n",
            "Epoch: [99]  [130/295]  eta: 0:00:47  lr: 0.000001  min_lr: 0.000001  loss: 2.3046 (2.4296)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0027  max mem: 3719\n",
            "Epoch: [99]  [140/295]  eta: 0:00:43  lr: 0.000001  min_lr: 0.000001  loss: 2.3777 (2.4273)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0019  max mem: 3719\n",
            "Epoch: [99]  [150/295]  eta: 0:00:40  lr: 0.000001  min_lr: 0.000001  loss: 2.4228 (2.4264)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0011  max mem: 3719\n",
            "Epoch: [99]  [160/295]  eta: 0:00:37  lr: 0.000001  min_lr: 0.000001  loss: 2.4254 (2.4258)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0009  max mem: 3719\n",
            "Epoch: [99]  [170/295]  eta: 0:00:35  lr: 0.000001  min_lr: 0.000001  loss: 2.3175 (2.4142)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0024  max mem: 3719\n",
            "Epoch: [99]  [180/295]  eta: 0:00:32  lr: 0.000001  min_lr: 0.000001  loss: 2.3345 (2.4148)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0034  max mem: 3719\n",
            "Epoch: [99]  [190/295]  eta: 0:00:29  lr: 0.000001  min_lr: 0.000001  loss: 2.3915 (2.4057)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0022  max mem: 3719\n",
            "Epoch: [99]  [200/295]  eta: 0:00:26  lr: 0.000001  min_lr: 0.000001  loss: 2.3202 (2.4013)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0011  max mem: 3719\n",
            "Epoch: [99]  [210/295]  eta: 0:00:23  lr: 0.000001  min_lr: 0.000001  loss: 2.5002 (2.4074)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0012  max mem: 3719\n",
            "Epoch: [99]  [220/295]  eta: 0:00:20  lr: 0.000001  min_lr: 0.000001  loss: 2.5353 (2.4062)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0018  max mem: 3719\n",
            "Epoch: [99]  [230/295]  eta: 0:00:17  lr: 0.000001  min_lr: 0.000001  loss: 2.4092 (2.4029)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0030  max mem: 3719\n",
            "Epoch: [99]  [240/295]  eta: 0:00:15  lr: 0.000001  min_lr: 0.000001  loss: 2.1957 (2.3945)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0047  max mem: 3719\n",
            "Epoch: [99]  [250/295]  eta: 0:00:12  lr: 0.000001  min_lr: 0.000001  loss: 2.3716 (2.3965)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0038  max mem: 3719\n",
            "Epoch: [99]  [260/295]  eta: 0:00:09  lr: 0.000001  min_lr: 0.000001  loss: 2.4922 (2.3962)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0017  max mem: 3719\n",
            "Epoch: [99]  [270/295]  eta: 0:00:06  lr: 0.000001  min_lr: 0.000001  loss: 2.4256 (2.3943)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0010  max mem: 3719\n",
            "Epoch: [99]  [280/295]  eta: 0:00:04  lr: 0.000001  min_lr: 0.000001  loss: 2.4043 (2.3948)  weight_decay: 0.0500 (0.0500)  time: 0.2566  data: 0.0008  max mem: 3719\n",
            "Epoch: [99]  [290/295]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000001  loss: 2.4889 (2.3976)  weight_decay: 0.0500 (0.0500)  time: 0.2566  data: 0.0004  max mem: 3719\n",
            "Epoch: [99]  [294/295]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.5029 (2.3989)  weight_decay: 0.0500 (0.0500)  time: 0.2191  data: 0.0002  max mem: 3719\n",
            "Epoch: [99] Total time: 0:01:20 (0.2723 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.5029 (2.3989)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:43  loss: 0.5555 (0.5555)  acc1: 87.5000 (87.5000)  acc5: 97.9167 (97.9167)  time: 1.9997  data: 1.8355  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.4960 (0.5124)  acc1: 91.6667 (90.9091)  acc5: 100.0000 (98.8636)  time: 0.3731  data: 0.2423  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.4956 (0.5193)  acc1: 91.6667 (91.2698)  acc5: 100.0000 (98.9087)  time: 0.1676  data: 0.0423  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.6282 (0.6873)  acc1: 87.5000 (84.0054)  acc5: 100.0000 (98.7903)  time: 0.1238  data: 0.0023  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.6927 (0.6713)  acc1: 83.3333 (84.4512)  acc5: 100.0000 (98.8313)  time: 0.1234  data: 0.0036  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6648 (0.6777)  acc1: 83.3333 (84.0686)  acc5: 100.0000 (98.8154)  time: 0.1220  data: 0.0035  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7493 (0.6894)  acc1: 81.2500 (83.5383)  acc5: 100.0000 (98.6339)  time: 0.1211  data: 0.0024  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8318 (0.7144)  acc1: 79.1667 (82.4824)  acc5: 97.9167 (98.3862)  time: 0.1208  data: 0.0014  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7044 (0.6976)  acc1: 83.3333 (83.1790)  acc5: 97.9167 (98.3539)  time: 0.1188  data: 0.0005  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7044 (0.6995)  acc1: 83.3333 (83.1338)  acc5: 97.9167 (98.3185)  time: 0.1171  data: 0.0001  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1621 s / it)\n",
            "* Acc@1 83.134 Acc@5 98.318 loss 0.700\n",
            "Accuracy of the model on the 3925 test images: 83.1%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/82]  eta: 0:03:44  loss: 1.2697 (1.2697)  acc1: 52.0833 (52.0833)  acc5: 93.7500 (93.7500)  time: 2.7427  data: 2.5812  max mem: 3719\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 1.5102 (1.6355)  acc1: 41.6667 (39.7727)  acc5: 97.9167 (97.3485)  time: 0.4038  data: 0.2566  max mem: 3719\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 2.0137 (1.9147)  acc1: 31.2500 (33.4325)  acc5: 97.9167 (96.8254)  time: 0.1507  data: 0.0145  max mem: 3719\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.4372 (2.4675)  acc1: 20.8333 (26.2769)  acc5: 91.6667 (84.6102)  time: 0.1270  data: 0.0037  max mem: 3719\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.4031 (2.4777)  acc1: 18.7500 (27.2866)  acc5: 81.2500 (84.7561)  time: 0.1223  data: 0.0032  max mem: 3719\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 2.6387 (2.7439)  acc1: 16.6667 (23.7745)  acc5: 70.8333 (78.5948)  time: 0.1247  data: 0.0040  max mem: 3719\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.6904 (2.7777)  acc1: 10.4167 (22.4727)  acc5: 56.2500 (77.8347)  time: 0.1267  data: 0.0051  max mem: 3719\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 2.4779 (2.6890)  acc1: 20.8333 (25.4695)  acc5: 83.3333 (77.7582)  time: 0.1237  data: 0.0040  max mem: 3719\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8635 (2.4400)  acc1: 72.9167 (32.2016)  acc5: 97.9167 (80.2984)  time: 0.1204  data: 0.0012  max mem: 3719\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8635 (2.4212)  acc1: 75.0000 (32.6115)  acc5: 97.9167 (80.3822)  time: 0.1182  data: 0.0002  max mem: 3719\n",
            "Test: Total time: 0:00:13 (0.1666 s / it)\n",
            "* Acc@1 32.611 Acc@5 80.382 loss 2.421\n",
            "Accuracy of the model EMA on 3925 test images: 32.6%\n",
            "Max EMA accuracy: 32.61%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/result_tiny)... Done. 14.3s\n",
            "Training time 0:37:39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▂▃▃▂▅▅▆▃▆█▇█▇████▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▁▆▅▃▆▆▆▇▆▄▅▆▇▇▆▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema ▁▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss ██▅▇▇▄▇▄▆▄▃▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema ██▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss ▆▆▅█▅▃▅▄▅▂▃▂▃▁▁▃▂▃▁▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr █▇▇▆▆▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr █▇▇▆▆▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss ▆▂▆▁▇▇▇▄▄▅▂▄▂▆▅▇▇▆█▂▂▃▂▆▄▇▂▄▂▅▅▆▄██▂▇▇▄▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 83.13376\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema 32.61147\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 98.31847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema 80.38217\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.69954\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema 2.42122\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 2.39889\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 7299\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 2.77291\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 28589128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpolished-disco-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/pua791sp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 13 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230305_015215-pua791sp/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python main.py --model convnext_tiny --eval true \\\n",
        "                --resume /content/result_tiny/checkpoint-best.pth \\\n",
        "                --input_size 160 --drop_path 0.1 \\\n",
        "                --data_path /content/imagenette2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QGCyEXWjoSn",
        "outputId": "6f3dc083-54c3-4b13-b644-c10c61520b31"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny/checkpoint-best.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7f09730a1bb0>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f09730a15e0>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f09730a6250>\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 147\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 2940\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny/checkpoint-best.pth\n",
            "With optim & sched!\n",
            "Eval only mode\n",
            "Test:  [ 0/41]  eta: 0:05:43  loss: 0.4732 (0.4732)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 8.3831  data: 5.5230  max mem: 2077\n",
            "Test:  [10/41]  eta: 0:00:30  loss: 0.5149 (0.5176)  acc1: 90.6250 (91.2879)  acc5: 98.9583 (98.4849)  time: 0.9686  data: 0.5030  max mem: 2077\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5864 (0.6629)  acc1: 87.5000 (85.0198)  acc5: 98.9583 (98.6607)  time: 0.2276  data: 0.0023  max mem: 2077\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6847 (0.6927)  acc1: 80.2083 (83.5013)  acc5: 98.9583 (98.3871)  time: 0.2282  data: 0.0018  max mem: 2077\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6706 (0.6961)  acc1: 83.5294 (83.3885)  acc5: 97.9167 (98.1656)  time: 0.2312  data: 0.0002  max mem: 2077\n",
            "Test: Total time: 0:00:18 (0.4416 s / it)\n",
            "* Acc@1 83.389 Acc@5 98.166 loss 0.696\n",
            "Accuracy of the network on 3925 test images: 83.38854%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acc@1 after 100 epochs: 83.389"
      ],
      "metadata": {
        "id": "GTfbQwkPXluV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConvNeXt-T -- Batch 64, Augmentation Default\n",
        "- Batch size: 64\n",
        "- Epochs: 100\n",
        "- Update Freq: 4\n",
        "- Input Size: 160 (Imagenette2-160)\n",
        "- Learning rate: 0.004\n",
        "- Drop: 0.2\n"
      ],
      "metadata": {
        "id": "LXN_bF2KnQlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this approach, I tried to make the batch size bigger so the training will be stable. It might be more stable though since the Acc@1 EMA is the highest among all, but the Acc@1 is considered smaller than the ones with smaller batch size."
      ],
      "metadata": {
        "id": "5oizDIaYXout"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/result_tiny2\n",
        "%cd /content/ConvNeXt\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_tiny \\\n",
        "                                    --epochs 50 \\\n",
        "                                    --batch_size 64 \\\n",
        "                                    --lr 4e-3 \\\n",
        "                                    --update_freq 4 \\\n",
        "                                    --model_ema true \\\n",
        "                                    --model_ema_eval true \\\n",
        "                                    --aa original \\\n",
        "                                    --drop_path 0.1 \\\n",
        "                                    --opt adamw \\\n",
        "                                    --train_interpolation bicubic \\\n",
        "                                    --input_size 160 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --nb_classes 10 \\\n",
        "                                    --output_dir /content/result_tiny2 \\\n",
        "                                    --log_dir /content/result_tiny2 \\\n",
        "                                    --enable_wandb true --wandb_ckpt true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHwcOpTjnPtp",
        "outputId": "647fa003-6ac9-41dc-ddea-49c162165000"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt\n",
            "| distributed init (rank 0): env://, gpu 0\n",
            "Namespace(aa='original', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_backend='nccl', dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=True, drop_path=0.1, enable_wandb=True, epochs=50, eval=False, eval_data_path=None, finetune='', gpu=0, head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=0, log_dir='/content/result_tiny2', lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=True, model_ema_decay=0.9999, model_ema_eval=True, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=10, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/content/result_tiny2', pin_mem=True, project='convnext', rank=0, recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=4, use_amp=False, wandb_ckpt=True, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.AutoAugment object at 0x7f24b4b18940>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f24b4aa0490>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f24b4b1d190>\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlolikgiovi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ConvNeXt/wandb/run-20230305_023906-82quyc77\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mleafy-night-19\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/82quyc77\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Using EMA with decay = 0.99990000\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 256\n",
            "Update frequent = 4\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 36\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 720\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Auto resume checkpoint: \n",
            "Start training for 50 epochs\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [0]  [  0/147]  eta: 0:16:06  lr: 0.000000  min_lr: 0.000000  loss: 7.1009 (7.1009)  weight_decay: 0.0500 (0.0500)  time: 6.5722  data: 4.2783  max mem: 5388\n",
            "Epoch: [0]  [ 10/147]  eta: 0:02:19  lr: 0.000011  min_lr: 0.000011  loss: 7.0640 (7.0759)  weight_decay: 0.0500 (0.0500)  time: 1.0189  data: 0.3900  max mem: 5388\n",
            "Epoch: [0]  [ 20/147]  eta: 0:01:36  lr: 0.000028  min_lr: 0.000028  loss: 7.0116 (7.0287)  weight_decay: 0.0500 (0.0500)  time: 0.4673  data: 0.0009  max mem: 5388\n",
            "Epoch: [0]  [ 30/147]  eta: 0:01:18  lr: 0.000039  min_lr: 0.000039  loss: 6.8625 (6.9353)  weight_decay: 0.0500 (0.0500)  time: 0.4765  data: 0.0008  max mem: 5388\n",
            "Epoch: [0]  [ 40/147]  eta: 0:01:06  lr: 0.000056  min_lr: 0.000056  loss: 6.5492 (6.8102)  weight_decay: 0.0500 (0.0500)  time: 0.4808  data: 0.0011  max mem: 5388\n",
            "Epoch: [0]  [ 50/147]  eta: 0:00:57  lr: 0.000067  min_lr: 0.000067  loss: 6.2277 (6.6550)  weight_decay: 0.0500 (0.0500)  time: 0.4756  data: 0.0011  max mem: 5388\n",
            "Epoch: [0]  [ 60/147]  eta: 0:00:50  lr: 0.000083  min_lr: 0.000083  loss: 5.8882 (6.5175)  weight_decay: 0.0500 (0.0500)  time: 0.4794  data: 0.0017  max mem: 5388\n",
            "Epoch: [0]  [ 70/147]  eta: 0:00:43  lr: 0.000095  min_lr: 0.000095  loss: 5.6270 (6.3531)  weight_decay: 0.0500 (0.0500)  time: 0.4906  data: 0.0021  max mem: 5388\n",
            "Epoch: [0]  [ 80/147]  eta: 0:00:37  lr: 0.000111  min_lr: 0.000111  loss: 5.0928 (6.1683)  weight_decay: 0.0500 (0.0500)  time: 0.4897  data: 0.0021  max mem: 5388\n",
            "Epoch: [0]  [ 90/147]  eta: 0:00:31  lr: 0.000122  min_lr: 0.000122  loss: 4.6156 (5.9932)  weight_decay: 0.0500 (0.0500)  time: 0.4875  data: 0.0023  max mem: 5388\n",
            "Epoch: [0]  [100/147]  eta: 0:00:25  lr: 0.000139  min_lr: 0.000139  loss: 4.3489 (5.8180)  weight_decay: 0.0500 (0.0500)  time: 0.4997  data: 0.0035  max mem: 5388\n",
            "Epoch: [0]  [110/147]  eta: 0:00:19  lr: 0.000150  min_lr: 0.000150  loss: 4.1250 (5.6722)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0036  max mem: 5388\n",
            "Epoch: [0]  [120/147]  eta: 0:00:14  lr: 0.000167  min_lr: 0.000167  loss: 4.0760 (5.5389)  weight_decay: 0.0500 (0.0500)  time: 0.4972  data: 0.0027  max mem: 5388\n",
            "Epoch: [0]  [130/147]  eta: 0:00:09  lr: 0.000178  min_lr: 0.000178  loss: 4.0199 (5.4182)  weight_decay: 0.0500 (0.0500)  time: 0.5004  data: 0.0018  max mem: 5388\n",
            "Epoch: [0]  [140/147]  eta: 0:00:03  lr: 0.000195  min_lr: 0.000195  loss: 4.0199 (5.3327)  weight_decay: 0.0500 (0.0500)  time: 0.5027  data: 0.0005  max mem: 5388\n",
            "Epoch: [0]  [146/147]  eta: 0:00:00  lr: 0.000195  min_lr: 0.000195  loss: 4.1212 (5.3031)  weight_decay: 0.0500 (0.0500)  time: 0.4287  data: 0.0002  max mem: 5388\n",
            "Epoch: [0] Total time: 0:01:17 (0.5239 s / it)\n",
            "Averaged stats: lr: 0.000195  min_lr: 0.000195  loss: 4.1212 (5.3031)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:03  loss: 5.2411 (5.2411)  acc1: 0.0000 (0.0000)  acc5: 23.9583 (23.9583)  time: 5.9296  data: 5.1136  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 4.7089 (4.5206)  acc1: 16.6667 (12.8788)  acc5: 60.4167 (54.0720)  time: 0.7756  data: 0.4680  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.9884 (4.8940)  acc1: 4.1667 (8.6310)  acc5: 31.2500 (40.8234)  time: 0.2573  data: 0.0063  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.0738 (4.8222)  acc1: 4.1667 (8.3669)  acc5: 36.4583 (48.5887)  time: 0.2608  data: 0.0188  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1219 (4.5964)  acc1: 7.2917 (10.5732)  acc5: 63.5417 (50.0892)  time: 0.2553  data: 0.0142  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.4034 s / it)\n",
            "* Acc@1 10.573 Acc@5 50.089 loss 4.596\n",
            "Accuracy of the model on the 3925 test images: 10.6%\n",
            "Max accuracy: 10.57%\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 7.3557 (7.3557)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.4909  data: 3.2046  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 7.0105 (7.1250)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.5336  data: 0.2933  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 7.0168 (7.0876)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.2441  data: 0.0023  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 7.0168 (7.0526)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0672)  time: 0.2781  data: 0.0259  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 7.0208 (7.0587)  acc1: 0.0000 (0.0510)  acc5: 0.0000 (0.2803)  time: 0.2702  data: 0.0247  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3445 s / it)\n",
            "* Acc@1 0.051 Acc@5 0.280 loss 7.059\n",
            "Accuracy of the model EMA on 3925 test images: 0.1%\n",
            "Max EMA accuracy: 0.05%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [1]  [  0/147]  eta: 0:07:15  lr: 0.000200  min_lr: 0.000200  loss: 3.6034 (3.6034)  weight_decay: 0.0500 (0.0500)  time: 2.9616  data: 2.3673  max mem: 5388\n",
            "Epoch: [1]  [ 10/147]  eta: 0:01:40  lr: 0.000211  min_lr: 0.000211  loss: 3.9957 (4.0937)  weight_decay: 0.0500 (0.0500)  time: 0.7352  data: 0.2165  max mem: 5388\n",
            "Epoch: [1]  [ 20/147]  eta: 0:01:20  lr: 0.000228  min_lr: 0.000228  loss: 3.9853 (4.0055)  weight_decay: 0.0500 (0.0500)  time: 0.5142  data: 0.0013  max mem: 5388\n",
            "Epoch: [1]  [ 30/147]  eta: 0:01:09  lr: 0.000239  min_lr: 0.000239  loss: 3.8478 (3.9202)  weight_decay: 0.0500 (0.0500)  time: 0.5105  data: 0.0023  max mem: 5388\n",
            "Epoch: [1]  [ 40/147]  eta: 0:01:00  lr: 0.000256  min_lr: 0.000256  loss: 3.6128 (3.8313)  weight_decay: 0.0500 (0.0500)  time: 0.5021  data: 0.0027  max mem: 5388\n",
            "Epoch: [1]  [ 50/147]  eta: 0:00:53  lr: 0.000267  min_lr: 0.000267  loss: 3.3884 (3.7479)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0013  max mem: 5388\n",
            "Epoch: [1]  [ 60/147]  eta: 0:00:47  lr: 0.000284  min_lr: 0.000284  loss: 3.2508 (3.6547)  weight_decay: 0.0500 (0.0500)  time: 0.5109  data: 0.0018  max mem: 5388\n",
            "Epoch: [1]  [ 70/147]  eta: 0:00:41  lr: 0.000295  min_lr: 0.000295  loss: 3.1297 (3.5787)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0024  max mem: 5388\n",
            "Epoch: [1]  [ 80/147]  eta: 0:00:35  lr: 0.000312  min_lr: 0.000312  loss: 3.1119 (3.5215)  weight_decay: 0.0500 (0.0500)  time: 0.4976  data: 0.0020  max mem: 5388\n",
            "Epoch: [1]  [ 90/147]  eta: 0:00:30  lr: 0.000323  min_lr: 0.000323  loss: 3.1074 (3.4738)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0030  max mem: 5388\n",
            "Epoch: [1]  [100/147]  eta: 0:00:24  lr: 0.000339  min_lr: 0.000339  loss: 3.0813 (3.4356)  weight_decay: 0.0500 (0.0500)  time: 0.5027  data: 0.0027  max mem: 5388\n",
            "Epoch: [1]  [110/147]  eta: 0:00:19  lr: 0.000350  min_lr: 0.000350  loss: 3.0813 (3.4042)  weight_decay: 0.0500 (0.0500)  time: 0.4969  data: 0.0018  max mem: 5388\n",
            "Epoch: [1]  [120/147]  eta: 0:00:14  lr: 0.000367  min_lr: 0.000367  loss: 3.0769 (3.3770)  weight_decay: 0.0500 (0.0500)  time: 0.4990  data: 0.0027  max mem: 5388\n",
            "Epoch: [1]  [130/147]  eta: 0:00:08  lr: 0.000378  min_lr: 0.000378  loss: 3.0807 (3.3557)  weight_decay: 0.0500 (0.0500)  time: 0.5052  data: 0.0024  max mem: 5388\n",
            "Epoch: [1]  [140/147]  eta: 0:00:03  lr: 0.000395  min_lr: 0.000395  loss: 3.0759 (3.3349)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0008  max mem: 5388\n",
            "Epoch: [1]  [146/147]  eta: 0:00:00  lr: 0.000395  min_lr: 0.000395  loss: 3.0713 (3.3293)  weight_decay: 0.0500 (0.0500)  time: 0.4220  data: 0.0002  max mem: 5388\n",
            "Epoch: [1] Total time: 0:01:15 (0.5127 s / it)\n",
            "Averaged stats: lr: 0.000395  min_lr: 0.000395  loss: 3.0713 (3.3293)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:34  loss: 2.5000 (2.5000)  acc1: 0.0000 (0.0000)  acc5: 16.6667 (16.6667)  time: 3.7707  data: 3.4816  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 2.4952 (2.4755)  acc1: 0.0000 (4.4508)  acc5: 15.6250 (31.0606)  time: 0.6822  data: 0.4445  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 2.3465 (2.3893)  acc1: 0.0000 (4.5139)  acc5: 76.0417 (56.4980)  time: 0.3602  data: 0.1274  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.2281 (2.3395)  acc1: 4.1667 (14.4489)  acc5: 91.6667 (63.8777)  time: 0.3074  data: 0.0741  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.1677 (2.2951)  acc1: 48.9583 (22.8790)  acc5: 77.0833 (65.5541)  time: 0.2479  data: 0.0171  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.3977 s / it)\n",
            "* Acc@1 22.879 Acc@5 65.554 loss 2.295\n",
            "Accuracy of the model on the 3925 test images: 22.9%\n",
            "Max accuracy: 22.88%\n",
            "Test:  [ 0/41]  eta: 0:02:03  loss: 7.3479 (7.3479)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.0168  data: 2.7145  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 6.9980 (7.1127)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.5897  data: 0.3438  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 7.0043 (7.0773)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.3484  data: 0.1053  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 7.0043 (7.0405)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0672)  time: 0.3083  data: 0.0670  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 7.0066 (7.0449)  acc1: 0.0000 (0.0510)  acc5: 0.0000 (0.2293)  time: 0.2495  data: 0.0156  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3753 s / it)\n",
            "* Acc@1 0.051 Acc@5 0.229 loss 7.045\n",
            "Accuracy of the model EMA on 3925 test images: 0.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [2]  [  0/147]  eta: 0:06:30  lr: 0.000401  min_lr: 0.000401  loss: 3.0267 (3.0267)  weight_decay: 0.0500 (0.0500)  time: 2.6587  data: 2.0639  max mem: 5388\n",
            "Epoch: [2]  [ 10/147]  eta: 0:01:37  lr: 0.000412  min_lr: 0.000412  loss: 3.0749 (3.0702)  weight_decay: 0.0500 (0.0500)  time: 0.7145  data: 0.1903  max mem: 5388\n",
            "Epoch: [2]  [ 20/147]  eta: 0:01:19  lr: 0.000428  min_lr: 0.000428  loss: 3.0721 (3.0660)  weight_decay: 0.0500 (0.0500)  time: 0.5219  data: 0.0019  max mem: 5388\n",
            "Epoch: [2]  [ 30/147]  eta: 0:01:09  lr: 0.000439  min_lr: 0.000439  loss: 3.0643 (3.0665)  weight_decay: 0.0500 (0.0500)  time: 0.5225  data: 0.0016  max mem: 5388\n",
            "Epoch: [2]  [ 40/147]  eta: 0:01:01  lr: 0.000456  min_lr: 0.000456  loss: 3.0704 (3.0690)  weight_decay: 0.0500 (0.0500)  time: 0.5149  data: 0.0019  max mem: 5388\n",
            "Epoch: [2]  [ 50/147]  eta: 0:00:54  lr: 0.000467  min_lr: 0.000467  loss: 3.0657 (3.0683)  weight_decay: 0.0500 (0.0500)  time: 0.5052  data: 0.0021  max mem: 5388\n",
            "Epoch: [2]  [ 60/147]  eta: 0:00:47  lr: 0.000484  min_lr: 0.000484  loss: 3.0661 (3.0669)  weight_decay: 0.0500 (0.0500)  time: 0.5054  data: 0.0024  max mem: 5388\n",
            "Epoch: [2]  [ 70/147]  eta: 0:00:41  lr: 0.000495  min_lr: 0.000495  loss: 3.0683 (3.0662)  weight_decay: 0.0500 (0.0500)  time: 0.5065  data: 0.0021  max mem: 5388\n",
            "Epoch: [2]  [ 80/147]  eta: 0:00:35  lr: 0.000512  min_lr: 0.000512  loss: 3.0757 (3.0694)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0014  max mem: 5388\n",
            "Epoch: [2]  [ 90/147]  eta: 0:00:30  lr: 0.000523  min_lr: 0.000523  loss: 3.0873 (3.0735)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0014  max mem: 5388\n",
            "Epoch: [2]  [100/147]  eta: 0:00:24  lr: 0.000540  min_lr: 0.000540  loss: 3.0867 (3.0782)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0031  max mem: 5388\n",
            "Epoch: [2]  [110/147]  eta: 0:00:19  lr: 0.000551  min_lr: 0.000551  loss: 3.0809 (3.0776)  weight_decay: 0.0500 (0.0500)  time: 0.5010  data: 0.0027  max mem: 5388\n",
            "Epoch: [2]  [120/147]  eta: 0:00:14  lr: 0.000567  min_lr: 0.000567  loss: 3.0748 (3.0781)  weight_decay: 0.0500 (0.0500)  time: 0.4954  data: 0.0011  max mem: 5388\n",
            "Epoch: [2]  [130/147]  eta: 0:00:08  lr: 0.000579  min_lr: 0.000579  loss: 3.0748 (3.0779)  weight_decay: 0.0500 (0.0500)  time: 0.5007  data: 0.0012  max mem: 5388\n",
            "Epoch: [2]  [140/147]  eta: 0:00:03  lr: 0.000595  min_lr: 0.000595  loss: 3.0762 (3.0787)  weight_decay: 0.0500 (0.0500)  time: 0.5007  data: 0.0009  max mem: 5388\n",
            "Epoch: [2]  [146/147]  eta: 0:00:00  lr: 0.000595  min_lr: 0.000595  loss: 3.0762 (3.0792)  weight_decay: 0.0500 (0.0500)  time: 0.4213  data: 0.0002  max mem: 5388\n",
            "Epoch: [2] Total time: 0:01:15 (0.5126 s / it)\n",
            "Averaged stats: lr: 0.000595  min_lr: 0.000595  loss: 3.0762 (3.0792)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:06  loss: 2.1226 (2.1226)  acc1: 31.2500 (31.2500)  acc5: 89.5833 (89.5833)  time: 3.0745  data: 2.7623  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 2.1226 (2.2433)  acc1: 31.2500 (22.8220)  acc5: 87.5000 (72.7273)  time: 0.5280  data: 0.2875  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 2.4288 (2.4138)  acc1: 0.0000 (16.1210)  acc5: 54.1667 (56.5972)  time: 0.2778  data: 0.0446  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.4175 (2.3614)  acc1: 0.0000 (18.9516)  acc5: 57.2917 (61.7272)  time: 0.3001  data: 0.0673  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.2251 (2.2993)  acc1: 12.5000 (22.1401)  acc5: 87.0588 (62.3185)  time: 0.2811  data: 0.0521  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3573 s / it)\n",
            "* Acc@1 22.140 Acc@5 62.318 loss 2.299\n",
            "Accuracy of the model on the 3925 test images: 22.1%\n",
            "Max accuracy: 22.88%\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 7.3358 (7.3358)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.1821  data: 2.8833  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 6.9861 (7.0975)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.5176  data: 0.2798  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.9899 (7.0647)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.2466  data: 0.0122  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.9899 (7.0263)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0672)  time: 0.2407  data: 0.0025  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.9911 (7.0283)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.2293)  time: 0.2352  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3242 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.229 loss 7.028\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [3]  [  0/147]  eta: 0:07:28  lr: 0.000601  min_lr: 0.000601  loss: 3.0930 (3.0930)  weight_decay: 0.0500 (0.0500)  time: 3.0504  data: 2.4835  max mem: 5388\n",
            "Epoch: [3]  [ 10/147]  eta: 0:01:50  lr: 0.000612  min_lr: 0.000612  loss: 3.0531 (3.0647)  weight_decay: 0.0500 (0.0500)  time: 0.8096  data: 0.2291  max mem: 5388\n",
            "Epoch: [3]  [ 20/147]  eta: 0:01:24  lr: 0.000629  min_lr: 0.000629  loss: 3.0501 (3.0584)  weight_decay: 0.0500 (0.0500)  time: 0.5467  data: 0.0020  max mem: 5388\n",
            "Epoch: [3]  [ 30/147]  eta: 0:01:12  lr: 0.000640  min_lr: 0.000640  loss: 3.0519 (3.0591)  weight_decay: 0.0500 (0.0500)  time: 0.5124  data: 0.0027  max mem: 5388\n",
            "Epoch: [3]  [ 40/147]  eta: 0:01:03  lr: 0.000656  min_lr: 0.000656  loss: 3.0519 (3.0555)  weight_decay: 0.0500 (0.0500)  time: 0.5141  data: 0.0042  max mem: 5388\n",
            "Epoch: [3]  [ 50/147]  eta: 0:00:55  lr: 0.000668  min_lr: 0.000668  loss: 3.0512 (3.0565)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0021  max mem: 5388\n",
            "Epoch: [3]  [ 60/147]  eta: 0:00:49  lr: 0.000684  min_lr: 0.000684  loss: 3.0682 (3.0612)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0013  max mem: 5388\n",
            "Epoch: [3]  [ 70/147]  eta: 0:00:42  lr: 0.000695  min_lr: 0.000695  loss: 3.0705 (3.0628)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0031  max mem: 5388\n",
            "Epoch: [3]  [ 80/147]  eta: 0:00:36  lr: 0.000712  min_lr: 0.000712  loss: 3.0611 (3.0613)  weight_decay: 0.0500 (0.0500)  time: 0.5046  data: 0.0024  max mem: 5388\n",
            "Epoch: [3]  [ 90/147]  eta: 0:00:31  lr: 0.000723  min_lr: 0.000723  loss: 3.0598 (3.0618)  weight_decay: 0.0500 (0.0500)  time: 0.5006  data: 0.0022  max mem: 5388\n",
            "Epoch: [3]  [100/147]  eta: 0:00:25  lr: 0.000740  min_lr: 0.000740  loss: 3.0609 (3.0624)  weight_decay: 0.0500 (0.0500)  time: 0.5056  data: 0.0041  max mem: 5388\n",
            "Epoch: [3]  [110/147]  eta: 0:00:19  lr: 0.000751  min_lr: 0.000751  loss: 3.0666 (3.0633)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0037  max mem: 5388\n",
            "Epoch: [3]  [120/147]  eta: 0:00:14  lr: 0.000768  min_lr: 0.000768  loss: 3.0666 (3.0636)  weight_decay: 0.0500 (0.0500)  time: 0.5056  data: 0.0046  max mem: 5388\n",
            "Epoch: [3]  [130/147]  eta: 0:00:09  lr: 0.000779  min_lr: 0.000779  loss: 3.0811 (3.0655)  weight_decay: 0.0500 (0.0500)  time: 0.5021  data: 0.0045  max mem: 5388\n",
            "Epoch: [3]  [140/147]  eta: 0:00:03  lr: 0.000796  min_lr: 0.000796  loss: 3.1028 (3.0693)  weight_decay: 0.0500 (0.0500)  time: 0.4983  data: 0.0016  max mem: 5388\n",
            "Epoch: [3]  [146/147]  eta: 0:00:00  lr: 0.000796  min_lr: 0.000796  loss: 3.1034 (3.0705)  weight_decay: 0.0500 (0.0500)  time: 0.4209  data: 0.0002  max mem: 5388\n",
            "Epoch: [3] Total time: 0:01:16 (0.5217 s / it)\n",
            "Averaged stats: lr: 0.000796  min_lr: 0.000796  loss: 3.1034 (3.0705)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:26  loss: 2.0186 (2.0186)  acc1: 35.4167 (35.4167)  acc5: 90.6250 (90.6250)  time: 3.5634  data: 3.3003  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 2.3439 (2.2669)  acc1: 6.2500 (17.2348)  acc5: 78.1250 (71.7803)  time: 0.5463  data: 0.3007  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 2.3088 (2.2513)  acc1: 5.2083 (13.5417)  acc5: 76.0417 (76.6369)  time: 0.2578  data: 0.0158  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.2933 (2.3065)  acc1: 2.0833 (17.5739)  acc5: 73.9583 (69.8589)  time: 0.2906  data: 0.0521  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.2891 (2.2256)  acc1: 2.0833 (21.8854)  acc5: 67.7083 (69.7580)  time: 0.2766  data: 0.0447  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3565 s / it)\n",
            "* Acc@1 21.885 Acc@5 69.758 loss 2.226\n",
            "Accuracy of the model on the 3925 test images: 21.9%\n",
            "Max accuracy: 22.88%\n",
            "Test:  [ 0/41]  eta: 0:02:02  loss: 7.3232 (7.3232)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.9897  data: 2.6658  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 6.9727 (7.0813)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0947)  time: 0.4882  data: 0.2438  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:07  loss: 6.9743 (7.0513)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0496)  time: 0.2388  data: 0.0022  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.9743 (7.0110)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.1008)  time: 0.2408  data: 0.0014  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.9744 (7.0105)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.2548)  time: 0.2376  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3177 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.255 loss 7.011\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [4]  [  0/147]  eta: 0:09:37  lr: 0.000801  min_lr: 0.000801  loss: 3.1229 (3.1229)  weight_decay: 0.0500 (0.0500)  time: 3.9286  data: 3.3526  max mem: 5388\n",
            "Epoch: [4]  [ 10/147]  eta: 0:01:52  lr: 0.000812  min_lr: 0.000812  loss: 3.1126 (3.0789)  weight_decay: 0.0500 (0.0500)  time: 0.8188  data: 0.3053  max mem: 5388\n",
            "Epoch: [4]  [ 20/147]  eta: 0:01:25  lr: 0.000829  min_lr: 0.000829  loss: 3.0520 (3.0726)  weight_decay: 0.0500 (0.0500)  time: 0.5093  data: 0.0008  max mem: 5388\n",
            "Epoch: [4]  [ 30/147]  eta: 0:01:12  lr: 0.000840  min_lr: 0.000840  loss: 3.0463 (3.0636)  weight_decay: 0.0500 (0.0500)  time: 0.5119  data: 0.0032  max mem: 5388\n",
            "Epoch: [4]  [ 40/147]  eta: 0:01:03  lr: 0.000857  min_lr: 0.000857  loss: 3.0199 (3.0595)  weight_decay: 0.0500 (0.0500)  time: 0.5109  data: 0.0036  max mem: 5388\n",
            "Epoch: [4]  [ 50/147]  eta: 0:00:55  lr: 0.000868  min_lr: 0.000868  loss: 3.0657 (3.0595)  weight_decay: 0.0500 (0.0500)  time: 0.5072  data: 0.0016  max mem: 5388\n",
            "Epoch: [4]  [ 60/147]  eta: 0:00:49  lr: 0.000885  min_lr: 0.000885  loss: 3.0694 (3.0597)  weight_decay: 0.0500 (0.0500)  time: 0.5115  data: 0.0037  max mem: 5388\n",
            "Epoch: [4]  [ 70/147]  eta: 0:00:42  lr: 0.000896  min_lr: 0.000896  loss: 3.0694 (3.0595)  weight_decay: 0.0500 (0.0500)  time: 0.5094  data: 0.0031  max mem: 5388\n",
            "Epoch: [4]  [ 80/147]  eta: 0:00:36  lr: 0.000912  min_lr: 0.000912  loss: 3.0441 (3.0554)  weight_decay: 0.0500 (0.0500)  time: 0.5000  data: 0.0012  max mem: 5388\n",
            "Epoch: [4]  [ 90/147]  eta: 0:00:31  lr: 0.000924  min_lr: 0.000924  loss: 3.0213 (3.0525)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0019  max mem: 5388\n",
            "Epoch: [4]  [100/147]  eta: 0:00:25  lr: 0.000940  min_lr: 0.000940  loss: 3.0213 (3.0502)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0028  max mem: 5388\n",
            "Epoch: [4]  [110/147]  eta: 0:00:19  lr: 0.000951  min_lr: 0.000951  loss: 3.0346 (3.0494)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0031  max mem: 5388\n",
            "Epoch: [4]  [120/147]  eta: 0:00:14  lr: 0.000968  min_lr: 0.000968  loss: 3.0359 (3.0474)  weight_decay: 0.0500 (0.0500)  time: 0.4962  data: 0.0026  max mem: 5388\n",
            "Epoch: [4]  [130/147]  eta: 0:00:09  lr: 0.000979  min_lr: 0.000979  loss: 3.0301 (3.0459)  weight_decay: 0.0500 (0.0500)  time: 0.4976  data: 0.0028  max mem: 5388\n",
            "Epoch: [4]  [140/147]  eta: 0:00:03  lr: 0.000996  min_lr: 0.000996  loss: 3.0176 (3.0442)  weight_decay: 0.0500 (0.0500)  time: 0.4959  data: 0.0014  max mem: 5388\n",
            "Epoch: [4]  [146/147]  eta: 0:00:00  lr: 0.000996  min_lr: 0.000996  loss: 3.0142 (3.0432)  weight_decay: 0.0500 (0.0500)  time: 0.4198  data: 0.0002  max mem: 5388\n",
            "Epoch: [4] Total time: 0:01:16 (0.5196 s / it)\n",
            "Averaged stats: lr: 0.000996  min_lr: 0.000996  loss: 3.0142 (3.0432)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:54  loss: 1.9791 (1.9791)  acc1: 44.7917 (44.7917)  acc5: 98.9583 (98.9583)  time: 2.7946  data: 2.4929  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 2.0870 (2.2483)  acc1: 44.7917 (33.6174)  acc5: 86.4583 (67.8030)  time: 0.5686  data: 0.3303  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 2.0870 (2.2061)  acc1: 39.5833 (31.1012)  acc5: 86.4583 (76.7361)  time: 0.3459  data: 0.1149  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.3099 (2.3012)  acc1: 2.0833 (21.5054)  acc5: 64.5833 (66.8011)  time: 0.3192  data: 0.0866  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.3158 (2.2169)  acc1: 2.0833 (25.2994)  acc5: 64.5833 (68.6115)  time: 0.2592  data: 0.0287  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3716 s / it)\n",
            "* Acc@1 25.299 Acc@5 68.611 loss 2.217\n",
            "Accuracy of the model on the 3925 test images: 25.3%\n",
            "Max accuracy: 25.30%\n",
            "Test:  [ 0/41]  eta: 0:02:06  loss: 7.3093 (7.3093)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.0800  data: 2.7833  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 6.9576 (7.0634)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0947)  time: 0.5181  data: 0.2769  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.9576 (7.0364)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0496)  time: 0.3105  data: 0.0728  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.9570 (6.9944)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.1008)  time: 0.3795  data: 0.1391  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.9570 (6.9909)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.2293)  time: 0.3220  data: 0.0844  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.3977 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.229 loss 6.991\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [5]  [  0/147]  eta: 0:07:55  lr: 0.001001  min_lr: 0.001001  loss: 3.0052 (3.0052)  weight_decay: 0.0500 (0.0500)  time: 3.2326  data: 2.6419  max mem: 5388\n",
            "Epoch: [5]  [ 10/147]  eta: 0:01:44  lr: 0.001013  min_lr: 0.001013  loss: 3.0273 (3.0292)  weight_decay: 0.0500 (0.0500)  time: 0.7593  data: 0.2413  max mem: 5388\n",
            "Epoch: [5]  [ 20/147]  eta: 0:01:21  lr: 0.001029  min_lr: 0.001029  loss: 3.0273 (3.0247)  weight_decay: 0.0500 (0.0500)  time: 0.5136  data: 0.0025  max mem: 5388\n",
            "Epoch: [5]  [ 30/147]  eta: 0:01:10  lr: 0.001040  min_lr: 0.001040  loss: 3.0198 (3.0215)  weight_decay: 0.0500 (0.0500)  time: 0.5151  data: 0.0026  max mem: 5388\n",
            "Epoch: [5]  [ 40/147]  eta: 0:01:02  lr: 0.001057  min_lr: 0.001057  loss: 3.0235 (3.0291)  weight_decay: 0.0500 (0.0500)  time: 0.5134  data: 0.0028  max mem: 5388\n",
            "Epoch: [5]  [ 50/147]  eta: 0:00:54  lr: 0.001068  min_lr: 0.001068  loss: 3.0375 (3.0272)  weight_decay: 0.0500 (0.0500)  time: 0.5114  data: 0.0025  max mem: 5388\n",
            "Epoch: [5]  [ 60/147]  eta: 0:00:48  lr: 0.001085  min_lr: 0.001085  loss: 3.0433 (3.0294)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0021  max mem: 5388\n",
            "Epoch: [5]  [ 70/147]  eta: 0:00:42  lr: 0.001096  min_lr: 0.001096  loss: 3.0292 (3.0284)  weight_decay: 0.0500 (0.0500)  time: 0.5108  data: 0.0027  max mem: 5388\n",
            "Epoch: [5]  [ 80/147]  eta: 0:00:36  lr: 0.001113  min_lr: 0.001113  loss: 3.0292 (3.0307)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0025  max mem: 5388\n",
            "Epoch: [5]  [ 90/147]  eta: 0:00:30  lr: 0.001124  min_lr: 0.001124  loss: 3.0031 (3.0282)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0039  max mem: 5388\n",
            "Epoch: [5]  [100/147]  eta: 0:00:25  lr: 0.001140  min_lr: 0.001140  loss: 3.0031 (3.0284)  weight_decay: 0.0500 (0.0500)  time: 0.5033  data: 0.0033  max mem: 5388\n",
            "Epoch: [5]  [110/147]  eta: 0:00:19  lr: 0.001152  min_lr: 0.001152  loss: 3.0049 (3.0244)  weight_decay: 0.0500 (0.0500)  time: 0.4981  data: 0.0012  max mem: 5388\n",
            "Epoch: [5]  [120/147]  eta: 0:00:14  lr: 0.001168  min_lr: 0.001168  loss: 3.0049 (3.0263)  weight_decay: 0.0500 (0.0500)  time: 0.4949  data: 0.0011  max mem: 5388\n",
            "Epoch: [5]  [130/147]  eta: 0:00:08  lr: 0.001179  min_lr: 0.001179  loss: 3.0386 (3.0262)  weight_decay: 0.0500 (0.0500)  time: 0.4964  data: 0.0008  max mem: 5388\n",
            "Epoch: [5]  [140/147]  eta: 0:00:03  lr: 0.001196  min_lr: 0.001196  loss: 3.0059 (3.0261)  weight_decay: 0.0500 (0.0500)  time: 0.4945  data: 0.0002  max mem: 5388\n",
            "Epoch: [5]  [146/147]  eta: 0:00:00  lr: 0.001196  min_lr: 0.001196  loss: 3.0081 (3.0263)  weight_decay: 0.0500 (0.0500)  time: 0.4183  data: 0.0002  max mem: 5388\n",
            "Epoch: [5] Total time: 0:01:15 (0.5155 s / it)\n",
            "Averaged stats: lr: 0.001196  min_lr: 0.001196  loss: 3.0081 (3.0263)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:59  loss: 2.6028 (2.6028)  acc1: 2.0833 (2.0833)  acc5: 30.2083 (30.2083)  time: 2.9120  data: 2.6491  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 2.1070 (2.2535)  acc1: 28.1250 (23.5795)  acc5: 85.4167 (70.5492)  time: 0.5322  data: 0.2738  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 2.0841 (2.1492)  acc1: 35.4167 (24.5536)  acc5: 85.4167 (78.8194)  time: 0.3104  data: 0.0609  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.2265 (2.1634)  acc1: 8.3333 (24.5968)  acc5: 84.3750 (77.2849)  time: 0.3283  data: 0.0887  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.3723 (2.1101)  acc1: 16.6667 (27.7707)  acc5: 71.8750 (75.8726)  time: 0.2786  data: 0.0460  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3680 s / it)\n",
            "* Acc@1 27.771 Acc@5 75.873 loss 2.110\n",
            "Accuracy of the model on the 3925 test images: 27.8%\n",
            "Max accuracy: 27.77%\n",
            "Test:  [ 0/41]  eta: 0:02:28  loss: 7.2938 (7.2938)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.6326  data: 3.3265  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 6.9417 (7.0442)  acc1: 0.0000 (0.0947)  acc5: 0.0000 (0.0947)  time: 0.5509  data: 0.3055  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.9404 (7.0202)  acc1: 0.0000 (0.0496)  acc5: 0.0000 (0.0496)  time: 0.2704  data: 0.0304  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.9380 (6.9764)  acc1: 0.0000 (0.0336)  acc5: 0.0000 (0.1008)  time: 0.3072  data: 0.0653  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.9306 (6.9696)  acc1: 0.0000 (0.0510)  acc5: 0.0000 (0.2548)  time: 0.2749  data: 0.0366  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3635 s / it)\n",
            "* Acc@1 0.051 Acc@5 0.255 loss 6.970\n",
            "Accuracy of the model EMA on 3925 test images: 0.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [6]  [  0/147]  eta: 0:07:14  lr: 0.001202  min_lr: 0.001202  loss: 3.1006 (3.1006)  weight_decay: 0.0500 (0.0500)  time: 2.9531  data: 2.3754  max mem: 5388\n",
            "Epoch: [6]  [ 10/147]  eta: 0:01:40  lr: 0.001213  min_lr: 0.001213  loss: 3.0588 (3.0431)  weight_decay: 0.0500 (0.0500)  time: 0.7354  data: 0.2183  max mem: 5388\n",
            "Epoch: [6]  [ 20/147]  eta: 0:01:20  lr: 0.001229  min_lr: 0.001229  loss: 3.0235 (3.0306)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0024  max mem: 5388\n",
            "Epoch: [6]  [ 30/147]  eta: 0:01:09  lr: 0.001241  min_lr: 0.001241  loss: 3.0157 (3.0313)  weight_decay: 0.0500 (0.0500)  time: 0.5138  data: 0.0014  max mem: 5388\n",
            "Epoch: [6]  [ 40/147]  eta: 0:01:01  lr: 0.001257  min_lr: 0.001257  loss: 3.0001 (3.0269)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0008  max mem: 5388\n",
            "Epoch: [6]  [ 50/147]  eta: 0:00:54  lr: 0.001268  min_lr: 0.001268  loss: 2.9994 (3.0206)  weight_decay: 0.0500 (0.0500)  time: 0.5088  data: 0.0008  max mem: 5388\n",
            "Epoch: [6]  [ 60/147]  eta: 0:00:48  lr: 0.001285  min_lr: 0.001285  loss: 2.9913 (3.0163)  weight_decay: 0.0500 (0.0500)  time: 0.5156  data: 0.0011  max mem: 5388\n",
            "Epoch: [6]  [ 70/147]  eta: 0:00:42  lr: 0.001296  min_lr: 0.001296  loss: 3.0015 (3.0189)  weight_decay: 0.0500 (0.0500)  time: 0.5195  data: 0.0043  max mem: 5388\n",
            "Epoch: [6]  [ 80/147]  eta: 0:00:36  lr: 0.001313  min_lr: 0.001313  loss: 3.0298 (3.0188)  weight_decay: 0.0500 (0.0500)  time: 0.5076  data: 0.0058  max mem: 5388\n",
            "Epoch: [6]  [ 90/147]  eta: 0:00:30  lr: 0.001324  min_lr: 0.001324  loss: 3.0219 (3.0195)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0038  max mem: 5388\n",
            "Epoch: [6]  [100/147]  eta: 0:00:25  lr: 0.001341  min_lr: 0.001341  loss: 2.9993 (3.0187)  weight_decay: 0.0500 (0.0500)  time: 0.4979  data: 0.0034  max mem: 5388\n",
            "Epoch: [6]  [110/147]  eta: 0:00:19  lr: 0.001352  min_lr: 0.001352  loss: 2.9993 (3.0185)  weight_decay: 0.0500 (0.0500)  time: 0.4967  data: 0.0036  max mem: 5388\n",
            "Epoch: [6]  [120/147]  eta: 0:00:14  lr: 0.001369  min_lr: 0.001369  loss: 3.0266 (3.0194)  weight_decay: 0.0500 (0.0500)  time: 0.4926  data: 0.0033  max mem: 5388\n",
            "Epoch: [6]  [130/147]  eta: 0:00:08  lr: 0.001380  min_lr: 0.001380  loss: 3.0176 (3.0184)  weight_decay: 0.0500 (0.0500)  time: 0.4940  data: 0.0030  max mem: 5388\n",
            "Epoch: [6]  [140/147]  eta: 0:00:03  lr: 0.001396  min_lr: 0.001396  loss: 3.0263 (3.0200)  weight_decay: 0.0500 (0.0500)  time: 0.4956  data: 0.0015  max mem: 5388\n",
            "Epoch: [6]  [146/147]  eta: 0:00:00  lr: 0.001396  min_lr: 0.001396  loss: 3.0443 (3.0194)  weight_decay: 0.0500 (0.0500)  time: 0.4206  data: 0.0002  max mem: 5388\n",
            "Epoch: [6] Total time: 0:01:15 (0.5137 s / it)\n",
            "Averaged stats: lr: 0.001396  min_lr: 0.001396  loss: 3.0443 (3.0194)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:13  loss: 2.1761 (2.1761)  acc1: 15.6250 (15.6250)  acc5: 83.3333 (83.3333)  time: 3.2563  data: 2.9294  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 2.1642 (2.1715)  acc1: 15.6250 (19.6970)  acc5: 83.3333 (82.1970)  time: 0.5125  data: 0.2695  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 2.1642 (2.2706)  acc1: 13.5417 (19.5437)  acc5: 78.1250 (66.1706)  time: 0.2820  data: 0.0438  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.1417 (2.2238)  acc1: 19.7917 (22.6815)  acc5: 81.2500 (72.7823)  time: 0.3127  data: 0.0724  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.0057 (2.1267)  acc1: 50.0000 (30.5732)  acc5: 86.4583 (75.7962)  time: 0.2655  data: 0.0305  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3554 s / it)\n",
            "* Acc@1 30.573 Acc@5 75.796 loss 2.127\n",
            "Accuracy of the model on the 3925 test images: 30.6%\n",
            "Max accuracy: 30.57%\n",
            "Test:  [ 0/41]  eta: 0:01:57  loss: 7.2744 (7.2744)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.8593  data: 2.5697  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 6.9249 (7.0222)  acc1: 0.0000 (0.0947)  acc5: 0.0000 (0.0947)  time: 0.5114  data: 0.2705  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.9182 (7.0022)  acc1: 0.0000 (0.0496)  acc5: 0.0000 (0.0992)  time: 0.2593  data: 0.0219  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.9150 (6.9566)  acc1: 0.0000 (0.0336)  acc5: 0.0000 (0.1680)  time: 0.2535  data: 0.0102  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.8876 (6.9462)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.2803)  time: 0.2487  data: 0.0087  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3311 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.280 loss 6.946\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [7]  [  0/147]  eta: 0:07:58  lr: 0.001402  min_lr: 0.001402  loss: 2.9812 (2.9812)  weight_decay: 0.0500 (0.0500)  time: 3.2582  data: 2.6760  max mem: 5388\n",
            "Epoch: [7]  [ 10/147]  eta: 0:01:43  lr: 0.001413  min_lr: 0.001413  loss: 3.0080 (3.0092)  weight_decay: 0.0500 (0.0500)  time: 0.7589  data: 0.2437  max mem: 5388\n",
            "Epoch: [7]  [ 20/147]  eta: 0:01:21  lr: 0.001430  min_lr: 0.001430  loss: 3.0080 (3.0162)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0041  max mem: 5388\n",
            "Epoch: [7]  [ 30/147]  eta: 0:01:10  lr: 0.001441  min_lr: 0.001441  loss: 3.0063 (3.0162)  weight_decay: 0.0500 (0.0500)  time: 0.5136  data: 0.0055  max mem: 5388\n",
            "Epoch: [7]  [ 40/147]  eta: 0:01:01  lr: 0.001458  min_lr: 0.001458  loss: 3.0058 (3.0105)  weight_decay: 0.0500 (0.0500)  time: 0.5067  data: 0.0028  max mem: 5388\n",
            "Epoch: [7]  [ 50/147]  eta: 0:00:54  lr: 0.001469  min_lr: 0.001469  loss: 3.0129 (3.0107)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0022  max mem: 5388\n",
            "Epoch: [7]  [ 60/147]  eta: 0:00:48  lr: 0.001485  min_lr: 0.001485  loss: 3.0090 (3.0086)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0013  max mem: 5388\n",
            "Epoch: [7]  [ 70/147]  eta: 0:00:42  lr: 0.001497  min_lr: 0.001497  loss: 3.0312 (3.0134)  weight_decay: 0.0500 (0.0500)  time: 0.5053  data: 0.0005  max mem: 5388\n",
            "Epoch: [7]  [ 80/147]  eta: 0:00:36  lr: 0.001513  min_lr: 0.001513  loss: 3.0551 (3.0192)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0015  max mem: 5388\n",
            "Epoch: [7]  [ 90/147]  eta: 0:00:30  lr: 0.001524  min_lr: 0.001524  loss: 3.0237 (3.0175)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0032  max mem: 5388\n",
            "Epoch: [7]  [100/147]  eta: 0:00:25  lr: 0.001541  min_lr: 0.001541  loss: 2.9887 (3.0148)  weight_decay: 0.0500 (0.0500)  time: 0.5050  data: 0.0044  max mem: 5388\n",
            "Epoch: [7]  [110/147]  eta: 0:00:19  lr: 0.001552  min_lr: 0.001552  loss: 2.9887 (3.0144)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0028  max mem: 5388\n",
            "Epoch: [7]  [120/147]  eta: 0:00:14  lr: 0.001569  min_lr: 0.001569  loss: 2.9801 (3.0126)  weight_decay: 0.0500 (0.0500)  time: 0.4970  data: 0.0009  max mem: 5388\n",
            "Epoch: [7]  [130/147]  eta: 0:00:08  lr: 0.001580  min_lr: 0.001580  loss: 3.0041 (3.0107)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0009  max mem: 5388\n",
            "Epoch: [7]  [140/147]  eta: 0:00:03  lr: 0.001597  min_lr: 0.001597  loss: 3.0156 (3.0103)  weight_decay: 0.0500 (0.0500)  time: 0.4972  data: 0.0004  max mem: 5388\n",
            "Epoch: [7]  [146/147]  eta: 0:00:00  lr: 0.001597  min_lr: 0.001597  loss: 3.0196 (3.0102)  weight_decay: 0.0500 (0.0500)  time: 0.4208  data: 0.0002  max mem: 5388\n",
            "Epoch: [7] Total time: 0:01:15 (0.5158 s / it)\n",
            "Averaged stats: lr: 0.001597  min_lr: 0.001597  loss: 3.0196 (3.0102)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:47  loss: 1.5783 (1.5783)  acc1: 68.7500 (68.7500)  acc5: 92.7083 (92.7083)  time: 4.0792  data: 3.7784  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 2.0935 (2.0031)  acc1: 44.7917 (42.8977)  acc5: 86.4583 (88.9205)  time: 0.6779  data: 0.4367  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 2.1023 (2.0649)  acc1: 40.6250 (37.9960)  acc5: 86.4583 (82.6389)  time: 0.3301  data: 0.0912  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.2741 (2.1803)  acc1: 12.5000 (29.0995)  acc5: 72.9167 (75.1680)  time: 0.2907  data: 0.0513  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.1191 (2.1296)  acc1: 8.3333 (28.7389)  acc5: 80.2083 (75.1338)  time: 0.2427  data: 0.0115  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3874 s / it)\n",
            "* Acc@1 28.739 Acc@5 75.134 loss 2.130\n",
            "Accuracy of the model on the 3925 test images: 28.7%\n",
            "Max accuracy: 30.57%\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 7.2533 (7.2533)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.5094  data: 3.2313  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 6.9067 (6.9986)  acc1: 0.0000 (0.0947)  acc5: 0.0000 (0.3788)  time: 0.5359  data: 0.2978  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.8981 (6.9830)  acc1: 0.0000 (0.0496)  acc5: 0.0000 (0.2480)  time: 0.2464  data: 0.0024  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.8892 (6.9358)  acc1: 0.0000 (0.0336)  acc5: 0.0000 (0.3696)  time: 0.2608  data: 0.0086  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.8321 (6.9213)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.4331)  time: 0.2505  data: 0.0085  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3361 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.433 loss 6.921\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [8]  [  0/147]  eta: 0:06:38  lr: 0.001602  min_lr: 0.001602  loss: 2.9813 (2.9813)  weight_decay: 0.0500 (0.0500)  time: 2.7139  data: 2.1198  max mem: 5388\n",
            "Epoch: [8]  [ 10/147]  eta: 0:01:37  lr: 0.001613  min_lr: 0.001613  loss: 3.0058 (3.0015)  weight_decay: 0.0500 (0.0500)  time: 0.7121  data: 0.1942  max mem: 5388\n",
            "Epoch: [8]  [ 20/147]  eta: 0:01:18  lr: 0.001630  min_lr: 0.001630  loss: 2.9891 (2.9992)  weight_decay: 0.0500 (0.0500)  time: 0.5133  data: 0.0023  max mem: 5388\n",
            "Epoch: [8]  [ 30/147]  eta: 0:01:08  lr: 0.001641  min_lr: 0.001641  loss: 3.0177 (3.0064)  weight_decay: 0.0500 (0.0500)  time: 0.5120  data: 0.0035  max mem: 5388\n",
            "Epoch: [8]  [ 40/147]  eta: 0:01:00  lr: 0.001658  min_lr: 0.001658  loss: 3.0199 (3.0097)  weight_decay: 0.0500 (0.0500)  time: 0.5071  data: 0.0031  max mem: 5388\n",
            "Epoch: [8]  [ 50/147]  eta: 0:00:53  lr: 0.001669  min_lr: 0.001669  loss: 3.0249 (3.0170)  weight_decay: 0.0500 (0.0500)  time: 0.5065  data: 0.0020  max mem: 5388\n",
            "Epoch: [8]  [ 60/147]  eta: 0:00:47  lr: 0.001686  min_lr: 0.001686  loss: 3.0095 (3.0136)  weight_decay: 0.0500 (0.0500)  time: 0.5076  data: 0.0017  max mem: 5388\n",
            "Epoch: [8]  [ 70/147]  eta: 0:00:41  lr: 0.001697  min_lr: 0.001697  loss: 2.9863 (3.0112)  weight_decay: 0.0500 (0.0500)  time: 0.5018  data: 0.0016  max mem: 5388\n",
            "Epoch: [8]  [ 80/147]  eta: 0:00:35  lr: 0.001713  min_lr: 0.001713  loss: 2.9628 (3.0027)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0024  max mem: 5388\n",
            "Epoch: [8]  [ 90/147]  eta: 0:00:30  lr: 0.001725  min_lr: 0.001725  loss: 2.9499 (3.0020)  weight_decay: 0.0500 (0.0500)  time: 0.5074  data: 0.0048  max mem: 5388\n",
            "Epoch: [8]  [100/147]  eta: 0:00:24  lr: 0.001741  min_lr: 0.001741  loss: 2.9951 (3.0004)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0039  max mem: 5388\n",
            "Epoch: [8]  [110/147]  eta: 0:00:19  lr: 0.001752  min_lr: 0.001752  loss: 2.9795 (2.9985)  weight_decay: 0.0500 (0.0500)  time: 0.4952  data: 0.0010  max mem: 5388\n",
            "Epoch: [8]  [120/147]  eta: 0:00:14  lr: 0.001769  min_lr: 0.001769  loss: 2.9763 (2.9984)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0025  max mem: 5388\n",
            "Epoch: [8]  [130/147]  eta: 0:00:08  lr: 0.001780  min_lr: 0.001780  loss: 2.9763 (2.9952)  weight_decay: 0.0500 (0.0500)  time: 0.5016  data: 0.0035  max mem: 5388\n",
            "Epoch: [8]  [140/147]  eta: 0:00:03  lr: 0.001797  min_lr: 0.001797  loss: 2.9897 (2.9943)  weight_decay: 0.0500 (0.0500)  time: 0.4936  data: 0.0014  max mem: 5388\n",
            "Epoch: [8]  [146/147]  eta: 0:00:00  lr: 0.001797  min_lr: 0.001797  loss: 3.0098 (2.9935)  weight_decay: 0.0500 (0.0500)  time: 0.4184  data: 0.0002  max mem: 5388\n",
            "Epoch: [8] Total time: 0:01:15 (0.5117 s / it)\n",
            "Averaged stats: lr: 0.001797  min_lr: 0.001797  loss: 3.0098 (2.9935)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:05  loss: 2.1220 (2.1220)  acc1: 29.1667 (29.1667)  acc5: 77.0833 (77.0833)  time: 4.5360  data: 4.2520  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 2.2336 (2.2531)  acc1: 18.7500 (25.2841)  acc5: 73.9583 (62.7841)  time: 0.6280  data: 0.3892  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 2.2329 (2.1856)  acc1: 17.7083 (25.9921)  acc5: 73.9583 (71.3790)  time: 0.2421  data: 0.0067  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.9824 (2.1038)  acc1: 31.2500 (27.7218)  acc5: 88.5417 (77.1841)  time: 0.2401  data: 0.0053  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.9824 (2.0211)  acc1: 35.4167 (32.0764)  acc5: 86.4583 (77.5032)  time: 0.2307  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3511 s / it)\n",
            "* Acc@1 32.076 Acc@5 77.503 loss 2.021\n",
            "Accuracy of the model on the 3925 test images: 32.1%\n",
            "Max accuracy: 32.08%\n",
            "Test:  [ 0/41]  eta: 0:03:19  loss: 7.2285 (7.2285)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 4.8659  data: 4.5054  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.8878 (6.9721)  acc1: 0.0000 (0.0947)  acc5: 0.0000 (0.7576)  time: 0.6800  data: 0.4319  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.8784 (6.9617)  acc1: 0.0000 (0.0496)  acc5: 0.0000 (0.4960)  time: 0.2509  data: 0.0138  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.8628 (6.9128)  acc1: 0.0000 (0.0336)  acc5: 0.0000 (0.6384)  time: 0.2379  data: 0.0016  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.7992 (6.8940)  acc1: 0.0000 (0.0255)  acc5: 0.0000 (0.6369)  time: 0.2335  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3628 s / it)\n",
            "* Acc@1 0.025 Acc@5 0.637 loss 6.894\n",
            "Accuracy of the model EMA on 3925 test images: 0.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [9]  [  0/147]  eta: 0:09:22  lr: 0.001803  min_lr: 0.001803  loss: 2.9385 (2.9385)  weight_decay: 0.0500 (0.0500)  time: 3.8297  data: 3.0705  max mem: 5388\n",
            "Epoch: [9]  [ 10/147]  eta: 0:01:57  lr: 0.001814  min_lr: 0.001814  loss: 3.0030 (2.9825)  weight_decay: 0.0500 (0.0500)  time: 0.8570  data: 0.2832  max mem: 5388\n",
            "Epoch: [9]  [ 20/147]  eta: 0:01:28  lr: 0.001830  min_lr: 0.001830  loss: 3.0089 (2.9961)  weight_decay: 0.0500 (0.0500)  time: 0.5381  data: 0.0035  max mem: 5388\n",
            "Epoch: [9]  [ 30/147]  eta: 0:01:14  lr: 0.001841  min_lr: 0.001841  loss: 2.9813 (2.9772)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0031  max mem: 5388\n",
            "Epoch: [9]  [ 40/147]  eta: 0:01:05  lr: 0.001858  min_lr: 0.001858  loss: 2.9476 (2.9697)  weight_decay: 0.0500 (0.0500)  time: 0.5196  data: 0.0029  max mem: 5388\n",
            "Epoch: [9]  [ 50/147]  eta: 0:00:57  lr: 0.001869  min_lr: 0.001869  loss: 2.9720 (2.9733)  weight_decay: 0.0500 (0.0500)  time: 0.5177  data: 0.0028  max mem: 5388\n",
            "Epoch: [9]  [ 60/147]  eta: 0:00:50  lr: 0.001886  min_lr: 0.001886  loss: 2.9888 (2.9789)  weight_decay: 0.0500 (0.0500)  time: 0.5085  data: 0.0029  max mem: 5388\n",
            "Epoch: [9]  [ 70/147]  eta: 0:00:43  lr: 0.001897  min_lr: 0.001897  loss: 3.0020 (2.9791)  weight_decay: 0.0500 (0.0500)  time: 0.5107  data: 0.0030  max mem: 5388\n",
            "Epoch: [9]  [ 80/147]  eta: 0:00:37  lr: 0.001914  min_lr: 0.001914  loss: 3.0054 (2.9812)  weight_decay: 0.0500 (0.0500)  time: 0.5076  data: 0.0041  max mem: 5388\n",
            "Epoch: [9]  [ 90/147]  eta: 0:00:31  lr: 0.001925  min_lr: 0.001925  loss: 2.9944 (2.9830)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0032  max mem: 5388\n",
            "Epoch: [9]  [100/147]  eta: 0:00:25  lr: 0.001942  min_lr: 0.001942  loss: 3.0128 (2.9875)  weight_decay: 0.0500 (0.0500)  time: 0.4984  data: 0.0023  max mem: 5388\n",
            "Epoch: [9]  [110/147]  eta: 0:00:20  lr: 0.001953  min_lr: 0.001953  loss: 3.0128 (2.9884)  weight_decay: 0.0500 (0.0500)  time: 0.5004  data: 0.0022  max mem: 5388\n",
            "Epoch: [9]  [120/147]  eta: 0:00:14  lr: 0.001969  min_lr: 0.001969  loss: 3.0126 (2.9903)  weight_decay: 0.0500 (0.0500)  time: 0.4955  data: 0.0015  max mem: 5388\n",
            "Epoch: [9]  [130/147]  eta: 0:00:09  lr: 0.001981  min_lr: 0.001981  loss: 2.9869 (2.9881)  weight_decay: 0.0500 (0.0500)  time: 0.4917  data: 0.0013  max mem: 5388\n",
            "Epoch: [9]  [140/147]  eta: 0:00:03  lr: 0.001997  min_lr: 0.001997  loss: 2.9691 (2.9862)  weight_decay: 0.0500 (0.0500)  time: 0.4929  data: 0.0007  max mem: 5388\n",
            "Epoch: [9]  [146/147]  eta: 0:00:00  lr: 0.001997  min_lr: 0.001997  loss: 2.9691 (2.9863)  weight_decay: 0.0500 (0.0500)  time: 0.4201  data: 0.0002  max mem: 5388\n",
            "Epoch: [9] Total time: 0:01:16 (0.5235 s / it)\n",
            "Averaged stats: lr: 0.001997  min_lr: 0.001997  loss: 2.9691 (2.9863)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:31  loss: 1.5534 (1.5534)  acc1: 69.7917 (69.7917)  acc5: 100.0000 (100.0000)  time: 3.6887  data: 3.4081  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 1.9832 (2.0057)  acc1: 46.8750 (39.9621)  acc5: 83.3333 (82.3864)  time: 0.5487  data: 0.3120  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 2.0441 (2.0650)  acc1: 27.0833 (31.0516)  acc5: 83.3333 (83.4821)  time: 0.2590  data: 0.0150  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.1892 (2.1228)  acc1: 17.7083 (27.3522)  acc5: 83.3333 (81.1156)  time: 0.2739  data: 0.0280  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 2.1145 (2.0368)  acc1: 22.9167 (30.4713)  acc5: 76.0417 (80.6369)  time: 0.2465  data: 0.0142  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3451 s / it)\n",
            "* Acc@1 30.471 Acc@5 80.637 loss 2.037\n",
            "Accuracy of the model on the 3925 test images: 30.5%\n",
            "Max accuracy: 32.08%\n",
            "Test:  [ 0/41]  eta: 0:01:56  loss: 7.2021 (7.2021)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.8497  data: 2.5658  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 6.8682 (6.9437)  acc1: 0.0000 (0.0947)  acc5: 0.0000 (0.9470)  time: 0.4860  data: 0.2485  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:07  loss: 6.8573 (6.9391)  acc1: 0.0000 (0.0496)  acc5: 0.0000 (0.7440)  time: 0.2446  data: 0.0111  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.8365 (6.8882)  acc1: 0.0000 (0.0672)  acc5: 0.0000 (1.0417)  time: 0.2383  data: 0.0028  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.7609 (6.8648)  acc1: 0.0000 (0.0510)  acc5: 0.0000 (0.9936)  time: 0.2349  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:12 (0.3153 s / it)\n",
            "* Acc@1 0.051 Acc@5 0.994 loss 6.865\n",
            "Accuracy of the model EMA on 3925 test images: 0.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [10]  [  0/147]  eta: 0:09:23  lr: 0.002003  min_lr: 0.002003  loss: 2.9641 (2.9641)  weight_decay: 0.0500 (0.0500)  time: 3.8321  data: 3.2451  max mem: 5388\n",
            "Epoch: [10]  [ 10/147]  eta: 0:01:51  lr: 0.002014  min_lr: 0.002014  loss: 2.9760 (2.9504)  weight_decay: 0.0500 (0.0500)  time: 0.8135  data: 0.2961  max mem: 5388\n",
            "Epoch: [10]  [ 20/147]  eta: 0:01:24  lr: 0.002031  min_lr: 0.002031  loss: 2.9855 (2.9700)  weight_decay: 0.0500 (0.0500)  time: 0.5107  data: 0.0022  max mem: 5388\n",
            "Epoch: [10]  [ 30/147]  eta: 0:01:12  lr: 0.002042  min_lr: 0.002042  loss: 2.9880 (2.9772)  weight_decay: 0.0500 (0.0500)  time: 0.5150  data: 0.0036  max mem: 5388\n",
            "Epoch: [10]  [ 40/147]  eta: 0:01:03  lr: 0.002058  min_lr: 0.002058  loss: 2.9986 (2.9818)  weight_decay: 0.0500 (0.0500)  time: 0.5140  data: 0.0030  max mem: 5388\n",
            "Epoch: [10]  [ 50/147]  eta: 0:00:55  lr: 0.002070  min_lr: 0.002070  loss: 2.9856 (2.9732)  weight_decay: 0.0500 (0.0500)  time: 0.5064  data: 0.0021  max mem: 5388\n",
            "Epoch: [10]  [ 60/147]  eta: 0:00:49  lr: 0.002086  min_lr: 0.002086  loss: 2.9320 (2.9611)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0037  max mem: 5388\n",
            "Epoch: [10]  [ 70/147]  eta: 0:00:42  lr: 0.002097  min_lr: 0.002097  loss: 2.9795 (2.9641)  weight_decay: 0.0500 (0.0500)  time: 0.5088  data: 0.0043  max mem: 5388\n",
            "Epoch: [10]  [ 80/147]  eta: 0:00:36  lr: 0.002114  min_lr: 0.002114  loss: 2.9759 (2.9627)  weight_decay: 0.0500 (0.0500)  time: 0.4997  data: 0.0024  max mem: 5388\n",
            "Epoch: [10]  [ 90/147]  eta: 0:00:31  lr: 0.002125  min_lr: 0.002125  loss: 2.9750 (2.9616)  weight_decay: 0.0500 (0.0500)  time: 0.5036  data: 0.0036  max mem: 5388\n",
            "Epoch: [10]  [100/147]  eta: 0:00:25  lr: 0.002142  min_lr: 0.002142  loss: 2.9376 (2.9564)  weight_decay: 0.0500 (0.0500)  time: 0.5130  data: 0.0049  max mem: 5388\n",
            "Epoch: [10]  [110/147]  eta: 0:00:19  lr: 0.002153  min_lr: 0.002153  loss: 2.9370 (2.9553)  weight_decay: 0.0500 (0.0500)  time: 0.5118  data: 0.0030  max mem: 5388\n",
            "Epoch: [10]  [120/147]  eta: 0:00:14  lr: 0.002170  min_lr: 0.002170  loss: 2.9218 (2.9518)  weight_decay: 0.0500 (0.0500)  time: 0.5027  data: 0.0026  max mem: 5388\n",
            "Epoch: [10]  [130/147]  eta: 0:00:09  lr: 0.002181  min_lr: 0.002181  loss: 2.8923 (2.9485)  weight_decay: 0.0500 (0.0500)  time: 0.5023  data: 0.0031  max mem: 5388\n",
            "Epoch: [10]  [140/147]  eta: 0:00:03  lr: 0.002197  min_lr: 0.002197  loss: 2.9151 (2.9482)  weight_decay: 0.0500 (0.0500)  time: 0.4982  data: 0.0017  max mem: 5388\n",
            "Epoch: [10]  [146/147]  eta: 0:00:00  lr: 0.002197  min_lr: 0.002197  loss: 2.9151 (2.9487)  weight_decay: 0.0500 (0.0500)  time: 0.4197  data: 0.0002  max mem: 5388\n",
            "Epoch: [10] Total time: 0:01:16 (0.5217 s / it)\n",
            "Averaged stats: lr: 0.002197  min_lr: 0.002197  loss: 2.9151 (2.9487)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:17  loss: 1.7501 (1.7501)  acc1: 56.2500 (56.2500)  acc5: 84.3750 (84.3750)  time: 4.8080  data: 4.4546  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 1.8111 (1.9030)  acc1: 51.0417 (45.5492)  acc5: 85.4167 (87.1212)  time: 0.6954  data: 0.4486  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 1.9686 (2.0130)  acc1: 35.4167 (35.6647)  acc5: 85.4167 (82.6389)  time: 0.2904  data: 0.0507  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.9358 (1.9775)  acc1: 38.5417 (38.8777)  acc5: 83.3333 (83.6022)  time: 0.2636  data: 0.0267  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.8484 (1.9217)  acc1: 44.7917 (40.5605)  acc5: 83.3333 (82.9299)  time: 0.2278  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3779 s / it)\n",
            "* Acc@1 40.561 Acc@5 82.930 loss 1.922\n",
            "Accuracy of the model on the 3925 test images: 40.6%\n",
            "Max accuracy: 40.56%\n",
            "Test:  [ 0/41]  eta: 0:01:56  loss: 7.1732 (7.1732)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.8414  data: 2.5422  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 6.8468 (6.9131)  acc1: 0.0000 (0.2841)  acc5: 0.0000 (1.4205)  time: 0.5751  data: 0.3321  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.8347 (6.9148)  acc1: 0.0000 (0.1984)  acc5: 0.0000 (0.9921)  time: 0.3371  data: 0.0973  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.8100 (6.8621)  acc1: 0.0000 (0.2016)  acc5: 0.0000 (1.3777)  time: 0.3269  data: 0.0871  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.7196 (6.8338)  acc1: 0.0000 (0.1783)  acc5: 0.0000 (1.2229)  time: 0.2785  data: 0.0455  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3812 s / it)\n",
            "* Acc@1 0.178 Acc@5 1.223 loss 6.834\n",
            "Accuracy of the model EMA on 3925 test images: 0.2%\n",
            "Max EMA accuracy: 0.18%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [11]  [  0/147]  eta: 0:07:25  lr: 0.002203  min_lr: 0.002203  loss: 3.0090 (3.0090)  weight_decay: 0.0500 (0.0500)  time: 3.0304  data: 2.4355  max mem: 5388\n",
            "Epoch: [11]  [ 10/147]  eta: 0:01:44  lr: 0.002214  min_lr: 0.002214  loss: 2.9627 (2.9453)  weight_decay: 0.0500 (0.0500)  time: 0.7618  data: 0.2261  max mem: 5388\n",
            "Epoch: [11]  [ 20/147]  eta: 0:01:21  lr: 0.002231  min_lr: 0.002231  loss: 2.9478 (2.9410)  weight_decay: 0.0500 (0.0500)  time: 0.5253  data: 0.0043  max mem: 5388\n",
            "Epoch: [11]  [ 30/147]  eta: 0:01:10  lr: 0.002242  min_lr: 0.002242  loss: 2.9446 (2.9434)  weight_decay: 0.0500 (0.0500)  time: 0.5141  data: 0.0031  max mem: 5388\n",
            "Epoch: [11]  [ 40/147]  eta: 0:01:02  lr: 0.002259  min_lr: 0.002259  loss: 2.9511 (2.9506)  weight_decay: 0.0500 (0.0500)  time: 0.5162  data: 0.0017  max mem: 5388\n",
            "Epoch: [11]  [ 50/147]  eta: 0:00:55  lr: 0.002270  min_lr: 0.002270  loss: 2.9496 (2.9530)  weight_decay: 0.0500 (0.0500)  time: 0.5177  data: 0.0015  max mem: 5388\n",
            "Epoch: [11]  [ 60/147]  eta: 0:00:48  lr: 0.002287  min_lr: 0.002287  loss: 2.9441 (2.9508)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0022  max mem: 5388\n",
            "Epoch: [11]  [ 70/147]  eta: 0:00:42  lr: 0.002298  min_lr: 0.002298  loss: 2.9441 (2.9511)  weight_decay: 0.0500 (0.0500)  time: 0.5072  data: 0.0017  max mem: 5388\n",
            "Epoch: [11]  [ 80/147]  eta: 0:00:36  lr: 0.002314  min_lr: 0.002314  loss: 2.9613 (2.9539)  weight_decay: 0.0500 (0.0500)  time: 0.5082  data: 0.0019  max mem: 5388\n",
            "Epoch: [11]  [ 90/147]  eta: 0:00:30  lr: 0.002325  min_lr: 0.002325  loss: 2.9689 (2.9557)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0023  max mem: 5388\n",
            "Epoch: [11]  [100/147]  eta: 0:00:25  lr: 0.002342  min_lr: 0.002342  loss: 2.9641 (2.9540)  weight_decay: 0.0500 (0.0500)  time: 0.4973  data: 0.0023  max mem: 5388\n",
            "Epoch: [11]  [110/147]  eta: 0:00:19  lr: 0.002353  min_lr: 0.002353  loss: 2.9212 (2.9517)  weight_decay: 0.0500 (0.0500)  time: 0.5044  data: 0.0043  max mem: 5388\n",
            "Epoch: [11]  [120/147]  eta: 0:00:14  lr: 0.002370  min_lr: 0.002370  loss: 2.9059 (2.9515)  weight_decay: 0.0500 (0.0500)  time: 0.5031  data: 0.0048  max mem: 5388\n",
            "Epoch: [11]  [130/147]  eta: 0:00:08  lr: 0.002381  min_lr: 0.002381  loss: 2.9147 (2.9461)  weight_decay: 0.0500 (0.0500)  time: 0.4946  data: 0.0030  max mem: 5388\n",
            "Epoch: [11]  [140/147]  eta: 0:00:03  lr: 0.002398  min_lr: 0.002398  loss: 2.9185 (2.9459)  weight_decay: 0.0500 (0.0500)  time: 0.4922  data: 0.0013  max mem: 5388\n",
            "Epoch: [11]  [146/147]  eta: 0:00:00  lr: 0.002398  min_lr: 0.002398  loss: 2.9185 (2.9461)  weight_decay: 0.0500 (0.0500)  time: 0.4187  data: 0.0002  max mem: 5388\n",
            "Epoch: [11] Total time: 0:01:16 (0.5177 s / it)\n",
            "Averaged stats: lr: 0.002398  min_lr: 0.002398  loss: 2.9185 (2.9461)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:12  loss: 1.6467 (1.6467)  acc1: 63.5417 (63.5417)  acc5: 94.7917 (94.7917)  time: 3.2416  data: 2.9466  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 1.7718 (1.8949)  acc1: 46.8750 (41.4773)  acc5: 86.4583 (87.5947)  time: 0.5105  data: 0.2725  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 1.8003 (2.0055)  acc1: 37.5000 (34.8214)  acc5: 85.4167 (80.2579)  time: 0.2452  data: 0.0031  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 1.9755 (2.0099)  acc1: 36.4583 (35.4167)  acc5: 78.1250 (81.2836)  time: 0.2566  data: 0.0114  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.7983 (1.8888)  acc1: 37.5000 (40.1783)  acc5: 90.5882 (83.5414)  time: 0.2833  data: 0.0490  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3523 s / it)\n",
            "* Acc@1 40.178 Acc@5 83.541 loss 1.889\n",
            "Accuracy of the model on the 3925 test images: 40.2%\n",
            "Max accuracy: 40.56%\n",
            "Test:  [ 0/41]  eta: 0:03:25  loss: 7.1391 (7.1391)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 5.0105  data: 4.7148  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 6.8246 (6.8794)  acc1: 0.0000 (0.5682)  acc5: 0.0000 (2.0833)  time: 0.6745  data: 0.4317  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.8146 (6.8883)  acc1: 0.0000 (0.3968)  acc5: 0.0000 (1.5377)  time: 0.2389  data: 0.0029  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.7831 (6.8340)  acc1: 0.0000 (0.5040)  acc5: 0.0000 (2.0161)  time: 0.2371  data: 0.0013  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.6776 (6.8008)  acc1: 0.0000 (0.4076)  acc5: 0.0000 (1.7325)  time: 0.2348  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3666 s / it)\n",
            "* Acc@1 0.408 Acc@5 1.732 loss 6.801\n",
            "Accuracy of the model EMA on 3925 test images: 0.4%\n",
            "Max EMA accuracy: 0.41%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [12]  [  0/147]  eta: 0:09:51  lr: 0.002403  min_lr: 0.002403  loss: 2.9676 (2.9676)  weight_decay: 0.0500 (0.0500)  time: 4.0260  data: 3.3426  max mem: 5388\n",
            "Epoch: [12]  [ 10/147]  eta: 0:01:56  lr: 0.002414  min_lr: 0.002414  loss: 2.9303 (2.9277)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.3077  max mem: 5388\n",
            "Epoch: [12]  [ 20/147]  eta: 0:01:27  lr: 0.002431  min_lr: 0.002431  loss: 2.9240 (2.9190)  weight_decay: 0.0500 (0.0500)  time: 0.5206  data: 0.0031  max mem: 5388\n",
            "Epoch: [12]  [ 30/147]  eta: 0:01:14  lr: 0.002442  min_lr: 0.002442  loss: 2.9053 (2.9135)  weight_decay: 0.0500 (0.0500)  time: 0.5172  data: 0.0047  max mem: 5388\n",
            "Epoch: [12]  [ 40/147]  eta: 0:01:04  lr: 0.002459  min_lr: 0.002459  loss: 2.9053 (2.9167)  weight_decay: 0.0500 (0.0500)  time: 0.5188  data: 0.0047  max mem: 5388\n",
            "Epoch: [12]  [ 50/147]  eta: 0:00:56  lr: 0.002470  min_lr: 0.002470  loss: 2.9743 (2.9238)  weight_decay: 0.0500 (0.0500)  time: 0.5125  data: 0.0028  max mem: 5388\n",
            "Epoch: [12]  [ 60/147]  eta: 0:00:50  lr: 0.002487  min_lr: 0.002487  loss: 2.9560 (2.9233)  weight_decay: 0.0500 (0.0500)  time: 0.5127  data: 0.0024  max mem: 5388\n",
            "Epoch: [12]  [ 70/147]  eta: 0:00:43  lr: 0.002498  min_lr: 0.002498  loss: 2.9027 (2.9232)  weight_decay: 0.0500 (0.0500)  time: 0.5095  data: 0.0021  max mem: 5388\n",
            "Epoch: [12]  [ 80/147]  eta: 0:00:37  lr: 0.002515  min_lr: 0.002515  loss: 2.9295 (2.9273)  weight_decay: 0.0500 (0.0500)  time: 0.5029  data: 0.0028  max mem: 5388\n",
            "Epoch: [12]  [ 90/147]  eta: 0:00:31  lr: 0.002526  min_lr: 0.002526  loss: 2.9308 (2.9293)  weight_decay: 0.0500 (0.0500)  time: 0.5017  data: 0.0025  max mem: 5388\n",
            "Epoch: [12]  [100/147]  eta: 0:00:25  lr: 0.002542  min_lr: 0.002542  loss: 2.9153 (2.9264)  weight_decay: 0.0500 (0.0500)  time: 0.5044  data: 0.0033  max mem: 5388\n",
            "Epoch: [12]  [110/147]  eta: 0:00:20  lr: 0.002554  min_lr: 0.002554  loss: 2.9245 (2.9282)  weight_decay: 0.0500 (0.0500)  time: 0.5003  data: 0.0027  max mem: 5388\n",
            "Epoch: [12]  [120/147]  eta: 0:00:14  lr: 0.002570  min_lr: 0.002570  loss: 2.9183 (2.9227)  weight_decay: 0.0500 (0.0500)  time: 0.4926  data: 0.0014  max mem: 5388\n",
            "Epoch: [12]  [130/147]  eta: 0:00:09  lr: 0.002581  min_lr: 0.002581  loss: 2.9163 (2.9265)  weight_decay: 0.0500 (0.0500)  time: 0.4952  data: 0.0017  max mem: 5388\n",
            "Epoch: [12]  [140/147]  eta: 0:00:03  lr: 0.002598  min_lr: 0.002598  loss: 2.9432 (2.9270)  weight_decay: 0.0500 (0.0500)  time: 0.4955  data: 0.0009  max mem: 5388\n",
            "Epoch: [12]  [146/147]  eta: 0:00:00  lr: 0.002598  min_lr: 0.002598  loss: 2.9366 (2.9261)  weight_decay: 0.0500 (0.0500)  time: 0.4191  data: 0.0002  max mem: 5388\n",
            "Epoch: [12] Total time: 0:01:16 (0.5229 s / it)\n",
            "Averaged stats: lr: 0.002598  min_lr: 0.002598  loss: 2.9366 (2.9261)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:02  loss: 1.5643 (1.5643)  acc1: 71.8750 (71.8750)  acc5: 91.6667 (91.6667)  time: 2.9841  data: 2.6860  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 1.6968 (1.8988)  acc1: 57.2917 (45.2652)  acc5: 86.4583 (79.9242)  time: 0.5748  data: 0.3254  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.6968 (1.9335)  acc1: 54.1667 (40.4266)  acc5: 86.4583 (81.9444)  time: 0.3278  data: 0.0834  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.9467 (1.9285)  acc1: 29.1667 (40.4234)  acc5: 88.5417 (82.2245)  time: 0.3012  data: 0.0585  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.9467 (1.8873)  acc1: 29.1667 (41.0701)  acc5: 89.5833 (82.8025)  time: 0.2547  data: 0.0199  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3661 s / it)\n",
            "* Acc@1 41.070 Acc@5 82.803 loss 1.887\n",
            "Accuracy of the model on the 3925 test images: 41.1%\n",
            "Max accuracy: 41.07%\n",
            "Test:  [ 0/41]  eta: 0:02:19  loss: 7.1008 (7.1008)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.4146  data: 3.1105  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 6.8011 (6.8425)  acc1: 0.0000 (0.6629)  acc5: 0.0000 (2.5568)  time: 0.5327  data: 0.2867  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.7921 (6.8593)  acc1: 0.0000 (0.4960)  acc5: 0.0000 (1.8353)  time: 0.2713  data: 0.0307  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.7543 (6.8041)  acc1: 0.0000 (0.5712)  acc5: 0.0000 (2.5538)  time: 0.2975  data: 0.0530  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.6338 (6.7652)  acc1: 0.0000 (0.4586)  acc5: 1.0417 (2.2675)  time: 0.2651  data: 0.0244  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3547 s / it)\n",
            "* Acc@1 0.459 Acc@5 2.268 loss 6.765\n",
            "Accuracy of the model EMA on 3925 test images: 0.5%\n",
            "Max EMA accuracy: 0.46%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [13]  [  0/147]  eta: 0:06:49  lr: 0.002604  min_lr: 0.002604  loss: 2.7452 (2.7452)  weight_decay: 0.0500 (0.0500)  time: 2.7845  data: 2.1836  max mem: 5388\n",
            "Epoch: [13]  [ 10/147]  eta: 0:01:39  lr: 0.002615  min_lr: 0.002615  loss: 2.9322 (2.9094)  weight_decay: 0.0500 (0.0500)  time: 0.7250  data: 0.2000  max mem: 5388\n",
            "Epoch: [13]  [ 20/147]  eta: 0:01:19  lr: 0.002631  min_lr: 0.002631  loss: 2.9414 (2.9273)  weight_decay: 0.0500 (0.0500)  time: 0.5200  data: 0.0029  max mem: 5388\n",
            "Epoch: [13]  [ 30/147]  eta: 0:01:09  lr: 0.002643  min_lr: 0.002643  loss: 2.9324 (2.9272)  weight_decay: 0.0500 (0.0500)  time: 0.5221  data: 0.0056  max mem: 5388\n",
            "Epoch: [13]  [ 40/147]  eta: 0:01:01  lr: 0.002659  min_lr: 0.002659  loss: 2.8912 (2.9160)  weight_decay: 0.0500 (0.0500)  time: 0.5157  data: 0.0040  max mem: 5388\n",
            "Epoch: [13]  [ 50/147]  eta: 0:00:54  lr: 0.002670  min_lr: 0.002670  loss: 2.9041 (2.9204)  weight_decay: 0.0500 (0.0500)  time: 0.5093  data: 0.0016  max mem: 5388\n",
            "Epoch: [13]  [ 60/147]  eta: 0:00:48  lr: 0.002687  min_lr: 0.002687  loss: 2.9041 (2.9185)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0029  max mem: 5388\n",
            "Epoch: [13]  [ 70/147]  eta: 0:00:41  lr: 0.002698  min_lr: 0.002698  loss: 2.8961 (2.9165)  weight_decay: 0.0500 (0.0500)  time: 0.5051  data: 0.0024  max mem: 5388\n",
            "Epoch: [13]  [ 80/147]  eta: 0:00:36  lr: 0.002715  min_lr: 0.002715  loss: 2.8809 (2.9125)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0020  max mem: 5388\n",
            "Epoch: [13]  [ 90/147]  eta: 0:00:30  lr: 0.002726  min_lr: 0.002726  loss: 2.8680 (2.9070)  weight_decay: 0.0500 (0.0500)  time: 0.5054  data: 0.0034  max mem: 5388\n",
            "Epoch: [13]  [100/147]  eta: 0:00:25  lr: 0.002743  min_lr: 0.002743  loss: 2.8680 (2.9042)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0041  max mem: 5388\n",
            "Epoch: [13]  [110/147]  eta: 0:00:19  lr: 0.002754  min_lr: 0.002754  loss: 2.9362 (2.9103)  weight_decay: 0.0500 (0.0500)  time: 0.4969  data: 0.0039  max mem: 5388\n",
            "Epoch: [13]  [120/147]  eta: 0:00:14  lr: 0.002771  min_lr: 0.002771  loss: 2.9421 (2.9092)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0029  max mem: 5388\n",
            "Epoch: [13]  [130/147]  eta: 0:00:08  lr: 0.002782  min_lr: 0.002782  loss: 2.8722 (2.9089)  weight_decay: 0.0500 (0.0500)  time: 0.4976  data: 0.0012  max mem: 5388\n",
            "Epoch: [13]  [140/147]  eta: 0:00:03  lr: 0.002798  min_lr: 0.002798  loss: 2.8977 (2.9093)  weight_decay: 0.0500 (0.0500)  time: 0.4921  data: 0.0002  max mem: 5388\n",
            "Epoch: [13]  [146/147]  eta: 0:00:00  lr: 0.002798  min_lr: 0.002798  loss: 2.9029 (2.9100)  weight_decay: 0.0500 (0.0500)  time: 0.4184  data: 0.0002  max mem: 5388\n",
            "Epoch: [13] Total time: 0:01:15 (0.5143 s / it)\n",
            "Averaged stats: lr: 0.002798  min_lr: 0.002798  loss: 2.9029 (2.9100)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:44  loss: 1.5960 (1.5960)  acc1: 69.7917 (69.7917)  acc5: 90.6250 (90.6250)  time: 5.4835  data: 5.1465  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 1.8031 (1.6870)  acc1: 53.1250 (53.6932)  acc5: 95.8333 (94.6970)  time: 0.7133  data: 0.4697  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 1.8166 (1.9687)  acc1: 42.7083 (40.3770)  acc5: 88.5417 (76.2401)  time: 0.2377  data: 0.0027  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.8767 (1.9735)  acc1: 34.3750 (38.0376)  acc5: 84.3750 (79.6371)  time: 0.2347  data: 0.0018  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.8301 (1.8543)  acc1: 40.6250 (41.7834)  acc5: 90.6250 (82.2930)  time: 0.2286  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3717 s / it)\n",
            "* Acc@1 41.783 Acc@5 82.293 loss 1.854\n",
            "Accuracy of the model on the 3925 test images: 41.8%\n",
            "Max accuracy: 41.78%\n",
            "Test:  [ 0/41]  eta: 0:03:30  loss: 7.0583 (7.0583)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 5.1231  data: 4.8441  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.7763 (6.8026)  acc1: 0.0000 (1.0417)  acc5: 0.0000 (3.7879)  time: 0.6858  data: 0.4423  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.7676 (6.8284)  acc1: 0.0000 (0.7440)  acc5: 0.0000 (2.7778)  time: 0.2409  data: 0.0032  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.7259 (6.7719)  acc1: 0.0000 (0.8401)  acc5: 1.0417 (3.7298)  time: 0.2387  data: 0.0022  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.6020 (6.7271)  acc1: 0.0000 (0.6624)  acc5: 1.0417 (3.2611)  time: 0.2345  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3651 s / it)\n",
            "* Acc@1 0.662 Acc@5 3.261 loss 6.727\n",
            "Accuracy of the model EMA on 3925 test images: 0.7%\n",
            "Max EMA accuracy: 0.66%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [14]  [  0/147]  eta: 0:11:15  lr: 0.002804  min_lr: 0.002804  loss: 2.8183 (2.8183)  weight_decay: 0.0500 (0.0500)  time: 4.5970  data: 3.9375  max mem: 5388\n",
            "Epoch: [14]  [ 10/147]  eta: 0:02:02  lr: 0.002815  min_lr: 0.002815  loss: 2.8621 (2.8794)  weight_decay: 0.0500 (0.0500)  time: 0.8909  data: 0.3602  max mem: 5388\n",
            "Epoch: [14]  [ 20/147]  eta: 0:01:30  lr: 0.002832  min_lr: 0.002832  loss: 2.8486 (2.8674)  weight_decay: 0.0500 (0.0500)  time: 0.5152  data: 0.0021  max mem: 5388\n",
            "Epoch: [14]  [ 30/147]  eta: 0:01:16  lr: 0.002843  min_lr: 0.002843  loss: 2.8963 (2.8757)  weight_decay: 0.0500 (0.0500)  time: 0.5174  data: 0.0017  max mem: 5388\n",
            "Epoch: [14]  [ 40/147]  eta: 0:01:06  lr: 0.002860  min_lr: 0.002860  loss: 2.9249 (2.8919)  weight_decay: 0.0500 (0.0500)  time: 0.5207  data: 0.0016  max mem: 5388\n",
            "Epoch: [14]  [ 50/147]  eta: 0:00:57  lr: 0.002871  min_lr: 0.002871  loss: 2.9536 (2.9039)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0022  max mem: 5388\n",
            "Epoch: [14]  [ 60/147]  eta: 0:00:50  lr: 0.002887  min_lr: 0.002887  loss: 2.9310 (2.9059)  weight_decay: 0.0500 (0.0500)  time: 0.5147  data: 0.0026  max mem: 5388\n",
            "Epoch: [14]  [ 70/147]  eta: 0:00:44  lr: 0.002898  min_lr: 0.002898  loss: 2.9133 (2.9049)  weight_decay: 0.0500 (0.0500)  time: 0.5124  data: 0.0020  max mem: 5388\n",
            "Epoch: [14]  [ 80/147]  eta: 0:00:37  lr: 0.002915  min_lr: 0.002915  loss: 2.9082 (2.9014)  weight_decay: 0.0500 (0.0500)  time: 0.5036  data: 0.0027  max mem: 5388\n",
            "Epoch: [14]  [ 90/147]  eta: 0:00:31  lr: 0.002926  min_lr: 0.002926  loss: 2.8744 (2.8996)  weight_decay: 0.0500 (0.0500)  time: 0.5017  data: 0.0043  max mem: 5388\n",
            "Epoch: [14]  [100/147]  eta: 0:00:26  lr: 0.002943  min_lr: 0.002943  loss: 2.8744 (2.8964)  weight_decay: 0.0500 (0.0500)  time: 0.5097  data: 0.0050  max mem: 5388\n",
            "Epoch: [14]  [110/147]  eta: 0:00:20  lr: 0.002954  min_lr: 0.002954  loss: 2.8883 (2.8960)  weight_decay: 0.0500 (0.0500)  time: 0.5118  data: 0.0035  max mem: 5388\n",
            "Epoch: [14]  [120/147]  eta: 0:00:14  lr: 0.002971  min_lr: 0.002971  loss: 2.8830 (2.8925)  weight_decay: 0.0500 (0.0500)  time: 0.5010  data: 0.0017  max mem: 5388\n",
            "Epoch: [14]  [130/147]  eta: 0:00:09  lr: 0.002982  min_lr: 0.002982  loss: 2.8563 (2.8894)  weight_decay: 0.0500 (0.0500)  time: 0.4946  data: 0.0015  max mem: 5388\n",
            "Epoch: [14]  [140/147]  eta: 0:00:03  lr: 0.002999  min_lr: 0.002999  loss: 2.8669 (2.8899)  weight_decay: 0.0500 (0.0500)  time: 0.4954  data: 0.0010  max mem: 5388\n",
            "Epoch: [14]  [146/147]  eta: 0:00:00  lr: 0.002999  min_lr: 0.002999  loss: 2.8669 (2.8883)  weight_decay: 0.0500 (0.0500)  time: 0.4203  data: 0.0002  max mem: 5388\n",
            "Epoch: [14] Total time: 0:01:17 (0.5285 s / it)\n",
            "Averaged stats: lr: 0.002999  min_lr: 0.002999  loss: 2.8669 (2.8883)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:20  loss: 1.0328 (1.0328)  acc1: 84.3750 (84.3750)  acc5: 100.0000 (100.0000)  time: 3.4258  data: 3.1377  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 1.6553 (1.5439)  acc1: 57.2917 (60.6061)  acc5: 93.7500 (90.6250)  time: 0.5353  data: 0.2879  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 1.6593 (1.7746)  acc1: 55.2083 (46.4286)  acc5: 89.5833 (87.8472)  time: 0.2422  data: 0.0019  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.8592 (1.8254)  acc1: 38.5417 (43.6828)  acc5: 86.4583 (86.3911)  time: 0.2765  data: 0.0283  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.6965 (1.7583)  acc1: 45.8333 (46.9045)  acc5: 87.5000 (87.4904)  time: 0.2732  data: 0.0300  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3433 s / it)\n",
            "* Acc@1 46.904 Acc@5 87.490 loss 1.758\n",
            "Accuracy of the model on the 3925 test images: 46.9%\n",
            "Max accuracy: 46.90%\n",
            "Test:  [ 0/41]  eta: 0:02:07  loss: 7.0129 (7.0129)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.0992  data: 2.8122  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 6.7494 (6.7600)  acc1: 0.0000 (1.7045)  acc5: 0.0000 (4.9242)  time: 0.5143  data: 0.2775  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.7411 (6.7952)  acc1: 0.0000 (1.1905)  acc5: 1.0417 (3.6210)  time: 0.2511  data: 0.0145  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.6967 (6.7373)  acc1: 0.0000 (1.3105)  acc5: 1.0417 (4.5699)  time: 0.2453  data: 0.0053  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.5674 (6.6862)  acc1: 0.0000 (1.0701)  acc5: 3.1250 (4.7389)  time: 0.2377  data: 0.0029  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3265 s / it)\n",
            "* Acc@1 1.070 Acc@5 4.739 loss 6.686\n",
            "Accuracy of the model EMA on 3925 test images: 1.1%\n",
            "Max EMA accuracy: 1.07%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [15]  [  0/147]  eta: 0:06:39  lr: 0.003004  min_lr: 0.003004  loss: 2.9143 (2.9143)  weight_decay: 0.0500 (0.0500)  time: 2.7183  data: 2.1420  max mem: 5388\n",
            "Epoch: [15]  [ 10/147]  eta: 0:01:38  lr: 0.003015  min_lr: 0.003015  loss: 2.9191 (2.9362)  weight_decay: 0.0500 (0.0500)  time: 0.7159  data: 0.1987  max mem: 5388\n",
            "Epoch: [15]  [ 20/147]  eta: 0:01:18  lr: 0.003032  min_lr: 0.003032  loss: 2.9091 (2.9073)  weight_decay: 0.0500 (0.0500)  time: 0.5163  data: 0.0043  max mem: 5388\n",
            "Epoch: [15]  [ 30/147]  eta: 0:01:08  lr: 0.003043  min_lr: 0.003043  loss: 2.8823 (2.9127)  weight_decay: 0.0500 (0.0500)  time: 0.5130  data: 0.0030  max mem: 5388\n",
            "Epoch: [15]  [ 40/147]  eta: 0:01:00  lr: 0.003060  min_lr: 0.003060  loss: 2.8823 (2.9091)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0016  max mem: 5388\n",
            "Epoch: [15]  [ 50/147]  eta: 0:00:54  lr: 0.003071  min_lr: 0.003071  loss: 2.8796 (2.9036)  weight_decay: 0.0500 (0.0500)  time: 0.5137  data: 0.0008  max mem: 5388\n",
            "Epoch: [15]  [ 60/147]  eta: 0:00:47  lr: 0.003088  min_lr: 0.003088  loss: 2.8949 (2.9033)  weight_decay: 0.0500 (0.0500)  time: 0.5177  data: 0.0002  max mem: 5388\n",
            "Epoch: [15]  [ 70/147]  eta: 0:00:41  lr: 0.003099  min_lr: 0.003099  loss: 2.9110 (2.9019)  weight_decay: 0.0500 (0.0500)  time: 0.5125  data: 0.0025  max mem: 5388\n",
            "Epoch: [15]  [ 80/147]  eta: 0:00:36  lr: 0.003115  min_lr: 0.003115  loss: 2.9172 (2.9009)  weight_decay: 0.0500 (0.0500)  time: 0.5051  data: 0.0033  max mem: 5388\n",
            "Epoch: [15]  [ 90/147]  eta: 0:00:30  lr: 0.003127  min_lr: 0.003127  loss: 2.8486 (2.8906)  weight_decay: 0.0500 (0.0500)  time: 0.5079  data: 0.0026  max mem: 5388\n",
            "Epoch: [15]  [100/147]  eta: 0:00:25  lr: 0.003143  min_lr: 0.003143  loss: 2.8456 (2.8863)  weight_decay: 0.0500 (0.0500)  time: 0.5047  data: 0.0020  max mem: 5388\n",
            "Epoch: [15]  [110/147]  eta: 0:00:19  lr: 0.003154  min_lr: 0.003154  loss: 2.8742 (2.8853)  weight_decay: 0.0500 (0.0500)  time: 0.4968  data: 0.0016  max mem: 5388\n",
            "Epoch: [15]  [120/147]  eta: 0:00:14  lr: 0.003171  min_lr: 0.003171  loss: 2.8987 (2.8863)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.0039  max mem: 5388\n",
            "Epoch: [15]  [130/147]  eta: 0:00:08  lr: 0.003182  min_lr: 0.003182  loss: 2.8766 (2.8865)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0034  max mem: 5388\n",
            "Epoch: [15]  [140/147]  eta: 0:00:03  lr: 0.003199  min_lr: 0.003199  loss: 2.8521 (2.8787)  weight_decay: 0.0500 (0.0500)  time: 0.4929  data: 0.0009  max mem: 5388\n",
            "Epoch: [15]  [146/147]  eta: 0:00:00  lr: 0.003199  min_lr: 0.003199  loss: 2.8484 (2.8793)  weight_decay: 0.0500 (0.0500)  time: 0.4181  data: 0.0002  max mem: 5388\n",
            "Epoch: [15] Total time: 0:01:15 (0.5145 s / it)\n",
            "Averaged stats: lr: 0.003199  min_lr: 0.003199  loss: 2.8484 (2.8793)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:56  loss: 0.9673 (0.9673)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 5.7570  data: 5.4451  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 1.3919 (1.4037)  acc1: 64.5833 (64.4886)  acc5: 93.7500 (92.0455)  time: 0.7332  data: 0.4972  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 1.7295 (1.7405)  acc1: 45.8333 (47.0734)  acc5: 89.5833 (86.1607)  time: 0.2368  data: 0.0016  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.8724 (1.7617)  acc1: 40.6250 (46.1022)  acc5: 88.5417 (88.3065)  time: 0.2635  data: 0.0240  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.7443 (1.6871)  acc1: 42.7083 (47.2866)  acc5: 92.7083 (89.0191)  time: 0.2556  data: 0.0237  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.3929 s / it)\n",
            "* Acc@1 47.287 Acc@5 89.019 loss 1.687\n",
            "Accuracy of the model on the 3925 test images: 47.3%\n",
            "Max accuracy: 47.29%\n",
            "Test:  [ 0/41]  eta: 0:02:56  loss: 6.9633 (6.9633)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 4.2993  data: 3.9984  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 6.7222 (6.7136)  acc1: 0.0000 (2.0833)  acc5: 0.0000 (6.3447)  time: 0.6200  data: 0.3830  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.7141 (6.7592)  acc1: 0.0000 (1.5873)  acc5: 1.0417 (4.6627)  time: 0.2502  data: 0.0176  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.6664 (6.7004)  acc1: 0.0000 (1.6801)  acc5: 2.0833 (6.1156)  time: 0.2426  data: 0.0070  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.5324 (6.6427)  acc1: 0.0000 (1.3503)  acc5: 4.1667 (7.3631)  time: 0.2335  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3516 s / it)\n",
            "* Acc@1 1.350 Acc@5 7.363 loss 6.643\n",
            "Accuracy of the model EMA on 3925 test images: 1.4%\n",
            "Max EMA accuracy: 1.35%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [16]  [  0/147]  eta: 0:11:10  lr: 0.003204  min_lr: 0.003204  loss: 2.8055 (2.8055)  weight_decay: 0.0500 (0.0500)  time: 4.5624  data: 3.9175  max mem: 5388\n",
            "Epoch: [16]  [ 10/147]  eta: 0:02:01  lr: 0.003216  min_lr: 0.003216  loss: 2.8055 (2.7976)  weight_decay: 0.0500 (0.0500)  time: 0.8845  data: 0.3589  max mem: 5388\n",
            "Epoch: [16]  [ 20/147]  eta: 0:01:29  lr: 0.003232  min_lr: 0.003232  loss: 2.8562 (2.8490)  weight_decay: 0.0500 (0.0500)  time: 0.5141  data: 0.0029  max mem: 5388\n",
            "Epoch: [16]  [ 30/147]  eta: 0:01:15  lr: 0.003243  min_lr: 0.003243  loss: 2.8845 (2.8529)  weight_decay: 0.0500 (0.0500)  time: 0.5168  data: 0.0035  max mem: 5388\n",
            "Epoch: [16]  [ 40/147]  eta: 0:01:05  lr: 0.003260  min_lr: 0.003260  loss: 2.8970 (2.8662)  weight_decay: 0.0500 (0.0500)  time: 0.5216  data: 0.0050  max mem: 5388\n",
            "Epoch: [16]  [ 50/147]  eta: 0:00:57  lr: 0.003271  min_lr: 0.003271  loss: 2.8928 (2.8656)  weight_decay: 0.0500 (0.0500)  time: 0.5174  data: 0.0041  max mem: 5388\n",
            "Epoch: [16]  [ 60/147]  eta: 0:00:50  lr: 0.003288  min_lr: 0.003288  loss: 2.8545 (2.8598)  weight_decay: 0.0500 (0.0500)  time: 0.5165  data: 0.0015  max mem: 5388\n",
            "Epoch: [16]  [ 70/147]  eta: 0:00:44  lr: 0.003299  min_lr: 0.003299  loss: 2.7803 (2.8518)  weight_decay: 0.0500 (0.0500)  time: 0.5156  data: 0.0023  max mem: 5388\n",
            "Epoch: [16]  [ 80/147]  eta: 0:00:37  lr: 0.003316  min_lr: 0.003316  loss: 2.7859 (2.8491)  weight_decay: 0.0500 (0.0500)  time: 0.5075  data: 0.0029  max mem: 5388\n",
            "Epoch: [16]  [ 90/147]  eta: 0:00:31  lr: 0.003327  min_lr: 0.003327  loss: 2.8433 (2.8494)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0018  max mem: 5388\n",
            "Epoch: [16]  [100/147]  eta: 0:00:25  lr: 0.003344  min_lr: 0.003344  loss: 2.8779 (2.8474)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0029  max mem: 5388\n",
            "Epoch: [16]  [110/147]  eta: 0:00:20  lr: 0.003355  min_lr: 0.003355  loss: 2.8625 (2.8519)  weight_decay: 0.0500 (0.0500)  time: 0.4987  data: 0.0030  max mem: 5388\n",
            "Epoch: [16]  [120/147]  eta: 0:00:14  lr: 0.003371  min_lr: 0.003371  loss: 2.9114 (2.8593)  weight_decay: 0.0500 (0.0500)  time: 0.4940  data: 0.0015  max mem: 5388\n",
            "Epoch: [16]  [130/147]  eta: 0:00:09  lr: 0.003382  min_lr: 0.003382  loss: 2.9035 (2.8580)  weight_decay: 0.0500 (0.0500)  time: 0.4991  data: 0.0023  max mem: 5388\n",
            "Epoch: [16]  [140/147]  eta: 0:00:03  lr: 0.003399  min_lr: 0.003399  loss: 2.8404 (2.8564)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0019  max mem: 5388\n",
            "Epoch: [16]  [146/147]  eta: 0:00:00  lr: 0.003399  min_lr: 0.003399  loss: 2.8327 (2.8561)  weight_decay: 0.0500 (0.0500)  time: 0.4183  data: 0.0002  max mem: 5388\n",
            "Epoch: [16] Total time: 0:01:17 (0.5273 s / it)\n",
            "Averaged stats: lr: 0.003399  min_lr: 0.003399  loss: 2.8327 (2.8561)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:11  loss: 0.8820 (0.8820)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 4.6682  data: 4.3836  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 1.1551 (1.5087)  acc1: 72.9167 (57.0076)  acc5: 95.8333 (91.7614)  time: 0.6733  data: 0.4265  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 2.0646 (1.8543)  acc1: 28.1250 (40.7242)  acc5: 84.3750 (83.1349)  time: 0.2744  data: 0.0321  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 2.0646 (1.8896)  acc1: 30.2083 (37.6680)  acc5: 80.2083 (83.7366)  time: 0.2555  data: 0.0169  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.7076 (1.7576)  acc1: 40.6250 (43.1847)  acc5: 90.6250 (86.3440)  time: 0.2316  data: 0.0002  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3702 s / it)\n",
            "* Acc@1 43.185 Acc@5 86.344 loss 1.758\n",
            "Accuracy of the model on the 3925 test images: 43.2%\n",
            "Max accuracy: 47.29%\n",
            "Test:  [ 0/41]  eta: 0:02:15  loss: 6.9105 (6.9105)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.3029  data: 3.0078  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 6.6921 (6.6641)  acc1: 0.0000 (2.7462)  acc5: 1.0417 (7.4811)  time: 0.5376  data: 0.2899  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.6840 (6.7208)  acc1: 0.0000 (2.0337)  acc5: 1.0417 (5.6548)  time: 0.2822  data: 0.0406  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.6351 (6.6614)  acc1: 0.0000 (2.0161)  acc5: 2.0833 (7.3589)  time: 0.3079  data: 0.0670  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.4966 (6.5969)  acc1: 0.0000 (1.6306)  acc5: 6.2500 (9.7070)  time: 0.2728  data: 0.0355  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3612 s / it)\n",
            "* Acc@1 1.631 Acc@5 9.707 loss 6.597\n",
            "Accuracy of the model EMA on 3925 test images: 1.6%\n",
            "Max EMA accuracy: 1.63%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [17]  [  0/147]  eta: 0:06:46  lr: 0.003405  min_lr: 0.003405  loss: 2.8125 (2.8125)  weight_decay: 0.0500 (0.0500)  time: 2.7640  data: 2.1749  max mem: 5388\n",
            "Epoch: [17]  [ 10/147]  eta: 0:01:39  lr: 0.003416  min_lr: 0.003416  loss: 2.9625 (2.9103)  weight_decay: 0.0500 (0.0500)  time: 0.7259  data: 0.2020  max mem: 5388\n",
            "Epoch: [17]  [ 20/147]  eta: 0:01:20  lr: 0.003433  min_lr: 0.003433  loss: 2.8773 (2.8854)  weight_decay: 0.0500 (0.0500)  time: 0.5254  data: 0.0049  max mem: 5388\n",
            "Epoch: [17]  [ 30/147]  eta: 0:01:09  lr: 0.003444  min_lr: 0.003444  loss: 2.8493 (2.8704)  weight_decay: 0.0500 (0.0500)  time: 0.5272  data: 0.0041  max mem: 5388\n",
            "Epoch: [17]  [ 40/147]  eta: 0:01:01  lr: 0.003460  min_lr: 0.003460  loss: 2.8436 (2.8509)  weight_decay: 0.0500 (0.0500)  time: 0.5191  data: 0.0028  max mem: 5388\n",
            "Epoch: [17]  [ 50/147]  eta: 0:00:54  lr: 0.003471  min_lr: 0.003471  loss: 2.8169 (2.8504)  weight_decay: 0.0500 (0.0500)  time: 0.5128  data: 0.0023  max mem: 5388\n",
            "Epoch: [17]  [ 60/147]  eta: 0:00:48  lr: 0.003488  min_lr: 0.003488  loss: 2.8176 (2.8456)  weight_decay: 0.0500 (0.0500)  time: 0.5122  data: 0.0018  max mem: 5388\n",
            "Epoch: [17]  [ 70/147]  eta: 0:00:42  lr: 0.003499  min_lr: 0.003499  loss: 2.8187 (2.8456)  weight_decay: 0.0500 (0.0500)  time: 0.5067  data: 0.0025  max mem: 5388\n",
            "Epoch: [17]  [ 80/147]  eta: 0:00:36  lr: 0.003516  min_lr: 0.003516  loss: 2.8021 (2.8322)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0027  max mem: 5388\n",
            "Epoch: [17]  [ 90/147]  eta: 0:00:30  lr: 0.003527  min_lr: 0.003527  loss: 2.7945 (2.8310)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0020  max mem: 5388\n",
            "Epoch: [17]  [100/147]  eta: 0:00:25  lr: 0.003544  min_lr: 0.003544  loss: 2.8050 (2.8305)  weight_decay: 0.0500 (0.0500)  time: 0.5019  data: 0.0025  max mem: 5388\n",
            "Epoch: [17]  [110/147]  eta: 0:00:19  lr: 0.003555  min_lr: 0.003555  loss: 2.7978 (2.8289)  weight_decay: 0.0500 (0.0500)  time: 0.4947  data: 0.0023  max mem: 5388\n",
            "Epoch: [17]  [120/147]  eta: 0:00:14  lr: 0.003572  min_lr: 0.003572  loss: 2.8539 (2.8308)  weight_decay: 0.0500 (0.0500)  time: 0.5007  data: 0.0022  max mem: 5388\n",
            "Epoch: [17]  [130/147]  eta: 0:00:08  lr: 0.003583  min_lr: 0.003583  loss: 2.8716 (2.8354)  weight_decay: 0.0500 (0.0500)  time: 0.5006  data: 0.0023  max mem: 5388\n",
            "Epoch: [17]  [140/147]  eta: 0:00:03  lr: 0.003599  min_lr: 0.003599  loss: 2.8692 (2.8349)  weight_decay: 0.0500 (0.0500)  time: 0.4931  data: 0.0012  max mem: 5388\n",
            "Epoch: [17]  [146/147]  eta: 0:00:00  lr: 0.003599  min_lr: 0.003599  loss: 2.8662 (2.8354)  weight_decay: 0.0500 (0.0500)  time: 0.4193  data: 0.0002  max mem: 5388\n",
            "Epoch: [17] Total time: 0:01:16 (0.5172 s / it)\n",
            "Averaged stats: lr: 0.003599  min_lr: 0.003599  loss: 2.8662 (2.8354)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:22  loss: 1.4049 (1.4049)  acc1: 73.9583 (73.9583)  acc5: 89.5833 (89.5833)  time: 4.9272  data: 4.6330  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 1.7410 (1.7084)  acc1: 55.2083 (51.6099)  acc5: 89.5833 (88.4470)  time: 0.6644  data: 0.4226  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.7758 (1.7561)  acc1: 48.9583 (43.4028)  acc5: 91.6667 (90.7738)  time: 0.2380  data: 0.0018  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.6536 (1.6932)  acc1: 48.9583 (48.7231)  acc5: 93.7500 (91.1626)  time: 0.2373  data: 0.0011  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.5565 (1.6211)  acc1: 57.2917 (51.8471)  acc5: 91.6667 (91.4140)  time: 0.2329  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3622 s / it)\n",
            "* Acc@1 51.847 Acc@5 91.414 loss 1.621\n",
            "Accuracy of the model on the 3925 test images: 51.8%\n",
            "Max accuracy: 51.85%\n",
            "Test:  [ 0/41]  eta: 0:03:32  loss: 6.8548 (6.8548)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 5.1732  data: 4.9097  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.6607 (6.6116)  acc1: 0.0000 (3.4091)  acc5: 2.0833 (9.0909)  time: 0.6869  data: 0.4509  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.6520 (6.6801)  acc1: 0.0000 (2.5298)  acc5: 2.0833 (6.7460)  time: 0.2381  data: 0.0045  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.6038 (6.6199)  acc1: 1.0417 (2.4530)  acc5: 2.0833 (8.6358)  time: 0.2389  data: 0.0020  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.4589 (6.5481)  acc1: 0.0000 (1.9873)  acc5: 8.3333 (12.2038)  time: 0.2360  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3710 s / it)\n",
            "* Acc@1 1.987 Acc@5 12.204 loss 6.548\n",
            "Accuracy of the model EMA on 3925 test images: 2.0%\n",
            "Max EMA accuracy: 1.99%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [18]  [  0/147]  eta: 0:08:46  lr: 0.003605  min_lr: 0.003605  loss: 2.7781 (2.7781)  weight_decay: 0.0500 (0.0500)  time: 3.5797  data: 2.9695  max mem: 5388\n",
            "Epoch: [18]  [ 10/147]  eta: 0:01:50  lr: 0.003616  min_lr: 0.003616  loss: 2.8488 (2.8619)  weight_decay: 0.0500 (0.0500)  time: 0.8047  data: 0.2750  max mem: 5388\n",
            "Epoch: [18]  [ 20/147]  eta: 0:01:24  lr: 0.003633  min_lr: 0.003633  loss: 2.8498 (2.8490)  weight_decay: 0.0500 (0.0500)  time: 0.5199  data: 0.0032  max mem: 5388\n",
            "Epoch: [18]  [ 30/147]  eta: 0:01:12  lr: 0.003644  min_lr: 0.003644  loss: 2.8774 (2.8567)  weight_decay: 0.0500 (0.0500)  time: 0.5161  data: 0.0015  max mem: 5388\n",
            "Epoch: [18]  [ 40/147]  eta: 0:01:03  lr: 0.003661  min_lr: 0.003661  loss: 2.8504 (2.8498)  weight_decay: 0.0500 (0.0500)  time: 0.5192  data: 0.0026  max mem: 5388\n",
            "Epoch: [18]  [ 50/147]  eta: 0:00:56  lr: 0.003672  min_lr: 0.003672  loss: 2.8470 (2.8537)  weight_decay: 0.0500 (0.0500)  time: 0.5137  data: 0.0027  max mem: 5388\n",
            "Epoch: [18]  [ 60/147]  eta: 0:00:49  lr: 0.003688  min_lr: 0.003688  loss: 2.7840 (2.8467)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0020  max mem: 5388\n",
            "Epoch: [18]  [ 70/147]  eta: 0:00:43  lr: 0.003700  min_lr: 0.003700  loss: 2.8601 (2.8497)  weight_decay: 0.0500 (0.0500)  time: 0.5108  data: 0.0019  max mem: 5388\n",
            "Epoch: [18]  [ 80/147]  eta: 0:00:36  lr: 0.003716  min_lr: 0.003716  loss: 2.8646 (2.8472)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0021  max mem: 5388\n",
            "Epoch: [18]  [ 90/147]  eta: 0:00:31  lr: 0.003727  min_lr: 0.003727  loss: 2.8261 (2.8441)  weight_decay: 0.0500 (0.0500)  time: 0.4981  data: 0.0015  max mem: 5388\n",
            "Epoch: [18]  [100/147]  eta: 0:00:25  lr: 0.003744  min_lr: 0.003744  loss: 2.8033 (2.8394)  weight_decay: 0.0500 (0.0500)  time: 0.5086  data: 0.0037  max mem: 5388\n",
            "Epoch: [18]  [110/147]  eta: 0:00:19  lr: 0.003755  min_lr: 0.003755  loss: 2.7956 (2.8399)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0055  max mem: 5388\n",
            "Epoch: [18]  [120/147]  eta: 0:00:14  lr: 0.003772  min_lr: 0.003772  loss: 2.8325 (2.8425)  weight_decay: 0.0500 (0.0500)  time: 0.5015  data: 0.0029  max mem: 5388\n",
            "Epoch: [18]  [130/147]  eta: 0:00:09  lr: 0.003783  min_lr: 0.003783  loss: 2.8678 (2.8408)  weight_decay: 0.0500 (0.0500)  time: 0.4927  data: 0.0011  max mem: 5388\n",
            "Epoch: [18]  [140/147]  eta: 0:00:03  lr: 0.003800  min_lr: 0.003800  loss: 2.8265 (2.8408)  weight_decay: 0.0500 (0.0500)  time: 0.4939  data: 0.0006  max mem: 5388\n",
            "Epoch: [18]  [146/147]  eta: 0:00:00  lr: 0.003800  min_lr: 0.003800  loss: 2.8265 (2.8427)  weight_decay: 0.0500 (0.0500)  time: 0.4214  data: 0.0002  max mem: 5388\n",
            "Epoch: [18] Total time: 0:01:16 (0.5212 s / it)\n",
            "Averaged stats: lr: 0.003800  min_lr: 0.003800  loss: 2.8265 (2.8427)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:21  loss: 0.7769 (0.7769)  acc1: 95.8333 (95.8333)  acc5: 98.9583 (98.9583)  time: 3.4470  data: 3.1161  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 1.6950 (1.4164)  acc1: 53.1250 (63.9205)  acc5: 91.6667 (92.1402)  time: 0.5264  data: 0.2871  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 1.7228 (1.6597)  acc1: 46.8750 (48.5119)  acc5: 91.6667 (91.5179)  time: 0.2412  data: 0.0027  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 1.8341 (1.7536)  acc1: 34.3750 (44.1196)  acc5: 90.6250 (89.3817)  time: 0.2594  data: 0.0165  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.8539 (1.7581)  acc1: 33.3333 (43.1592)  acc5: 89.5833 (86.8026)  time: 0.2514  data: 0.0159  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3353 s / it)\n",
            "* Acc@1 43.159 Acc@5 86.803 loss 1.758\n",
            "Accuracy of the model on the 3925 test images: 43.2%\n",
            "Max accuracy: 51.85%\n",
            "Test:  [ 0/41]  eta: 0:02:13  loss: 6.7972 (6.7972)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.2450  data: 2.9290  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 6.6267 (6.5563)  acc1: 0.0000 (3.8826)  acc5: 3.1250 (10.4167)  time: 0.5153  data: 0.2716  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.6170 (6.6373)  acc1: 0.0000 (2.8274)  acc5: 3.1250 (7.7381)  time: 0.2418  data: 0.0060  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.5729 (6.5759)  acc1: 1.0417 (2.6210)  acc5: 3.1250 (10.0134)  time: 0.2395  data: 0.0031  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.4186 (6.4959)  acc1: 0.0000 (2.1656)  acc5: 11.4583 (14.4204)  time: 0.2360  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3252 s / it)\n",
            "* Acc@1 2.166 Acc@5 14.420 loss 6.496\n",
            "Accuracy of the model EMA on 3925 test images: 2.2%\n",
            "Max EMA accuracy: 2.17%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [19]  [  0/147]  eta: 0:07:05  lr: 0.003805  min_lr: 0.003805  loss: 2.9864 (2.9864)  weight_decay: 0.0500 (0.0500)  time: 2.8959  data: 2.3071  max mem: 5388\n",
            "Epoch: [19]  [ 10/147]  eta: 0:01:40  lr: 0.003816  min_lr: 0.003816  loss: 2.8828 (2.8926)  weight_decay: 0.0500 (0.0500)  time: 0.7350  data: 0.2118  max mem: 5388\n",
            "Epoch: [19]  [ 20/147]  eta: 0:01:19  lr: 0.003833  min_lr: 0.003833  loss: 2.8712 (2.8676)  weight_decay: 0.0500 (0.0500)  time: 0.5157  data: 0.0024  max mem: 5388\n",
            "Epoch: [19]  [ 30/147]  eta: 0:01:09  lr: 0.003844  min_lr: 0.003844  loss: 2.8712 (2.8709)  weight_decay: 0.0500 (0.0500)  time: 0.5147  data: 0.0031  max mem: 5388\n",
            "Epoch: [19]  [ 40/147]  eta: 0:01:01  lr: 0.003861  min_lr: 0.003861  loss: 2.8367 (2.8541)  weight_decay: 0.0500 (0.0500)  time: 0.5089  data: 0.0023  max mem: 5388\n",
            "Epoch: [19]  [ 50/147]  eta: 0:00:54  lr: 0.003872  min_lr: 0.003872  loss: 2.8232 (2.8565)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0012  max mem: 5388\n",
            "Epoch: [19]  [ 60/147]  eta: 0:00:47  lr: 0.003889  min_lr: 0.003889  loss: 2.8452 (2.8492)  weight_decay: 0.0500 (0.0500)  time: 0.5083  data: 0.0036  max mem: 5388\n",
            "Epoch: [19]  [ 70/147]  eta: 0:00:41  lr: 0.003900  min_lr: 0.003900  loss: 2.8544 (2.8504)  weight_decay: 0.0500 (0.0500)  time: 0.5064  data: 0.0042  max mem: 5388\n",
            "Epoch: [19]  [ 80/147]  eta: 0:00:35  lr: 0.003917  min_lr: 0.003917  loss: 2.8801 (2.8478)  weight_decay: 0.0500 (0.0500)  time: 0.4980  data: 0.0019  max mem: 5388\n",
            "Epoch: [19]  [ 90/147]  eta: 0:00:30  lr: 0.003928  min_lr: 0.003928  loss: 2.7923 (2.8406)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0018  max mem: 5388\n",
            "Epoch: [19]  [100/147]  eta: 0:00:24  lr: 0.003944  min_lr: 0.003944  loss: 2.7923 (2.8359)  weight_decay: 0.0500 (0.0500)  time: 0.5034  data: 0.0018  max mem: 5388\n",
            "Epoch: [19]  [110/147]  eta: 0:00:19  lr: 0.003955  min_lr: 0.003955  loss: 2.8044 (2.8334)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0021  max mem: 5388\n",
            "Epoch: [19]  [120/147]  eta: 0:00:14  lr: 0.003972  min_lr: 0.003972  loss: 2.7852 (2.8289)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0029  max mem: 5388\n",
            "Epoch: [19]  [130/147]  eta: 0:00:08  lr: 0.003983  min_lr: 0.003983  loss: 2.7738 (2.8232)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0026  max mem: 5388\n",
            "Epoch: [19]  [140/147]  eta: 0:00:03  lr: 0.004000  min_lr: 0.004000  loss: 2.7767 (2.8231)  weight_decay: 0.0500 (0.0500)  time: 0.4993  data: 0.0013  max mem: 5388\n",
            "Epoch: [19]  [146/147]  eta: 0:00:00  lr: 0.004000  min_lr: 0.004000  loss: 2.7833 (2.8227)  weight_decay: 0.0500 (0.0500)  time: 0.4228  data: 0.0002  max mem: 5388\n",
            "Epoch: [19] Total time: 0:01:15 (0.5133 s / it)\n",
            "Averaged stats: lr: 0.004000  min_lr: 0.004000  loss: 2.7833 (2.8227)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:36  loss: 1.1954 (1.1954)  acc1: 72.9167 (72.9167)  acc5: 93.7500 (93.7500)  time: 3.8082  data: 3.5300  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 1.5817 (1.6139)  acc1: 57.2917 (54.2614)  acc5: 91.6667 (91.3826)  time: 0.6957  data: 0.4558  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 1.6090 (1.6958)  acc1: 53.1250 (48.3631)  acc5: 92.7083 (92.9067)  time: 0.3361  data: 0.0967  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.6015 (1.6574)  acc1: 53.1250 (51.6129)  acc5: 93.7500 (92.3723)  time: 0.2994  data: 0.0564  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.4198 (1.5755)  acc1: 64.5833 (55.1338)  acc5: 92.7083 (92.5605)  time: 0.2915  data: 0.0563  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.4085 s / it)\n",
            "* Acc@1 55.134 Acc@5 92.561 loss 1.576\n",
            "Accuracy of the model on the 3925 test images: 55.1%\n",
            "Max accuracy: 55.13%\n",
            "Test:  [ 0/41]  eta: 0:03:49  loss: 6.7324 (6.7324)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 5.5954  data: 5.2938  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 6.5791 (6.4955)  acc1: 0.0000 (4.4508)  acc5: 5.2083 (12.4053)  time: 0.8023  data: 0.5572  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 6.5750 (6.5912)  acc1: 0.0000 (3.1250)  acc5: 4.1667 (9.3254)  time: 0.2821  data: 0.0435  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.5446 (6.5288)  acc1: 1.0417 (2.7890)  acc5: 4.1667 (12.0296)  time: 0.2375  data: 0.0018  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.3778 (6.4408)  acc1: 1.0417 (2.4204)  acc5: 13.5417 (16.7134)  time: 0.2323  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.3961 s / it)\n",
            "* Acc@1 2.420 Acc@5 16.713 loss 6.441\n",
            "Accuracy of the model EMA on 3925 test images: 2.4%\n",
            "Max EMA accuracy: 2.42%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [20]  [  0/147]  eta: 0:09:31  lr: 0.004000  min_lr: 0.004000  loss: 2.9136 (2.9136)  weight_decay: 0.0500 (0.0500)  time: 3.8895  data: 3.1795  max mem: 5388\n",
            "Epoch: [20]  [ 10/147]  eta: 0:02:02  lr: 0.004000  min_lr: 0.004000  loss: 2.8302 (2.8235)  weight_decay: 0.0500 (0.0500)  time: 0.8923  data: 0.2903  max mem: 5388\n",
            "Epoch: [20]  [ 20/147]  eta: 0:01:30  lr: 0.004000  min_lr: 0.004000  loss: 2.7863 (2.8172)  weight_decay: 0.0500 (0.0500)  time: 0.5506  data: 0.0016  max mem: 5388\n",
            "Epoch: [20]  [ 30/147]  eta: 0:01:15  lr: 0.004000  min_lr: 0.004000  loss: 2.7808 (2.8199)  weight_decay: 0.0500 (0.0500)  time: 0.5102  data: 0.0027  max mem: 5388\n",
            "Epoch: [20]  [ 40/147]  eta: 0:01:06  lr: 0.003999  min_lr: 0.003999  loss: 2.7669 (2.7922)  weight_decay: 0.0500 (0.0500)  time: 0.5197  data: 0.0033  max mem: 5388\n",
            "Epoch: [20]  [ 50/147]  eta: 0:00:57  lr: 0.003999  min_lr: 0.003999  loss: 2.7303 (2.7882)  weight_decay: 0.0500 (0.0500)  time: 0.5203  data: 0.0026  max mem: 5388\n",
            "Epoch: [20]  [ 60/147]  eta: 0:00:50  lr: 0.003998  min_lr: 0.003998  loss: 2.8035 (2.7909)  weight_decay: 0.0500 (0.0500)  time: 0.5116  data: 0.0029  max mem: 5388\n",
            "Epoch: [20]  [ 70/147]  eta: 0:00:44  lr: 0.003998  min_lr: 0.003998  loss: 2.8033 (2.7905)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0045  max mem: 5388\n",
            "Epoch: [20]  [ 80/147]  eta: 0:00:37  lr: 0.003997  min_lr: 0.003997  loss: 2.7935 (2.7994)  weight_decay: 0.0500 (0.0500)  time: 0.5108  data: 0.0039  max mem: 5388\n",
            "Epoch: [20]  [ 90/147]  eta: 0:00:31  lr: 0.003996  min_lr: 0.003996  loss: 2.7626 (2.7954)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0039  max mem: 5388\n",
            "Epoch: [20]  [100/147]  eta: 0:00:25  lr: 0.003995  min_lr: 0.003995  loss: 2.7243 (2.7948)  weight_decay: 0.0500 (0.0500)  time: 0.5007  data: 0.0038  max mem: 5388\n",
            "Epoch: [20]  [110/147]  eta: 0:00:20  lr: 0.003994  min_lr: 0.003994  loss: 2.7273 (2.7918)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0022  max mem: 5388\n",
            "Epoch: [20]  [120/147]  eta: 0:00:14  lr: 0.003992  min_lr: 0.003992  loss: 2.7474 (2.7915)  weight_decay: 0.0500 (0.0500)  time: 0.4974  data: 0.0022  max mem: 5388\n",
            "Epoch: [20]  [130/147]  eta: 0:00:09  lr: 0.003991  min_lr: 0.003991  loss: 2.7641 (2.7893)  weight_decay: 0.0500 (0.0500)  time: 0.4956  data: 0.0024  max mem: 5388\n",
            "Epoch: [20]  [140/147]  eta: 0:00:03  lr: 0.003990  min_lr: 0.003990  loss: 2.7377 (2.7864)  weight_decay: 0.0500 (0.0500)  time: 0.4943  data: 0.0014  max mem: 5388\n",
            "Epoch: [20]  [146/147]  eta: 0:00:00  lr: 0.003990  min_lr: 0.003990  loss: 2.8095 (2.7882)  weight_decay: 0.0500 (0.0500)  time: 0.4190  data: 0.0002  max mem: 5388\n",
            "Epoch: [20] Total time: 0:01:17 (0.5271 s / it)\n",
            "Averaged stats: lr: 0.003990  min_lr: 0.003990  loss: 2.8095 (2.7882)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:14  loss: 1.0406 (1.0406)  acc1: 79.1667 (79.1667)  acc5: 94.7917 (94.7917)  time: 3.2844  data: 2.9724  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 1.2928 (1.4099)  acc1: 69.7917 (60.3220)  acc5: 92.7083 (90.3409)  time: 0.5127  data: 0.2734  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 1.6341 (1.6735)  acc1: 44.7917 (46.6766)  acc5: 87.5000 (88.5913)  time: 0.2564  data: 0.0210  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.5618 (1.6040)  acc1: 48.9583 (49.3280)  acc5: 91.6667 (90.3226)  time: 0.2950  data: 0.0520  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.4447 (1.5428)  acc1: 54.1667 (52.2548)  acc5: 93.7500 (91.2357)  time: 0.2706  data: 0.0328  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3471 s / it)\n",
            "* Acc@1 52.255 Acc@5 91.236 loss 1.543\n",
            "Accuracy of the model on the 3925 test images: 52.3%\n",
            "Max accuracy: 55.13%\n",
            "Test:  [ 0/41]  eta: 0:01:59  loss: 6.6621 (6.6621)  acc1: 0.0000 (0.0000)  acc5: 1.0417 (1.0417)  time: 2.9253  data: 2.6342  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 6.5388 (6.4321)  acc1: 0.0000 (4.9242)  acc5: 9.3750 (15.9091)  time: 0.4853  data: 0.2459  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:07  loss: 6.5388 (6.5425)  acc1: 0.0000 (3.4226)  acc5: 6.2500 (11.7560)  time: 0.2414  data: 0.0043  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.5143 (6.4795)  acc1: 1.0417 (2.9570)  acc5: 6.2500 (14.2473)  time: 0.2430  data: 0.0008  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.3344 (6.3829)  acc1: 2.0833 (2.7771)  acc5: 14.5833 (19.3121)  time: 0.2383  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3184 s / it)\n",
            "* Acc@1 2.777 Acc@5 19.312 loss 6.383\n",
            "Accuracy of the model EMA on 3925 test images: 2.8%\n",
            "Max EMA accuracy: 2.78%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [21]  [  0/147]  eta: 0:07:21  lr: 0.003989  min_lr: 0.003989  loss: 3.1114 (3.1114)  weight_decay: 0.0500 (0.0500)  time: 3.0028  data: 2.4203  max mem: 5388\n",
            "Epoch: [21]  [ 10/147]  eta: 0:01:42  lr: 0.003988  min_lr: 0.003988  loss: 2.9534 (2.8692)  weight_decay: 0.0500 (0.0500)  time: 0.7449  data: 0.2209  max mem: 5388\n",
            "Epoch: [21]  [ 20/147]  eta: 0:01:20  lr: 0.003986  min_lr: 0.003986  loss: 2.7740 (2.8094)  weight_decay: 0.0500 (0.0500)  time: 0.5161  data: 0.0010  max mem: 5388\n",
            "Epoch: [21]  [ 30/147]  eta: 0:01:10  lr: 0.003984  min_lr: 0.003984  loss: 2.7592 (2.8003)  weight_decay: 0.0500 (0.0500)  time: 0.5193  data: 0.0036  max mem: 5388\n",
            "Epoch: [21]  [ 40/147]  eta: 0:01:02  lr: 0.003982  min_lr: 0.003982  loss: 2.7671 (2.7926)  weight_decay: 0.0500 (0.0500)  time: 0.5243  data: 0.0041  max mem: 5388\n",
            "Epoch: [21]  [ 50/147]  eta: 0:00:54  lr: 0.003981  min_lr: 0.003981  loss: 2.8064 (2.8045)  weight_decay: 0.0500 (0.0500)  time: 0.5158  data: 0.0017  max mem: 5388\n",
            "Epoch: [21]  [ 60/147]  eta: 0:00:48  lr: 0.003978  min_lr: 0.003978  loss: 2.8064 (2.8029)  weight_decay: 0.0500 (0.0500)  time: 0.5105  data: 0.0012  max mem: 5388\n",
            "Epoch: [21]  [ 70/147]  eta: 0:00:42  lr: 0.003976  min_lr: 0.003976  loss: 2.8266 (2.8093)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0017  max mem: 5388\n",
            "Epoch: [21]  [ 80/147]  eta: 0:00:36  lr: 0.003974  min_lr: 0.003974  loss: 2.8268 (2.8064)  weight_decay: 0.0500 (0.0500)  time: 0.5057  data: 0.0024  max mem: 5388\n",
            "Epoch: [21]  [ 90/147]  eta: 0:00:30  lr: 0.003972  min_lr: 0.003972  loss: 2.8095 (2.8096)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0016  max mem: 5388\n",
            "Epoch: [21]  [100/147]  eta: 0:00:25  lr: 0.003969  min_lr: 0.003969  loss: 2.8258 (2.8096)  weight_decay: 0.0500 (0.0500)  time: 0.5060  data: 0.0022  max mem: 5388\n",
            "Epoch: [21]  [110/147]  eta: 0:00:19  lr: 0.003967  min_lr: 0.003967  loss: 2.8604 (2.8183)  weight_decay: 0.0500 (0.0500)  time: 0.5040  data: 0.0041  max mem: 5388\n",
            "Epoch: [21]  [120/147]  eta: 0:00:14  lr: 0.003963  min_lr: 0.003963  loss: 2.8874 (2.8215)  weight_decay: 0.0500 (0.0500)  time: 0.4966  data: 0.0040  max mem: 5388\n",
            "Epoch: [21]  [130/147]  eta: 0:00:08  lr: 0.003961  min_lr: 0.003961  loss: 2.8588 (2.8200)  weight_decay: 0.0500 (0.0500)  time: 0.4968  data: 0.0023  max mem: 5388\n",
            "Epoch: [21]  [140/147]  eta: 0:00:03  lr: 0.003958  min_lr: 0.003958  loss: 2.8263 (2.8187)  weight_decay: 0.0500 (0.0500)  time: 0.4950  data: 0.0006  max mem: 5388\n",
            "Epoch: [21]  [146/147]  eta: 0:00:00  lr: 0.003958  min_lr: 0.003958  loss: 2.8416 (2.8199)  weight_decay: 0.0500 (0.0500)  time: 0.4193  data: 0.0002  max mem: 5388\n",
            "Epoch: [21] Total time: 0:01:15 (0.5164 s / it)\n",
            "Averaged stats: lr: 0.003958  min_lr: 0.003958  loss: 2.8416 (2.8199)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:18  loss: 1.4144 (1.4144)  acc1: 70.8333 (70.8333)  acc5: 92.7083 (92.7083)  time: 3.3690  data: 3.0653  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 1.5636 (1.5981)  acc1: 54.1667 (54.6402)  acc5: 91.6667 (88.3523)  time: 0.6115  data: 0.3721  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 1.5636 (1.6793)  acc1: 52.0833 (48.0159)  acc5: 91.6667 (88.5417)  time: 0.3511  data: 0.1130  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.8029 (1.7123)  acc1: 37.5000 (43.7500)  acc5: 91.6667 (89.3817)  time: 0.3002  data: 0.0616  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.6293 (1.6319)  acc1: 40.6250 (47.9745)  acc5: 94.7917 (90.4459)  time: 0.2310  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3745 s / it)\n",
            "* Acc@1 47.975 Acc@5 90.446 loss 1.632\n",
            "Accuracy of the model on the 3925 test images: 48.0%\n",
            "Max accuracy: 55.13%\n",
            "Test:  [ 0/41]  eta: 0:02:15  loss: 6.5895 (6.5895)  acc1: 0.0000 (0.0000)  acc5: 4.1667 (4.1667)  time: 3.2953  data: 3.0010  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 6.4972 (6.3669)  acc1: 2.0833 (6.1553)  acc5: 16.6667 (20.6439)  time: 0.5144  data: 0.2756  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.4972 (6.4920)  acc1: 1.0417 (4.2163)  acc5: 8.3333 (14.8313)  time: 0.2428  data: 0.0030  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.4824 (6.4282)  acc1: 1.0417 (3.5954)  acc5: 7.2917 (17.4059)  time: 0.2789  data: 0.0379  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.2904 (6.3227)  acc1: 2.0833 (3.5924)  acc5: 19.7917 (22.6497)  time: 0.2707  data: 0.0365  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3402 s / it)\n",
            "* Acc@1 3.592 Acc@5 22.650 loss 6.323\n",
            "Accuracy of the model EMA on 3925 test images: 3.6%\n",
            "Max EMA accuracy: 3.59%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [22]  [  0/147]  eta: 0:06:06  lr: 0.003956  min_lr: 0.003956  loss: 2.8693 (2.8693)  weight_decay: 0.0500 (0.0500)  time: 2.4924  data: 1.9122  max mem: 5388\n",
            "Epoch: [22]  [ 10/147]  eta: 0:01:36  lr: 0.003954  min_lr: 0.003954  loss: 2.8750 (2.8653)  weight_decay: 0.0500 (0.0500)  time: 0.7059  data: 0.1770  max mem: 5388\n",
            "Epoch: [22]  [ 20/147]  eta: 0:01:18  lr: 0.003950  min_lr: 0.003950  loss: 2.8819 (2.8672)  weight_decay: 0.0500 (0.0500)  time: 0.5224  data: 0.0026  max mem: 5388\n",
            "Epoch: [22]  [ 30/147]  eta: 0:01:08  lr: 0.003947  min_lr: 0.003947  loss: 2.8150 (2.8351)  weight_decay: 0.0500 (0.0500)  time: 0.5146  data: 0.0018  max mem: 5388\n",
            "Epoch: [22]  [ 40/147]  eta: 0:01:00  lr: 0.003943  min_lr: 0.003943  loss: 2.7237 (2.8092)  weight_decay: 0.0500 (0.0500)  time: 0.5116  data: 0.0018  max mem: 5388\n",
            "Epoch: [22]  [ 50/147]  eta: 0:00:53  lr: 0.003941  min_lr: 0.003941  loss: 2.7338 (2.8078)  weight_decay: 0.0500 (0.0500)  time: 0.5142  data: 0.0016  max mem: 5388\n",
            "Epoch: [22]  [ 60/147]  eta: 0:00:47  lr: 0.003936  min_lr: 0.003936  loss: 2.7517 (2.8116)  weight_decay: 0.0500 (0.0500)  time: 0.5150  data: 0.0026  max mem: 5388\n",
            "Epoch: [22]  [ 70/147]  eta: 0:00:41  lr: 0.003933  min_lr: 0.003933  loss: 2.8212 (2.8104)  weight_decay: 0.0500 (0.0500)  time: 0.5074  data: 0.0033  max mem: 5388\n",
            "Epoch: [22]  [ 80/147]  eta: 0:00:36  lr: 0.003929  min_lr: 0.003929  loss: 2.7965 (2.8056)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0016  max mem: 5388\n",
            "Epoch: [22]  [ 90/147]  eta: 0:00:30  lr: 0.003926  min_lr: 0.003926  loss: 2.8111 (2.8059)  weight_decay: 0.0500 (0.0500)  time: 0.5031  data: 0.0004  max mem: 5388\n",
            "Epoch: [22]  [100/147]  eta: 0:00:24  lr: 0.003921  min_lr: 0.003921  loss: 2.7997 (2.7966)  weight_decay: 0.0500 (0.0500)  time: 0.5013  data: 0.0018  max mem: 5388\n",
            "Epoch: [22]  [110/147]  eta: 0:00:19  lr: 0.003918  min_lr: 0.003918  loss: 2.7997 (2.8013)  weight_decay: 0.0500 (0.0500)  time: 0.5045  data: 0.0028  max mem: 5388\n",
            "Epoch: [22]  [120/147]  eta: 0:00:14  lr: 0.003913  min_lr: 0.003913  loss: 2.8229 (2.8031)  weight_decay: 0.0500 (0.0500)  time: 0.5098  data: 0.0036  max mem: 5388\n",
            "Epoch: [22]  [130/147]  eta: 0:00:08  lr: 0.003909  min_lr: 0.003909  loss: 2.8690 (2.8074)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0029  max mem: 5388\n",
            "Epoch: [22]  [140/147]  eta: 0:00:03  lr: 0.003904  min_lr: 0.003904  loss: 2.8117 (2.8039)  weight_decay: 0.0500 (0.0500)  time: 0.4935  data: 0.0008  max mem: 5388\n",
            "Epoch: [22]  [146/147]  eta: 0:00:00  lr: 0.003904  min_lr: 0.003904  loss: 2.7965 (2.8045)  weight_decay: 0.0500 (0.0500)  time: 0.4185  data: 0.0003  max mem: 5388\n",
            "Epoch: [22] Total time: 0:01:15 (0.5150 s / it)\n",
            "Averaged stats: lr: 0.003904  min_lr: 0.003904  loss: 2.7965 (2.8045)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:06  loss: 0.8960 (0.8960)  acc1: 92.7083 (92.7083)  acc5: 95.8333 (95.8333)  time: 4.5413  data: 4.2421  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 1.4243 (1.4431)  acc1: 66.6667 (63.6364)  acc5: 92.7083 (93.1818)  time: 0.6286  data: 0.3927  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.4514 (1.5778)  acc1: 63.5417 (54.1667)  acc5: 92.7083 (91.4187)  time: 0.2373  data: 0.0056  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.6519 (1.6123)  acc1: 52.0833 (52.9234)  acc5: 90.6250 (90.8602)  time: 0.2366  data: 0.0018  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.5996 (1.5661)  acc1: 54.1667 (55.0318)  acc5: 91.6667 (91.1338)  time: 0.2318  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3514 s / it)\n",
            "* Acc@1 55.032 Acc@5 91.134 loss 1.566\n",
            "Accuracy of the model on the 3925 test images: 55.0%\n",
            "Max accuracy: 55.13%\n",
            "Test:  [ 0/41]  eta: 0:03:00  loss: 6.5126 (6.5126)  acc1: 0.0000 (0.0000)  acc5: 7.2917 (7.2917)  time: 4.4141  data: 4.1088  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 6.4414 (6.2974)  acc1: 5.2083 (7.3864)  acc5: 21.8750 (24.9053)  time: 0.6733  data: 0.4326  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.4516 (6.4386)  acc1: 2.0833 (5.0595)  acc5: 11.4583 (17.6091)  time: 0.2715  data: 0.0351  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.4516 (6.3741)  acc1: 1.0417 (4.3683)  acc5: 9.3750 (19.7581)  time: 0.2415  data: 0.0026  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.2435 (6.2594)  acc1: 4.1667 (4.5096)  acc5: 23.9583 (25.2739)  time: 0.2372  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3644 s / it)\n",
            "* Acc@1 4.510 Acc@5 25.274 loss 6.259\n",
            "Accuracy of the model EMA on 3925 test images: 4.5%\n",
            "Max EMA accuracy: 4.51%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [23]  [  0/147]  eta: 0:11:43  lr: 0.003902  min_lr: 0.003902  loss: 2.4835 (2.4835)  weight_decay: 0.0500 (0.0500)  time: 4.7826  data: 4.1652  max mem: 5388\n",
            "Epoch: [23]  [ 10/147]  eta: 0:02:06  lr: 0.003899  min_lr: 0.003899  loss: 2.7473 (2.7149)  weight_decay: 0.0500 (0.0500)  time: 0.9206  data: 0.3825  max mem: 5388\n",
            "Epoch: [23]  [ 20/147]  eta: 0:01:32  lr: 0.003893  min_lr: 0.003893  loss: 2.6854 (2.7016)  weight_decay: 0.0500 (0.0500)  time: 0.5225  data: 0.0035  max mem: 5388\n",
            "Epoch: [23]  [ 30/147]  eta: 0:01:16  lr: 0.003889  min_lr: 0.003889  loss: 2.6756 (2.7219)  weight_decay: 0.0500 (0.0500)  time: 0.5114  data: 0.0031  max mem: 5388\n",
            "Epoch: [23]  [ 40/147]  eta: 0:01:06  lr: 0.003883  min_lr: 0.003883  loss: 2.7597 (2.7294)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0034  max mem: 5388\n",
            "Epoch: [23]  [ 50/147]  eta: 0:00:58  lr: 0.003879  min_lr: 0.003879  loss: 2.7597 (2.7466)  weight_decay: 0.0500 (0.0500)  time: 0.5085  data: 0.0034  max mem: 5388\n",
            "Epoch: [23]  [ 60/147]  eta: 0:00:50  lr: 0.003873  min_lr: 0.003873  loss: 2.8112 (2.7502)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.0028  max mem: 5388\n",
            "Epoch: [23]  [ 70/147]  eta: 0:00:44  lr: 0.003869  min_lr: 0.003869  loss: 2.7440 (2.7494)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0021  max mem: 5388\n",
            "Epoch: [23]  [ 80/147]  eta: 0:00:37  lr: 0.003863  min_lr: 0.003863  loss: 2.7391 (2.7492)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0025  max mem: 5388\n",
            "Epoch: [23]  [ 90/147]  eta: 0:00:31  lr: 0.003859  min_lr: 0.003859  loss: 2.7666 (2.7497)  weight_decay: 0.0500 (0.0500)  time: 0.4990  data: 0.0037  max mem: 5388\n",
            "Epoch: [23]  [100/147]  eta: 0:00:25  lr: 0.003852  min_lr: 0.003852  loss: 2.7888 (2.7565)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0035  max mem: 5388\n",
            "Epoch: [23]  [110/147]  eta: 0:00:20  lr: 0.003848  min_lr: 0.003848  loss: 2.7910 (2.7583)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0037  max mem: 5388\n",
            "Epoch: [23]  [120/147]  eta: 0:00:14  lr: 0.003841  min_lr: 0.003841  loss: 2.7550 (2.7545)  weight_decay: 0.0500 (0.0500)  time: 0.4975  data: 0.0034  max mem: 5388\n",
            "Epoch: [23]  [130/147]  eta: 0:00:09  lr: 0.003836  min_lr: 0.003836  loss: 2.7868 (2.7584)  weight_decay: 0.0500 (0.0500)  time: 0.5007  data: 0.0020  max mem: 5388\n",
            "Epoch: [23]  [140/147]  eta: 0:00:03  lr: 0.003829  min_lr: 0.003829  loss: 2.8211 (2.7583)  weight_decay: 0.0500 (0.0500)  time: 0.5009  data: 0.0011  max mem: 5388\n",
            "Epoch: [23]  [146/147]  eta: 0:00:00  lr: 0.003829  min_lr: 0.003829  loss: 2.8211 (2.7617)  weight_decay: 0.0500 (0.0500)  time: 0.4221  data: 0.0002  max mem: 5388\n",
            "Epoch: [23] Total time: 0:01:17 (0.5277 s / it)\n",
            "Averaged stats: lr: 0.003829  min_lr: 0.003829  loss: 2.8211 (2.7617)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 0.8692 (0.8692)  acc1: 80.2083 (80.2083)  acc5: 97.9167 (97.9167)  time: 3.1720  data: 2.8880  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 1.3238 (1.2370)  acc1: 70.8333 (70.6439)  acc5: 94.7917 (95.5492)  time: 0.5638  data: 0.3211  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.4481 (1.5220)  acc1: 63.5417 (56.2996)  acc5: 93.7500 (93.6508)  time: 0.3214  data: 0.0856  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.6568 (1.5826)  acc1: 54.1667 (54.1331)  acc5: 89.5833 (91.6331)  time: 0.3011  data: 0.0633  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3544 (1.4957)  acc1: 61.4583 (56.9427)  acc5: 90.6250 (92.0764)  time: 0.2464  data: 0.0113  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3692 s / it)\n",
            "* Acc@1 56.943 Acc@5 92.076 loss 1.496\n",
            "Accuracy of the model on the 3925 test images: 56.9%\n",
            "Max accuracy: 56.94%\n",
            "Test:  [ 0/41]  eta: 0:02:54  loss: 6.4310 (6.4310)  acc1: 1.0417 (1.0417)  acc5: 15.6250 (15.6250)  time: 4.2507  data: 3.9613  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 6.3587 (6.2255)  acc1: 6.2500 (8.8068)  acc5: 22.9167 (28.6932)  time: 0.6088  data: 0.3612  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 6.4043 (6.3832)  acc1: 3.1250 (6.0020)  acc5: 14.5833 (20.6349)  time: 0.2899  data: 0.0477  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.4214 (6.3187)  acc1: 1.0417 (5.1075)  acc5: 10.4167 (22.3454)  time: 0.3082  data: 0.0677  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.1972 (6.1941)  acc1: 4.7059 (6.0382)  acc5: 26.0417 (27.8981)  time: 0.2571  data: 0.0207  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3795 s / it)\n",
            "* Acc@1 6.038 Acc@5 27.898 loss 6.194\n",
            "Accuracy of the model EMA on 3925 test images: 6.0%\n",
            "Max EMA accuracy: 6.04%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [24]  [  0/147]  eta: 0:07:32  lr: 0.003827  min_lr: 0.003827  loss: 2.8619 (2.8619)  weight_decay: 0.0500 (0.0500)  time: 3.0756  data: 2.5028  max mem: 5388\n",
            "Epoch: [24]  [ 10/147]  eta: 0:01:42  lr: 0.003822  min_lr: 0.003822  loss: 2.8443 (2.8325)  weight_decay: 0.0500 (0.0500)  time: 0.7483  data: 0.2309  max mem: 5388\n",
            "Epoch: [24]  [ 20/147]  eta: 0:01:21  lr: 0.003815  min_lr: 0.003815  loss: 2.8138 (2.7907)  weight_decay: 0.0500 (0.0500)  time: 0.5161  data: 0.0020  max mem: 5388\n",
            "Epoch: [24]  [ 30/147]  eta: 0:01:09  lr: 0.003810  min_lr: 0.003810  loss: 2.7794 (2.7835)  weight_decay: 0.0500 (0.0500)  time: 0.5133  data: 0.0017  max mem: 5388\n",
            "Epoch: [24]  [ 40/147]  eta: 0:01:01  lr: 0.003803  min_lr: 0.003803  loss: 2.7747 (2.7704)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0019  max mem: 5388\n",
            "Epoch: [24]  [ 50/147]  eta: 0:00:54  lr: 0.003798  min_lr: 0.003798  loss: 2.6726 (2.7603)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0021  max mem: 5388\n",
            "Epoch: [24]  [ 60/147]  eta: 0:00:48  lr: 0.003790  min_lr: 0.003790  loss: 2.7692 (2.7655)  weight_decay: 0.0500 (0.0500)  time: 0.5122  data: 0.0033  max mem: 5388\n",
            "Epoch: [24]  [ 70/147]  eta: 0:00:42  lr: 0.003785  min_lr: 0.003785  loss: 2.7642 (2.7566)  weight_decay: 0.0500 (0.0500)  time: 0.5046  data: 0.0034  max mem: 5388\n",
            "Epoch: [24]  [ 80/147]  eta: 0:00:36  lr: 0.003777  min_lr: 0.003777  loss: 2.7912 (2.7702)  weight_decay: 0.0500 (0.0500)  time: 0.5043  data: 0.0027  max mem: 5388\n",
            "Epoch: [24]  [ 90/147]  eta: 0:00:30  lr: 0.003771  min_lr: 0.003771  loss: 2.8412 (2.7734)  weight_decay: 0.0500 (0.0500)  time: 0.5018  data: 0.0013  max mem: 5388\n",
            "Epoch: [24]  [100/147]  eta: 0:00:25  lr: 0.003763  min_lr: 0.003763  loss: 2.7881 (2.7725)  weight_decay: 0.0500 (0.0500)  time: 0.4972  data: 0.0013  max mem: 5388\n",
            "Epoch: [24]  [110/147]  eta: 0:00:19  lr: 0.003758  min_lr: 0.003758  loss: 2.7017 (2.7675)  weight_decay: 0.0500 (0.0500)  time: 0.4996  data: 0.0031  max mem: 5388\n",
            "Epoch: [24]  [120/147]  eta: 0:00:14  lr: 0.003749  min_lr: 0.003749  loss: 2.6898 (2.7638)  weight_decay: 0.0500 (0.0500)  time: 0.5045  data: 0.0044  max mem: 5388\n",
            "Epoch: [24]  [130/147]  eta: 0:00:08  lr: 0.003744  min_lr: 0.003744  loss: 2.7379 (2.7638)  weight_decay: 0.0500 (0.0500)  time: 0.5003  data: 0.0027  max mem: 5388\n",
            "Epoch: [24]  [140/147]  eta: 0:00:03  lr: 0.003735  min_lr: 0.003735  loss: 2.7965 (2.7683)  weight_decay: 0.0500 (0.0500)  time: 0.4927  data: 0.0008  max mem: 5388\n",
            "Epoch: [24]  [146/147]  eta: 0:00:00  lr: 0.003735  min_lr: 0.003735  loss: 2.7835 (2.7657)  weight_decay: 0.0500 (0.0500)  time: 0.4191  data: 0.0002  max mem: 5388\n",
            "Epoch: [24] Total time: 0:01:15 (0.5163 s / it)\n",
            "Averaged stats: lr: 0.003735  min_lr: 0.003735  loss: 2.7835 (2.7657)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:48  loss: 0.7420 (0.7420)  acc1: 84.3750 (84.3750)  acc5: 95.8333 (95.8333)  time: 4.1139  data: 3.8088  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 1.0077 (1.1913)  acc1: 71.8750 (67.8030)  acc5: 95.8333 (92.8030)  time: 0.5879  data: 0.3479  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 1.5415 (1.5413)  acc1: 52.0833 (51.8849)  acc5: 90.6250 (91.0218)  time: 0.2384  data: 0.0021  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 1.4377 (1.4560)  acc1: 60.4167 (56.2500)  acc5: 91.6667 (92.1707)  time: 0.2362  data: 0.0012  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2180 (1.3965)  acc1: 63.5417 (58.1401)  acc5: 94.7917 (92.7898)  time: 0.2301  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3422 s / it)\n",
            "* Acc@1 58.140 Acc@5 92.790 loss 1.397\n",
            "Accuracy of the model on the 3925 test images: 58.1%\n",
            "Max accuracy: 58.14%\n",
            "Test:  [ 0/41]  eta: 0:02:48  loss: 6.3484 (6.3484)  acc1: 3.1250 (3.1250)  acc5: 20.8333 (20.8333)  time: 4.1135  data: 3.7954  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 6.3055 (6.1524)  acc1: 7.2917 (10.4167)  acc5: 29.1667 (32.4811)  time: 0.5984  data: 0.3551  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.3440 (6.3267)  acc1: 4.1667 (7.0933)  acc5: 19.7917 (23.7599)  time: 0.2446  data: 0.0065  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.3933 (6.2619)  acc1: 1.0417 (5.8804)  acc5: 12.5000 (25.1344)  time: 0.2392  data: 0.0011  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.1504 (6.1270)  acc1: 5.2083 (7.9490)  acc5: 29.1667 (30.5223)  time: 0.2342  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3477 s / it)\n",
            "* Acc@1 7.949 Acc@5 30.522 loss 6.127\n",
            "Accuracy of the model EMA on 3925 test images: 7.9%\n",
            "Max EMA accuracy: 7.95%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [25]  [  0/147]  eta: 0:09:29  lr: 0.003732  min_lr: 0.003732  loss: 2.8231 (2.8231)  weight_decay: 0.0500 (0.0500)  time: 3.8757  data: 3.3158  max mem: 5388\n",
            "Epoch: [25]  [ 10/147]  eta: 0:01:51  lr: 0.003726  min_lr: 0.003726  loss: 2.7819 (2.7460)  weight_decay: 0.0500 (0.0500)  time: 0.8173  data: 0.3023  max mem: 5388\n",
            "Epoch: [25]  [ 20/147]  eta: 0:01:25  lr: 0.003717  min_lr: 0.003717  loss: 2.6991 (2.6898)  weight_decay: 0.0500 (0.0500)  time: 0.5133  data: 0.0015  max mem: 5388\n",
            "Epoch: [25]  [ 30/147]  eta: 0:01:13  lr: 0.003711  min_lr: 0.003711  loss: 2.7349 (2.7202)  weight_decay: 0.0500 (0.0500)  time: 0.5197  data: 0.0035  max mem: 5388\n",
            "Epoch: [25]  [ 40/147]  eta: 0:01:04  lr: 0.003702  min_lr: 0.003702  loss: 2.7349 (2.7083)  weight_decay: 0.0500 (0.0500)  time: 0.5301  data: 0.0063  max mem: 5388\n",
            "Epoch: [25]  [ 50/147]  eta: 0:00:56  lr: 0.003696  min_lr: 0.003696  loss: 2.7171 (2.7233)  weight_decay: 0.0500 (0.0500)  time: 0.5224  data: 0.0047  max mem: 5388\n",
            "Epoch: [25]  [ 60/147]  eta: 0:00:49  lr: 0.003687  min_lr: 0.003687  loss: 2.7171 (2.7202)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0014  max mem: 5388\n",
            "Epoch: [25]  [ 70/147]  eta: 0:00:43  lr: 0.003681  min_lr: 0.003681  loss: 2.6580 (2.7193)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0012  max mem: 5388\n",
            "Epoch: [25]  [ 80/147]  eta: 0:00:37  lr: 0.003671  min_lr: 0.003671  loss: 2.6963 (2.7178)  weight_decay: 0.0500 (0.0500)  time: 0.5043  data: 0.0015  max mem: 5388\n",
            "Epoch: [25]  [ 90/147]  eta: 0:00:31  lr: 0.003665  min_lr: 0.003665  loss: 2.7281 (2.7255)  weight_decay: 0.0500 (0.0500)  time: 0.5010  data: 0.0023  max mem: 5388\n",
            "Epoch: [25]  [100/147]  eta: 0:00:25  lr: 0.003655  min_lr: 0.003655  loss: 2.7720 (2.7208)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0030  max mem: 5388\n",
            "Epoch: [25]  [110/147]  eta: 0:00:20  lr: 0.003648  min_lr: 0.003648  loss: 2.7803 (2.7312)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0030  max mem: 5388\n",
            "Epoch: [25]  [120/147]  eta: 0:00:14  lr: 0.003638  min_lr: 0.003638  loss: 2.7284 (2.7264)  weight_decay: 0.0500 (0.0500)  time: 0.4962  data: 0.0025  max mem: 5388\n",
            "Epoch: [25]  [130/147]  eta: 0:00:09  lr: 0.003632  min_lr: 0.003632  loss: 2.7289 (2.7289)  weight_decay: 0.0500 (0.0500)  time: 0.4989  data: 0.0016  max mem: 5388\n",
            "Epoch: [25]  [140/147]  eta: 0:00:03  lr: 0.003622  min_lr: 0.003622  loss: 2.7663 (2.7291)  weight_decay: 0.0500 (0.0500)  time: 0.4983  data: 0.0007  max mem: 5388\n",
            "Epoch: [25]  [146/147]  eta: 0:00:00  lr: 0.003622  min_lr: 0.003622  loss: 2.7451 (2.7288)  weight_decay: 0.0500 (0.0500)  time: 0.4203  data: 0.0002  max mem: 5388\n",
            "Epoch: [25] Total time: 0:01:16 (0.5231 s / it)\n",
            "Averaged stats: lr: 0.003622  min_lr: 0.003622  loss: 2.7451 (2.7288)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:58  loss: 0.6776 (0.6776)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 2.8968  data: 2.5978  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 1.2042 (1.0951)  acc1: 72.9167 (75.5682)  acc5: 95.8333 (96.4015)  time: 0.5440  data: 0.3005  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.3269 (1.4073)  acc1: 64.5833 (58.1845)  acc5: 94.7917 (94.3948)  time: 0.3200  data: 0.0829  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.3924 (1.3903)  acc1: 55.2083 (60.0470)  acc5: 92.7083 (93.6492)  time: 0.3030  data: 0.0660  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3474 (1.3755)  acc1: 61.4583 (61.1975)  acc5: 92.7083 (93.3503)  time: 0.2517  data: 0.0185  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3595 s / it)\n",
            "* Acc@1 61.197 Acc@5 93.350 loss 1.375\n",
            "Accuracy of the model on the 3925 test images: 61.2%\n",
            "Max accuracy: 61.20%\n",
            "Test:  [ 0/41]  eta: 0:02:11  loss: 6.2607 (6.2607)  acc1: 6.2500 (6.2500)  acc5: 30.2083 (30.2083)  time: 3.1992  data: 2.8828  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 6.2183 (6.0769)  acc1: 10.4167 (13.2576)  acc5: 31.2500 (36.7424)  time: 0.5253  data: 0.2708  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.3058 (6.2686)  acc1: 8.3333 (8.8790)  acc5: 25.0000 (26.5873)  time: 0.2698  data: 0.0254  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.3647 (6.2040)  acc1: 2.0833 (7.1237)  acc5: 15.6250 (27.8562)  time: 0.3083  data: 0.0678  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.0922 (6.0585)  acc1: 5.2083 (10.3694)  acc5: 32.2917 (33.1720)  time: 0.2957  data: 0.0604  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3623 s / it)\n",
            "* Acc@1 10.369 Acc@5 33.172 loss 6.059\n",
            "Accuracy of the model EMA on 3925 test images: 10.4%\n",
            "Max EMA accuracy: 10.37%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [26]  [  0/147]  eta: 0:07:09  lr: 0.003618  min_lr: 0.003618  loss: 2.7592 (2.7592)  weight_decay: 0.0500 (0.0500)  time: 2.9199  data: 2.3368  max mem: 5388\n",
            "Epoch: [26]  [ 10/147]  eta: 0:01:40  lr: 0.003611  min_lr: 0.003611  loss: 2.7527 (2.7602)  weight_decay: 0.0500 (0.0500)  time: 0.7352  data: 0.2145  max mem: 5388\n",
            "Epoch: [26]  [ 20/147]  eta: 0:01:20  lr: 0.003601  min_lr: 0.003601  loss: 2.7378 (2.7174)  weight_decay: 0.0500 (0.0500)  time: 0.5188  data: 0.0031  max mem: 5388\n",
            "Epoch: [26]  [ 30/147]  eta: 0:01:09  lr: 0.003594  min_lr: 0.003594  loss: 2.6385 (2.6946)  weight_decay: 0.0500 (0.0500)  time: 0.5152  data: 0.0031  max mem: 5388\n",
            "Epoch: [26]  [ 40/147]  eta: 0:01:01  lr: 0.003583  min_lr: 0.003583  loss: 2.6385 (2.6899)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0019  max mem: 5388\n",
            "Epoch: [26]  [ 50/147]  eta: 0:00:54  lr: 0.003576  min_lr: 0.003576  loss: 2.6772 (2.7013)  weight_decay: 0.0500 (0.0500)  time: 0.5169  data: 0.0015  max mem: 5388\n",
            "Epoch: [26]  [ 60/147]  eta: 0:00:48  lr: 0.003565  min_lr: 0.003565  loss: 2.7287 (2.7096)  weight_decay: 0.0500 (0.0500)  time: 0.5137  data: 0.0024  max mem: 5388\n",
            "Epoch: [26]  [ 70/147]  eta: 0:00:42  lr: 0.003558  min_lr: 0.003558  loss: 2.7642 (2.7122)  weight_decay: 0.0500 (0.0500)  time: 0.5046  data: 0.0027  max mem: 5388\n",
            "Epoch: [26]  [ 80/147]  eta: 0:00:36  lr: 0.003547  min_lr: 0.003547  loss: 2.7642 (2.7221)  weight_decay: 0.0500 (0.0500)  time: 0.5061  data: 0.0019  max mem: 5388\n",
            "Epoch: [26]  [ 90/147]  eta: 0:00:30  lr: 0.003540  min_lr: 0.003540  loss: 2.8244 (2.7343)  weight_decay: 0.0500 (0.0500)  time: 0.5079  data: 0.0035  max mem: 5388\n",
            "Epoch: [26]  [100/147]  eta: 0:00:25  lr: 0.003528  min_lr: 0.003528  loss: 2.7672 (2.7323)  weight_decay: 0.0500 (0.0500)  time: 0.5016  data: 0.0047  max mem: 5388\n",
            "Epoch: [26]  [110/147]  eta: 0:00:19  lr: 0.003521  min_lr: 0.003521  loss: 2.6646 (2.7272)  weight_decay: 0.0500 (0.0500)  time: 0.5028  data: 0.0046  max mem: 5388\n",
            "Epoch: [26]  [120/147]  eta: 0:00:14  lr: 0.003510  min_lr: 0.003510  loss: 2.7478 (2.7292)  weight_decay: 0.0500 (0.0500)  time: 0.5137  data: 0.0052  max mem: 5388\n",
            "Epoch: [26]  [130/147]  eta: 0:00:08  lr: 0.003502  min_lr: 0.003502  loss: 2.7715 (2.7257)  weight_decay: 0.0500 (0.0500)  time: 0.5100  data: 0.0038  max mem: 5388\n",
            "Epoch: [26]  [140/147]  eta: 0:00:03  lr: 0.003490  min_lr: 0.003490  loss: 2.7233 (2.7296)  weight_decay: 0.0500 (0.0500)  time: 0.4964  data: 0.0012  max mem: 5388\n",
            "Epoch: [26]  [146/147]  eta: 0:00:00  lr: 0.003490  min_lr: 0.003490  loss: 2.7401 (2.7276)  weight_decay: 0.0500 (0.0500)  time: 0.4187  data: 0.0002  max mem: 5388\n",
            "Epoch: [26] Total time: 0:01:16 (0.5172 s / it)\n",
            "Averaged stats: lr: 0.003490  min_lr: 0.003490  loss: 2.7401 (2.7276)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:06  loss: 0.7623 (0.7623)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 4.5443  data: 4.2372  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 1.0122 (1.1417)  acc1: 76.0417 (72.0644)  acc5: 96.8750 (96.4962)  time: 0.6295  data: 0.3885  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.3433 (1.3681)  acc1: 63.5417 (60.4167)  acc5: 95.8333 (95.4861)  time: 0.2652  data: 0.0251  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.3402 (1.3418)  acc1: 63.5417 (62.3656)  acc5: 93.7500 (95.1613)  time: 0.2651  data: 0.0234  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3140 (1.3559)  acc1: 65.6250 (63.0318)  acc5: 93.7500 (94.5223)  time: 0.2339  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3632 s / it)\n",
            "* Acc@1 63.032 Acc@5 94.522 loss 1.356\n",
            "Accuracy of the model on the 3925 test images: 63.0%\n",
            "Max accuracy: 63.03%\n",
            "Test:  [ 0/41]  eta: 0:03:39  loss: 6.1710 (6.1710)  acc1: 10.4167 (10.4167)  acc5: 35.4167 (35.4167)  time: 5.3567  data: 5.0486  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.1206 (6.0009)  acc1: 15.6250 (16.3826)  acc5: 36.4583 (40.3409)  time: 0.7089  data: 0.4695  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 6.2548 (6.2095)  acc1: 9.3750 (10.8135)  acc5: 27.0833 (29.4147)  time: 0.2432  data: 0.0069  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.3190 (6.1452)  acc1: 4.1667 (8.5349)  acc5: 17.7083 (30.4099)  time: 0.2412  data: 0.0012  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.0197 (5.9890)  acc1: 6.2500 (12.3312)  acc5: 36.4583 (35.8471)  time: 0.2365  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3732 s / it)\n",
            "* Acc@1 12.331 Acc@5 35.847 loss 5.989\n",
            "Accuracy of the model EMA on 3925 test images: 12.3%\n",
            "Max EMA accuracy: 12.33%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [27]  [  0/147]  eta: 0:11:26  lr: 0.003486  min_lr: 0.003486  loss: 2.6577 (2.6577)  weight_decay: 0.0500 (0.0500)  time: 4.6691  data: 4.0658  max mem: 5388\n",
            "Epoch: [27]  [ 10/147]  eta: 0:02:03  lr: 0.003479  min_lr: 0.003479  loss: 2.7865 (2.7606)  weight_decay: 0.0500 (0.0500)  time: 0.9004  data: 0.3715  max mem: 5388\n",
            "Epoch: [27]  [ 20/147]  eta: 0:01:30  lr: 0.003467  min_lr: 0.003467  loss: 2.7596 (2.7398)  weight_decay: 0.0500 (0.0500)  time: 0.5177  data: 0.0026  max mem: 5388\n",
            "Epoch: [27]  [ 30/147]  eta: 0:01:16  lr: 0.003459  min_lr: 0.003459  loss: 2.7149 (2.7332)  weight_decay: 0.0500 (0.0500)  time: 0.5154  data: 0.0019  max mem: 5388\n",
            "Epoch: [27]  [ 40/147]  eta: 0:01:06  lr: 0.003447  min_lr: 0.003447  loss: 2.7183 (2.7240)  weight_decay: 0.0500 (0.0500)  time: 0.5188  data: 0.0017  max mem: 5388\n",
            "Epoch: [27]  [ 50/147]  eta: 0:00:57  lr: 0.003439  min_lr: 0.003439  loss: 2.6949 (2.7242)  weight_decay: 0.0500 (0.0500)  time: 0.5140  data: 0.0016  max mem: 5388\n",
            "Epoch: [27]  [ 60/147]  eta: 0:00:50  lr: 0.003427  min_lr: 0.003427  loss: 2.6936 (2.7243)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0011  max mem: 5388\n",
            "Epoch: [27]  [ 70/147]  eta: 0:00:44  lr: 0.003418  min_lr: 0.003418  loss: 2.6719 (2.7145)  weight_decay: 0.0500 (0.0500)  time: 0.5133  data: 0.0028  max mem: 5388\n",
            "Epoch: [27]  [ 80/147]  eta: 0:00:37  lr: 0.003406  min_lr: 0.003406  loss: 2.6880 (2.7073)  weight_decay: 0.0500 (0.0500)  time: 0.5047  data: 0.0039  max mem: 5388\n",
            "Epoch: [27]  [ 90/147]  eta: 0:00:31  lr: 0.003398  min_lr: 0.003398  loss: 2.7230 (2.7150)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0044  max mem: 5388\n",
            "Epoch: [27]  [100/147]  eta: 0:00:25  lr: 0.003385  min_lr: 0.003385  loss: 2.7059 (2.7145)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0040  max mem: 5388\n",
            "Epoch: [27]  [110/147]  eta: 0:00:20  lr: 0.003377  min_lr: 0.003377  loss: 2.7088 (2.7165)  weight_decay: 0.0500 (0.0500)  time: 0.4968  data: 0.0033  max mem: 5388\n",
            "Epoch: [27]  [120/147]  eta: 0:00:14  lr: 0.003364  min_lr: 0.003364  loss: 2.7399 (2.7168)  weight_decay: 0.0500 (0.0500)  time: 0.4928  data: 0.0030  max mem: 5388\n",
            "Epoch: [27]  [130/147]  eta: 0:00:09  lr: 0.003356  min_lr: 0.003356  loss: 2.7134 (2.7160)  weight_decay: 0.0500 (0.0500)  time: 0.4963  data: 0.0027  max mem: 5388\n",
            "Epoch: [27]  [140/147]  eta: 0:00:03  lr: 0.003343  min_lr: 0.003343  loss: 2.7284 (2.7197)  weight_decay: 0.0500 (0.0500)  time: 0.4952  data: 0.0015  max mem: 5388\n",
            "Epoch: [27]  [146/147]  eta: 0:00:00  lr: 0.003343  min_lr: 0.003343  loss: 2.7494 (2.7183)  weight_decay: 0.0500 (0.0500)  time: 0.4182  data: 0.0002  max mem: 5388\n",
            "Epoch: [27] Total time: 0:01:17 (0.5266 s / it)\n",
            "Averaged stats: lr: 0.003343  min_lr: 0.003343  loss: 2.7494 (2.7183)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:54  loss: 0.5821 (0.5821)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 4.2641  data: 3.9583  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 1.2030 (1.0643)  acc1: 70.8333 (73.8636)  acc5: 95.8333 (95.8333)  time: 0.7010  data: 0.4572  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 1.3046 (1.3745)  acc1: 62.5000 (58.6310)  acc5: 93.7500 (94.5933)  time: 0.3383  data: 0.0970  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.3739 (1.3519)  acc1: 60.4167 (60.5847)  acc5: 92.7083 (93.7836)  time: 0.3229  data: 0.0791  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3275 (1.3207)  acc1: 63.5417 (61.7834)  acc5: 93.7500 (94.0127)  time: 0.2720  data: 0.0357  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.4100 s / it)\n",
            "* Acc@1 61.783 Acc@5 94.013 loss 1.321\n",
            "Accuracy of the model on the 3925 test images: 61.8%\n",
            "Max accuracy: 63.03%\n",
            "Test:  [ 0/41]  eta: 0:02:14  loss: 6.0790 (6.0790)  acc1: 14.5833 (14.5833)  acc5: 43.7500 (43.7500)  time: 3.2906  data: 3.0261  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 6.0204 (5.9230)  acc1: 16.6667 (17.9924)  acc5: 40.6250 (44.2235)  time: 0.5177  data: 0.2785  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.2232 (6.1492)  acc1: 10.4167 (11.9048)  acc5: 27.0833 (32.2421)  time: 0.2604  data: 0.0161  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.2534 (6.0860)  acc1: 4.1667 (9.3414)  acc5: 18.7500 (33.0309)  time: 0.2817  data: 0.0358  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.9471 (5.9194)  acc1: 5.2083 (13.2229)  acc5: 38.5417 (38.1656)  time: 0.2597  data: 0.0217  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3452 s / it)\n",
            "* Acc@1 13.223 Acc@5 38.166 loss 5.919\n",
            "Accuracy of the model EMA on 3925 test images: 13.2%\n",
            "Max EMA accuracy: 13.22%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [28]  [  0/147]  eta: 0:08:02  lr: 0.003338  min_lr: 0.003338  loss: 2.7860 (2.7860)  weight_decay: 0.0500 (0.0500)  time: 3.2830  data: 2.6977  max mem: 5388\n",
            "Epoch: [28]  [ 10/147]  eta: 0:01:45  lr: 0.003330  min_lr: 0.003330  loss: 2.6303 (2.6070)  weight_decay: 0.0500 (0.0500)  time: 0.7686  data: 0.2485  max mem: 5388\n",
            "Epoch: [28]  [ 20/147]  eta: 0:01:22  lr: 0.003317  min_lr: 0.003317  loss: 2.6316 (2.6156)  weight_decay: 0.0500 (0.0500)  time: 0.5207  data: 0.0031  max mem: 5388\n",
            "Epoch: [28]  [ 30/147]  eta: 0:01:10  lr: 0.003308  min_lr: 0.003308  loss: 2.6415 (2.6243)  weight_decay: 0.0500 (0.0500)  time: 0.5173  data: 0.0022  max mem: 5388\n",
            "Epoch: [28]  [ 40/147]  eta: 0:01:02  lr: 0.003295  min_lr: 0.003295  loss: 2.6781 (2.6353)  weight_decay: 0.0500 (0.0500)  time: 0.5122  data: 0.0015  max mem: 5388\n",
            "Epoch: [28]  [ 50/147]  eta: 0:00:55  lr: 0.003286  min_lr: 0.003286  loss: 2.6814 (2.6461)  weight_decay: 0.0500 (0.0500)  time: 0.5138  data: 0.0015  max mem: 5388\n",
            "Epoch: [28]  [ 60/147]  eta: 0:00:48  lr: 0.003272  min_lr: 0.003272  loss: 2.6144 (2.6437)  weight_decay: 0.0500 (0.0500)  time: 0.5093  data: 0.0017  max mem: 5388\n",
            "Epoch: [28]  [ 70/147]  eta: 0:00:42  lr: 0.003263  min_lr: 0.003263  loss: 2.6610 (2.6561)  weight_decay: 0.0500 (0.0500)  time: 0.5027  data: 0.0025  max mem: 5388\n",
            "Epoch: [28]  [ 80/147]  eta: 0:00:36  lr: 0.003250  min_lr: 0.003250  loss: 2.7336 (2.6696)  weight_decay: 0.0500 (0.0500)  time: 0.5048  data: 0.0026  max mem: 5388\n",
            "Epoch: [28]  [ 90/147]  eta: 0:00:30  lr: 0.003241  min_lr: 0.003241  loss: 2.7103 (2.6680)  weight_decay: 0.0500 (0.0500)  time: 0.5074  data: 0.0017  max mem: 5388\n",
            "Epoch: [28]  [100/147]  eta: 0:00:25  lr: 0.003227  min_lr: 0.003227  loss: 2.6720 (2.6631)  weight_decay: 0.0500 (0.0500)  time: 0.4999  data: 0.0009  max mem: 5388\n",
            "Epoch: [28]  [110/147]  eta: 0:00:19  lr: 0.003218  min_lr: 0.003218  loss: 2.6720 (2.6605)  weight_decay: 0.0500 (0.0500)  time: 0.4975  data: 0.0018  max mem: 5388\n",
            "Epoch: [28]  [120/147]  eta: 0:00:14  lr: 0.003204  min_lr: 0.003204  loss: 2.7314 (2.6662)  weight_decay: 0.0500 (0.0500)  time: 0.5033  data: 0.0038  max mem: 5388\n",
            "Epoch: [28]  [130/147]  eta: 0:00:08  lr: 0.003195  min_lr: 0.003195  loss: 2.7882 (2.6708)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0023  max mem: 5388\n",
            "Epoch: [28]  [140/147]  eta: 0:00:03  lr: 0.003180  min_lr: 0.003180  loss: 2.7061 (2.6690)  weight_decay: 0.0500 (0.0500)  time: 0.4930  data: 0.0002  max mem: 5388\n",
            "Epoch: [28]  [146/147]  eta: 0:00:00  lr: 0.003180  min_lr: 0.003180  loss: 2.7061 (2.6697)  weight_decay: 0.0500 (0.0500)  time: 0.4207  data: 0.0002  max mem: 5388\n",
            "Epoch: [28] Total time: 0:01:16 (0.5190 s / it)\n",
            "Averaged stats: lr: 0.003180  min_lr: 0.003180  loss: 2.7061 (2.6697)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:29  loss: 0.8183 (0.8183)  acc1: 80.2083 (80.2083)  acc5: 94.7917 (94.7917)  time: 3.6392  data: 3.3586  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 1.0576 (1.1820)  acc1: 71.8750 (68.7500)  acc5: 94.7917 (93.8447)  time: 0.6279  data: 0.3936  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.2041 (1.3820)  acc1: 59.3750 (57.8869)  acc5: 94.7917 (93.3532)  time: 0.2889  data: 0.0520  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.2041 (1.3092)  acc1: 62.5000 (61.8952)  acc5: 94.7917 (94.0860)  time: 0.2415  data: 0.0035  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1028 (1.3097)  acc1: 72.9167 (61.3503)  acc5: 94.7917 (94.0382)  time: 0.2308  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3574 s / it)\n",
            "* Acc@1 61.350 Acc@5 94.038 loss 1.310\n",
            "Accuracy of the model on the 3925 test images: 61.4%\n",
            "Max accuracy: 63.03%\n",
            "Test:  [ 0/41]  eta: 0:03:58  loss: 5.9843 (5.9843)  acc1: 21.8750 (21.8750)  acc5: 46.8750 (46.8750)  time: 5.8121  data: 5.5200  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 5.9176 (5.8433)  acc1: 18.7500 (19.1288)  acc5: 46.8750 (47.4432)  time: 0.7485  data: 0.5075  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 6.1937 (6.0879)  acc1: 10.4167 (12.5496)  acc5: 30.2083 (35.1190)  time: 0.2418  data: 0.0061  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.2162 (6.0261)  acc1: 4.1667 (9.8118)  acc5: 20.8333 (35.8871)  time: 0.2378  data: 0.0030  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.8728 (5.8493)  acc1: 5.2083 (13.9618)  acc5: 43.7500 (40.8408)  time: 0.2336  data: 0.0002  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3886 s / it)\n",
            "* Acc@1 13.962 Acc@5 40.841 loss 5.849\n",
            "Accuracy of the model EMA on 3925 test images: 14.0%\n",
            "Max EMA accuracy: 13.96%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [29]  [  0/147]  eta: 0:09:30  lr: 0.003176  min_lr: 0.003176  loss: 2.7138 (2.7138)  weight_decay: 0.0500 (0.0500)  time: 3.8789  data: 3.3264  max mem: 5388\n",
            "Epoch: [29]  [ 10/147]  eta: 0:01:51  lr: 0.003166  min_lr: 0.003166  loss: 2.7282 (2.7050)  weight_decay: 0.0500 (0.0500)  time: 0.8147  data: 0.3038  max mem: 5388\n",
            "Epoch: [29]  [ 20/147]  eta: 0:01:25  lr: 0.003152  min_lr: 0.003152  loss: 2.7395 (2.7130)  weight_decay: 0.0500 (0.0500)  time: 0.5157  data: 0.0043  max mem: 5388\n",
            "Epoch: [29]  [ 30/147]  eta: 0:01:13  lr: 0.003143  min_lr: 0.003143  loss: 2.6790 (2.6883)  weight_decay: 0.0500 (0.0500)  time: 0.5194  data: 0.0055  max mem: 5388\n",
            "Epoch: [29]  [ 40/147]  eta: 0:01:03  lr: 0.003128  min_lr: 0.003128  loss: 2.6790 (2.6792)  weight_decay: 0.0500 (0.0500)  time: 0.5156  data: 0.0027  max mem: 5388\n",
            "Epoch: [29]  [ 50/147]  eta: 0:00:56  lr: 0.003119  min_lr: 0.003119  loss: 2.7172 (2.6926)  weight_decay: 0.0500 (0.0500)  time: 0.5127  data: 0.0018  max mem: 5388\n",
            "Epoch: [29]  [ 60/147]  eta: 0:00:49  lr: 0.003104  min_lr: 0.003104  loss: 2.7377 (2.6871)  weight_decay: 0.0500 (0.0500)  time: 0.5126  data: 0.0020  max mem: 5388\n",
            "Epoch: [29]  [ 70/147]  eta: 0:00:43  lr: 0.003094  min_lr: 0.003094  loss: 2.7369 (2.6919)  weight_decay: 0.0500 (0.0500)  time: 0.5114  data: 0.0019  max mem: 5388\n",
            "Epoch: [29]  [ 80/147]  eta: 0:00:37  lr: 0.003080  min_lr: 0.003080  loss: 2.7067 (2.6889)  weight_decay: 0.0500 (0.0500)  time: 0.5037  data: 0.0017  max mem: 5388\n",
            "Epoch: [29]  [ 90/147]  eta: 0:00:31  lr: 0.003070  min_lr: 0.003070  loss: 2.6513 (2.6896)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0020  max mem: 5388\n",
            "Epoch: [29]  [100/147]  eta: 0:00:25  lr: 0.003055  min_lr: 0.003055  loss: 2.6378 (2.6869)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0026  max mem: 5388\n",
            "Epoch: [29]  [110/147]  eta: 0:00:19  lr: 0.003045  min_lr: 0.003045  loss: 2.6426 (2.6832)  weight_decay: 0.0500 (0.0500)  time: 0.5000  data: 0.0027  max mem: 5388\n",
            "Epoch: [29]  [120/147]  eta: 0:00:14  lr: 0.003030  min_lr: 0.003030  loss: 2.7327 (2.6897)  weight_decay: 0.0500 (0.0500)  time: 0.4955  data: 0.0024  max mem: 5388\n",
            "Epoch: [29]  [130/147]  eta: 0:00:09  lr: 0.003020  min_lr: 0.003020  loss: 2.7321 (2.6834)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0021  max mem: 5388\n",
            "Epoch: [29]  [140/147]  eta: 0:00:03  lr: 0.003005  min_lr: 0.003005  loss: 2.6829 (2.6826)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0012  max mem: 5388\n",
            "Epoch: [29]  [146/147]  eta: 0:00:00  lr: 0.003005  min_lr: 0.003005  loss: 2.6830 (2.6836)  weight_decay: 0.0500 (0.0500)  time: 0.4186  data: 0.0002  max mem: 5388\n",
            "Epoch: [29] Total time: 0:01:16 (0.5212 s / it)\n",
            "Averaged stats: lr: 0.003005  min_lr: 0.003005  loss: 2.6830 (2.6836)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:27  loss: 0.9515 (0.9515)  acc1: 80.2083 (80.2083)  acc5: 95.8333 (95.8333)  time: 3.5955  data: 3.1993  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 1.0855 (1.0665)  acc1: 75.0000 (73.7689)  acc5: 95.8333 (95.3599)  time: 0.6494  data: 0.4059  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.0855 (1.2506)  acc1: 72.9167 (64.9306)  acc5: 96.8750 (94.8909)  time: 0.3195  data: 0.0870  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.1832 (1.2537)  acc1: 65.6250 (64.9530)  acc5: 95.8333 (95.1949)  time: 0.2602  data: 0.0243  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1832 (1.2360)  acc1: 65.6250 (65.6561)  acc5: 94.7917 (94.9045)  time: 0.2324  data: 0.0006  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3672 s / it)\n",
            "* Acc@1 65.656 Acc@5 94.904 loss 1.236\n",
            "Accuracy of the model on the 3925 test images: 65.7%\n",
            "Max accuracy: 65.66%\n",
            "Test:  [ 0/41]  eta: 0:02:15  loss: 5.8862 (5.8862)  acc1: 23.9583 (23.9583)  acc5: 50.0000 (50.0000)  time: 3.3033  data: 3.0312  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 5.8145 (5.7625)  acc1: 23.9583 (21.8750)  acc5: 50.0000 (50.0947)  time: 0.5845  data: 0.3415  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.1615 (6.0258)  acc1: 11.4583 (13.9385)  acc5: 32.2917 (37.2520)  time: 0.3140  data: 0.0745  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.1743 (5.9653)  acc1: 5.2083 (10.9879)  acc5: 23.9583 (38.1048)  time: 0.2852  data: 0.0462  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.7972 (5.7786)  acc1: 5.2083 (15.0573)  acc5: 44.7917 (42.8280)  time: 0.2446  data: 0.0080  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3625 s / it)\n",
            "* Acc@1 15.057 Acc@5 42.828 loss 5.779\n",
            "Accuracy of the model EMA on 3925 test images: 15.1%\n",
            "Max EMA accuracy: 15.06%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [30]  [  0/147]  eta: 0:07:52  lr: 0.003000  min_lr: 0.003000  loss: 2.6247 (2.6247)  weight_decay: 0.0500 (0.0500)  time: 3.2126  data: 2.6544  max mem: 5388\n",
            "Epoch: [30]  [ 10/147]  eta: 0:01:44  lr: 0.002990  min_lr: 0.002990  loss: 2.5702 (2.6193)  weight_decay: 0.0500 (0.0500)  time: 0.7638  data: 0.2446  max mem: 5388\n",
            "Epoch: [30]  [ 20/147]  eta: 0:01:22  lr: 0.002975  min_lr: 0.002975  loss: 2.5702 (2.6491)  weight_decay: 0.0500 (0.0500)  time: 0.5187  data: 0.0032  max mem: 5388\n",
            "Epoch: [30]  [ 30/147]  eta: 0:01:10  lr: 0.002965  min_lr: 0.002965  loss: 2.6870 (2.6576)  weight_decay: 0.0500 (0.0500)  time: 0.5152  data: 0.0031  max mem: 5388\n",
            "Epoch: [30]  [ 40/147]  eta: 0:01:02  lr: 0.002949  min_lr: 0.002949  loss: 2.6679 (2.6663)  weight_decay: 0.0500 (0.0500)  time: 0.5122  data: 0.0028  max mem: 5388\n",
            "Epoch: [30]  [ 50/147]  eta: 0:00:55  lr: 0.002939  min_lr: 0.002939  loss: 2.7082 (2.6680)  weight_decay: 0.0500 (0.0500)  time: 0.5144  data: 0.0026  max mem: 5388\n",
            "Epoch: [30]  [ 60/147]  eta: 0:00:48  lr: 0.002924  min_lr: 0.002924  loss: 2.7161 (2.6753)  weight_decay: 0.0500 (0.0500)  time: 0.5110  data: 0.0025  max mem: 5388\n",
            "Epoch: [30]  [ 70/147]  eta: 0:00:42  lr: 0.002913  min_lr: 0.002913  loss: 2.6972 (2.6779)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0020  max mem: 5388\n",
            "Epoch: [30]  [ 80/147]  eta: 0:00:36  lr: 0.002898  min_lr: 0.002898  loss: 2.7513 (2.6877)  weight_decay: 0.0500 (0.0500)  time: 0.5075  data: 0.0021  max mem: 5388\n",
            "Epoch: [30]  [ 90/147]  eta: 0:00:30  lr: 0.002887  min_lr: 0.002887  loss: 2.8100 (2.6988)  weight_decay: 0.0500 (0.0500)  time: 0.5119  data: 0.0030  max mem: 5388\n",
            "Epoch: [30]  [100/147]  eta: 0:00:25  lr: 0.002872  min_lr: 0.002872  loss: 2.8363 (2.7109)  weight_decay: 0.0500 (0.0500)  time: 0.5059  data: 0.0026  max mem: 5388\n",
            "Epoch: [30]  [110/147]  eta: 0:00:19  lr: 0.002861  min_lr: 0.002861  loss: 2.8066 (2.7077)  weight_decay: 0.0500 (0.0500)  time: 0.4972  data: 0.0020  max mem: 5388\n",
            "Epoch: [30]  [120/147]  eta: 0:00:14  lr: 0.002846  min_lr: 0.002846  loss: 2.6173 (2.7008)  weight_decay: 0.0500 (0.0500)  time: 0.4994  data: 0.0023  max mem: 5388\n",
            "Epoch: [30]  [130/147]  eta: 0:00:08  lr: 0.002835  min_lr: 0.002835  loss: 2.6401 (2.7006)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0015  max mem: 5388\n",
            "Epoch: [30]  [140/147]  eta: 0:00:03  lr: 0.002819  min_lr: 0.002819  loss: 2.6740 (2.6955)  weight_decay: 0.0500 (0.0500)  time: 0.4969  data: 0.0006  max mem: 5388\n",
            "Epoch: [30]  [146/147]  eta: 0:00:00  lr: 0.002819  min_lr: 0.002819  loss: 2.6783 (2.6941)  weight_decay: 0.0500 (0.0500)  time: 0.4182  data: 0.0002  max mem: 5388\n",
            "Epoch: [30] Total time: 0:01:16 (0.5177 s / it)\n",
            "Averaged stats: lr: 0.002819  min_lr: 0.002819  loss: 2.6783 (2.6941)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:13  loss: 0.7081 (0.7081)  acc1: 86.4583 (86.4583)  acc5: 94.7917 (94.7917)  time: 4.7167  data: 4.4262  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 1.0042 (1.0185)  acc1: 75.0000 (73.6742)  acc5: 94.7917 (94.8864)  time: 0.7041  data: 0.4679  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 1.1365 (1.2061)  acc1: 68.7500 (64.3849)  acc5: 95.8333 (95.8829)  time: 0.2815  data: 0.0471  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.1683 (1.1765)  acc1: 68.7500 (66.8011)  acc5: 95.8333 (95.5309)  time: 0.2469  data: 0.0111  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1759 (1.2092)  acc1: 68.7500 (65.2229)  acc5: 94.7917 (94.8280)  time: 0.2318  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3736 s / it)\n",
            "* Acc@1 65.223 Acc@5 94.828 loss 1.209\n",
            "Accuracy of the model on the 3925 test images: 65.2%\n",
            "Max accuracy: 65.66%\n",
            "Test:  [ 0/41]  eta: 0:02:33  loss: 5.7846 (5.7846)  acc1: 26.0417 (26.0417)  acc5: 52.0833 (52.0833)  time: 3.7449  data: 3.3966  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 5.7159 (5.6812)  acc1: 26.0417 (23.2008)  acc5: 52.0833 (51.9886)  time: 0.6416  data: 0.3940  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 6.1017 (5.9634)  acc1: 12.5000 (14.6825)  acc5: 35.4167 (38.8393)  time: 0.3114  data: 0.0721  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 6.1417 (5.9054)  acc1: 5.2083 (11.7944)  acc5: 25.0000 (40.2554)  time: 0.2665  data: 0.0280  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.7216 (5.7088)  acc1: 7.2917 (15.7452)  acc5: 47.9167 (44.8153)  time: 0.2372  data: 0.0028  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3676 s / it)\n",
            "* Acc@1 15.745 Acc@5 44.815 loss 5.709\n",
            "Accuracy of the model EMA on 3925 test images: 15.7%\n",
            "Max EMA accuracy: 15.75%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [31]  [  0/147]  eta: 0:06:12  lr: 0.002814  min_lr: 0.002814  loss: 2.6774 (2.6774)  weight_decay: 0.0500 (0.0500)  time: 2.5311  data: 1.9421  max mem: 5388\n",
            "Epoch: [31]  [ 10/147]  eta: 0:01:45  lr: 0.002803  min_lr: 0.002803  loss: 2.6774 (2.6914)  weight_decay: 0.0500 (0.0500)  time: 0.7725  data: 0.2010  max mem: 5388\n",
            "Epoch: [31]  [ 20/147]  eta: 0:01:22  lr: 0.002787  min_lr: 0.002787  loss: 2.7077 (2.6997)  weight_decay: 0.0500 (0.0500)  time: 0.5560  data: 0.0143  max mem: 5388\n",
            "Epoch: [31]  [ 30/147]  eta: 0:01:10  lr: 0.002776  min_lr: 0.002776  loss: 2.6796 (2.6800)  weight_decay: 0.0500 (0.0500)  time: 0.5117  data: 0.0025  max mem: 5388\n",
            "Epoch: [31]  [ 40/147]  eta: 0:01:02  lr: 0.002760  min_lr: 0.002760  loss: 2.6654 (2.6964)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0033  max mem: 5388\n",
            "Epoch: [31]  [ 50/147]  eta: 0:00:55  lr: 0.002750  min_lr: 0.002750  loss: 2.6877 (2.6860)  weight_decay: 0.0500 (0.0500)  time: 0.5144  data: 0.0023  max mem: 5388\n",
            "Epoch: [31]  [ 60/147]  eta: 0:00:48  lr: 0.002733  min_lr: 0.002733  loss: 2.6877 (2.6877)  weight_decay: 0.0500 (0.0500)  time: 0.5077  data: 0.0025  max mem: 5388\n",
            "Epoch: [31]  [ 70/147]  eta: 0:00:42  lr: 0.002722  min_lr: 0.002722  loss: 2.7164 (2.6861)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0021  max mem: 5388\n",
            "Epoch: [31]  [ 80/147]  eta: 0:00:36  lr: 0.002706  min_lr: 0.002706  loss: 2.7037 (2.6887)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0033  max mem: 5388\n",
            "Epoch: [31]  [ 90/147]  eta: 0:00:30  lr: 0.002695  min_lr: 0.002695  loss: 2.7295 (2.6954)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0047  max mem: 5388\n",
            "Epoch: [31]  [100/147]  eta: 0:00:25  lr: 0.002679  min_lr: 0.002679  loss: 2.7495 (2.6960)  weight_decay: 0.0500 (0.0500)  time: 0.5002  data: 0.0029  max mem: 5388\n",
            "Epoch: [31]  [110/147]  eta: 0:00:19  lr: 0.002668  min_lr: 0.002668  loss: 2.7214 (2.6950)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0033  max mem: 5388\n",
            "Epoch: [31]  [120/147]  eta: 0:00:14  lr: 0.002651  min_lr: 0.002651  loss: 2.7214 (2.6946)  weight_decay: 0.0500 (0.0500)  time: 0.5044  data: 0.0033  max mem: 5388\n",
            "Epoch: [31]  [130/147]  eta: 0:00:08  lr: 0.002640  min_lr: 0.002640  loss: 2.6828 (2.6958)  weight_decay: 0.0500 (0.0500)  time: 0.4958  data: 0.0016  max mem: 5388\n",
            "Epoch: [31]  [140/147]  eta: 0:00:03  lr: 0.002624  min_lr: 0.002624  loss: 2.7014 (2.6902)  weight_decay: 0.0500 (0.0500)  time: 0.4958  data: 0.0002  max mem: 5388\n",
            "Epoch: [31]  [146/147]  eta: 0:00:00  lr: 0.002624  min_lr: 0.002624  loss: 2.6993 (2.6901)  weight_decay: 0.0500 (0.0500)  time: 0.4225  data: 0.0002  max mem: 5388\n",
            "Epoch: [31] Total time: 0:01:16 (0.5199 s / it)\n",
            "Averaged stats: lr: 0.002624  min_lr: 0.002624  loss: 2.6993 (2.6901)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:19  loss: 0.6239 (0.6239)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 4.8742  data: 4.5902  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 1.0037 (1.0226)  acc1: 76.0417 (74.4318)  acc5: 96.8750 (96.6856)  time: 0.6591  data: 0.4201  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.1171 (1.2978)  acc1: 69.7917 (61.0119)  acc5: 95.8333 (94.0972)  time: 0.2383  data: 0.0045  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.2117 (1.2716)  acc1: 68.7500 (64.1801)  acc5: 93.7500 (94.1532)  time: 0.2347  data: 0.0031  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1720 (1.2380)  acc1: 71.7647 (65.9873)  acc5: 94.7917 (94.4204)  time: 0.2281  data: 0.0002  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3597 s / it)\n",
            "* Acc@1 65.987 Acc@5 94.420 loss 1.238\n",
            "Accuracy of the model on the 3925 test images: 66.0%\n",
            "Max accuracy: 65.99%\n",
            "Test:  [ 0/41]  eta: 0:02:13  loss: 5.6849 (5.6849)  acc1: 31.2500 (31.2500)  acc5: 53.1250 (53.1250)  time: 3.2637  data: 2.9932  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 5.6189 (5.5998)  acc1: 27.0833 (24.6212)  acc5: 53.1250 (53.3144)  time: 0.5323  data: 0.2916  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 6.0394 (5.9012)  acc1: 13.5417 (15.6250)  acc5: 39.5833 (40.0298)  time: 0.2486  data: 0.0122  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.1086 (5.8464)  acc1: 5.2083 (12.7016)  acc5: 28.1250 (41.9691)  time: 0.2381  data: 0.0015  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.6467 (5.6406)  acc1: 9.3750 (16.5605)  acc5: 47.9167 (46.3440)  time: 0.2337  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3300 s / it)\n",
            "* Acc@1 16.561 Acc@5 46.344 loss 5.641\n",
            "Accuracy of the model EMA on 3925 test images: 16.6%\n",
            "Max EMA accuracy: 16.56%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [32]  [  0/147]  eta: 0:08:48  lr: 0.002618  min_lr: 0.002618  loss: 2.4491 (2.4491)  weight_decay: 0.0500 (0.0500)  time: 3.5938  data: 3.0242  max mem: 5388\n",
            "Epoch: [32]  [ 10/147]  eta: 0:01:48  lr: 0.002607  min_lr: 0.002607  loss: 2.6228 (2.6495)  weight_decay: 0.0500 (0.0500)  time: 0.7937  data: 0.2772  max mem: 5388\n",
            "Epoch: [32]  [ 20/147]  eta: 0:01:24  lr: 0.002591  min_lr: 0.002591  loss: 2.6086 (2.6311)  weight_decay: 0.0500 (0.0500)  time: 0.5152  data: 0.0028  max mem: 5388\n",
            "Epoch: [32]  [ 30/147]  eta: 0:01:12  lr: 0.002580  min_lr: 0.002580  loss: 2.5980 (2.6219)  weight_decay: 0.0500 (0.0500)  time: 0.5214  data: 0.0032  max mem: 5388\n",
            "Epoch: [32]  [ 40/147]  eta: 0:01:03  lr: 0.002563  min_lr: 0.002563  loss: 2.6821 (2.6341)  weight_decay: 0.0500 (0.0500)  time: 0.5220  data: 0.0024  max mem: 5388\n",
            "Epoch: [32]  [ 50/147]  eta: 0:00:56  lr: 0.002552  min_lr: 0.002552  loss: 2.6808 (2.6329)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0017  max mem: 5388\n",
            "Epoch: [32]  [ 60/147]  eta: 0:00:49  lr: 0.002535  min_lr: 0.002535  loss: 2.5728 (2.6159)  weight_decay: 0.0500 (0.0500)  time: 0.5182  data: 0.0024  max mem: 5388\n",
            "Epoch: [32]  [ 70/147]  eta: 0:00:43  lr: 0.002524  min_lr: 0.002524  loss: 2.5807 (2.6199)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0026  max mem: 5388\n",
            "Epoch: [32]  [ 80/147]  eta: 0:00:37  lr: 0.002507  min_lr: 0.002507  loss: 2.6510 (2.6200)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0024  max mem: 5388\n",
            "Epoch: [32]  [ 90/147]  eta: 0:00:31  lr: 0.002496  min_lr: 0.002496  loss: 2.6117 (2.6188)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0019  max mem: 5388\n",
            "Epoch: [32]  [100/147]  eta: 0:00:25  lr: 0.002479  min_lr: 0.002479  loss: 2.6662 (2.6274)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0027  max mem: 5388\n",
            "Epoch: [32]  [110/147]  eta: 0:00:19  lr: 0.002467  min_lr: 0.002467  loss: 2.7196 (2.6263)  weight_decay: 0.0500 (0.0500)  time: 0.4989  data: 0.0040  max mem: 5388\n",
            "Epoch: [32]  [120/147]  eta: 0:00:14  lr: 0.002450  min_lr: 0.002450  loss: 2.5483 (2.6221)  weight_decay: 0.0500 (0.0500)  time: 0.4983  data: 0.0038  max mem: 5388\n",
            "Epoch: [32]  [130/147]  eta: 0:00:09  lr: 0.002439  min_lr: 0.002439  loss: 2.5483 (2.6177)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0043  max mem: 5388\n",
            "Epoch: [32]  [140/147]  eta: 0:00:03  lr: 0.002422  min_lr: 0.002422  loss: 2.5584 (2.6165)  weight_decay: 0.0500 (0.0500)  time: 0.4954  data: 0.0025  max mem: 5388\n",
            "Epoch: [32]  [146/147]  eta: 0:00:00  lr: 0.002422  min_lr: 0.002422  loss: 2.5514 (2.6202)  weight_decay: 0.0500 (0.0500)  time: 0.4180  data: 0.0003  max mem: 5388\n",
            "Epoch: [32] Total time: 0:01:16 (0.5212 s / it)\n",
            "Averaged stats: lr: 0.002422  min_lr: 0.002422  loss: 2.5514 (2.6202)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:31  loss: 0.7203 (0.7203)  acc1: 83.3333 (83.3333)  acc5: 96.8750 (96.8750)  time: 5.1550  data: 4.7662  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.9097 (0.9070)  acc1: 77.0833 (77.6515)  acc5: 96.8750 (96.6856)  time: 0.7364  data: 0.4789  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 1.0139 (1.1994)  acc1: 71.8750 (64.0873)  acc5: 95.8333 (95.7341)  time: 0.2801  data: 0.0410  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0869 (1.1643)  acc1: 68.7500 (66.0618)  acc5: 95.8333 (95.7997)  time: 0.2516  data: 0.0162  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0752 (1.1439)  acc1: 68.7500 (67.1083)  acc5: 95.8333 (95.5414)  time: 0.2324  data: 0.0004  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3842 s / it)\n",
            "* Acc@1 67.108 Acc@5 95.541 loss 1.144\n",
            "Accuracy of the model on the 3925 test images: 67.1%\n",
            "Max accuracy: 67.11%\n",
            "Test:  [ 0/41]  eta: 0:01:58  loss: 5.5870 (5.5870)  acc1: 32.2917 (32.2917)  acc5: 54.1667 (54.1667)  time: 2.8889  data: 2.5889  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 5.5231 (5.5202)  acc1: 28.1250 (25.0947)  acc5: 57.2917 (55.1136)  time: 0.5929  data: 0.3557  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 5.9766 (5.8397)  acc1: 12.5000 (15.8234)  acc5: 40.6250 (41.8651)  time: 0.3729  data: 0.1377  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.0478 (5.7878)  acc1: 4.1667 (13.0376)  acc5: 29.1667 (44.0860)  time: 0.3918  data: 0.1539  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.5742 (5.5732)  acc1: 7.2917 (16.9427)  acc5: 47.9167 (48.1529)  time: 0.3285  data: 0.0957  max mem: 5388\n",
            "Test: Total time: 0:00:17 (0.4219 s / it)\n",
            "* Acc@1 16.943 Acc@5 48.153 loss 5.573\n",
            "Accuracy of the model EMA on 3925 test images: 16.9%\n",
            "Max EMA accuracy: 16.94%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [33]  [  0/147]  eta: 0:07:50  lr: 0.002416  min_lr: 0.002416  loss: 2.6990 (2.6990)  weight_decay: 0.0500 (0.0500)  time: 3.1999  data: 2.6319  max mem: 5388\n",
            "Epoch: [33]  [ 10/147]  eta: 0:01:44  lr: 0.002405  min_lr: 0.002405  loss: 2.6932 (2.6600)  weight_decay: 0.0500 (0.0500)  time: 0.7608  data: 0.2421  max mem: 5388\n",
            "Epoch: [33]  [ 20/147]  eta: 0:01:22  lr: 0.002388  min_lr: 0.002388  loss: 2.6932 (2.6724)  weight_decay: 0.0500 (0.0500)  time: 0.5196  data: 0.0030  max mem: 5388\n",
            "Epoch: [33]  [ 30/147]  eta: 0:01:10  lr: 0.002376  min_lr: 0.002376  loss: 2.6110 (2.6530)  weight_decay: 0.0500 (0.0500)  time: 0.5179  data: 0.0029  max mem: 5388\n",
            "Epoch: [33]  [ 40/147]  eta: 0:01:02  lr: 0.002359  min_lr: 0.002359  loss: 2.5010 (2.6308)  weight_decay: 0.0500 (0.0500)  time: 0.5167  data: 0.0024  max mem: 5388\n",
            "Epoch: [33]  [ 50/147]  eta: 0:00:55  lr: 0.002348  min_lr: 0.002348  loss: 2.5604 (2.6325)  weight_decay: 0.0500 (0.0500)  time: 0.5187  data: 0.0038  max mem: 5388\n",
            "Epoch: [33]  [ 60/147]  eta: 0:00:48  lr: 0.002331  min_lr: 0.002331  loss: 2.6772 (2.6495)  weight_decay: 0.0500 (0.0500)  time: 0.5122  data: 0.0031  max mem: 5388\n",
            "Epoch: [33]  [ 70/147]  eta: 0:00:42  lr: 0.002319  min_lr: 0.002319  loss: 2.6617 (2.6466)  weight_decay: 0.0500 (0.0500)  time: 0.5058  data: 0.0008  max mem: 5388\n",
            "Epoch: [33]  [ 80/147]  eta: 0:00:36  lr: 0.002302  min_lr: 0.002302  loss: 2.6469 (2.6449)  weight_decay: 0.0500 (0.0500)  time: 0.5100  data: 0.0020  max mem: 5388\n",
            "Epoch: [33]  [ 90/147]  eta: 0:00:30  lr: 0.002290  min_lr: 0.002290  loss: 2.6708 (2.6430)  weight_decay: 0.0500 (0.0500)  time: 0.5058  data: 0.0022  max mem: 5388\n",
            "Epoch: [33]  [100/147]  eta: 0:00:25  lr: 0.002273  min_lr: 0.002273  loss: 2.7131 (2.6446)  weight_decay: 0.0500 (0.0500)  time: 0.4952  data: 0.0012  max mem: 5388\n",
            "Epoch: [33]  [110/147]  eta: 0:00:19  lr: 0.002261  min_lr: 0.002261  loss: 2.7170 (2.6509)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0025  max mem: 5388\n",
            "Epoch: [33]  [120/147]  eta: 0:00:14  lr: 0.002244  min_lr: 0.002244  loss: 2.7170 (2.6558)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0029  max mem: 5388\n",
            "Epoch: [33]  [130/147]  eta: 0:00:08  lr: 0.002233  min_lr: 0.002233  loss: 2.7125 (2.6593)  weight_decay: 0.0500 (0.0500)  time: 0.4981  data: 0.0022  max mem: 5388\n",
            "Epoch: [33]  [140/147]  eta: 0:00:03  lr: 0.002215  min_lr: 0.002215  loss: 2.7444 (2.6652)  weight_decay: 0.0500 (0.0500)  time: 0.4931  data: 0.0012  max mem: 5388\n",
            "Epoch: [33]  [146/147]  eta: 0:00:00  lr: 0.002215  min_lr: 0.002215  loss: 2.7125 (2.6652)  weight_decay: 0.0500 (0.0500)  time: 0.4193  data: 0.0002  max mem: 5388\n",
            "Epoch: [33] Total time: 0:01:16 (0.5191 s / it)\n",
            "Averaged stats: lr: 0.002215  min_lr: 0.002215  loss: 2.7125 (2.6652)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:11  loss: 0.7157 (0.7157)  acc1: 87.5000 (87.5000)  acc5: 97.9167 (97.9167)  time: 3.2134  data: 2.9153  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 0.9623 (0.9786)  acc1: 77.0833 (76.8939)  acc5: 97.9167 (96.9697)  time: 0.5338  data: 0.2952  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 1.0413 (1.2148)  acc1: 75.0000 (66.0714)  acc5: 96.8750 (95.6349)  time: 0.2523  data: 0.0182  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 1.1181 (1.1828)  acc1: 70.8333 (68.2124)  acc5: 94.7917 (95.4637)  time: 0.2386  data: 0.0017  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1343 (1.1689)  acc1: 70.8333 (68.9936)  acc5: 94.7917 (95.1338)  time: 0.2340  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3280 s / it)\n",
            "* Acc@1 68.994 Acc@5 95.134 loss 1.169\n",
            "Accuracy of the model on the 3925 test images: 69.0%\n",
            "Max accuracy: 68.99%\n",
            "Test:  [ 0/41]  eta: 0:02:26  loss: 5.4895 (5.4895)  acc1: 33.3333 (33.3333)  acc5: 58.3333 (58.3333)  time: 3.5849  data: 3.3032  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 5.4281 (5.4415)  acc1: 29.1667 (25.4735)  acc5: 60.4167 (56.8182)  time: 0.5517  data: 0.3109  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 5.9152 (5.7793)  acc1: 13.5417 (16.0218)  acc5: 40.6250 (43.4524)  time: 0.2427  data: 0.0073  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.0239 (5.7308)  acc1: 4.1667 (13.3737)  acc5: 29.1667 (45.8669)  time: 0.2357  data: 0.0015  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.5014 (5.5077)  acc1: 7.2917 (17.3503)  acc5: 51.0417 (49.8344)  time: 0.2332  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3327 s / it)\n",
            "* Acc@1 17.350 Acc@5 49.834 loss 5.508\n",
            "Accuracy of the model EMA on 3925 test images: 17.4%\n",
            "Max EMA accuracy: 17.35%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [34]  [  0/147]  eta: 0:09:04  lr: 0.002210  min_lr: 0.002210  loss: 2.8307 (2.8307)  weight_decay: 0.0500 (0.0500)  time: 3.7009  data: 3.1354  max mem: 5388\n",
            "Epoch: [34]  [ 10/147]  eta: 0:01:49  lr: 0.002198  min_lr: 0.002198  loss: 2.6715 (2.6620)  weight_decay: 0.0500 (0.0500)  time: 0.8010  data: 0.2864  max mem: 5388\n",
            "Epoch: [34]  [ 20/147]  eta: 0:01:24  lr: 0.002181  min_lr: 0.002181  loss: 2.6632 (2.6507)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0019  max mem: 5388\n",
            "Epoch: [34]  [ 30/147]  eta: 0:01:12  lr: 0.002169  min_lr: 0.002169  loss: 2.6166 (2.6467)  weight_decay: 0.0500 (0.0500)  time: 0.5160  data: 0.0022  max mem: 5388\n",
            "Epoch: [34]  [ 40/147]  eta: 0:01:03  lr: 0.002152  min_lr: 0.002152  loss: 2.6437 (2.6432)  weight_decay: 0.0500 (0.0500)  time: 0.5260  data: 0.0042  max mem: 5388\n",
            "Epoch: [34]  [ 50/147]  eta: 0:00:56  lr: 0.002140  min_lr: 0.002140  loss: 2.6628 (2.6450)  weight_decay: 0.0500 (0.0500)  time: 0.5221  data: 0.0038  max mem: 5388\n",
            "Epoch: [34]  [ 60/147]  eta: 0:00:49  lr: 0.002123  min_lr: 0.002123  loss: 2.6745 (2.6528)  weight_decay: 0.0500 (0.0500)  time: 0.5117  data: 0.0025  max mem: 5388\n",
            "Epoch: [34]  [ 70/147]  eta: 0:00:43  lr: 0.002111  min_lr: 0.002111  loss: 2.7031 (2.6599)  weight_decay: 0.0500 (0.0500)  time: 0.5124  data: 0.0031  max mem: 5388\n",
            "Epoch: [34]  [ 80/147]  eta: 0:00:37  lr: 0.002094  min_lr: 0.002094  loss: 2.6758 (2.6513)  weight_decay: 0.0500 (0.0500)  time: 0.5059  data: 0.0020  max mem: 5388\n",
            "Epoch: [34]  [ 90/147]  eta: 0:00:31  lr: 0.002082  min_lr: 0.002082  loss: 2.5942 (2.6446)  weight_decay: 0.0500 (0.0500)  time: 0.4979  data: 0.0014  max mem: 5388\n",
            "Epoch: [34]  [100/147]  eta: 0:00:25  lr: 0.002064  min_lr: 0.002064  loss: 2.6449 (2.6450)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0023  max mem: 5388\n",
            "Epoch: [34]  [110/147]  eta: 0:00:19  lr: 0.002053  min_lr: 0.002053  loss: 2.6449 (2.6429)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0032  max mem: 5388\n",
            "Epoch: [34]  [120/147]  eta: 0:00:14  lr: 0.002035  min_lr: 0.002035  loss: 2.5857 (2.6330)  weight_decay: 0.0500 (0.0500)  time: 0.4962  data: 0.0026  max mem: 5388\n",
            "Epoch: [34]  [130/147]  eta: 0:00:09  lr: 0.002024  min_lr: 0.002024  loss: 2.5275 (2.6307)  weight_decay: 0.0500 (0.0500)  time: 0.4999  data: 0.0025  max mem: 5388\n",
            "Epoch: [34]  [140/147]  eta: 0:00:03  lr: 0.002006  min_lr: 0.002006  loss: 2.7070 (2.6358)  weight_decay: 0.0500 (0.0500)  time: 0.4991  data: 0.0016  max mem: 5388\n",
            "Epoch: [34]  [146/147]  eta: 0:00:00  lr: 0.002006  min_lr: 0.002006  loss: 2.5909 (2.6351)  weight_decay: 0.0500 (0.0500)  time: 0.4204  data: 0.0002  max mem: 5388\n",
            "Epoch: [34] Total time: 0:01:16 (0.5215 s / it)\n",
            "Averaged stats: lr: 0.002006  min_lr: 0.002006  loss: 2.5909 (2.6351)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 0.7193 (0.7193)  acc1: 84.3750 (84.3750)  acc5: 96.8750 (96.8750)  time: 3.1716  data: 2.8834  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.9021 (0.8547)  acc1: 79.1667 (79.8295)  acc5: 96.8750 (97.4432)  time: 0.5693  data: 0.3247  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.9927 (1.1904)  acc1: 73.9583 (65.7738)  acc5: 95.8333 (93.4524)  time: 0.3329  data: 0.0902  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.1669 (1.1884)  acc1: 66.6667 (66.4987)  acc5: 93.7500 (93.8508)  time: 0.2979  data: 0.0562  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0780 (1.1403)  acc1: 73.9583 (68.3312)  acc5: 94.7917 (94.3440)  time: 0.2344  data: 0.0005  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3647 s / it)\n",
            "* Acc@1 68.331 Acc@5 94.344 loss 1.140\n",
            "Accuracy of the model on the 3925 test images: 68.3%\n",
            "Max accuracy: 68.99%\n",
            "Test:  [ 0/41]  eta: 0:01:38  loss: 5.3947 (5.3947)  acc1: 36.4583 (36.4583)  acc5: 58.3333 (58.3333)  time: 2.3923  data: 2.1138  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 5.3357 (5.3653)  acc1: 29.1667 (26.3258)  acc5: 61.4583 (58.6174)  time: 0.4916  data: 0.2505  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:07  loss: 5.8546 (5.7206)  acc1: 12.5000 (16.3690)  acc5: 42.7083 (45.0397)  time: 0.2716  data: 0.0331  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 6.0024 (5.6755)  acc1: 2.0833 (13.7769)  acc5: 30.2083 (47.3454)  time: 0.2634  data: 0.0247  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.4278 (5.4439)  acc1: 8.3333 (17.7580)  acc5: 51.0417 (51.0318)  time: 0.2942  data: 0.0597  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3427 s / it)\n",
            "* Acc@1 17.758 Acc@5 51.032 loss 5.444\n",
            "Accuracy of the model EMA on 3925 test images: 17.8%\n",
            "Max EMA accuracy: 17.76%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [35]  [  0/147]  eta: 0:07:06  lr: 0.002001  min_lr: 0.002001  loss: 2.7256 (2.7256)  weight_decay: 0.0500 (0.0500)  time: 2.9034  data: 2.3054  max mem: 5388\n",
            "Epoch: [35]  [ 10/147]  eta: 0:01:39  lr: 0.001989  min_lr: 0.001989  loss: 2.6859 (2.6703)  weight_decay: 0.0500 (0.0500)  time: 0.7284  data: 0.2115  max mem: 5388\n",
            "Epoch: [35]  [ 20/147]  eta: 0:01:20  lr: 0.001971  min_lr: 0.001971  loss: 2.6737 (2.6664)  weight_decay: 0.0500 (0.0500)  time: 0.5180  data: 0.0036  max mem: 5388\n",
            "Epoch: [35]  [ 30/147]  eta: 0:01:09  lr: 0.001960  min_lr: 0.001960  loss: 2.6699 (2.6444)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0030  max mem: 5388\n",
            "Epoch: [35]  [ 40/147]  eta: 0:01:01  lr: 0.001942  min_lr: 0.001942  loss: 2.5750 (2.6059)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0012  max mem: 5388\n",
            "Epoch: [35]  [ 50/147]  eta: 0:00:54  lr: 0.001931  min_lr: 0.001931  loss: 2.5693 (2.6134)  weight_decay: 0.0500 (0.0500)  time: 0.5125  data: 0.0011  max mem: 5388\n",
            "Epoch: [35]  [ 60/147]  eta: 0:00:48  lr: 0.001913  min_lr: 0.001913  loss: 2.6783 (2.6191)  weight_decay: 0.0500 (0.0500)  time: 0.5155  data: 0.0014  max mem: 5388\n",
            "Epoch: [35]  [ 70/147]  eta: 0:00:42  lr: 0.001902  min_lr: 0.001902  loss: 2.7420 (2.6342)  weight_decay: 0.0500 (0.0500)  time: 0.5085  data: 0.0023  max mem: 5388\n",
            "Epoch: [35]  [ 80/147]  eta: 0:00:36  lr: 0.001884  min_lr: 0.001884  loss: 2.7203 (2.6290)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0017  max mem: 5388\n",
            "Epoch: [35]  [ 90/147]  eta: 0:00:30  lr: 0.001873  min_lr: 0.001873  loss: 2.7027 (2.6390)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0018  max mem: 5388\n",
            "Epoch: [35]  [100/147]  eta: 0:00:25  lr: 0.001855  min_lr: 0.001855  loss: 2.5844 (2.6245)  weight_decay: 0.0500 (0.0500)  time: 0.5151  data: 0.0038  max mem: 5388\n",
            "Epoch: [35]  [110/147]  eta: 0:00:19  lr: 0.001844  min_lr: 0.001844  loss: 2.4714 (2.6200)  weight_decay: 0.0500 (0.0500)  time: 0.5075  data: 0.0038  max mem: 5388\n",
            "Epoch: [35]  [120/147]  eta: 0:00:14  lr: 0.001826  min_lr: 0.001826  loss: 2.5682 (2.6200)  weight_decay: 0.0500 (0.0500)  time: 0.4995  data: 0.0030  max mem: 5388\n",
            "Epoch: [35]  [130/147]  eta: 0:00:08  lr: 0.001815  min_lr: 0.001815  loss: 2.5739 (2.6231)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0026  max mem: 5388\n",
            "Epoch: [35]  [140/147]  eta: 0:00:03  lr: 0.001797  min_lr: 0.001797  loss: 2.7362 (2.6297)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0011  max mem: 5388\n",
            "Epoch: [35]  [146/147]  eta: 0:00:00  lr: 0.001797  min_lr: 0.001797  loss: 2.6009 (2.6245)  weight_decay: 0.0500 (0.0500)  time: 0.4198  data: 0.0002  max mem: 5388\n",
            "Epoch: [35] Total time: 0:01:15 (0.5164 s / it)\n",
            "Averaged stats: lr: 0.001797  min_lr: 0.001797  loss: 2.6009 (2.6245)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:44  loss: 0.5888 (0.5888)  acc1: 88.5417 (88.5417)  acc5: 97.9167 (97.9167)  time: 4.0052  data: 3.6874  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 0.8799 (0.8452)  acc1: 80.2083 (80.1136)  acc5: 96.8750 (97.4432)  time: 0.6313  data: 0.3847  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.9613 (1.1294)  acc1: 73.9583 (68.5516)  acc5: 96.8750 (96.4782)  time: 0.2987  data: 0.0622  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.1722 (1.1265)  acc1: 69.7917 (69.7917)  acc5: 94.7917 (95.8333)  time: 0.2686  data: 0.0350  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1718 (1.1347)  acc1: 68.7500 (69.1465)  acc5: 94.7917 (95.6178)  time: 0.2310  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3668 s / it)\n",
            "* Acc@1 69.146 Acc@5 95.618 loss 1.135\n",
            "Accuracy of the model on the 3925 test images: 69.1%\n",
            "Max accuracy: 69.15%\n",
            "Test:  [ 0/41]  eta: 0:02:34  loss: 5.3028 (5.3028)  acc1: 36.4583 (36.4583)  acc5: 59.3750 (59.3750)  time: 3.7639  data: 3.4769  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 5.2465 (5.2905)  acc1: 30.2083 (26.7045)  acc5: 63.5417 (60.1326)  time: 0.6495  data: 0.3951  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 5.7963 (5.6633)  acc1: 12.5000 (16.5179)  acc5: 42.7083 (46.4782)  time: 0.3213  data: 0.0775  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.9834 (5.6220)  acc1: 2.0833 (14.0457)  acc5: 30.2083 (48.9583)  time: 0.2718  data: 0.0342  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.3555 (5.3826)  acc1: 8.3333 (18.0892)  acc5: 55.2083 (52.4841)  time: 0.2342  data: 0.0002  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3723 s / it)\n",
            "* Acc@1 18.089 Acc@5 52.484 loss 5.383\n",
            "Accuracy of the model EMA on 3925 test images: 18.1%\n",
            "Max EMA accuracy: 18.09%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [36]  [  0/147]  eta: 0:07:56  lr: 0.001791  min_lr: 0.001791  loss: 2.9795 (2.9795)  weight_decay: 0.0500 (0.0500)  time: 3.2438  data: 2.6249  max mem: 5388\n",
            "Epoch: [36]  [ 10/147]  eta: 0:01:45  lr: 0.001780  min_lr: 0.001780  loss: 2.6537 (2.5967)  weight_decay: 0.0500 (0.0500)  time: 0.7676  data: 0.2404  max mem: 5388\n",
            "Epoch: [36]  [ 20/147]  eta: 0:01:22  lr: 0.001763  min_lr: 0.001763  loss: 2.5435 (2.6036)  weight_decay: 0.0500 (0.0500)  time: 0.5177  data: 0.0019  max mem: 5388\n",
            "Epoch: [36]  [ 30/147]  eta: 0:01:10  lr: 0.001751  min_lr: 0.001751  loss: 2.6566 (2.6016)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0026  max mem: 5388\n",
            "Epoch: [36]  [ 40/147]  eta: 0:01:02  lr: 0.001734  min_lr: 0.001734  loss: 2.6779 (2.6229)  weight_decay: 0.0500 (0.0500)  time: 0.5137  data: 0.0024  max mem: 5388\n",
            "Epoch: [36]  [ 50/147]  eta: 0:00:55  lr: 0.001722  min_lr: 0.001722  loss: 2.6422 (2.6062)  weight_decay: 0.0500 (0.0500)  time: 0.5167  data: 0.0024  max mem: 5388\n",
            "Epoch: [36]  [ 60/147]  eta: 0:00:48  lr: 0.001705  min_lr: 0.001705  loss: 2.7005 (2.6245)  weight_decay: 0.0500 (0.0500)  time: 0.5139  data: 0.0028  max mem: 5388\n",
            "Epoch: [36]  [ 70/147]  eta: 0:00:42  lr: 0.001693  min_lr: 0.001693  loss: 2.7005 (2.6222)  weight_decay: 0.0500 (0.0500)  time: 0.5106  data: 0.0033  max mem: 5388\n",
            "Epoch: [36]  [ 80/147]  eta: 0:00:36  lr: 0.001676  min_lr: 0.001676  loss: 2.6227 (2.6229)  weight_decay: 0.0500 (0.0500)  time: 0.5149  data: 0.0043  max mem: 5388\n",
            "Epoch: [36]  [ 90/147]  eta: 0:00:30  lr: 0.001665  min_lr: 0.001665  loss: 2.6227 (2.6191)  weight_decay: 0.0500 (0.0500)  time: 0.5092  data: 0.0032  max mem: 5388\n",
            "Epoch: [36]  [100/147]  eta: 0:00:25  lr: 0.001648  min_lr: 0.001648  loss: 2.6773 (2.6192)  weight_decay: 0.0500 (0.0500)  time: 0.4990  data: 0.0018  max mem: 5388\n",
            "Epoch: [36]  [110/147]  eta: 0:00:19  lr: 0.001636  min_lr: 0.001636  loss: 2.6199 (2.6168)  weight_decay: 0.0500 (0.0500)  time: 0.5036  data: 0.0023  max mem: 5388\n",
            "Epoch: [36]  [120/147]  eta: 0:00:14  lr: 0.001619  min_lr: 0.001619  loss: 2.6111 (2.6137)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0025  max mem: 5388\n",
            "Epoch: [36]  [130/147]  eta: 0:00:09  lr: 0.001608  min_lr: 0.001608  loss: 2.5818 (2.6114)  weight_decay: 0.0500 (0.0500)  time: 0.4949  data: 0.0016  max mem: 5388\n",
            "Epoch: [36]  [140/147]  eta: 0:00:03  lr: 0.001590  min_lr: 0.001590  loss: 2.6458 (2.6185)  weight_decay: 0.0500 (0.0500)  time: 0.4943  data: 0.0007  max mem: 5388\n",
            "Epoch: [36]  [146/147]  eta: 0:00:00  lr: 0.001590  min_lr: 0.001590  loss: 2.6458 (2.6159)  weight_decay: 0.0500 (0.0500)  time: 0.4221  data: 0.0002  max mem: 5388\n",
            "Epoch: [36] Total time: 0:01:16 (0.5203 s / it)\n",
            "Averaged stats: lr: 0.001590  min_lr: 0.001590  loss: 2.6458 (2.6159)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:44  loss: 0.6837 (0.6837)  acc1: 84.3750 (84.3750)  acc5: 96.8750 (96.8750)  time: 4.0066  data: 3.7215  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.9189 (0.9552)  acc1: 77.0833 (74.9053)  acc5: 96.8750 (95.9280)  time: 0.5794  data: 0.3406  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.9263 (1.0714)  acc1: 76.0417 (70.0893)  acc5: 96.8750 (96.4286)  time: 0.2400  data: 0.0049  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 1.0116 (1.0557)  acc1: 72.9167 (70.9005)  acc5: 96.8750 (96.3710)  time: 0.2375  data: 0.0037  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0844 (1.0779)  acc1: 67.7083 (69.7834)  acc5: 94.7917 (95.7197)  time: 0.2294  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3403 s / it)\n",
            "* Acc@1 69.783 Acc@5 95.720 loss 1.078\n",
            "Accuracy of the model on the 3925 test images: 69.8%\n",
            "Max accuracy: 69.78%\n",
            "Test:  [ 0/41]  eta: 0:02:25  loss: 5.2131 (5.2131)  acc1: 36.4583 (36.4583)  acc5: 60.4167 (60.4167)  time: 3.5497  data: 3.2255  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 5.1598 (5.2179)  acc1: 30.2083 (26.9886)  acc5: 64.5833 (61.5530)  time: 0.5436  data: 0.3014  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 5.7400 (5.6080)  acc1: 12.5000 (16.7163)  acc5: 44.7917 (48.0159)  time: 0.2446  data: 0.0052  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.9673 (5.5709)  acc1: 2.0833 (14.4489)  acc5: 31.2500 (50.5040)  time: 0.2391  data: 0.0008  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.2849 (5.3235)  acc1: 8.3333 (18.6242)  acc5: 58.3333 (53.8854)  time: 0.2318  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3309 s / it)\n",
            "* Acc@1 18.624 Acc@5 53.885 loss 5.324\n",
            "Accuracy of the model EMA on 3925 test images: 18.6%\n",
            "Max EMA accuracy: 18.62%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [37]  [  0/147]  eta: 0:08:15  lr: 0.001585  min_lr: 0.001585  loss: 2.6411 (2.6411)  weight_decay: 0.0500 (0.0500)  time: 3.3701  data: 2.7974  max mem: 5388\n",
            "Epoch: [37]  [ 10/147]  eta: 0:01:46  lr: 0.001573  min_lr: 0.001573  loss: 2.6010 (2.5398)  weight_decay: 0.0500 (0.0500)  time: 0.7767  data: 0.2568  max mem: 5388\n",
            "Epoch: [37]  [ 20/147]  eta: 0:01:22  lr: 0.001556  min_lr: 0.001556  loss: 2.5811 (2.5624)  weight_decay: 0.0500 (0.0500)  time: 0.5170  data: 0.0044  max mem: 5388\n",
            "Epoch: [37]  [ 30/147]  eta: 0:01:11  lr: 0.001545  min_lr: 0.001545  loss: 2.6596 (2.5945)  weight_decay: 0.0500 (0.0500)  time: 0.5189  data: 0.0050  max mem: 5388\n",
            "Epoch: [37]  [ 40/147]  eta: 0:01:02  lr: 0.001528  min_lr: 0.001528  loss: 2.5965 (2.5680)  weight_decay: 0.0500 (0.0500)  time: 0.5184  data: 0.0031  max mem: 5388\n",
            "Epoch: [37]  [ 50/147]  eta: 0:00:55  lr: 0.001517  min_lr: 0.001517  loss: 2.5259 (2.5878)  weight_decay: 0.0500 (0.0500)  time: 0.5136  data: 0.0020  max mem: 5388\n",
            "Epoch: [37]  [ 60/147]  eta: 0:00:48  lr: 0.001500  min_lr: 0.001500  loss: 2.5537 (2.5780)  weight_decay: 0.0500 (0.0500)  time: 0.5127  data: 0.0017  max mem: 5388\n",
            "Epoch: [37]  [ 70/147]  eta: 0:00:42  lr: 0.001489  min_lr: 0.001489  loss: 2.6127 (2.5809)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0022  max mem: 5388\n",
            "Epoch: [37]  [ 80/147]  eta: 0:00:36  lr: 0.001472  min_lr: 0.001472  loss: 2.6621 (2.5934)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0035  max mem: 5388\n",
            "Epoch: [37]  [ 90/147]  eta: 0:00:31  lr: 0.001461  min_lr: 0.001461  loss: 2.6631 (2.5929)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0041  max mem: 5388\n",
            "Epoch: [37]  [100/147]  eta: 0:00:25  lr: 0.001444  min_lr: 0.001444  loss: 2.5416 (2.5885)  weight_decay: 0.0500 (0.0500)  time: 0.5064  data: 0.0045  max mem: 5388\n",
            "Epoch: [37]  [110/147]  eta: 0:00:19  lr: 0.001433  min_lr: 0.001433  loss: 2.5106 (2.5877)  weight_decay: 0.0500 (0.0500)  time: 0.4987  data: 0.0047  max mem: 5388\n",
            "Epoch: [37]  [120/147]  eta: 0:00:14  lr: 0.001416  min_lr: 0.001416  loss: 2.5638 (2.5914)  weight_decay: 0.0500 (0.0500)  time: 0.4976  data: 0.0028  max mem: 5388\n",
            "Epoch: [37]  [130/147]  eta: 0:00:09  lr: 0.001405  min_lr: 0.001405  loss: 2.5638 (2.5898)  weight_decay: 0.0500 (0.0500)  time: 0.5006  data: 0.0017  max mem: 5388\n",
            "Epoch: [37]  [140/147]  eta: 0:00:03  lr: 0.001388  min_lr: 0.001388  loss: 2.5030 (2.5854)  weight_decay: 0.0500 (0.0500)  time: 0.4962  data: 0.0013  max mem: 5388\n",
            "Epoch: [37]  [146/147]  eta: 0:00:00  lr: 0.001388  min_lr: 0.001388  loss: 2.5030 (2.5844)  weight_decay: 0.0500 (0.0500)  time: 0.4186  data: 0.0002  max mem: 5388\n",
            "Epoch: [37] Total time: 0:01:16 (0.5190 s / it)\n",
            "Averaged stats: lr: 0.001388  min_lr: 0.001388  loss: 2.5030 (2.5844)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:53  loss: 0.6874 (0.6874)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 4.2299  data: 3.9424  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.8974 (0.9071)  acc1: 76.0417 (76.3258)  acc5: 96.8750 (96.6856)  time: 0.6748  data: 0.4281  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.9155 (1.0927)  acc1: 76.0417 (69.0476)  acc5: 96.8750 (95.8333)  time: 0.2973  data: 0.0564  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0483 (1.0658)  acc1: 71.8750 (70.2621)  acc5: 96.8750 (95.9677)  time: 0.2608  data: 0.0231  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0826 (1.0498)  acc1: 68.7500 (70.5733)  acc5: 96.8750 (95.9745)  time: 0.2375  data: 0.0051  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3764 s / it)\n",
            "* Acc@1 70.573 Acc@5 95.975 loss 1.050\n",
            "Accuracy of the model on the 3925 test images: 70.6%\n",
            "Max accuracy: 70.57%\n",
            "Test:  [ 0/41]  eta: 0:02:57  loss: 5.1264 (5.1264)  acc1: 36.4583 (36.4583)  acc5: 61.4583 (61.4583)  time: 4.3290  data: 4.0226  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 5.0762 (5.1481)  acc1: 31.2500 (26.8939)  acc5: 66.6667 (62.8788)  time: 0.7422  data: 0.4952  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 5.6839 (5.5546)  acc1: 11.4583 (16.8651)  acc5: 46.8750 (49.3056)  time: 0.3720  data: 0.1341  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.9522 (5.5215)  acc1: 2.0833 (14.7177)  acc5: 34.3750 (51.4449)  time: 0.3410  data: 0.1061  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.2180 (5.2670)  acc1: 8.3333 (18.9045)  acc5: 61.4583 (54.8280)  time: 0.2767  data: 0.0432  max mem: 5388\n",
            "Test: Total time: 0:00:17 (0.4303 s / it)\n",
            "* Acc@1 18.904 Acc@5 54.828 loss 5.267\n",
            "Accuracy of the model EMA on 3925 test images: 18.9%\n",
            "Max EMA accuracy: 18.90%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [38]  [  0/147]  eta: 0:06:40  lr: 0.001383  min_lr: 0.001383  loss: 2.5733 (2.5733)  weight_decay: 0.0500 (0.0500)  time: 2.7261  data: 2.1688  max mem: 5388\n",
            "Epoch: [38]  [ 10/147]  eta: 0:01:39  lr: 0.001372  min_lr: 0.001372  loss: 2.6661 (2.6201)  weight_decay: 0.0500 (0.0500)  time: 0.7294  data: 0.2011  max mem: 5388\n",
            "Epoch: [38]  [ 20/147]  eta: 0:01:20  lr: 0.001355  min_lr: 0.001355  loss: 2.7405 (2.6766)  weight_decay: 0.0500 (0.0500)  time: 0.5258  data: 0.0026  max mem: 5388\n",
            "Epoch: [38]  [ 30/147]  eta: 0:01:09  lr: 0.001344  min_lr: 0.001344  loss: 2.7189 (2.6377)  weight_decay: 0.0500 (0.0500)  time: 0.5176  data: 0.0015  max mem: 5388\n",
            "Epoch: [38]  [ 40/147]  eta: 0:01:01  lr: 0.001328  min_lr: 0.001328  loss: 2.6730 (2.6544)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0019  max mem: 5388\n",
            "Epoch: [38]  [ 50/147]  eta: 0:00:54  lr: 0.001317  min_lr: 0.001317  loss: 2.6269 (2.6338)  weight_decay: 0.0500 (0.0500)  time: 0.5141  data: 0.0012  max mem: 5388\n",
            "Epoch: [38]  [ 60/147]  eta: 0:00:48  lr: 0.001300  min_lr: 0.001300  loss: 2.4994 (2.6061)  weight_decay: 0.0500 (0.0500)  time: 0.5086  data: 0.0023  max mem: 5388\n",
            "Epoch: [38]  [ 70/147]  eta: 0:00:41  lr: 0.001289  min_lr: 0.001289  loss: 2.5415 (2.6071)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0034  max mem: 5388\n",
            "Epoch: [38]  [ 80/147]  eta: 0:00:36  lr: 0.001273  min_lr: 0.001273  loss: 2.6262 (2.6140)  weight_decay: 0.0500 (0.0500)  time: 0.5074  data: 0.0036  max mem: 5388\n",
            "Epoch: [38]  [ 90/147]  eta: 0:00:30  lr: 0.001262  min_lr: 0.001262  loss: 2.6218 (2.6122)  weight_decay: 0.0500 (0.0500)  time: 0.5074  data: 0.0036  max mem: 5388\n",
            "Epoch: [38]  [100/147]  eta: 0:00:25  lr: 0.001246  min_lr: 0.001246  loss: 2.6245 (2.6138)  weight_decay: 0.0500 (0.0500)  time: 0.4972  data: 0.0022  max mem: 5388\n",
            "Epoch: [38]  [110/147]  eta: 0:00:19  lr: 0.001235  min_lr: 0.001235  loss: 2.6524 (2.6236)  weight_decay: 0.0500 (0.0500)  time: 0.4991  data: 0.0033  max mem: 5388\n",
            "Epoch: [38]  [120/147]  eta: 0:00:14  lr: 0.001219  min_lr: 0.001219  loss: 2.6130 (2.6147)  weight_decay: 0.0500 (0.0500)  time: 0.5028  data: 0.0032  max mem: 5388\n",
            "Epoch: [38]  [130/147]  eta: 0:00:08  lr: 0.001209  min_lr: 0.001209  loss: 2.6838 (2.6208)  weight_decay: 0.0500 (0.0500)  time: 0.4966  data: 0.0014  max mem: 5388\n",
            "Epoch: [38]  [140/147]  eta: 0:00:03  lr: 0.001193  min_lr: 0.001193  loss: 2.7223 (2.6253)  weight_decay: 0.0500 (0.0500)  time: 0.4929  data: 0.0009  max mem: 5388\n",
            "Epoch: [38]  [146/147]  eta: 0:00:00  lr: 0.001193  min_lr: 0.001193  loss: 2.7024 (2.6269)  weight_decay: 0.0500 (0.0500)  time: 0.4201  data: 0.0002  max mem: 5388\n",
            "Epoch: [38] Total time: 0:01:15 (0.5152 s / it)\n",
            "Averaged stats: lr: 0.001193  min_lr: 0.001193  loss: 2.7024 (2.6269)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:39  loss: 0.6206 (0.6206)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 3.8934  data: 3.5986  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.8299 (0.8807)  acc1: 82.2917 (80.3977)  acc5: 96.8750 (96.8750)  time: 0.5738  data: 0.3315  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.9200 (1.0641)  acc1: 78.1250 (72.1230)  acc5: 96.8750 (96.9246)  time: 0.2400  data: 0.0042  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 1.0589 (1.0666)  acc1: 73.9583 (72.3790)  acc5: 95.8333 (96.7406)  time: 0.2349  data: 0.0019  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0689 (1.0665)  acc1: 68.7500 (71.6943)  acc5: 95.8333 (96.4076)  time: 0.2310  data: 0.0002  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3382 s / it)\n",
            "* Acc@1 71.694 Acc@5 96.408 loss 1.067\n",
            "Accuracy of the model on the 3925 test images: 71.7%\n",
            "Max accuracy: 71.69%\n",
            "Test:  [ 0/41]  eta: 0:02:27  loss: 5.0413 (5.0413)  acc1: 36.4583 (36.4583)  acc5: 63.5417 (63.5417)  time: 3.6092  data: 3.3182  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 4.9945 (5.0803)  acc1: 29.1667 (26.9886)  acc5: 67.7083 (63.9205)  time: 0.5477  data: 0.3079  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 5.6289 (5.5027)  acc1: 10.4167 (16.9643)  acc5: 47.9167 (50.2976)  time: 0.2396  data: 0.0054  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.9316 (5.4745)  acc1: 2.0833 (14.9530)  acc5: 35.4167 (52.3522)  time: 0.2382  data: 0.0020  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.1524 (5.2132)  acc1: 8.3333 (19.1847)  acc5: 64.5833 (55.7962)  time: 0.2357  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3331 s / it)\n",
            "* Acc@1 19.185 Acc@5 55.796 loss 5.213\n",
            "Accuracy of the model EMA on 3925 test images: 19.2%\n",
            "Max EMA accuracy: 19.18%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [39]  [  0/147]  eta: 0:07:50  lr: 0.001187  min_lr: 0.001187  loss: 2.6279 (2.6279)  weight_decay: 0.0500 (0.0500)  time: 3.1974  data: 2.6297  max mem: 5388\n",
            "Epoch: [39]  [ 10/147]  eta: 0:01:45  lr: 0.001177  min_lr: 0.001177  loss: 2.6481 (2.6472)  weight_decay: 0.0500 (0.0500)  time: 0.7735  data: 0.2485  max mem: 5388\n",
            "Epoch: [39]  [ 20/147]  eta: 0:01:22  lr: 0.001161  min_lr: 0.001161  loss: 2.6481 (2.6383)  weight_decay: 0.0500 (0.0500)  time: 0.5227  data: 0.0061  max mem: 5388\n",
            "Epoch: [39]  [ 30/147]  eta: 0:01:11  lr: 0.001150  min_lr: 0.001150  loss: 2.5913 (2.6225)  weight_decay: 0.0500 (0.0500)  time: 0.5220  data: 0.0034  max mem: 5388\n",
            "Epoch: [39]  [ 40/147]  eta: 0:01:03  lr: 0.001134  min_lr: 0.001134  loss: 2.6831 (2.6503)  weight_decay: 0.0500 (0.0500)  time: 0.5272  data: 0.0041  max mem: 5388\n",
            "Epoch: [39]  [ 50/147]  eta: 0:00:55  lr: 0.001124  min_lr: 0.001124  loss: 2.7354 (2.6226)  weight_decay: 0.0500 (0.0500)  time: 0.5157  data: 0.0023  max mem: 5388\n",
            "Epoch: [39]  [ 60/147]  eta: 0:00:49  lr: 0.001108  min_lr: 0.001108  loss: 2.5739 (2.6129)  weight_decay: 0.0500 (0.0500)  time: 0.5084  data: 0.0029  max mem: 5388\n",
            "Epoch: [39]  [ 70/147]  eta: 0:00:42  lr: 0.001098  min_lr: 0.001098  loss: 2.5739 (2.6045)  weight_decay: 0.0500 (0.0500)  time: 0.5116  data: 0.0037  max mem: 5388\n",
            "Epoch: [39]  [ 80/147]  eta: 0:00:36  lr: 0.001082  min_lr: 0.001082  loss: 2.5908 (2.6071)  weight_decay: 0.0500 (0.0500)  time: 0.5068  data: 0.0017  max mem: 5388\n",
            "Epoch: [39]  [ 90/147]  eta: 0:00:30  lr: 0.001072  min_lr: 0.001072  loss: 2.6010 (2.6025)  weight_decay: 0.0500 (0.0500)  time: 0.4991  data: 0.0008  max mem: 5388\n",
            "Epoch: [39]  [100/147]  eta: 0:00:25  lr: 0.001057  min_lr: 0.001057  loss: 2.5867 (2.5877)  weight_decay: 0.0500 (0.0500)  time: 0.5036  data: 0.0012  max mem: 5388\n",
            "Epoch: [39]  [110/147]  eta: 0:00:19  lr: 0.001046  min_lr: 0.001046  loss: 2.5247 (2.5919)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0021  max mem: 5388\n",
            "Epoch: [39]  [120/147]  eta: 0:00:14  lr: 0.001031  min_lr: 0.001031  loss: 2.6608 (2.5907)  weight_decay: 0.0500 (0.0500)  time: 0.4958  data: 0.0022  max mem: 5388\n",
            "Epoch: [39]  [130/147]  eta: 0:00:09  lr: 0.001021  min_lr: 0.001021  loss: 2.5762 (2.5785)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0025  max mem: 5388\n",
            "Epoch: [39]  [140/147]  eta: 0:00:03  lr: 0.001006  min_lr: 0.001006  loss: 2.5721 (2.5802)  weight_decay: 0.0500 (0.0500)  time: 0.4997  data: 0.0019  max mem: 5388\n",
            "Epoch: [39]  [146/147]  eta: 0:00:00  lr: 0.001006  min_lr: 0.001006  loss: 2.6085 (2.5845)  weight_decay: 0.0500 (0.0500)  time: 0.4211  data: 0.0002  max mem: 5388\n",
            "Epoch: [39] Total time: 0:01:16 (0.5193 s / it)\n",
            "Averaged stats: lr: 0.001006  min_lr: 0.001006  loss: 2.6085 (2.5845)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:53  loss: 0.5077 (0.5077)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 2.7575  data: 2.4916  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 0.7640 (0.7791)  acc1: 83.3333 (82.5758)  acc5: 97.9167 (97.5379)  time: 0.5087  data: 0.2681  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.8557 (1.0004)  acc1: 77.0833 (71.8750)  acc5: 96.8750 (96.6766)  time: 0.3062  data: 0.0650  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0909 (1.0340)  acc1: 71.8750 (71.5054)  acc5: 95.8333 (96.1022)  time: 0.3288  data: 0.0786  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0909 (1.0115)  acc1: 68.7500 (71.8981)  acc5: 95.8333 (96.1529)  time: 0.2794  data: 0.0365  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3613 s / it)\n",
            "* Acc@1 71.898 Acc@5 96.153 loss 1.012\n",
            "Accuracy of the model on the 3925 test images: 71.9%\n",
            "Max accuracy: 71.90%\n",
            "Test:  [ 0/41]  eta: 0:01:56  loss: 4.9568 (4.9568)  acc1: 37.5000 (37.5000)  acc5: 63.5417 (63.5417)  time: 2.8479  data: 2.5447  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 4.9143 (5.0138)  acc1: 29.1667 (27.0833)  acc5: 67.7083 (64.7727)  time: 0.4852  data: 0.2437  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:07  loss: 5.5758 (5.4521)  acc1: 9.3750 (16.9643)  acc5: 48.9583 (51.4881)  time: 0.2552  data: 0.0193  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.9097 (5.4289)  acc1: 2.0833 (15.1546)  acc5: 36.4583 (53.4946)  time: 0.3013  data: 0.0655  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.0881 (5.1615)  acc1: 8.3333 (19.3376)  acc5: 64.5833 (56.7643)  time: 0.2916  data: 0.0584  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3469 s / it)\n",
            "* Acc@1 19.338 Acc@5 56.764 loss 5.161\n",
            "Accuracy of the model EMA on 3925 test images: 19.3%\n",
            "Max EMA accuracy: 19.34%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [40]  [  0/147]  eta: 0:04:57  lr: 0.001001  min_lr: 0.001001  loss: 2.3001 (2.3001)  weight_decay: 0.0500 (0.0500)  time: 2.0249  data: 1.4366  max mem: 5388\n",
            "Epoch: [40]  [ 10/147]  eta: 0:01:41  lr: 0.000991  min_lr: 0.000991  loss: 2.5554 (2.4882)  weight_decay: 0.0500 (0.0500)  time: 0.7436  data: 0.2270  max mem: 5388\n",
            "Epoch: [40]  [ 20/147]  eta: 0:01:20  lr: 0.000976  min_lr: 0.000976  loss: 2.5764 (2.5374)  weight_decay: 0.0500 (0.0500)  time: 0.5666  data: 0.0548  max mem: 5388\n",
            "Epoch: [40]  [ 30/147]  eta: 0:01:09  lr: 0.000966  min_lr: 0.000966  loss: 2.5627 (2.5236)  weight_decay: 0.0500 (0.0500)  time: 0.5114  data: 0.0030  max mem: 5388\n",
            "Epoch: [40]  [ 40/147]  eta: 0:01:01  lr: 0.000951  min_lr: 0.000951  loss: 2.5957 (2.5721)  weight_decay: 0.0500 (0.0500)  time: 0.5053  data: 0.0017  max mem: 5388\n",
            "Epoch: [40]  [ 50/147]  eta: 0:00:54  lr: 0.000941  min_lr: 0.000941  loss: 2.6385 (2.5701)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0010  max mem: 5388\n",
            "Epoch: [40]  [ 60/147]  eta: 0:00:48  lr: 0.000926  min_lr: 0.000926  loss: 2.5994 (2.5665)  weight_decay: 0.0500 (0.0500)  time: 0.5109  data: 0.0015  max mem: 5388\n",
            "Epoch: [40]  [ 70/147]  eta: 0:00:42  lr: 0.000916  min_lr: 0.000916  loss: 2.6600 (2.5770)  weight_decay: 0.0500 (0.0500)  time: 0.5059  data: 0.0017  max mem: 5388\n",
            "Epoch: [40]  [ 80/147]  eta: 0:00:36  lr: 0.000902  min_lr: 0.000902  loss: 2.6369 (2.5750)  weight_decay: 0.0500 (0.0500)  time: 0.5051  data: 0.0019  max mem: 5388\n",
            "Epoch: [40]  [ 90/147]  eta: 0:00:30  lr: 0.000892  min_lr: 0.000892  loss: 2.6369 (2.5822)  weight_decay: 0.0500 (0.0500)  time: 0.5096  data: 0.0017  max mem: 5388\n",
            "Epoch: [40]  [100/147]  eta: 0:00:25  lr: 0.000878  min_lr: 0.000878  loss: 2.6705 (2.5797)  weight_decay: 0.0500 (0.0500)  time: 0.5117  data: 0.0026  max mem: 5388\n",
            "Epoch: [40]  [110/147]  eta: 0:00:19  lr: 0.000868  min_lr: 0.000868  loss: 2.5056 (2.5712)  weight_decay: 0.0500 (0.0500)  time: 0.5033  data: 0.0026  max mem: 5388\n",
            "Epoch: [40]  [120/147]  eta: 0:00:14  lr: 0.000854  min_lr: 0.000854  loss: 2.4534 (2.5633)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0030  max mem: 5388\n",
            "Epoch: [40]  [130/147]  eta: 0:00:08  lr: 0.000844  min_lr: 0.000844  loss: 2.4678 (2.5591)  weight_decay: 0.0500 (0.0500)  time: 0.5031  data: 0.0035  max mem: 5388\n",
            "Epoch: [40]  [140/147]  eta: 0:00:03  lr: 0.000830  min_lr: 0.000830  loss: 2.5236 (2.5573)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0013  max mem: 5388\n",
            "Epoch: [40]  [146/147]  eta: 0:00:00  lr: 0.000830  min_lr: 0.000830  loss: 2.5788 (2.5572)  weight_decay: 0.0500 (0.0500)  time: 0.4219  data: 0.0002  max mem: 5388\n",
            "Epoch: [40] Total time: 0:01:15 (0.5161 s / it)\n",
            "Averaged stats: lr: 0.000830  min_lr: 0.000830  loss: 2.5788 (2.5572)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:40  loss: 0.5417 (0.5417)  acc1: 88.5417 (88.5417)  acc5: 97.9167 (97.9167)  time: 3.9245  data: 3.6247  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.7134 (0.7378)  acc1: 83.3333 (82.6705)  acc5: 97.9167 (97.0644)  time: 0.6672  data: 0.4200  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.7757 (0.9589)  acc1: 80.2083 (73.2639)  acc5: 96.8750 (96.7758)  time: 0.3141  data: 0.0741  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9519 (0.9836)  acc1: 73.9583 (72.7823)  acc5: 95.8333 (96.3374)  time: 0.2599  data: 0.0244  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0284 (0.9861)  acc1: 69.7917 (72.6115)  acc5: 95.8333 (96.1783)  time: 0.2307  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3698 s / it)\n",
            "* Acc@1 72.611 Acc@5 96.178 loss 0.986\n",
            "Accuracy of the model on the 3925 test images: 72.6%\n",
            "Max accuracy: 72.61%\n",
            "Test:  [ 0/41]  eta: 0:02:29  loss: 4.8763 (4.8763)  acc1: 38.5417 (38.5417)  acc5: 64.5833 (64.5833)  time: 3.6475  data: 3.2712  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 4.8376 (4.9504)  acc1: 30.2083 (26.8939)  acc5: 67.7083 (65.1515)  time: 0.6345  data: 0.3837  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 5.5246 (5.4041)  acc1: 9.3750 (16.8651)  acc5: 48.9583 (52.0833)  time: 0.3080  data: 0.0712  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.8890 (5.3859)  acc1: 2.0833 (15.2554)  acc5: 37.5000 (54.0995)  time: 0.2896  data: 0.0544  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.0234 (5.1124)  acc1: 8.3333 (19.4395)  acc5: 65.6250 (57.3503)  time: 0.2631  data: 0.0307  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3758 s / it)\n",
            "* Acc@1 19.439 Acc@5 57.350 loss 5.112\n",
            "Accuracy of the model EMA on 3925 test images: 19.4%\n",
            "Max EMA accuracy: 19.44%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [41]  [  0/147]  eta: 0:07:38  lr: 0.000825  min_lr: 0.000825  loss: 2.2128 (2.2128)  weight_decay: 0.0500 (0.0500)  time: 3.1173  data: 2.5235  max mem: 5388\n",
            "Epoch: [41]  [ 10/147]  eta: 0:01:44  lr: 0.000816  min_lr: 0.000816  loss: 2.5338 (2.5074)  weight_decay: 0.0500 (0.0500)  time: 0.7659  data: 0.2307  max mem: 5388\n",
            "Epoch: [41]  [ 20/147]  eta: 0:01:21  lr: 0.000802  min_lr: 0.000802  loss: 2.5338 (2.5185)  weight_decay: 0.0500 (0.0500)  time: 0.5221  data: 0.0025  max mem: 5388\n",
            "Epoch: [41]  [ 30/147]  eta: 0:01:10  lr: 0.000793  min_lr: 0.000793  loss: 2.5059 (2.5124)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0030  max mem: 5388\n",
            "Epoch: [41]  [ 40/147]  eta: 0:01:02  lr: 0.000779  min_lr: 0.000779  loss: 2.6550 (2.5609)  weight_decay: 0.0500 (0.0500)  time: 0.5163  data: 0.0027  max mem: 5388\n",
            "Epoch: [41]  [ 50/147]  eta: 0:00:55  lr: 0.000769  min_lr: 0.000769  loss: 2.7136 (2.5804)  weight_decay: 0.0500 (0.0500)  time: 0.5188  data: 0.0035  max mem: 5388\n",
            "Epoch: [41]  [ 60/147]  eta: 0:00:48  lr: 0.000756  min_lr: 0.000756  loss: 2.6459 (2.5821)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0033  max mem: 5388\n",
            "Epoch: [41]  [ 70/147]  eta: 0:00:42  lr: 0.000747  min_lr: 0.000747  loss: 2.6140 (2.5830)  weight_decay: 0.0500 (0.0500)  time: 0.5088  data: 0.0024  max mem: 5388\n",
            "Epoch: [41]  [ 80/147]  eta: 0:00:36  lr: 0.000733  min_lr: 0.000733  loss: 2.5986 (2.5849)  weight_decay: 0.0500 (0.0500)  time: 0.5106  data: 0.0035  max mem: 5388\n",
            "Epoch: [41]  [ 90/147]  eta: 0:00:30  lr: 0.000724  min_lr: 0.000724  loss: 2.6059 (2.5791)  weight_decay: 0.0500 (0.0500)  time: 0.5044  data: 0.0031  max mem: 5388\n",
            "Epoch: [41]  [100/147]  eta: 0:00:25  lr: 0.000711  min_lr: 0.000711  loss: 2.6529 (2.5865)  weight_decay: 0.0500 (0.0500)  time: 0.4981  data: 0.0014  max mem: 5388\n",
            "Epoch: [41]  [110/147]  eta: 0:00:19  lr: 0.000702  min_lr: 0.000702  loss: 2.6434 (2.5883)  weight_decay: 0.0500 (0.0500)  time: 0.5040  data: 0.0025  max mem: 5388\n",
            "Epoch: [41]  [120/147]  eta: 0:00:14  lr: 0.000689  min_lr: 0.000689  loss: 2.6179 (2.5865)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0038  max mem: 5388\n",
            "Epoch: [41]  [130/147]  eta: 0:00:08  lr: 0.000680  min_lr: 0.000680  loss: 2.6575 (2.5951)  weight_decay: 0.0500 (0.0500)  time: 0.4944  data: 0.0026  max mem: 5388\n",
            "Epoch: [41]  [140/147]  eta: 0:00:03  lr: 0.000667  min_lr: 0.000667  loss: 2.6601 (2.5934)  weight_decay: 0.0500 (0.0500)  time: 0.4926  data: 0.0007  max mem: 5388\n",
            "Epoch: [41]  [146/147]  eta: 0:00:00  lr: 0.000667  min_lr: 0.000667  loss: 2.5382 (2.5893)  weight_decay: 0.0500 (0.0500)  time: 0.4208  data: 0.0002  max mem: 5388\n",
            "Epoch: [41] Total time: 0:01:16 (0.5195 s / it)\n",
            "Averaged stats: lr: 0.000667  min_lr: 0.000667  loss: 2.5382 (2.5893)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:15  loss: 0.5991 (0.5991)  acc1: 89.5833 (89.5833)  acc5: 96.8750 (96.8750)  time: 4.7696  data: 4.4619  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.7475 (0.7317)  acc1: 84.3750 (84.7538)  acc5: 96.8750 (97.7273)  time: 0.6496  data: 0.4066  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.7818 (0.9620)  acc1: 82.2917 (74.6528)  acc5: 96.8750 (96.8750)  time: 0.2397  data: 0.0013  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0674 (1.0194)  acc1: 71.8750 (73.4543)  acc5: 95.8333 (96.2702)  time: 0.2376  data: 0.0009  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0138 (1.0177)  acc1: 72.9167 (73.2229)  acc5: 94.7917 (96.1529)  time: 0.2309  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3609 s / it)\n",
            "* Acc@1 73.223 Acc@5 96.153 loss 1.018\n",
            "Accuracy of the model on the 3925 test images: 73.2%\n",
            "Max accuracy: 73.22%\n",
            "Test:  [ 0/41]  eta: 0:02:50  loss: 4.7990 (4.7990)  acc1: 39.5833 (39.5833)  acc5: 64.5833 (64.5833)  time: 4.1705  data: 3.8785  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 4.7652 (4.8900)  acc1: 30.2083 (26.7045)  acc5: 69.7917 (66.1932)  time: 0.5914  data: 0.3554  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 5.4755 (5.3581)  acc1: 9.3750 (16.9643)  acc5: 52.0833 (53.2738)  time: 0.2364  data: 0.0024  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.8682 (5.3455)  acc1: 2.0833 (15.4906)  acc5: 40.6250 (55.1075)  time: 0.2388  data: 0.0009  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.9605 (5.0660)  acc1: 9.3750 (19.7707)  acc5: 65.6250 (58.2420)  time: 0.2349  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3444 s / it)\n",
            "* Acc@1 19.771 Acc@5 58.242 loss 5.066\n",
            "Accuracy of the model EMA on 3925 test images: 19.8%\n",
            "Max EMA accuracy: 19.77%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [42]  [  0/147]  eta: 0:10:21  lr: 0.000663  min_lr: 0.000663  loss: 2.6445 (2.6445)  weight_decay: 0.0500 (0.0500)  time: 4.2311  data: 3.6237  max mem: 5388\n",
            "Epoch: [42]  [ 10/147]  eta: 0:01:55  lr: 0.000654  min_lr: 0.000654  loss: 2.6445 (2.6434)  weight_decay: 0.0500 (0.0500)  time: 0.8444  data: 0.3311  max mem: 5388\n",
            "Epoch: [42]  [ 20/147]  eta: 0:01:27  lr: 0.000641  min_lr: 0.000641  loss: 2.6294 (2.6192)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0026  max mem: 5388\n",
            "Epoch: [42]  [ 30/147]  eta: 0:01:14  lr: 0.000633  min_lr: 0.000633  loss: 2.5804 (2.5907)  weight_decay: 0.0500 (0.0500)  time: 0.5167  data: 0.0026  max mem: 5388\n",
            "Epoch: [42]  [ 40/147]  eta: 0:01:04  lr: 0.000620  min_lr: 0.000620  loss: 2.5608 (2.5802)  weight_decay: 0.0500 (0.0500)  time: 0.5158  data: 0.0019  max mem: 5388\n",
            "Epoch: [42]  [ 50/147]  eta: 0:00:56  lr: 0.000612  min_lr: 0.000612  loss: 2.5442 (2.5596)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0020  max mem: 5388\n",
            "Epoch: [42]  [ 60/147]  eta: 0:00:49  lr: 0.000599  min_lr: 0.000599  loss: 2.5059 (2.5653)  weight_decay: 0.0500 (0.0500)  time: 0.5142  data: 0.0016  max mem: 5388\n",
            "Epoch: [42]  [ 70/147]  eta: 0:00:43  lr: 0.000591  min_lr: 0.000591  loss: 2.6038 (2.5588)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0018  max mem: 5388\n",
            "Epoch: [42]  [ 80/147]  eta: 0:00:37  lr: 0.000578  min_lr: 0.000578  loss: 2.5240 (2.5573)  weight_decay: 0.0500 (0.0500)  time: 0.5029  data: 0.0021  max mem: 5388\n",
            "Epoch: [42]  [ 90/147]  eta: 0:00:31  lr: 0.000570  min_lr: 0.000570  loss: 2.5932 (2.5637)  weight_decay: 0.0500 (0.0500)  time: 0.5050  data: 0.0030  max mem: 5388\n",
            "Epoch: [42]  [100/147]  eta: 0:00:25  lr: 0.000558  min_lr: 0.000558  loss: 2.5377 (2.5517)  weight_decay: 0.0500 (0.0500)  time: 0.5046  data: 0.0043  max mem: 5388\n",
            "Epoch: [42]  [110/147]  eta: 0:00:20  lr: 0.000550  min_lr: 0.000550  loss: 2.4671 (2.5538)  weight_decay: 0.0500 (0.0500)  time: 0.4982  data: 0.0028  max mem: 5388\n",
            "Epoch: [42]  [120/147]  eta: 0:00:14  lr: 0.000538  min_lr: 0.000538  loss: 2.5428 (2.5534)  weight_decay: 0.0500 (0.0500)  time: 0.4977  data: 0.0022  max mem: 5388\n",
            "Epoch: [42]  [130/147]  eta: 0:00:09  lr: 0.000530  min_lr: 0.000530  loss: 2.6099 (2.5621)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0027  max mem: 5388\n",
            "Epoch: [42]  [140/147]  eta: 0:00:03  lr: 0.000518  min_lr: 0.000518  loss: 2.6658 (2.5595)  weight_decay: 0.0500 (0.0500)  time: 0.4974  data: 0.0012  max mem: 5388\n",
            "Epoch: [42]  [146/147]  eta: 0:00:00  lr: 0.000518  min_lr: 0.000518  loss: 2.5222 (2.5588)  weight_decay: 0.0500 (0.0500)  time: 0.4190  data: 0.0002  max mem: 5388\n",
            "Epoch: [42] Total time: 0:01:16 (0.5235 s / it)\n",
            "Averaged stats: lr: 0.000518  min_lr: 0.000518  loss: 2.5222 (2.5588)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:18  loss: 0.4347 (0.4347)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 4.8340  data: 4.5019  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.7438 (0.6930)  acc1: 84.3750 (84.5644)  acc5: 97.9167 (97.7273)  time: 0.7117  data: 0.4623  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.7667 (0.9365)  acc1: 82.2917 (74.4544)  acc5: 96.8750 (96.6270)  time: 0.2733  data: 0.0346  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0541 (0.9840)  acc1: 69.7917 (73.2863)  acc5: 95.8333 (96.2702)  time: 0.2418  data: 0.0055  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0234 (0.9735)  acc1: 71.8750 (73.7834)  acc5: 95.8333 (96.3312)  time: 0.2328  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3741 s / it)\n",
            "* Acc@1 73.783 Acc@5 96.331 loss 0.973\n",
            "Accuracy of the model on the 3925 test images: 73.8%\n",
            "Max accuracy: 73.78%\n",
            "Test:  [ 0/41]  eta: 0:02:54  loss: 4.7250 (4.7250)  acc1: 39.5833 (39.5833)  acc5: 65.6250 (65.6250)  time: 4.2533  data: 3.9749  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 4.6962 (4.8318)  acc1: 30.2083 (26.6098)  acc5: 69.7917 (66.8561)  time: 0.6876  data: 0.4469  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 5.4283 (5.3141)  acc1: 8.3333 (16.9147)  acc5: 52.0833 (54.1667)  time: 0.3279  data: 0.0880  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.8501 (5.3074)  acc1: 2.0833 (15.4906)  acc5: 40.6250 (55.8468)  time: 0.3212  data: 0.0801  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.8974 (5.0222)  acc1: 9.3750 (19.9236)  acc5: 65.6250 (58.9554)  time: 0.2744  data: 0.0393  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.4061 s / it)\n",
            "* Acc@1 19.924 Acc@5 58.955 loss 5.022\n",
            "Accuracy of the model EMA on 3925 test images: 19.9%\n",
            "Max EMA accuracy: 19.92%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [43]  [  0/147]  eta: 0:06:07  lr: 0.000515  min_lr: 0.000515  loss: 2.1826 (2.1826)  weight_decay: 0.0500 (0.0500)  time: 2.4971  data: 1.9240  max mem: 5388\n",
            "Epoch: [43]  [ 10/147]  eta: 0:01:43  lr: 0.000507  min_lr: 0.000507  loss: 2.5297 (2.5564)  weight_decay: 0.0500 (0.0500)  time: 0.7566  data: 0.1764  max mem: 5388\n",
            "Epoch: [43]  [ 20/147]  eta: 0:01:21  lr: 0.000495  min_lr: 0.000495  loss: 2.5297 (2.5253)  weight_decay: 0.0500 (0.0500)  time: 0.5473  data: 0.0017  max mem: 5388\n",
            "Epoch: [43]  [ 30/147]  eta: 0:01:10  lr: 0.000488  min_lr: 0.000488  loss: 2.5024 (2.5076)  weight_decay: 0.0500 (0.0500)  time: 0.5122  data: 0.0020  max mem: 5388\n",
            "Epoch: [43]  [ 40/147]  eta: 0:01:02  lr: 0.000476  min_lr: 0.000476  loss: 2.4673 (2.4988)  weight_decay: 0.0500 (0.0500)  time: 0.5180  data: 0.0013  max mem: 5388\n",
            "Epoch: [43]  [ 50/147]  eta: 0:00:55  lr: 0.000469  min_lr: 0.000469  loss: 2.6235 (2.5187)  weight_decay: 0.0500 (0.0500)  time: 0.5175  data: 0.0011  max mem: 5388\n",
            "Epoch: [43]  [ 60/147]  eta: 0:00:48  lr: 0.000458  min_lr: 0.000458  loss: 2.6328 (2.5336)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0016  max mem: 5388\n",
            "Epoch: [43]  [ 70/147]  eta: 0:00:42  lr: 0.000450  min_lr: 0.000450  loss: 2.6060 (2.5320)  weight_decay: 0.0500 (0.0500)  time: 0.5053  data: 0.0027  max mem: 5388\n",
            "Epoch: [43]  [ 80/147]  eta: 0:00:36  lr: 0.000439  min_lr: 0.000439  loss: 2.6114 (2.5429)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0031  max mem: 5388\n",
            "Epoch: [43]  [ 90/147]  eta: 0:00:30  lr: 0.000432  min_lr: 0.000432  loss: 2.6116 (2.5413)  weight_decay: 0.0500 (0.0500)  time: 0.5015  data: 0.0021  max mem: 5388\n",
            "Epoch: [43]  [100/147]  eta: 0:00:25  lr: 0.000421  min_lr: 0.000421  loss: 2.4521 (2.5410)  weight_decay: 0.0500 (0.0500)  time: 0.4980  data: 0.0016  max mem: 5388\n",
            "Epoch: [43]  [110/147]  eta: 0:00:19  lr: 0.000414  min_lr: 0.000414  loss: 2.5722 (2.5462)  weight_decay: 0.0500 (0.0500)  time: 0.5031  data: 0.0016  max mem: 5388\n",
            "Epoch: [43]  [120/147]  eta: 0:00:14  lr: 0.000404  min_lr: 0.000404  loss: 2.5618 (2.5421)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0023  max mem: 5388\n",
            "Epoch: [43]  [130/147]  eta: 0:00:08  lr: 0.000397  min_lr: 0.000397  loss: 2.5236 (2.5434)  weight_decay: 0.0500 (0.0500)  time: 0.4926  data: 0.0019  max mem: 5388\n",
            "Epoch: [43]  [140/147]  eta: 0:00:03  lr: 0.000386  min_lr: 0.000386  loss: 2.5754 (2.5429)  weight_decay: 0.0500 (0.0500)  time: 0.4933  data: 0.0007  max mem: 5388\n",
            "Epoch: [43]  [146/147]  eta: 0:00:00  lr: 0.000386  min_lr: 0.000386  loss: 2.6107 (2.5402)  weight_decay: 0.0500 (0.0500)  time: 0.4210  data: 0.0002  max mem: 5388\n",
            "Epoch: [43] Total time: 0:01:15 (0.5156 s / it)\n",
            "Averaged stats: lr: 0.000386  min_lr: 0.000386  loss: 2.6107 (2.5402)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:19  loss: 0.5203 (0.5203)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 3.4008  data: 3.0898  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 0.6554 (0.6901)  acc1: 85.4167 (85.0379)  acc5: 97.9167 (97.9167)  time: 0.5279  data: 0.2827  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.7814 (0.9081)  acc1: 81.2500 (76.9345)  acc5: 96.8750 (97.2222)  time: 0.2398  data: 0.0023  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 0.9252 (0.9335)  acc1: 75.0000 (75.9745)  acc5: 96.8750 (96.9758)  time: 0.2445  data: 0.0014  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9636 (0.9436)  acc1: 74.1176 (75.4140)  acc5: 96.8750 (96.7643)  time: 0.2398  data: 0.0002  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3302 s / it)\n",
            "* Acc@1 75.414 Acc@5 96.764 loss 0.944\n",
            "Accuracy of the model on the 3925 test images: 75.4%\n",
            "Max accuracy: 75.41%\n",
            "Test:  [ 0/41]  eta: 0:01:58  loss: 4.6529 (4.6529)  acc1: 40.6250 (40.6250)  acc5: 65.6250 (65.6250)  time: 2.8862  data: 2.5732  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:14  loss: 4.6298 (4.7763)  acc1: 30.2083 (26.8939)  acc5: 69.7917 (67.9924)  time: 0.4825  data: 0.2367  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:07  loss: 5.3832 (5.2722)  acc1: 7.2917 (17.0635)  acc5: 53.1250 (55.3075)  time: 0.2439  data: 0.0031  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.8321 (5.2714)  acc1: 2.0833 (15.6250)  acc5: 40.6250 (56.7204)  time: 0.2424  data: 0.0027  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.8379 (4.9810)  acc1: 9.3750 (20.1019)  acc5: 65.6250 (59.7962)  time: 0.2367  data: 0.0012  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3184 s / it)\n",
            "* Acc@1 20.102 Acc@5 59.796 loss 4.981\n",
            "Accuracy of the model EMA on 3925 test images: 20.1%\n",
            "Max EMA accuracy: 20.10%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [44]  [  0/147]  eta: 0:07:29  lr: 0.000383  min_lr: 0.000383  loss: 2.6818 (2.6818)  weight_decay: 0.0500 (0.0500)  time: 3.0560  data: 2.4864  max mem: 5388\n",
            "Epoch: [44]  [ 10/147]  eta: 0:01:41  lr: 0.000376  min_lr: 0.000376  loss: 2.6514 (2.5833)  weight_decay: 0.0500 (0.0500)  time: 0.7410  data: 0.2275  max mem: 5388\n",
            "Epoch: [44]  [ 20/147]  eta: 0:01:20  lr: 0.000366  min_lr: 0.000366  loss: 2.6514 (2.6100)  weight_decay: 0.0500 (0.0500)  time: 0.5094  data: 0.0012  max mem: 5388\n",
            "Epoch: [44]  [ 30/147]  eta: 0:01:09  lr: 0.000359  min_lr: 0.000359  loss: 2.6330 (2.5968)  weight_decay: 0.0500 (0.0500)  time: 0.5115  data: 0.0015  max mem: 5388\n",
            "Epoch: [44]  [ 40/147]  eta: 0:01:01  lr: 0.000349  min_lr: 0.000349  loss: 2.6046 (2.6137)  weight_decay: 0.0500 (0.0500)  time: 0.5089  data: 0.0017  max mem: 5388\n",
            "Epoch: [44]  [ 50/147]  eta: 0:00:54  lr: 0.000343  min_lr: 0.000343  loss: 2.6001 (2.5814)  weight_decay: 0.0500 (0.0500)  time: 0.5090  data: 0.0010  max mem: 5388\n",
            "Epoch: [44]  [ 60/147]  eta: 0:00:48  lr: 0.000333  min_lr: 0.000333  loss: 2.4244 (2.5721)  weight_decay: 0.0500 (0.0500)  time: 0.5152  data: 0.0016  max mem: 5388\n",
            "Epoch: [44]  [ 70/147]  eta: 0:00:42  lr: 0.000327  min_lr: 0.000327  loss: 2.5458 (2.5632)  weight_decay: 0.0500 (0.0500)  time: 0.5102  data: 0.0022  max mem: 5388\n",
            "Epoch: [44]  [ 80/147]  eta: 0:00:36  lr: 0.000317  min_lr: 0.000317  loss: 2.5458 (2.5593)  weight_decay: 0.0500 (0.0500)  time: 0.5013  data: 0.0025  max mem: 5388\n",
            "Epoch: [44]  [ 90/147]  eta: 0:00:30  lr: 0.000311  min_lr: 0.000311  loss: 2.5134 (2.5432)  weight_decay: 0.0500 (0.0500)  time: 0.4991  data: 0.0029  max mem: 5388\n",
            "Epoch: [44]  [100/147]  eta: 0:00:25  lr: 0.000302  min_lr: 0.000302  loss: 2.5122 (2.5431)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0022  max mem: 5388\n",
            "Epoch: [44]  [110/147]  eta: 0:00:19  lr: 0.000296  min_lr: 0.000296  loss: 2.5679 (2.5492)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0031  max mem: 5388\n",
            "Epoch: [44]  [120/147]  eta: 0:00:14  lr: 0.000287  min_lr: 0.000287  loss: 2.5811 (2.5504)  weight_decay: 0.0500 (0.0500)  time: 0.4992  data: 0.0034  max mem: 5388\n",
            "Epoch: [44]  [130/147]  eta: 0:00:08  lr: 0.000281  min_lr: 0.000281  loss: 2.5811 (2.5536)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0021  max mem: 5388\n",
            "Epoch: [44]  [140/147]  eta: 0:00:03  lr: 0.000272  min_lr: 0.000272  loss: 2.5271 (2.5498)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0010  max mem: 5388\n",
            "Epoch: [44]  [146/147]  eta: 0:00:00  lr: 0.000272  min_lr: 0.000272  loss: 2.5271 (2.5521)  weight_decay: 0.0500 (0.0500)  time: 0.4239  data: 0.0002  max mem: 5388\n",
            "Epoch: [44] Total time: 0:01:15 (0.5150 s / it)\n",
            "Averaged stats: lr: 0.000272  min_lr: 0.000272  loss: 2.5271 (2.5521)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:49  loss: 0.6265 (0.6265)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 4.1343  data: 3.8156  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.7850 (0.7758)  acc1: 84.3750 (83.7121)  acc5: 96.8750 (97.2538)  time: 0.6852  data: 0.4287  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.7957 (0.9684)  acc1: 82.2917 (75.1488)  acc5: 96.8750 (96.9742)  time: 0.3093  data: 0.0583  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8828 (0.9610)  acc1: 76.0417 (75.2688)  acc5: 96.8750 (96.8078)  time: 0.2566  data: 0.0133  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9476 (0.9469)  acc1: 76.0417 (75.4650)  acc5: 96.8750 (96.8153)  time: 0.2320  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3732 s / it)\n",
            "* Acc@1 75.465 Acc@5 96.815 loss 0.947\n",
            "Accuracy of the model on the 3925 test images: 75.5%\n",
            "Max accuracy: 75.46%\n",
            "Test:  [ 0/41]  eta: 0:01:56  loss: 4.5855 (4.5855)  acc1: 42.7083 (42.7083)  acc5: 67.7083 (67.7083)  time: 2.8403  data: 2.5535  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 4.5682 (4.7239)  acc1: 30.2083 (27.0833)  acc5: 70.8333 (68.7500)  time: 0.5181  data: 0.2760  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 5.3387 (5.2323)  acc1: 8.3333 (17.3115)  acc5: 54.1667 (56.1012)  time: 0.3164  data: 0.0760  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.8134 (5.2377)  acc1: 2.0833 (15.7930)  acc5: 40.6250 (57.2917)  time: 0.3099  data: 0.0658  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.7789 (4.9419)  acc1: 9.3750 (20.4586)  acc5: 66.6667 (60.3822)  time: 0.2553  data: 0.0169  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3574 s / it)\n",
            "* Acc@1 20.459 Acc@5 60.382 loss 4.942\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "Max EMA accuracy: 20.46%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [45]  [  0/147]  eta: 0:07:43  lr: 0.000269  min_lr: 0.000269  loss: 2.4639 (2.4639)  weight_decay: 0.0500 (0.0500)  time: 3.1553  data: 2.5861  max mem: 5388\n",
            "Epoch: [45]  [ 10/147]  eta: 0:01:43  lr: 0.000263  min_lr: 0.000263  loss: 2.4135 (2.3468)  weight_decay: 0.0500 (0.0500)  time: 0.7550  data: 0.2383  max mem: 5388\n",
            "Epoch: [45]  [ 20/147]  eta: 0:01:21  lr: 0.000255  min_lr: 0.000255  loss: 2.4294 (2.4661)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0033  max mem: 5388\n",
            "Epoch: [45]  [ 30/147]  eta: 0:01:09  lr: 0.000249  min_lr: 0.000249  loss: 2.5489 (2.4860)  weight_decay: 0.0500 (0.0500)  time: 0.5111  data: 0.0032  max mem: 5388\n",
            "Epoch: [45]  [ 40/147]  eta: 0:01:01  lr: 0.000241  min_lr: 0.000241  loss: 2.4978 (2.4832)  weight_decay: 0.0500 (0.0500)  time: 0.5097  data: 0.0028  max mem: 5388\n",
            "Epoch: [45]  [ 50/147]  eta: 0:00:54  lr: 0.000235  min_lr: 0.000235  loss: 2.4978 (2.4970)  weight_decay: 0.0500 (0.0500)  time: 0.5141  data: 0.0017  max mem: 5388\n",
            "Epoch: [45]  [ 60/147]  eta: 0:00:48  lr: 0.000227  min_lr: 0.000227  loss: 2.4854 (2.4854)  weight_decay: 0.0500 (0.0500)  time: 0.5100  data: 0.0009  max mem: 5388\n",
            "Epoch: [45]  [ 70/147]  eta: 0:00:42  lr: 0.000222  min_lr: 0.000222  loss: 2.4854 (2.4976)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0007  max mem: 5388\n",
            "Epoch: [45]  [ 80/147]  eta: 0:00:36  lr: 0.000214  min_lr: 0.000214  loss: 2.6348 (2.5160)  weight_decay: 0.0500 (0.0500)  time: 0.5068  data: 0.0032  max mem: 5388\n",
            "Epoch: [45]  [ 90/147]  eta: 0:00:30  lr: 0.000208  min_lr: 0.000208  loss: 2.6179 (2.5148)  weight_decay: 0.0500 (0.0500)  time: 0.5072  data: 0.0048  max mem: 5388\n",
            "Epoch: [45]  [100/147]  eta: 0:00:25  lr: 0.000201  min_lr: 0.000201  loss: 2.5496 (2.5233)  weight_decay: 0.0500 (0.0500)  time: 0.4997  data: 0.0031  max mem: 5388\n",
            "Epoch: [45]  [110/147]  eta: 0:00:19  lr: 0.000196  min_lr: 0.000196  loss: 2.6025 (2.5146)  weight_decay: 0.0500 (0.0500)  time: 0.5064  data: 0.0033  max mem: 5388\n",
            "Epoch: [45]  [120/147]  eta: 0:00:14  lr: 0.000188  min_lr: 0.000188  loss: 2.3245 (2.5055)  weight_decay: 0.0500 (0.0500)  time: 0.5163  data: 0.0052  max mem: 5388\n",
            "Epoch: [45]  [130/147]  eta: 0:00:08  lr: 0.000183  min_lr: 0.000183  loss: 2.5698 (2.5053)  weight_decay: 0.0500 (0.0500)  time: 0.5059  data: 0.0037  max mem: 5388\n",
            "Epoch: [45]  [140/147]  eta: 0:00:03  lr: 0.000176  min_lr: 0.000176  loss: 2.5756 (2.5059)  weight_decay: 0.0500 (0.0500)  time: 0.4925  data: 0.0008  max mem: 5388\n",
            "Epoch: [45]  [146/147]  eta: 0:00:00  lr: 0.000176  min_lr: 0.000176  loss: 2.5756 (2.5054)  weight_decay: 0.0500 (0.0500)  time: 0.4185  data: 0.0002  max mem: 5388\n",
            "Epoch: [45] Total time: 0:01:16 (0.5189 s / it)\n",
            "Averaged stats: lr: 0.000176  min_lr: 0.000176  loss: 2.5756 (2.5054)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:03  loss: 0.4841 (0.4841)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 4.4716  data: 4.1937  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 0.6752 (0.6841)  acc1: 85.4167 (85.2273)  acc5: 97.9167 (97.3485)  time: 0.6204  data: 0.3849  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.7787 (0.9091)  acc1: 81.2500 (76.1409)  acc5: 96.8750 (96.8750)  time: 0.2343  data: 0.0030  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8865 (0.9240)  acc1: 77.0833 (75.9409)  acc5: 96.8750 (96.9758)  time: 0.2335  data: 0.0011  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9325 (0.9197)  acc1: 76.0417 (75.8217)  acc5: 96.8750 (96.9427)  time: 0.2309  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3479 s / it)\n",
            "* Acc@1 75.822 Acc@5 96.943 loss 0.920\n",
            "Accuracy of the model on the 3925 test images: 75.8%\n",
            "Max accuracy: 75.82%\n",
            "Test:  [ 0/41]  eta: 0:03:00  loss: 4.5207 (4.5207)  acc1: 42.7083 (42.7083)  acc5: 68.7500 (68.7500)  time: 4.3914  data: 4.0754  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 4.5095 (4.6741)  acc1: 30.2083 (27.1780)  acc5: 70.8333 (69.2235)  time: 0.6169  data: 0.3773  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 5.2958 (5.1943)  acc1: 8.3333 (17.3115)  acc5: 54.1667 (56.6964)  time: 0.2402  data: 0.0048  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.7950 (5.2056)  acc1: 2.0833 (15.9274)  acc5: 42.7083 (57.6613)  time: 0.2395  data: 0.0018  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.7205 (4.9049)  acc1: 9.3750 (20.7134)  acc5: 66.6667 (60.7389)  time: 0.2345  data: 0.0008  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3505 s / it)\n",
            "* Acc@1 20.713 Acc@5 60.739 loss 4.905\n",
            "Accuracy of the model EMA on 3925 test images: 20.7%\n",
            "Max EMA accuracy: 20.71%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [46]  [  0/147]  eta: 0:07:59  lr: 0.000174  min_lr: 0.000174  loss: 2.6456 (2.6456)  weight_decay: 0.0500 (0.0500)  time: 3.2628  data: 2.6085  max mem: 5388\n",
            "Epoch: [46]  [ 10/147]  eta: 0:01:52  lr: 0.000169  min_lr: 0.000169  loss: 2.5065 (2.4634)  weight_decay: 0.0500 (0.0500)  time: 0.8232  data: 0.2922  max mem: 5388\n",
            "Epoch: [46]  [ 20/147]  eta: 0:01:25  lr: 0.000162  min_lr: 0.000162  loss: 2.5205 (2.5167)  weight_decay: 0.0500 (0.0500)  time: 0.5445  data: 0.0311  max mem: 5388\n",
            "Epoch: [46]  [ 30/147]  eta: 0:01:13  lr: 0.000158  min_lr: 0.000158  loss: 2.5308 (2.5204)  weight_decay: 0.0500 (0.0500)  time: 0.5144  data: 0.0013  max mem: 5388\n",
            "Epoch: [46]  [ 40/147]  eta: 0:01:03  lr: 0.000151  min_lr: 0.000151  loss: 2.6125 (2.5212)  weight_decay: 0.0500 (0.0500)  time: 0.5173  data: 0.0013  max mem: 5388\n",
            "Epoch: [46]  [ 50/147]  eta: 0:00:56  lr: 0.000147  min_lr: 0.000147  loss: 2.6848 (2.5546)  weight_decay: 0.0500 (0.0500)  time: 0.5124  data: 0.0014  max mem: 5388\n",
            "Epoch: [46]  [ 60/147]  eta: 0:00:49  lr: 0.000140  min_lr: 0.000140  loss: 2.6895 (2.5566)  weight_decay: 0.0500 (0.0500)  time: 0.5106  data: 0.0017  max mem: 5388\n",
            "Epoch: [46]  [ 70/147]  eta: 0:00:43  lr: 0.000136  min_lr: 0.000136  loss: 2.4770 (2.5430)  weight_decay: 0.0500 (0.0500)  time: 0.5085  data: 0.0019  max mem: 5388\n",
            "Epoch: [46]  [ 80/147]  eta: 0:00:37  lr: 0.000130  min_lr: 0.000130  loss: 2.4980 (2.5440)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0029  max mem: 5388\n",
            "Epoch: [46]  [ 90/147]  eta: 0:00:31  lr: 0.000126  min_lr: 0.000126  loss: 2.4806 (2.5275)  weight_decay: 0.0500 (0.0500)  time: 0.5023  data: 0.0048  max mem: 5388\n",
            "Epoch: [46]  [100/147]  eta: 0:00:25  lr: 0.000120  min_lr: 0.000120  loss: 2.3358 (2.5151)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0037  max mem: 5388\n",
            "Epoch: [46]  [110/147]  eta: 0:00:19  lr: 0.000116  min_lr: 0.000116  loss: 2.3634 (2.5180)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0019  max mem: 5388\n",
            "Epoch: [46]  [120/147]  eta: 0:00:14  lr: 0.000110  min_lr: 0.000110  loss: 2.6224 (2.5259)  weight_decay: 0.0500 (0.0500)  time: 0.4969  data: 0.0028  max mem: 5388\n",
            "Epoch: [46]  [130/147]  eta: 0:00:09  lr: 0.000106  min_lr: 0.000106  loss: 2.5801 (2.5305)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0023  max mem: 5388\n",
            "Epoch: [46]  [140/147]  eta: 0:00:03  lr: 0.000101  min_lr: 0.000101  loss: 2.6985 (2.5377)  weight_decay: 0.0500 (0.0500)  time: 0.4973  data: 0.0007  max mem: 5388\n",
            "Epoch: [46]  [146/147]  eta: 0:00:00  lr: 0.000101  min_lr: 0.000101  loss: 2.6985 (2.5377)  weight_decay: 0.0500 (0.0500)  time: 0.4185  data: 0.0002  max mem: 5388\n",
            "Epoch: [46] Total time: 0:01:16 (0.5208 s / it)\n",
            "Averaged stats: lr: 0.000101  min_lr: 0.000101  loss: 2.6985 (2.5377)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:47  loss: 0.4741 (0.4741)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 4.0761  data: 3.7706  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.6919 (0.6839)  acc1: 85.4167 (85.2273)  acc5: 97.9167 (97.6326)  time: 0.6933  data: 0.4540  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.7643 (0.8961)  acc1: 81.2500 (76.7857)  acc5: 96.8750 (97.4206)  time: 0.3296  data: 0.0929  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9121 (0.9075)  acc1: 78.1250 (76.8481)  acc5: 96.8750 (97.1438)  time: 0.3201  data: 0.0823  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9142 (0.9184)  acc1: 73.9583 (76.0764)  acc5: 96.8750 (97.0191)  time: 0.2838  data: 0.0506  max mem: 5388\n",
            "Test: Total time: 0:00:16 (0.4110 s / it)\n",
            "* Acc@1 76.076 Acc@5 97.019 loss 0.918\n",
            "Accuracy of the model on the 3925 test images: 76.1%\n",
            "Max accuracy: 76.08%\n",
            "Test:  [ 0/41]  eta: 0:02:06  loss: 4.4596 (4.4596)  acc1: 41.6667 (41.6667)  acc5: 68.7500 (68.7500)  time: 3.0914  data: 2.8226  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 4.4545 (4.6271)  acc1: 30.2083 (27.1780)  acc5: 70.8333 (69.2235)  time: 0.5379  data: 0.2905  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 5.2549 (5.1582)  acc1: 9.3750 (17.2619)  acc5: 55.2083 (57.0437)  time: 0.3025  data: 0.0588  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.7765 (5.1755)  acc1: 2.0833 (15.8602)  acc5: 43.7500 (57.9637)  time: 0.3162  data: 0.0763  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6974 (4.8698)  acc1: 9.3750 (20.6115)  acc5: 69.7917 (61.1465)  time: 0.2715  data: 0.0361  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3656 s / it)\n",
            "* Acc@1 20.611 Acc@5 61.146 loss 4.870\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [47]  [  0/147]  eta: 0:05:35  lr: 0.000099  min_lr: 0.000099  loss: 2.4949 (2.4949)  weight_decay: 0.0500 (0.0500)  time: 2.2835  data: 1.6812  max mem: 5388\n",
            "Epoch: [47]  [ 10/147]  eta: 0:01:33  lr: 0.000095  min_lr: 0.000095  loss: 2.6849 (2.5535)  weight_decay: 0.0500 (0.0500)  time: 0.6836  data: 0.1535  max mem: 5388\n",
            "Epoch: [47]  [ 20/147]  eta: 0:01:17  lr: 0.000090  min_lr: 0.000090  loss: 2.6923 (2.5916)  weight_decay: 0.0500 (0.0500)  time: 0.5246  data: 0.0018  max mem: 5388\n",
            "Epoch: [47]  [ 30/147]  eta: 0:01:07  lr: 0.000087  min_lr: 0.000087  loss: 2.5705 (2.5475)  weight_decay: 0.0500 (0.0500)  time: 0.5196  data: 0.0019  max mem: 5388\n",
            "Epoch: [47]  [ 40/147]  eta: 0:01:00  lr: 0.000082  min_lr: 0.000082  loss: 2.5462 (2.5516)  weight_decay: 0.0500 (0.0500)  time: 0.5129  data: 0.0010  max mem: 5388\n",
            "Epoch: [47]  [ 50/147]  eta: 0:00:53  lr: 0.000078  min_lr: 0.000078  loss: 2.5267 (2.5345)  weight_decay: 0.0500 (0.0500)  time: 0.5155  data: 0.0006  max mem: 5388\n",
            "Epoch: [47]  [ 60/147]  eta: 0:00:47  lr: 0.000074  min_lr: 0.000074  loss: 2.5066 (2.5350)  weight_decay: 0.0500 (0.0500)  time: 0.5120  data: 0.0008  max mem: 5388\n",
            "Epoch: [47]  [ 70/147]  eta: 0:00:41  lr: 0.000071  min_lr: 0.000071  loss: 2.3955 (2.5191)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0016  max mem: 5388\n",
            "Epoch: [47]  [ 80/147]  eta: 0:00:35  lr: 0.000066  min_lr: 0.000066  loss: 2.5535 (2.5281)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.0027  max mem: 5388\n",
            "Epoch: [47]  [ 90/147]  eta: 0:00:30  lr: 0.000063  min_lr: 0.000063  loss: 2.6603 (2.5362)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0037  max mem: 5388\n",
            "Epoch: [47]  [100/147]  eta: 0:00:24  lr: 0.000059  min_lr: 0.000059  loss: 2.6108 (2.5421)  weight_decay: 0.0500 (0.0500)  time: 0.4989  data: 0.0029  max mem: 5388\n",
            "Epoch: [47]  [110/147]  eta: 0:00:19  lr: 0.000056  min_lr: 0.000056  loss: 2.5920 (2.5401)  weight_decay: 0.0500 (0.0500)  time: 0.4973  data: 0.0021  max mem: 5388\n",
            "Epoch: [47]  [120/147]  eta: 0:00:14  lr: 0.000052  min_lr: 0.000052  loss: 2.4189 (2.5312)  weight_decay: 0.0500 (0.0500)  time: 0.5043  data: 0.0032  max mem: 5388\n",
            "Epoch: [47]  [130/147]  eta: 0:00:08  lr: 0.000050  min_lr: 0.000050  loss: 2.5048 (2.5350)  weight_decay: 0.0500 (0.0500)  time: 0.5007  data: 0.0027  max mem: 5388\n",
            "Epoch: [47]  [140/147]  eta: 0:00:03  lr: 0.000046  min_lr: 0.000046  loss: 2.5961 (2.5398)  weight_decay: 0.0500 (0.0500)  time: 0.4924  data: 0.0007  max mem: 5388\n",
            "Epoch: [47]  [146/147]  eta: 0:00:00  lr: 0.000046  min_lr: 0.000046  loss: 2.5931 (2.5382)  weight_decay: 0.0500 (0.0500)  time: 0.4196  data: 0.0002  max mem: 5388\n",
            "Epoch: [47] Total time: 0:01:15 (0.5129 s / it)\n",
            "Averaged stats: lr: 0.000046  min_lr: 0.000046  loss: 2.5931 (2.5382)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:13  loss: 0.5302 (0.5302)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 3.2554  data: 2.9935  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 0.6960 (0.7171)  acc1: 84.3750 (84.2803)  acc5: 97.9167 (97.4432)  time: 0.5139  data: 0.2811  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.7698 (0.9099)  acc1: 82.2917 (76.4385)  acc5: 96.8750 (97.1230)  time: 0.2389  data: 0.0060  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 0.8804 (0.9192)  acc1: 77.0833 (76.4113)  acc5: 96.8750 (97.1102)  time: 0.2387  data: 0.0012  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9330 (0.9197)  acc1: 77.0833 (76.2293)  acc5: 96.8750 (97.0701)  time: 0.2343  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:13 (0.3231 s / it)\n",
            "* Acc@1 76.229 Acc@5 97.070 loss 0.920\n",
            "Accuracy of the model on the 3925 test images: 76.2%\n",
            "Max accuracy: 76.23%\n",
            "Test:  [ 0/41]  eta: 0:02:59  loss: 4.4014 (4.4014)  acc1: 41.6667 (41.6667)  acc5: 69.7917 (69.7917)  time: 4.3777  data: 4.0901  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 4.4014 (4.5821)  acc1: 30.2083 (27.0833)  acc5: 70.8333 (69.7917)  time: 0.6228  data: 0.3736  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 5.2156 (5.1236)  acc1: 9.3750 (17.2619)  acc5: 55.2083 (57.5893)  time: 0.2430  data: 0.0028  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.7578 (5.1470)  acc1: 2.0833 (15.9274)  acc5: 43.7500 (58.4341)  time: 0.2361  data: 0.0020  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6928 (4.8366)  acc1: 9.3750 (20.7898)  acc5: 71.8750 (61.6051)  time: 0.2325  data: 0.0003  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3524 s / it)\n",
            "* Acc@1 20.790 Acc@5 61.605 loss 4.837\n",
            "Accuracy of the model EMA on 3925 test images: 20.8%\n",
            "Max EMA accuracy: 20.79%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [48]  [  0/147]  eta: 0:08:34  lr: 0.000045  min_lr: 0.000045  loss: 2.6361 (2.6361)  weight_decay: 0.0500 (0.0500)  time: 3.5015  data: 2.9151  max mem: 5388\n",
            "Epoch: [48]  [ 10/147]  eta: 0:01:49  lr: 0.000042  min_lr: 0.000042  loss: 2.5976 (2.4940)  weight_decay: 0.0500 (0.0500)  time: 0.7967  data: 0.2686  max mem: 5388\n",
            "Epoch: [48]  [ 20/147]  eta: 0:01:24  lr: 0.000039  min_lr: 0.000039  loss: 2.4685 (2.4939)  weight_decay: 0.0500 (0.0500)  time: 0.5248  data: 0.0040  max mem: 5388\n",
            "Epoch: [48]  [ 30/147]  eta: 0:01:12  lr: 0.000037  min_lr: 0.000037  loss: 2.5475 (2.5098)  weight_decay: 0.0500 (0.0500)  time: 0.5242  data: 0.0030  max mem: 5388\n",
            "Epoch: [48]  [ 40/147]  eta: 0:01:03  lr: 0.000033  min_lr: 0.000033  loss: 2.6217 (2.5294)  weight_decay: 0.0500 (0.0500)  time: 0.5224  data: 0.0031  max mem: 5388\n",
            "Epoch: [48]  [ 50/147]  eta: 0:00:56  lr: 0.000031  min_lr: 0.000031  loss: 2.6217 (2.5351)  weight_decay: 0.0500 (0.0500)  time: 0.5138  data: 0.0029  max mem: 5388\n",
            "Epoch: [48]  [ 60/147]  eta: 0:00:49  lr: 0.000028  min_lr: 0.000028  loss: 2.5870 (2.5372)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0022  max mem: 5388\n",
            "Epoch: [48]  [ 70/147]  eta: 0:00:43  lr: 0.000027  min_lr: 0.000027  loss: 2.5822 (2.5354)  weight_decay: 0.0500 (0.0500)  time: 0.5090  data: 0.0027  max mem: 5388\n",
            "Epoch: [48]  [ 80/147]  eta: 0:00:36  lr: 0.000024  min_lr: 0.000024  loss: 2.4779 (2.5251)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0018  max mem: 5388\n",
            "Epoch: [48]  [ 90/147]  eta: 0:00:31  lr: 0.000022  min_lr: 0.000022  loss: 2.4582 (2.5219)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0012  max mem: 5388\n",
            "Epoch: [48]  [100/147]  eta: 0:00:25  lr: 0.000020  min_lr: 0.000020  loss: 2.4538 (2.5151)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0016  max mem: 5388\n",
            "Epoch: [48]  [110/147]  eta: 0:00:19  lr: 0.000018  min_lr: 0.000018  loss: 2.5794 (2.5246)  weight_decay: 0.0500 (0.0500)  time: 0.4980  data: 0.0017  max mem: 5388\n",
            "Epoch: [48]  [120/147]  eta: 0:00:14  lr: 0.000016  min_lr: 0.000016  loss: 2.5818 (2.5198)  weight_decay: 0.0500 (0.0500)  time: 0.4952  data: 0.0034  max mem: 5388\n",
            "Epoch: [48]  [130/147]  eta: 0:00:09  lr: 0.000015  min_lr: 0.000015  loss: 2.5177 (2.5178)  weight_decay: 0.0500 (0.0500)  time: 0.4991  data: 0.0026  max mem: 5388\n",
            "Epoch: [48]  [140/147]  eta: 0:00:03  lr: 0.000013  min_lr: 0.000013  loss: 2.5008 (2.5177)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0002  max mem: 5388\n",
            "Epoch: [48]  [146/147]  eta: 0:00:00  lr: 0.000013  min_lr: 0.000013  loss: 2.5306 (2.5171)  weight_decay: 0.0500 (0.0500)  time: 0.4189  data: 0.0002  max mem: 5388\n",
            "Epoch: [48] Total time: 0:01:16 (0.5198 s / it)\n",
            "Averaged stats: lr: 0.000013  min_lr: 0.000013  loss: 2.5306 (2.5171)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 0.5172 (0.5172)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 3.4950  data: 3.1400  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 0.6824 (0.6927)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.6326)  time: 0.6304  data: 0.3764  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.7423 (0.9000)  acc1: 82.2917 (77.0337)  acc5: 96.8750 (97.3710)  time: 0.3183  data: 0.0726  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8706 (0.9129)  acc1: 78.1250 (76.7809)  acc5: 96.8750 (97.1774)  time: 0.2936  data: 0.0538  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9198 (0.9148)  acc1: 77.0833 (76.4331)  acc5: 95.8333 (97.0955)  time: 0.2619  data: 0.0313  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3761 s / it)\n",
            "* Acc@1 76.433 Acc@5 97.096 loss 0.915\n",
            "Accuracy of the model on the 3925 test images: 76.4%\n",
            "Max accuracy: 76.43%\n",
            "Test:  [ 0/41]  eta: 0:02:07  loss: 4.3461 (4.3461)  acc1: 41.6667 (41.6667)  acc5: 69.7917 (69.7917)  time: 3.1073  data: 2.7963  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 4.3461 (4.5392)  acc1: 30.2083 (26.7992)  acc5: 70.8333 (70.2652)  time: 0.5958  data: 0.3567  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 5.1782 (5.0906)  acc1: 9.3750 (17.2123)  acc5: 57.2917 (58.4325)  time: 0.3197  data: 0.0824  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.7393 (5.1202)  acc1: 2.0833 (15.9274)  acc5: 45.8333 (58.8710)  time: 0.2728  data: 0.0342  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6897 (4.8052)  acc1: 10.4167 (20.8662)  acc5: 72.9167 (62.0127)  time: 0.2455  data: 0.0120  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3612 s / it)\n",
            "* Acc@1 20.866 Acc@5 62.013 loss 4.805\n",
            "Accuracy of the model EMA on 3925 test images: 20.9%\n",
            "Max EMA accuracy: 20.87%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [49]  [  0/147]  eta: 0:04:35  lr: 0.000012  min_lr: 0.000012  loss: 2.3917 (2.3917)  weight_decay: 0.0500 (0.0500)  time: 1.8758  data: 1.3102  max mem: 5388\n",
            "Epoch: [49]  [ 10/147]  eta: 0:01:38  lr: 0.000011  min_lr: 0.000011  loss: 2.4904 (2.5111)  weight_decay: 0.0500 (0.0500)  time: 0.7209  data: 0.1826  max mem: 5388\n",
            "Epoch: [49]  [ 20/147]  eta: 0:01:19  lr: 0.000009  min_lr: 0.000009  loss: 2.4904 (2.5018)  weight_decay: 0.0500 (0.0500)  time: 0.5643  data: 0.0361  max mem: 5388\n",
            "Epoch: [49]  [ 30/147]  eta: 0:01:09  lr: 0.000008  min_lr: 0.000008  loss: 2.5870 (2.5312)  weight_decay: 0.0500 (0.0500)  time: 0.5178  data: 0.0020  max mem: 5388\n",
            "Epoch: [49]  [ 40/147]  eta: 0:01:01  lr: 0.000007  min_lr: 0.000007  loss: 2.5794 (2.5229)  weight_decay: 0.0500 (0.0500)  time: 0.5144  data: 0.0020  max mem: 5388\n",
            "Epoch: [49]  [ 50/147]  eta: 0:00:54  lr: 0.000006  min_lr: 0.000006  loss: 2.5499 (2.5104)  weight_decay: 0.0500 (0.0500)  time: 0.5144  data: 0.0012  max mem: 5388\n",
            "Epoch: [49]  [ 60/147]  eta: 0:00:47  lr: 0.000005  min_lr: 0.000005  loss: 2.5625 (2.5148)  weight_decay: 0.0500 (0.0500)  time: 0.5088  data: 0.0011  max mem: 5388\n",
            "Epoch: [49]  [ 70/147]  eta: 0:00:41  lr: 0.000004  min_lr: 0.000004  loss: 2.4963 (2.5111)  weight_decay: 0.0500 (0.0500)  time: 0.5036  data: 0.0017  max mem: 5388\n",
            "Epoch: [49]  [ 80/147]  eta: 0:00:36  lr: 0.000003  min_lr: 0.000003  loss: 2.4331 (2.5138)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0029  max mem: 5388\n",
            "Epoch: [49]  [ 90/147]  eta: 0:00:30  lr: 0.000003  min_lr: 0.000003  loss: 2.6397 (2.5274)  weight_decay: 0.0500 (0.0500)  time: 0.5195  data: 0.0041  max mem: 5388\n",
            "Epoch: [49]  [100/147]  eta: 0:00:25  lr: 0.000002  min_lr: 0.000002  loss: 2.6368 (2.5215)  weight_decay: 0.0500 (0.0500)  time: 0.5097  data: 0.0026  max mem: 5388\n",
            "Epoch: [49]  [110/147]  eta: 0:00:19  lr: 0.000002  min_lr: 0.000002  loss: 2.4675 (2.5180)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0010  max mem: 5388\n",
            "Epoch: [49]  [120/147]  eta: 0:00:14  lr: 0.000001  min_lr: 0.000001  loss: 2.5782 (2.5222)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0009  max mem: 5388\n",
            "Epoch: [49]  [130/147]  eta: 0:00:08  lr: 0.000001  min_lr: 0.000001  loss: 2.6011 (2.5227)  weight_decay: 0.0500 (0.0500)  time: 0.5013  data: 0.0011  max mem: 5388\n",
            "Epoch: [49]  [140/147]  eta: 0:00:03  lr: 0.000001  min_lr: 0.000001  loss: 2.5492 (2.5264)  weight_decay: 0.0500 (0.0500)  time: 0.4947  data: 0.0007  max mem: 5388\n",
            "Epoch: [49]  [146/147]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.5492 (2.5249)  weight_decay: 0.0500 (0.0500)  time: 0.4186  data: 0.0002  max mem: 5388\n",
            "Epoch: [49] Total time: 0:01:15 (0.5156 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.5492 (2.5249)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:25  loss: 0.5173 (0.5173)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 5.0174  data: 4.7261  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.6852 (0.6911)  acc1: 86.4583 (85.7008)  acc5: 97.9167 (97.6326)  time: 0.6716  data: 0.4315  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.7361 (0.8987)  acc1: 82.2917 (77.1329)  acc5: 96.8750 (97.3710)  time: 0.2406  data: 0.0060  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8638 (0.9121)  acc1: 78.1250 (76.8145)  acc5: 96.8750 (97.2110)  time: 0.2416  data: 0.0051  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9194 (0.9142)  acc1: 76.0417 (76.3822)  acc5: 95.8333 (97.0955)  time: 0.2347  data: 0.0001  max mem: 5388\n",
            "Test: Total time: 0:00:14 (0.3642 s / it)\n",
            "* Acc@1 76.382 Acc@5 97.096 loss 0.914\n",
            "Accuracy of the model on the 3925 test images: 76.4%\n",
            "Max accuracy: 76.43%\n",
            "Test:  [ 0/41]  eta: 0:02:39  loss: 4.2933 (4.2933)  acc1: 41.6667 (41.6667)  acc5: 69.7917 (69.7917)  time: 3.8823  data: 3.6108  max mem: 5388\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 4.2933 (4.4983)  acc1: 30.2083 (26.6098)  acc5: 70.8333 (70.5492)  time: 0.6382  data: 0.4017  max mem: 5388\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 5.1426 (5.0590)  acc1: 8.3333 (17.1131)  acc5: 59.3750 (59.1270)  time: 0.3047  data: 0.0689  max mem: 5388\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.7207 (5.0949)  acc1: 2.0833 (15.9274)  acc5: 47.9167 (59.3414)  time: 0.2757  data: 0.0382  max mem: 5388\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6879 (4.7754)  acc1: 10.4167 (20.9427)  acc5: 72.9167 (62.4459)  time: 0.2449  data: 0.0097  max mem: 5388\n",
            "Test: Total time: 0:00:15 (0.3737 s / it)\n",
            "* Acc@1 20.943 Acc@5 62.446 loss 4.775\n",
            "Accuracy of the model EMA on 3925 test images: 20.9%\n",
            "Max EMA accuracy: 20.94%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/result_tiny2)... Done. 13.7s\n",
            "Training time 1:31:34\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▂▂▂▃▃▃▃▄▄▄▄▅▄▅▄▅▅▆▆▆▇▆▆▇▇▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▅▅▆▆▇▇▇▇▇▇▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▁▃▃▄▅▅▅▅▆▆▆▆▇▆▇▆▇▇▇▇▇███████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss █▄▄▃▃▃▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema ███████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss █▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr ▁▂▂▂▃▃▄▄▅▅▅▆▆▇▇▇████▇▇▇▇▆▆▅▅▄▄▄▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr ▁▂▂▂▃▃▄▄▅▅▅▆▆▇▇▇████▇▇▇▇▆▆▅▅▄▄▄▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss █▃▃▃▃▂▂▃▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇█████▇▇▇▆▆▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇█████▇▇▇▆▆▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 76.38217\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema 20.94268\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 97.09554\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema 62.44586\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.91423\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema 4.77539\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 2.52488\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 1799\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 2.42779\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 49\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 28589128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mleafy-night-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/82quyc77\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230305_023906-82quyc77/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python main.py --model convnext_tiny --eval true \\\n",
        "                --resume /content/result_tiny2/checkpoint-best.pth \\\n",
        "                --input_size 160 --drop_path 0.1 \\\n",
        "                --data_path /content/imagenette2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Y3lTCv90Q5",
        "outputId": "49c3c433-6096-4249-89de-638b47614f32"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny2/checkpoint-best.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7f7684b4eb80>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f7684b4e5b0>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f7684b53220>\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 147\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 2940\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny2/checkpoint-best.pth\n",
            "With optim & sched!\n",
            "Eval only mode\n",
            "Test:  [ 0/41]  eta: 0:06:04  loss: 0.5172 (0.5172)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 8.8944  data: 3.8638  max mem: 2077\n",
            "Test:  [10/41]  eta: 0:00:31  loss: 0.6824 (0.6927)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.6326)  time: 1.0187  data: 0.3560  max mem: 2077\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.7423 (0.9000)  acc1: 82.2917 (77.0337)  acc5: 96.8750 (97.3710)  time: 0.2326  data: 0.0061  max mem: 2077\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.8706 (0.9129)  acc1: 78.1250 (76.7809)  acc5: 96.8750 (97.1774)  time: 0.2310  data: 0.0036  max mem: 2077\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9198 (0.9148)  acc1: 77.0833 (76.4331)  acc5: 95.8333 (97.0955)  time: 0.2308  data: 0.0002  max mem: 2077\n",
            "Test: Total time: 0:00:18 (0.4525 s / it)\n",
            "* Acc@1 76.433 Acc@5 97.096 loss 0.915\n",
            "Accuracy of the network on 3925 test images: 76.43312%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/result_tiny2\n",
        "%cd /content/ConvNeXt\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_tiny \\\n",
        "                                    --resume /content/result_tiny2/checkpoint-49.pth\\\n",
        "                                    --epochs 100 \\\n",
        "                                    --start_epoch 50 \\\n",
        "                                    --batch_size 64 \\\n",
        "                                    --lr 4e-3 \\\n",
        "                                    --update_freq 4 \\\n",
        "                                    --model_ema true \\\n",
        "                                    --model_ema_eval true \\\n",
        "                                    --aa original \\\n",
        "                                    --drop_path 0.1 \\\n",
        "                                    --opt adamw \\\n",
        "                                    --train_interpolation bicubic \\\n",
        "                                    --input_size 160 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --nb_classes 10 \\\n",
        "                                    --output_dir /content/result_tiny2 \\\n",
        "                                    --log_dir /content/result_tiny2 \\\n",
        "                                    --enable_wandb true --wandb_ckpt true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T32J56F6-b4t",
        "outputId": "b34c4e7f-68d8-4b19-b51c-d51e05d3d135"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt\n",
            "| distributed init (rank 0): env://, gpu 0\n",
            "Namespace(aa='original', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_backend='nccl', dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=True, drop_path=0.1, enable_wandb=True, epochs=100, eval=False, eval_data_path=None, finetune='', gpu=0, head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=0, log_dir='/content/result_tiny2', lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=True, model_ema_decay=0.9999, model_ema_eval=True, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=10, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/content/result_tiny2', pin_mem=True, project='convnext', rank=0, recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny2/checkpoint-49.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=50, train_interpolation='bicubic', update_freq=4, use_amp=False, wandb_ckpt=True, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.AutoAugment object at 0x7fa03827e7f0>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7fa03820b4f0>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fa0382881f0>\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlolikgiovi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ConvNeXt/wandb/run-20230305_041426-b0irt2b1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhopeful-monkey-20\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/b0irt2b1\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Using EMA with decay = 0.99990000\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 256\n",
            "Update frequent = 4\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 36\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 720\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny2/checkpoint-49.pth\n",
            "With optim & sched!\n",
            "Start training for 100 epochs\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [50]  [  0/147]  eta: 0:17:15  lr: 0.002766  min_lr: 0.002766  loss: 2.7300 (2.7300)  weight_decay: 0.0500 (0.0500)  time: 7.0432  data: 3.7907  max mem: 5608\n",
            "Epoch: [50]  [ 10/147]  eta: 0:02:28  lr: 0.002762  min_lr: 0.002762  loss: 2.6567 (2.6255)  weight_decay: 0.0500 (0.0500)  time: 1.0839  data: 0.3451  max mem: 5608\n",
            "Epoch: [50]  [ 20/147]  eta: 0:01:41  lr: 0.002756  min_lr: 0.002756  loss: 2.6563 (2.6246)  weight_decay: 0.0500 (0.0500)  time: 0.4876  data: 0.0004  max mem: 5608\n",
            "Epoch: [50]  [ 30/147]  eta: 0:01:22  lr: 0.002752  min_lr: 0.002752  loss: 2.6221 (2.6097)  weight_decay: 0.0500 (0.0500)  time: 0.4904  data: 0.0006  max mem: 5608\n",
            "Epoch: [50]  [ 40/147]  eta: 0:01:10  lr: 0.002745  min_lr: 0.002745  loss: 2.6309 (2.6073)  weight_decay: 0.0500 (0.0500)  time: 0.5049  data: 0.0011  max mem: 5608\n",
            "Epoch: [50]  [ 50/147]  eta: 0:01:00  lr: 0.002741  min_lr: 0.002741  loss: 2.5499 (2.5864)  weight_decay: 0.0500 (0.0500)  time: 0.5103  data: 0.0015  max mem: 5608\n",
            "Epoch: [50]  [ 60/147]  eta: 0:00:52  lr: 0.002735  min_lr: 0.002735  loss: 2.6402 (2.5924)  weight_decay: 0.0500 (0.0500)  time: 0.5090  data: 0.0026  max mem: 5608\n",
            "Epoch: [50]  [ 70/147]  eta: 0:00:45  lr: 0.002731  min_lr: 0.002731  loss: 2.6402 (2.5983)  weight_decay: 0.0500 (0.0500)  time: 0.5202  data: 0.0033  max mem: 5608\n",
            "Epoch: [50]  [ 80/147]  eta: 0:00:39  lr: 0.002725  min_lr: 0.002725  loss: 2.5933 (2.5913)  weight_decay: 0.0500 (0.0500)  time: 0.5250  data: 0.0021  max mem: 5608\n",
            "Epoch: [50]  [ 90/147]  eta: 0:00:33  lr: 0.002721  min_lr: 0.002721  loss: 2.5468 (2.5905)  weight_decay: 0.0500 (0.0500)  time: 0.5191  data: 0.0013  max mem: 5608\n",
            "Epoch: [50]  [100/147]  eta: 0:00:26  lr: 0.002715  min_lr: 0.002715  loss: 2.6221 (2.5966)  weight_decay: 0.0500 (0.0500)  time: 0.5180  data: 0.0015  max mem: 5608\n",
            "Epoch: [50]  [110/147]  eta: 0:00:21  lr: 0.002711  min_lr: 0.002711  loss: 2.6700 (2.5989)  weight_decay: 0.0500 (0.0500)  time: 0.5149  data: 0.0023  max mem: 5608\n",
            "Epoch: [50]  [120/147]  eta: 0:00:15  lr: 0.002705  min_lr: 0.002705  loss: 2.6776 (2.6035)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0024  max mem: 5608\n",
            "Epoch: [50]  [130/147]  eta: 0:00:09  lr: 0.002701  min_lr: 0.002701  loss: 2.7153 (2.6105)  weight_decay: 0.0500 (0.0500)  time: 0.4969  data: 0.0021  max mem: 5608\n",
            "Epoch: [50]  [140/147]  eta: 0:00:03  lr: 0.002695  min_lr: 0.002695  loss: 2.5912 (2.6062)  weight_decay: 0.0500 (0.0500)  time: 0.4953  data: 0.0011  max mem: 5608\n",
            "Epoch: [50]  [146/147]  eta: 0:00:00  lr: 0.002695  min_lr: 0.002695  loss: 2.6280 (2.6059)  weight_decay: 0.0500 (0.0500)  time: 0.4205  data: 0.0002  max mem: 5608\n",
            "Epoch: [50] Total time: 0:01:19 (0.5427 s / it)\n",
            "Averaged stats: lr: 0.002695  min_lr: 0.002695  loss: 2.6280 (2.6059)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:44  loss: 0.5020 (0.5020)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 4.0076  data: 3.1723  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 0.8447 (0.8732)  acc1: 80.2083 (78.5038)  acc5: 97.9167 (97.8220)  time: 0.6001  data: 0.2898  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 1.0811 (1.1117)  acc1: 63.5417 (67.8571)  acc5: 97.9167 (97.3710)  time: 0.2541  data: 0.0013  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.3317 (1.1366)  acc1: 62.5000 (68.1116)  acc5: 96.8750 (96.3374)  time: 0.2538  data: 0.0051  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2282 (1.1632)  acc1: 65.6250 (67.7197)  acc5: 93.7500 (95.7197)  time: 0.2477  data: 0.0046  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3525 s / it)\n",
            "* Acc@1 67.720 Acc@5 95.720 loss 1.163\n",
            "Accuracy of the model on the 3925 test images: 67.7%\n",
            "Max accuracy: 67.72%\n",
            "Test:  [ 0/41]  eta: 0:02:07  loss: 4.2448 (4.2448)  acc1: 41.6667 (41.6667)  acc5: 69.7917 (69.7917)  time: 3.1033  data: 2.8324  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 4.2448 (4.4579)  acc1: 29.1667 (26.4205)  acc5: 71.8750 (70.8333)  time: 0.5220  data: 0.2873  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 5.1067 (5.0275)  acc1: 7.2917 (17.1131)  acc5: 59.3750 (59.8214)  time: 0.2508  data: 0.0200  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.6990 (5.0694)  acc1: 2.0833 (16.0282)  acc5: 48.9583 (59.7782)  time: 0.2466  data: 0.0119  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6320 (4.7461)  acc1: 10.4167 (21.0701)  acc5: 72.9167 (62.8790)  time: 0.2497  data: 0.0145  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3332 s / it)\n",
            "* Acc@1 21.070 Acc@5 62.879 loss 4.746\n",
            "Accuracy of the model EMA on 3925 test images: 21.1%\n",
            "Max EMA accuracy: 21.07%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [51]  [  0/147]  eta: 0:12:23  lr: 0.002693  min_lr: 0.002693  loss: 2.7354 (2.7354)  weight_decay: 0.0500 (0.0500)  time: 5.0574  data: 4.1642  max mem: 5608\n",
            "Epoch: [51]  [ 10/147]  eta: 0:02:12  lr: 0.002688  min_lr: 0.002688  loss: 2.7496 (2.6918)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.3821  max mem: 5608\n",
            "Epoch: [51]  [ 20/147]  eta: 0:01:36  lr: 0.002682  min_lr: 0.002682  loss: 2.6790 (2.6506)  weight_decay: 0.0500 (0.0500)  time: 0.5420  data: 0.0025  max mem: 5608\n",
            "Epoch: [51]  [ 30/147]  eta: 0:01:19  lr: 0.002678  min_lr: 0.002678  loss: 2.6043 (2.6216)  weight_decay: 0.0500 (0.0500)  time: 0.5203  data: 0.0014  max mem: 5608\n",
            "Epoch: [51]  [ 40/147]  eta: 0:01:08  lr: 0.002672  min_lr: 0.002672  loss: 2.6043 (2.6127)  weight_decay: 0.0500 (0.0500)  time: 0.5175  data: 0.0013  max mem: 5608\n",
            "Epoch: [51]  [ 50/147]  eta: 0:00:59  lr: 0.002668  min_lr: 0.002668  loss: 2.5156 (2.5914)  weight_decay: 0.0500 (0.0500)  time: 0.5180  data: 0.0012  max mem: 5608\n",
            "Epoch: [51]  [ 60/147]  eta: 0:00:52  lr: 0.002662  min_lr: 0.002662  loss: 2.5668 (2.5903)  weight_decay: 0.0500 (0.0500)  time: 0.5200  data: 0.0027  max mem: 5608\n",
            "Epoch: [51]  [ 70/147]  eta: 0:00:45  lr: 0.002658  min_lr: 0.002658  loss: 2.6431 (2.6087)  weight_decay: 0.0500 (0.0500)  time: 0.5143  data: 0.0026  max mem: 5608\n",
            "Epoch: [51]  [ 80/147]  eta: 0:00:38  lr: 0.002651  min_lr: 0.002651  loss: 2.6514 (2.6028)  weight_decay: 0.0500 (0.0500)  time: 0.5073  data: 0.0018  max mem: 5608\n",
            "Epoch: [51]  [ 90/147]  eta: 0:00:32  lr: 0.002647  min_lr: 0.002647  loss: 2.6252 (2.6020)  weight_decay: 0.0500 (0.0500)  time: 0.5111  data: 0.0030  max mem: 5608\n",
            "Epoch: [51]  [100/147]  eta: 0:00:26  lr: 0.002641  min_lr: 0.002641  loss: 2.5701 (2.5943)  weight_decay: 0.0500 (0.0500)  time: 0.5062  data: 0.0023  max mem: 5608\n",
            "Epoch: [51]  [110/147]  eta: 0:00:20  lr: 0.002637  min_lr: 0.002637  loss: 2.4768 (2.5872)  weight_decay: 0.0500 (0.0500)  time: 0.4965  data: 0.0013  max mem: 5608\n",
            "Epoch: [51]  [120/147]  eta: 0:00:14  lr: 0.002631  min_lr: 0.002631  loss: 2.5353 (2.5845)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0020  max mem: 5608\n",
            "Epoch: [51]  [130/147]  eta: 0:00:09  lr: 0.002627  min_lr: 0.002627  loss: 2.6180 (2.5848)  weight_decay: 0.0500 (0.0500)  time: 0.5076  data: 0.0020  max mem: 5608\n",
            "Epoch: [51]  [140/147]  eta: 0:00:03  lr: 0.002620  min_lr: 0.002620  loss: 2.6285 (2.5883)  weight_decay: 0.0500 (0.0500)  time: 0.4980  data: 0.0011  max mem: 5608\n",
            "Epoch: [51]  [146/147]  eta: 0:00:00  lr: 0.002620  min_lr: 0.002620  loss: 2.6180 (2.5877)  weight_decay: 0.0500 (0.0500)  time: 0.4185  data: 0.0003  max mem: 5608\n",
            "Epoch: [51] Total time: 0:01:18 (0.5361 s / it)\n",
            "Averaged stats: lr: 0.002620  min_lr: 0.002620  loss: 2.6180 (2.5877)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:15  loss: 0.7930 (0.7930)  acc1: 81.2500 (81.2500)  acc5: 94.7917 (94.7917)  time: 6.2345  data: 5.9355  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.9503 (0.9415)  acc1: 78.1250 (76.7992)  acc5: 96.8750 (96.8750)  time: 0.7857  data: 0.5459  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.9973 (1.1072)  acc1: 75.0000 (69.1468)  acc5: 96.8750 (96.9246)  time: 0.2429  data: 0.0046  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0260 (1.1107)  acc1: 72.9167 (69.6909)  acc5: 96.8750 (95.6989)  time: 0.2431  data: 0.0012  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9995 (1.0994)  acc1: 72.9167 (70.1147)  acc5: 93.7500 (95.1847)  time: 0.2360  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3958 s / it)\n",
            "* Acc@1 70.115 Acc@5 95.185 loss 1.099\n",
            "Accuracy of the model on the 3925 test images: 70.1%\n",
            "Max accuracy: 70.11%\n",
            "Test:  [ 0/41]  eta: 0:03:50  loss: 4.1933 (4.1933)  acc1: 41.6667 (41.6667)  acc5: 69.7917 (69.7917)  time: 5.6287  data: 5.3184  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 4.1933 (4.4177)  acc1: 29.1667 (26.5152)  acc5: 71.8750 (71.5909)  time: 0.7822  data: 0.5402  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 5.0727 (4.9962)  acc1: 7.2917 (17.0635)  acc5: 61.4583 (60.5159)  time: 0.2729  data: 0.0322  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.6748 (5.0445)  acc1: 2.0833 (15.9274)  acc5: 48.9583 (60.3159)  time: 0.2443  data: 0.0011  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5748 (4.7177)  acc1: 11.4583 (21.0955)  acc5: 73.9583 (63.4650)  time: 0.2364  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3950 s / it)\n",
            "* Acc@1 21.096 Acc@5 63.465 loss 4.718\n",
            "Accuracy of the model EMA on 3925 test images: 21.1%\n",
            "Max EMA accuracy: 21.10%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [52]  [  0/147]  eta: 0:11:08  lr: 0.002618  min_lr: 0.002618  loss: 2.6135 (2.6135)  weight_decay: 0.0500 (0.0500)  time: 4.5450  data: 3.8238  max mem: 5608\n",
            "Epoch: [52]  [ 10/147]  eta: 0:02:07  lr: 0.002614  min_lr: 0.002614  loss: 2.6448 (2.6358)  weight_decay: 0.0500 (0.0500)  time: 0.9336  data: 0.3794  max mem: 5608\n",
            "Epoch: [52]  [ 20/147]  eta: 0:01:33  lr: 0.002608  min_lr: 0.002608  loss: 2.6448 (2.6438)  weight_decay: 0.0500 (0.0500)  time: 0.5421  data: 0.0178  max mem: 5608\n",
            "Epoch: [52]  [ 30/147]  eta: 0:01:17  lr: 0.002604  min_lr: 0.002604  loss: 2.6215 (2.6353)  weight_decay: 0.0500 (0.0500)  time: 0.5176  data: 0.0009  max mem: 5608\n",
            "Epoch: [52]  [ 40/147]  eta: 0:01:07  lr: 0.002598  min_lr: 0.002598  loss: 2.6246 (2.6378)  weight_decay: 0.0500 (0.0500)  time: 0.5231  data: 0.0014  max mem: 5608\n",
            "Epoch: [52]  [ 50/147]  eta: 0:00:59  lr: 0.002593  min_lr: 0.002593  loss: 2.6160 (2.6219)  weight_decay: 0.0500 (0.0500)  time: 0.5210  data: 0.0014  max mem: 5608\n",
            "Epoch: [52]  [ 60/147]  eta: 0:00:51  lr: 0.002587  min_lr: 0.002587  loss: 2.4813 (2.6244)  weight_decay: 0.0500 (0.0500)  time: 0.5162  data: 0.0010  max mem: 5608\n",
            "Epoch: [52]  [ 70/147]  eta: 0:00:44  lr: 0.002583  min_lr: 0.002583  loss: 2.6190 (2.6262)  weight_decay: 0.0500 (0.0500)  time: 0.5149  data: 0.0019  max mem: 5608\n",
            "Epoch: [52]  [ 80/147]  eta: 0:00:38  lr: 0.002577  min_lr: 0.002577  loss: 2.6190 (2.6289)  weight_decay: 0.0500 (0.0500)  time: 0.5107  data: 0.0029  max mem: 5608\n",
            "Epoch: [52]  [ 90/147]  eta: 0:00:32  lr: 0.002573  min_lr: 0.002573  loss: 2.6594 (2.6192)  weight_decay: 0.0500 (0.0500)  time: 0.5019  data: 0.0025  max mem: 5608\n",
            "Epoch: [52]  [100/147]  eta: 0:00:26  lr: 0.002566  min_lr: 0.002566  loss: 2.5719 (2.6074)  weight_decay: 0.0500 (0.0500)  time: 0.5045  data: 0.0021  max mem: 5608\n",
            "Epoch: [52]  [110/147]  eta: 0:00:20  lr: 0.002562  min_lr: 0.002562  loss: 2.5455 (2.6032)  weight_decay: 0.0500 (0.0500)  time: 0.5047  data: 0.0014  max mem: 5608\n",
            "Epoch: [52]  [120/147]  eta: 0:00:14  lr: 0.002556  min_lr: 0.002556  loss: 2.5877 (2.6062)  weight_decay: 0.0500 (0.0500)  time: 0.4980  data: 0.0008  max mem: 5608\n",
            "Epoch: [52]  [130/147]  eta: 0:00:09  lr: 0.002552  min_lr: 0.002552  loss: 2.6066 (2.6002)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0009  max mem: 5608\n",
            "Epoch: [52]  [140/147]  eta: 0:00:03  lr: 0.002545  min_lr: 0.002545  loss: 2.5682 (2.5975)  weight_decay: 0.0500 (0.0500)  time: 0.4967  data: 0.0007  max mem: 5608\n",
            "Epoch: [52]  [146/147]  eta: 0:00:00  lr: 0.002545  min_lr: 0.002545  loss: 2.4994 (2.5943)  weight_decay: 0.0500 (0.0500)  time: 0.4217  data: 0.0002  max mem: 5608\n",
            "Epoch: [52] Total time: 0:01:18 (0.5325 s / it)\n",
            "Averaged stats: lr: 0.002545  min_lr: 0.002545  loss: 2.4994 (2.5943)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:39  loss: 0.6341 (0.6341)  acc1: 87.5000 (87.5000)  acc5: 97.9167 (97.9167)  time: 3.8983  data: 3.6025  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.7682 (0.8460)  acc1: 83.3333 (81.2500)  acc5: 96.8750 (97.2538)  time: 0.5805  data: 0.3409  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.9685 (1.0908)  acc1: 76.0417 (70.6349)  acc5: 95.8333 (95.3373)  time: 0.2458  data: 0.0082  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0012 (1.0691)  acc1: 72.9167 (71.1358)  acc5: 95.8333 (95.4973)  time: 0.2742  data: 0.0290  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0552 (1.0476)  acc1: 68.7500 (71.5159)  acc5: 96.8750 (95.7962)  time: 0.2846  data: 0.0461  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3635 s / it)\n",
            "* Acc@1 71.516 Acc@5 95.796 loss 1.048\n",
            "Accuracy of the model on the 3925 test images: 71.5%\n",
            "Max accuracy: 71.52%\n",
            "Test:  [ 0/41]  eta: 0:02:39  loss: 4.1423 (4.1423)  acc1: 39.5833 (39.5833)  acc5: 69.7917 (69.7917)  time: 3.8875  data: 3.5968  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 4.1423 (4.3796)  acc1: 29.1667 (26.0417)  acc5: 72.9167 (72.2538)  time: 0.5672  data: 0.3304  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 5.0419 (4.9672)  acc1: 7.2917 (16.7659)  acc5: 62.5000 (61.4087)  time: 0.2392  data: 0.0028  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.6539 (5.0218)  acc1: 2.0833 (15.7258)  acc5: 48.9583 (61.0215)  time: 0.2439  data: 0.0010  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5457 (4.6908)  acc1: 11.4583 (21.0955)  acc5: 73.9583 (64.1019)  time: 0.2401  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3416 s / it)\n",
            "* Acc@1 21.096 Acc@5 64.102 loss 4.691\n",
            "Accuracy of the model EMA on 3925 test images: 21.1%\n",
            "Max EMA accuracy: 21.10%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [53]  [  0/147]  eta: 0:07:23  lr: 0.002543  min_lr: 0.002543  loss: 2.9842 (2.9842)  weight_decay: 0.0500 (0.0500)  time: 3.0155  data: 2.4005  max mem: 5608\n",
            "Epoch: [53]  [ 10/147]  eta: 0:01:42  lr: 0.002539  min_lr: 0.002539  loss: 2.5593 (2.5682)  weight_decay: 0.0500 (0.0500)  time: 0.7467  data: 0.2198  max mem: 5608\n",
            "Epoch: [53]  [ 20/147]  eta: 0:01:21  lr: 0.002533  min_lr: 0.002533  loss: 2.5392 (2.5592)  weight_decay: 0.0500 (0.0500)  time: 0.5213  data: 0.0018  max mem: 5608\n",
            "Epoch: [53]  [ 30/147]  eta: 0:01:10  lr: 0.002529  min_lr: 0.002529  loss: 2.4783 (2.5267)  weight_decay: 0.0500 (0.0500)  time: 0.5186  data: 0.0012  max mem: 5608\n",
            "Epoch: [53]  [ 40/147]  eta: 0:01:01  lr: 0.002522  min_lr: 0.002522  loss: 2.3363 (2.4911)  weight_decay: 0.0500 (0.0500)  time: 0.5115  data: 0.0005  max mem: 5608\n",
            "Epoch: [53]  [ 50/147]  eta: 0:00:54  lr: 0.002518  min_lr: 0.002518  loss: 2.3614 (2.4946)  weight_decay: 0.0500 (0.0500)  time: 0.5076  data: 0.0015  max mem: 5608\n",
            "Epoch: [53]  [ 60/147]  eta: 0:00:48  lr: 0.002512  min_lr: 0.002512  loss: 2.4793 (2.5005)  weight_decay: 0.0500 (0.0500)  time: 0.5126  data: 0.0017  max mem: 5608\n",
            "Epoch: [53]  [ 70/147]  eta: 0:00:42  lr: 0.002507  min_lr: 0.002507  loss: 2.6694 (2.5346)  weight_decay: 0.0500 (0.0500)  time: 0.5090  data: 0.0013  max mem: 5608\n",
            "Epoch: [53]  [ 80/147]  eta: 0:00:36  lr: 0.002501  min_lr: 0.002501  loss: 2.6765 (2.5438)  weight_decay: 0.0500 (0.0500)  time: 0.4997  data: 0.0020  max mem: 5608\n",
            "Epoch: [53]  [ 90/147]  eta: 0:00:30  lr: 0.002497  min_lr: 0.002497  loss: 2.6305 (2.5509)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0017  max mem: 5608\n",
            "Epoch: [53]  [100/147]  eta: 0:00:25  lr: 0.002491  min_lr: 0.002491  loss: 2.6577 (2.5637)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0028  max mem: 5608\n",
            "Epoch: [53]  [110/147]  eta: 0:00:19  lr: 0.002486  min_lr: 0.002486  loss: 2.7178 (2.5783)  weight_decay: 0.0500 (0.0500)  time: 0.4989  data: 0.0026  max mem: 5608\n",
            "Epoch: [53]  [120/147]  eta: 0:00:14  lr: 0.002480  min_lr: 0.002480  loss: 2.6781 (2.5822)  weight_decay: 0.0500 (0.0500)  time: 0.5069  data: 0.0028  max mem: 5608\n",
            "Epoch: [53]  [130/147]  eta: 0:00:08  lr: 0.002476  min_lr: 0.002476  loss: 2.5831 (2.5779)  weight_decay: 0.0500 (0.0500)  time: 0.5126  data: 0.0032  max mem: 5608\n",
            "Epoch: [53]  [140/147]  eta: 0:00:03  lr: 0.002469  min_lr: 0.002469  loss: 2.5127 (2.5763)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0009  max mem: 5608\n",
            "Epoch: [53]  [146/147]  eta: 0:00:00  lr: 0.002469  min_lr: 0.002469  loss: 2.6235 (2.5770)  weight_decay: 0.0500 (0.0500)  time: 0.4219  data: 0.0002  max mem: 5608\n",
            "Epoch: [53] Total time: 0:01:16 (0.5175 s / it)\n",
            "Averaged stats: lr: 0.002469  min_lr: 0.002469  loss: 2.6235 (2.5770)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:22  loss: 0.5923 (0.5923)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 4.9477  data: 4.1971  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.7636 (0.7644)  acc1: 82.2917 (82.8599)  acc5: 96.8750 (97.1591)  time: 0.6859  data: 0.3971  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.8299 (1.0002)  acc1: 80.2083 (72.5198)  acc5: 96.8750 (97.0238)  time: 0.2681  data: 0.0249  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0188 (1.0162)  acc1: 73.9583 (72.6479)  acc5: 96.8750 (96.7742)  time: 0.2890  data: 0.0447  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0591 (1.0215)  acc1: 73.9583 (72.7898)  acc5: 95.8333 (96.4076)  time: 0.2654  data: 0.0283  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3927 s / it)\n",
            "* Acc@1 72.790 Acc@5 96.408 loss 1.022\n",
            "Accuracy of the model on the 3925 test images: 72.8%\n",
            "Max accuracy: 72.79%\n",
            "Test:  [ 0/41]  eta: 0:02:33  loss: 4.0923 (4.0923)  acc1: 39.5833 (39.5833)  acc5: 69.7917 (69.7917)  time: 3.7415  data: 3.4498  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 4.0923 (4.3414)  acc1: 29.1667 (25.9470)  acc5: 72.9167 (72.4432)  time: 0.5638  data: 0.3155  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 5.0111 (4.9378)  acc1: 7.2917 (16.7163)  acc5: 62.5000 (61.7064)  time: 0.2450  data: 0.0060  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.6319 (4.9992)  acc1: 2.0833 (15.6922)  acc5: 48.9583 (61.3575)  time: 0.2494  data: 0.0124  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5364 (4.6645)  acc1: 11.4583 (21.1720)  acc5: 76.0417 (64.5350)  time: 0.2438  data: 0.0075  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3407 s / it)\n",
            "* Acc@1 21.172 Acc@5 64.535 loss 4.665\n",
            "Accuracy of the model EMA on 3925 test images: 21.2%\n",
            "Max EMA accuracy: 21.17%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [54]  [  0/147]  eta: 0:07:40  lr: 0.002467  min_lr: 0.002467  loss: 2.6293 (2.6293)  weight_decay: 0.0500 (0.0500)  time: 3.1308  data: 2.5054  max mem: 5608\n",
            "Epoch: [54]  [ 10/147]  eta: 0:01:42  lr: 0.002463  min_lr: 0.002463  loss: 2.5789 (2.5535)  weight_decay: 0.0500 (0.0500)  time: 0.7486  data: 0.2301  max mem: 5608\n",
            "Epoch: [54]  [ 20/147]  eta: 0:01:21  lr: 0.002457  min_lr: 0.002457  loss: 2.5789 (2.5637)  weight_decay: 0.0500 (0.0500)  time: 0.5165  data: 0.0033  max mem: 5608\n",
            "Epoch: [54]  [ 30/147]  eta: 0:01:10  lr: 0.002452  min_lr: 0.002452  loss: 2.6666 (2.5862)  weight_decay: 0.0500 (0.0500)  time: 0.5172  data: 0.0025  max mem: 5608\n",
            "Epoch: [54]  [ 40/147]  eta: 0:01:01  lr: 0.002446  min_lr: 0.002446  loss: 2.5219 (2.5635)  weight_decay: 0.0500 (0.0500)  time: 0.5109  data: 0.0007  max mem: 5608\n",
            "Epoch: [54]  [ 50/147]  eta: 0:00:54  lr: 0.002442  min_lr: 0.002442  loss: 2.5432 (2.5833)  weight_decay: 0.0500 (0.0500)  time: 0.5100  data: 0.0011  max mem: 5608\n",
            "Epoch: [54]  [ 60/147]  eta: 0:00:48  lr: 0.002435  min_lr: 0.002435  loss: 2.6700 (2.5792)  weight_decay: 0.0500 (0.0500)  time: 0.5126  data: 0.0010  max mem: 5608\n",
            "Epoch: [54]  [ 70/147]  eta: 0:00:42  lr: 0.002431  min_lr: 0.002431  loss: 2.6584 (2.5860)  weight_decay: 0.0500 (0.0500)  time: 0.5093  data: 0.0012  max mem: 5608\n",
            "Epoch: [54]  [ 80/147]  eta: 0:00:36  lr: 0.002425  min_lr: 0.002425  loss: 2.6736 (2.5903)  weight_decay: 0.0500 (0.0500)  time: 0.5048  data: 0.0014  max mem: 5608\n",
            "Epoch: [54]  [ 90/147]  eta: 0:00:30  lr: 0.002420  min_lr: 0.002420  loss: 2.6001 (2.5874)  weight_decay: 0.0500 (0.0500)  time: 0.5098  data: 0.0023  max mem: 5608\n",
            "Epoch: [54]  [100/147]  eta: 0:00:25  lr: 0.002414  min_lr: 0.002414  loss: 2.5214 (2.5875)  weight_decay: 0.0500 (0.0500)  time: 0.5079  data: 0.0030  max mem: 5608\n",
            "Epoch: [54]  [110/147]  eta: 0:00:19  lr: 0.002410  min_lr: 0.002410  loss: 2.4931 (2.5811)  weight_decay: 0.0500 (0.0500)  time: 0.4984  data: 0.0016  max mem: 5608\n",
            "Epoch: [54]  [120/147]  eta: 0:00:14  lr: 0.002403  min_lr: 0.002403  loss: 2.5367 (2.5851)  weight_decay: 0.0500 (0.0500)  time: 0.5020  data: 0.0022  max mem: 5608\n",
            "Epoch: [54]  [130/147]  eta: 0:00:08  lr: 0.002399  min_lr: 0.002399  loss: 2.6780 (2.5915)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0027  max mem: 5608\n",
            "Epoch: [54]  [140/147]  eta: 0:00:03  lr: 0.002393  min_lr: 0.002393  loss: 2.6573 (2.5935)  weight_decay: 0.0500 (0.0500)  time: 0.4968  data: 0.0010  max mem: 5608\n",
            "Epoch: [54]  [146/147]  eta: 0:00:00  lr: 0.002393  min_lr: 0.002393  loss: 2.6463 (2.5909)  weight_decay: 0.0500 (0.0500)  time: 0.4189  data: 0.0002  max mem: 5608\n",
            "Epoch: [54] Total time: 0:01:16 (0.5173 s / it)\n",
            "Averaged stats: lr: 0.002393  min_lr: 0.002393  loss: 2.6463 (2.5909)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:35  loss: 0.6733 (0.6733)  acc1: 88.5417 (88.5417)  acc5: 95.8333 (95.8333)  time: 3.7854  data: 3.5124  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.9337 (0.9702)  acc1: 79.1667 (78.2197)  acc5: 96.8750 (96.7803)  time: 0.6742  data: 0.4242  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.9598 (1.1895)  acc1: 78.1250 (68.4524)  acc5: 96.8750 (93.9484)  time: 0.3300  data: 0.0824  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0982 (1.1597)  acc1: 72.9167 (69.7245)  acc5: 96.8750 (94.9933)  time: 0.2690  data: 0.0248  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0541 (1.1171)  acc1: 75.0000 (71.6943)  acc5: 96.8750 (95.4140)  time: 0.2346  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3766 s / it)\n",
            "* Acc@1 71.694 Acc@5 95.414 loss 1.117\n",
            "Accuracy of the model on the 3925 test images: 71.7%\n",
            "Max accuracy: 72.79%\n",
            "Test:  [ 0/41]  eta: 0:02:14  loss: 4.0509 (4.0509)  acc1: 39.5833 (39.5833)  acc5: 69.7917 (69.7917)  time: 3.2797  data: 2.9763  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 4.0509 (4.3101)  acc1: 29.1667 (25.8523)  acc5: 72.9167 (72.5379)  time: 0.6556  data: 0.3988  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.9824 (4.9133)  acc1: 8.3333 (16.7163)  acc5: 62.5000 (62.4008)  time: 0.3915  data: 0.1419  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.6105 (4.9809)  acc1: 2.0833 (15.6922)  acc5: 50.0000 (61.6599)  time: 0.3837  data: 0.1369  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5188 (4.6416)  acc1: 11.4583 (21.2229)  acc5: 76.0417 (64.7643)  time: 0.3058  data: 0.0656  max mem: 5608\n",
            "Test: Total time: 0:00:17 (0.4305 s / it)\n",
            "* Acc@1 21.223 Acc@5 64.764 loss 4.642\n",
            "Accuracy of the model EMA on 3925 test images: 21.2%\n",
            "Max EMA accuracy: 21.22%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [55]  [  0/147]  eta: 0:08:26  lr: 0.002391  min_lr: 0.002391  loss: 2.8377 (2.8377)  weight_decay: 0.0500 (0.0500)  time: 3.4435  data: 2.8536  max mem: 5608\n",
            "Epoch: [55]  [ 10/147]  eta: 0:01:46  lr: 0.002386  min_lr: 0.002386  loss: 2.6599 (2.6089)  weight_decay: 0.0500 (0.0500)  time: 0.7786  data: 0.2613  max mem: 5608\n",
            "Epoch: [55]  [ 20/147]  eta: 0:01:23  lr: 0.002380  min_lr: 0.002380  loss: 2.6880 (2.6228)  weight_decay: 0.0500 (0.0500)  time: 0.5178  data: 0.0023  max mem: 5608\n",
            "Epoch: [55]  [ 30/147]  eta: 0:01:11  lr: 0.002376  min_lr: 0.002376  loss: 2.6880 (2.6213)  weight_decay: 0.0500 (0.0500)  time: 0.5166  data: 0.0031  max mem: 5608\n",
            "Epoch: [55]  [ 40/147]  eta: 0:01:02  lr: 0.002369  min_lr: 0.002369  loss: 2.5792 (2.6166)  weight_decay: 0.0500 (0.0500)  time: 0.5103  data: 0.0029  max mem: 5608\n",
            "Epoch: [55]  [ 50/147]  eta: 0:00:55  lr: 0.002365  min_lr: 0.002365  loss: 2.5770 (2.6060)  weight_decay: 0.0500 (0.0500)  time: 0.5141  data: 0.0017  max mem: 5608\n",
            "Epoch: [55]  [ 60/147]  eta: 0:00:48  lr: 0.002358  min_lr: 0.002358  loss: 2.6577 (2.6132)  weight_decay: 0.0500 (0.0500)  time: 0.5151  data: 0.0014  max mem: 5608\n",
            "Epoch: [55]  [ 70/147]  eta: 0:00:42  lr: 0.002354  min_lr: 0.002354  loss: 2.6752 (2.6012)  weight_decay: 0.0500 (0.0500)  time: 0.5059  data: 0.0015  max mem: 5608\n",
            "Epoch: [55]  [ 80/147]  eta: 0:00:36  lr: 0.002348  min_lr: 0.002348  loss: 2.6752 (2.6104)  weight_decay: 0.0500 (0.0500)  time: 0.5034  data: 0.0020  max mem: 5608\n",
            "Epoch: [55]  [ 90/147]  eta: 0:00:31  lr: 0.002343  min_lr: 0.002343  loss: 2.7028 (2.6092)  weight_decay: 0.0500 (0.0500)  time: 0.5102  data: 0.0033  max mem: 5608\n",
            "Epoch: [55]  [100/147]  eta: 0:00:25  lr: 0.002337  min_lr: 0.002337  loss: 2.6302 (2.5998)  weight_decay: 0.0500 (0.0500)  time: 0.5046  data: 0.0037  max mem: 5608\n",
            "Epoch: [55]  [110/147]  eta: 0:00:19  lr: 0.002333  min_lr: 0.002333  loss: 2.5351 (2.5959)  weight_decay: 0.0500 (0.0500)  time: 0.4973  data: 0.0026  max mem: 5608\n",
            "Epoch: [55]  [120/147]  eta: 0:00:14  lr: 0.002326  min_lr: 0.002326  loss: 2.5767 (2.5949)  weight_decay: 0.0500 (0.0500)  time: 0.5057  data: 0.0018  max mem: 5608\n",
            "Epoch: [55]  [130/147]  eta: 0:00:09  lr: 0.002322  min_lr: 0.002322  loss: 2.5701 (2.5893)  weight_decay: 0.0500 (0.0500)  time: 0.5054  data: 0.0016  max mem: 5608\n",
            "Epoch: [55]  [140/147]  eta: 0:00:03  lr: 0.002315  min_lr: 0.002315  loss: 2.5072 (2.5836)  weight_decay: 0.0500 (0.0500)  time: 0.4946  data: 0.0010  max mem: 5608\n",
            "Epoch: [55]  [146/147]  eta: 0:00:00  lr: 0.002315  min_lr: 0.002315  loss: 2.5568 (2.5838)  weight_decay: 0.0500 (0.0500)  time: 0.4193  data: 0.0003  max mem: 5608\n",
            "Epoch: [55] Total time: 0:01:16 (0.5212 s / it)\n",
            "Averaged stats: lr: 0.002315  min_lr: 0.002315  loss: 2.5568 (2.5838)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:08  loss: 0.5563 (0.5563)  acc1: 87.5000 (87.5000)  acc5: 98.9583 (98.9583)  time: 4.5916  data: 4.3200  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.7532 (0.7670)  acc1: 82.2917 (81.8182)  acc5: 97.9167 (97.5379)  time: 0.6756  data: 0.4367  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.8534 (0.9375)  acc1: 79.1667 (75.6448)  acc5: 97.9167 (97.4702)  time: 0.2815  data: 0.0474  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0383 (0.9760)  acc1: 70.8333 (74.1263)  acc5: 96.8750 (97.3118)  time: 0.2558  data: 0.0233  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0247 (0.9738)  acc1: 71.8750 (73.9363)  acc5: 96.8750 (97.1210)  time: 0.2307  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3776 s / it)\n",
            "* Acc@1 73.936 Acc@5 97.121 loss 0.974\n",
            "Accuracy of the model on the 3925 test images: 73.9%\n",
            "Max accuracy: 73.94%\n",
            "Test:  [ 0/41]  eta: 0:03:07  loss: 4.0065 (4.0065)  acc1: 38.5417 (38.5417)  acc5: 70.8333 (70.8333)  time: 4.5688  data: 4.1973  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 4.0065 (4.2772)  acc1: 29.1667 (25.7576)  acc5: 72.9167 (72.9167)  time: 0.6785  data: 0.4256  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 4.9547 (4.8873)  acc1: 8.3333 (16.7163)  acc5: 62.5000 (62.9464)  time: 0.2720  data: 0.0312  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.5862 (4.9615)  acc1: 3.1250 (15.7258)  acc5: 51.0417 (62.0296)  time: 0.2472  data: 0.0071  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4595 (4.6179)  acc1: 11.4583 (21.3503)  acc5: 76.0417 (65.1210)  time: 0.2375  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3693 s / it)\n",
            "* Acc@1 21.350 Acc@5 65.121 loss 4.618\n",
            "Accuracy of the model EMA on 3925 test images: 21.4%\n",
            "Max EMA accuracy: 21.35%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [56]  [  0/147]  eta: 0:12:00  lr: 0.002313  min_lr: 0.002313  loss: 2.7531 (2.7531)  weight_decay: 0.0500 (0.0500)  time: 4.9045  data: 4.1703  max mem: 5608\n",
            "Epoch: [56]  [ 10/147]  eta: 0:02:07  lr: 0.002309  min_lr: 0.002309  loss: 2.4435 (2.4658)  weight_decay: 0.0500 (0.0500)  time: 0.9315  data: 0.3800  max mem: 5608\n",
            "Epoch: [56]  [ 20/147]  eta: 0:01:32  lr: 0.002303  min_lr: 0.002303  loss: 2.4435 (2.5174)  weight_decay: 0.0500 (0.0500)  time: 0.5232  data: 0.0019  max mem: 5608\n",
            "Epoch: [56]  [ 30/147]  eta: 0:01:18  lr: 0.002298  min_lr: 0.002298  loss: 2.6510 (2.5538)  weight_decay: 0.0500 (0.0500)  time: 0.5221  data: 0.0032  max mem: 5608\n",
            "Epoch: [56]  [ 40/147]  eta: 0:01:07  lr: 0.002292  min_lr: 0.002292  loss: 2.5805 (2.5516)  weight_decay: 0.0500 (0.0500)  time: 0.5294  data: 0.0031  max mem: 5608\n",
            "Epoch: [56]  [ 50/147]  eta: 0:00:59  lr: 0.002287  min_lr: 0.002287  loss: 2.5361 (2.5492)  weight_decay: 0.0500 (0.0500)  time: 0.5224  data: 0.0032  max mem: 5608\n",
            "Epoch: [56]  [ 60/147]  eta: 0:00:51  lr: 0.002281  min_lr: 0.002281  loss: 2.5651 (2.5560)  weight_decay: 0.0500 (0.0500)  time: 0.5117  data: 0.0034  max mem: 5608\n",
            "Epoch: [56]  [ 70/147]  eta: 0:00:44  lr: 0.002277  min_lr: 0.002277  loss: 2.6146 (2.5587)  weight_decay: 0.0500 (0.0500)  time: 0.5059  data: 0.0030  max mem: 5608\n",
            "Epoch: [56]  [ 80/147]  eta: 0:00:38  lr: 0.002270  min_lr: 0.002270  loss: 2.6180 (2.5654)  weight_decay: 0.0500 (0.0500)  time: 0.5054  data: 0.0026  max mem: 5608\n",
            "Epoch: [56]  [ 90/147]  eta: 0:00:32  lr: 0.002266  min_lr: 0.002266  loss: 2.6553 (2.5751)  weight_decay: 0.0500 (0.0500)  time: 0.4999  data: 0.0030  max mem: 5608\n",
            "Epoch: [56]  [100/147]  eta: 0:00:26  lr: 0.002259  min_lr: 0.002259  loss: 2.7043 (2.5766)  weight_decay: 0.0500 (0.0500)  time: 0.4961  data: 0.0027  max mem: 5608\n",
            "Epoch: [56]  [110/147]  eta: 0:00:20  lr: 0.002255  min_lr: 0.002255  loss: 2.5252 (2.5667)  weight_decay: 0.0500 (0.0500)  time: 0.4994  data: 0.0034  max mem: 5608\n",
            "Epoch: [56]  [120/147]  eta: 0:00:14  lr: 0.002249  min_lr: 0.002249  loss: 2.4634 (2.5664)  weight_decay: 0.0500 (0.0500)  time: 0.4996  data: 0.0035  max mem: 5608\n",
            "Epoch: [56]  [130/147]  eta: 0:00:09  lr: 0.002244  min_lr: 0.002244  loss: 2.5258 (2.5584)  weight_decay: 0.0500 (0.0500)  time: 0.4958  data: 0.0012  max mem: 5608\n",
            "Epoch: [56]  [140/147]  eta: 0:00:03  lr: 0.002238  min_lr: 0.002238  loss: 2.6057 (2.5636)  weight_decay: 0.0500 (0.0500)  time: 0.4956  data: 0.0004  max mem: 5608\n",
            "Epoch: [56]  [146/147]  eta: 0:00:00  lr: 0.002238  min_lr: 0.002238  loss: 2.6223 (2.5650)  weight_decay: 0.0500 (0.0500)  time: 0.4218  data: 0.0002  max mem: 5608\n",
            "Epoch: [56] Total time: 0:01:18 (0.5317 s / it)\n",
            "Averaged stats: lr: 0.002238  min_lr: 0.002238  loss: 2.6223 (2.5650)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:55  loss: 0.5471 (0.5471)  acc1: 87.5000 (87.5000)  acc5: 97.9167 (97.9167)  time: 4.2763  data: 4.0100  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 0.7153 (0.7679)  acc1: 82.2917 (82.1023)  acc5: 97.9167 (98.3902)  time: 0.6130  data: 0.3725  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.9574 (1.0754)  acc1: 77.0833 (70.2877)  acc5: 97.9167 (96.5278)  time: 0.2449  data: 0.0063  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0721 (1.0792)  acc1: 70.8333 (71.3038)  acc5: 93.7500 (95.9005)  time: 0.2375  data: 0.0020  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8995 (1.0216)  acc1: 76.4706 (73.2229)  acc5: 96.8750 (96.1529)  time: 0.2304  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3508 s / it)\n",
            "* Acc@1 73.223 Acc@5 96.153 loss 1.022\n",
            "Accuracy of the model on the 3925 test images: 73.2%\n",
            "Max accuracy: 73.94%\n",
            "Test:  [ 0/41]  eta: 0:02:34  loss: 3.9659 (3.9659)  acc1: 37.5000 (37.5000)  acc5: 70.8333 (70.8333)  time: 3.7623  data: 3.4782  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.9659 (4.2452)  acc1: 30.2083 (25.3788)  acc5: 72.9167 (73.2008)  time: 0.5663  data: 0.3222  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.9285 (4.8624)  acc1: 8.3333 (16.4683)  acc5: 62.5000 (63.2440)  time: 0.2429  data: 0.0046  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.5620 (4.9434)  acc1: 3.1250 (15.5578)  acc5: 52.0833 (62.2984)  time: 0.2392  data: 0.0013  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4484 (4.5955)  acc1: 12.5000 (21.2484)  acc5: 76.0417 (65.4013)  time: 0.2363  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3398 s / it)\n",
            "* Acc@1 21.248 Acc@5 65.401 loss 4.596\n",
            "Accuracy of the model EMA on 3925 test images: 21.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [57]  [  0/147]  eta: 0:11:48  lr: 0.002236  min_lr: 0.002236  loss: 2.6883 (2.6883)  weight_decay: 0.0500 (0.0500)  time: 4.8220  data: 4.1172  max mem: 5608\n",
            "Epoch: [57]  [ 10/147]  eta: 0:02:05  lr: 0.002231  min_lr: 0.002231  loss: 2.6566 (2.6188)  weight_decay: 0.0500 (0.0500)  time: 0.9182  data: 0.3748  max mem: 5608\n",
            "Epoch: [57]  [ 20/147]  eta: 0:01:31  lr: 0.002225  min_lr: 0.002225  loss: 2.6210 (2.6405)  weight_decay: 0.0500 (0.0500)  time: 0.5172  data: 0.0004  max mem: 5608\n",
            "Epoch: [57]  [ 30/147]  eta: 0:01:16  lr: 0.002220  min_lr: 0.002220  loss: 2.5997 (2.6031)  weight_decay: 0.0500 (0.0500)  time: 0.5124  data: 0.0020  max mem: 5608\n",
            "Epoch: [57]  [ 40/147]  eta: 0:01:06  lr: 0.002214  min_lr: 0.002214  loss: 2.5421 (2.5995)  weight_decay: 0.0500 (0.0500)  time: 0.5166  data: 0.0030  max mem: 5608\n",
            "Epoch: [57]  [ 50/147]  eta: 0:00:58  lr: 0.002210  min_lr: 0.002210  loss: 2.5862 (2.5982)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0024  max mem: 5608\n",
            "Epoch: [57]  [ 60/147]  eta: 0:00:50  lr: 0.002203  min_lr: 0.002203  loss: 2.5862 (2.5894)  weight_decay: 0.0500 (0.0500)  time: 0.5079  data: 0.0019  max mem: 5608\n",
            "Epoch: [57]  [ 70/147]  eta: 0:00:44  lr: 0.002199  min_lr: 0.002199  loss: 2.5920 (2.5956)  weight_decay: 0.0500 (0.0500)  time: 0.5126  data: 0.0016  max mem: 5608\n",
            "Epoch: [57]  [ 80/147]  eta: 0:00:37  lr: 0.002192  min_lr: 0.002192  loss: 2.6539 (2.5916)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0015  max mem: 5608\n",
            "Epoch: [57]  [ 90/147]  eta: 0:00:31  lr: 0.002188  min_lr: 0.002188  loss: 2.6525 (2.5893)  weight_decay: 0.0500 (0.0500)  time: 0.4998  data: 0.0016  max mem: 5608\n",
            "Epoch: [57]  [100/147]  eta: 0:00:26  lr: 0.002181  min_lr: 0.002181  loss: 2.6308 (2.5873)  weight_decay: 0.0500 (0.0500)  time: 0.5068  data: 0.0028  max mem: 5608\n",
            "Epoch: [57]  [110/147]  eta: 0:00:20  lr: 0.002177  min_lr: 0.002177  loss: 2.5189 (2.5816)  weight_decay: 0.0500 (0.0500)  time: 0.5079  data: 0.0024  max mem: 5608\n",
            "Epoch: [57]  [120/147]  eta: 0:00:14  lr: 0.002170  min_lr: 0.002170  loss: 2.5607 (2.5828)  weight_decay: 0.0500 (0.0500)  time: 0.5073  data: 0.0015  max mem: 5608\n",
            "Epoch: [57]  [130/147]  eta: 0:00:09  lr: 0.002166  min_lr: 0.002166  loss: 2.5910 (2.5770)  weight_decay: 0.0500 (0.0500)  time: 0.5062  data: 0.0014  max mem: 5608\n",
            "Epoch: [57]  [140/147]  eta: 0:00:03  lr: 0.002160  min_lr: 0.002160  loss: 2.5921 (2.5746)  weight_decay: 0.0500 (0.0500)  time: 0.4968  data: 0.0007  max mem: 5608\n",
            "Epoch: [57]  [146/147]  eta: 0:00:00  lr: 0.002160  min_lr: 0.002160  loss: 2.5921 (2.5738)  weight_decay: 0.0500 (0.0500)  time: 0.4216  data: 0.0002  max mem: 5608\n",
            "Epoch: [57] Total time: 0:01:17 (0.5300 s / it)\n",
            "Averaged stats: lr: 0.002160  min_lr: 0.002160  loss: 2.5921 (2.5738)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:55  loss: 0.4001 (0.4001)  acc1: 93.7500 (93.7500)  acc5: 97.9167 (97.9167)  time: 2.8157  data: 2.5102  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.7826 (0.7188)  acc1: 83.3333 (84.0909)  acc5: 97.9167 (98.2008)  time: 0.5720  data: 0.3200  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.9185 (1.0189)  acc1: 78.1250 (71.4286)  acc5: 97.9167 (96.8254)  time: 0.3616  data: 0.1191  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9389 (0.9889)  acc1: 75.0000 (72.3454)  acc5: 95.8333 (96.4382)  time: 0.3236  data: 0.0821  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9747 (0.9879)  acc1: 72.9167 (72.5860)  acc5: 95.8333 (96.4076)  time: 0.2506  data: 0.0136  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3774 s / it)\n",
            "* Acc@1 72.586 Acc@5 96.408 loss 0.988\n",
            "Accuracy of the model on the 3925 test images: 72.6%\n",
            "Max accuracy: 73.94%\n",
            "Test:  [ 0/41]  eta: 0:01:20  loss: 3.9230 (3.9230)  acc1: 38.5417 (38.5417)  acc5: 72.9167 (72.9167)  time: 1.9647  data: 1.6935  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 3.9366 (4.2134)  acc1: 29.1667 (25.2841)  acc5: 72.9167 (73.7689)  time: 0.5158  data: 0.2773  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.9034 (4.8378)  acc1: 8.3333 (16.4187)  acc5: 63.5417 (63.8889)  time: 0.3065  data: 0.0686  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.5383 (4.9248)  acc1: 3.1250 (15.5242)  acc5: 54.1667 (62.7688)  time: 0.2424  data: 0.0012  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4439 (4.5730)  acc1: 14.5833 (21.3248)  acc5: 76.0417 (65.8854)  time: 0.2377  data: 0.0005  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3256 s / it)\n",
            "* Acc@1 21.325 Acc@5 65.885 loss 4.573\n",
            "Accuracy of the model EMA on 3925 test images: 21.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [58]  [  0/147]  eta: 0:07:23  lr: 0.002157  min_lr: 0.002157  loss: 2.3222 (2.3222)  weight_decay: 0.0500 (0.0500)  time: 3.0175  data: 2.4499  max mem: 5608\n",
            "Epoch: [58]  [ 10/147]  eta: 0:01:45  lr: 0.002153  min_lr: 0.002153  loss: 2.6770 (2.6221)  weight_decay: 0.0500 (0.0500)  time: 0.7706  data: 0.2478  max mem: 5608\n",
            "Epoch: [58]  [ 20/147]  eta: 0:01:22  lr: 0.002147  min_lr: 0.002147  loss: 2.5694 (2.5225)  weight_decay: 0.0500 (0.0500)  time: 0.5315  data: 0.0148  max mem: 5608\n",
            "Epoch: [58]  [ 30/147]  eta: 0:01:10  lr: 0.002142  min_lr: 0.002142  loss: 2.4612 (2.5192)  weight_decay: 0.0500 (0.0500)  time: 0.5163  data: 0.0019  max mem: 5608\n",
            "Epoch: [58]  [ 40/147]  eta: 0:01:02  lr: 0.002136  min_lr: 0.002136  loss: 2.5018 (2.5163)  weight_decay: 0.0500 (0.0500)  time: 0.5108  data: 0.0018  max mem: 5608\n",
            "Epoch: [58]  [ 50/147]  eta: 0:00:55  lr: 0.002131  min_lr: 0.002131  loss: 2.5817 (2.5457)  weight_decay: 0.0500 (0.0500)  time: 0.5062  data: 0.0015  max mem: 5608\n",
            "Epoch: [58]  [ 60/147]  eta: 0:00:48  lr: 0.002125  min_lr: 0.002125  loss: 2.6810 (2.5450)  weight_decay: 0.0500 (0.0500)  time: 0.5100  data: 0.0016  max mem: 5608\n",
            "Epoch: [58]  [ 70/147]  eta: 0:00:42  lr: 0.002120  min_lr: 0.002120  loss: 2.4875 (2.5406)  weight_decay: 0.0500 (0.0500)  time: 0.5086  data: 0.0014  max mem: 5608\n",
            "Epoch: [58]  [ 80/147]  eta: 0:00:36  lr: 0.002114  min_lr: 0.002114  loss: 2.5440 (2.5460)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0005  max mem: 5608\n",
            "Epoch: [58]  [ 90/147]  eta: 0:00:30  lr: 0.002110  min_lr: 0.002110  loss: 2.6375 (2.5515)  weight_decay: 0.0500 (0.0500)  time: 0.5015  data: 0.0013  max mem: 5608\n",
            "Epoch: [58]  [100/147]  eta: 0:00:25  lr: 0.002103  min_lr: 0.002103  loss: 2.6408 (2.5571)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0023  max mem: 5608\n",
            "Epoch: [58]  [110/147]  eta: 0:00:19  lr: 0.002099  min_lr: 0.002099  loss: 2.5440 (2.5523)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0019  max mem: 5608\n",
            "Epoch: [58]  [120/147]  eta: 0:00:14  lr: 0.002092  min_lr: 0.002092  loss: 2.4632 (2.5494)  weight_decay: 0.0500 (0.0500)  time: 0.4973  data: 0.0010  max mem: 5608\n",
            "Epoch: [58]  [130/147]  eta: 0:00:08  lr: 0.002088  min_lr: 0.002088  loss: 2.4453 (2.5424)  weight_decay: 0.0500 (0.0500)  time: 0.5004  data: 0.0004  max mem: 5608\n",
            "Epoch: [58]  [140/147]  eta: 0:00:03  lr: 0.002081  min_lr: 0.002081  loss: 2.4794 (2.5475)  weight_decay: 0.0500 (0.0500)  time: 0.4979  data: 0.0002  max mem: 5608\n",
            "Epoch: [58]  [146/147]  eta: 0:00:00  lr: 0.002081  min_lr: 0.002081  loss: 2.5839 (2.5458)  weight_decay: 0.0500 (0.0500)  time: 0.4198  data: 0.0002  max mem: 5608\n",
            "Epoch: [58] Total time: 0:01:16 (0.5171 s / it)\n",
            "Averaged stats: lr: 0.002081  min_lr: 0.002081  loss: 2.5839 (2.5458)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:06  loss: 0.5320 (0.5320)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 4.5428  data: 4.2570  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.7344 (0.7309)  acc1: 86.4583 (84.0909)  acc5: 97.9167 (98.1061)  time: 0.6986  data: 0.4554  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.8727 (0.9598)  acc1: 78.1250 (74.5040)  acc5: 97.9167 (97.2718)  time: 0.3045  data: 0.0640  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9769 (0.9327)  acc1: 72.9167 (75.3024)  acc5: 96.8750 (97.0766)  time: 0.2671  data: 0.0264  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9108 (0.9376)  acc1: 75.0000 (75.4395)  acc5: 96.8750 (96.9427)  time: 0.2336  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3830 s / it)\n",
            "* Acc@1 75.439 Acc@5 96.943 loss 0.938\n",
            "Accuracy of the model on the 3925 test images: 75.4%\n",
            "Max accuracy: 75.44%\n",
            "Test:  [ 0/41]  eta: 0:02:14  loss: 3.8831 (3.8831)  acc1: 38.5417 (38.5417)  acc5: 73.9583 (73.9583)  time: 3.2876  data: 2.9902  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.9099 (4.1834)  acc1: 29.1667 (25.1894)  acc5: 73.9583 (74.2424)  time: 0.5209  data: 0.2726  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.8814 (4.8147)  acc1: 8.3333 (16.3690)  acc5: 63.5417 (64.4841)  time: 0.2747  data: 0.0327  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.5140 (4.9080)  acc1: 3.1250 (15.5242)  acc5: 56.2500 (63.1048)  time: 0.3477  data: 0.1030  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4388 (4.5520)  acc1: 14.5833 (21.3503)  acc5: 76.0417 (66.1147)  time: 0.3143  data: 0.0709  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3859 s / it)\n",
            "* Acc@1 21.350 Acc@5 66.115 loss 4.552\n",
            "Accuracy of the model EMA on 3925 test images: 21.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [59]  [  0/147]  eta: 0:10:09  lr: 0.002079  min_lr: 0.002079  loss: 2.3047 (2.3047)  weight_decay: 0.0500 (0.0500)  time: 4.1462  data: 3.5652  max mem: 5608\n",
            "Epoch: [59]  [ 10/147]  eta: 0:01:55  lr: 0.002075  min_lr: 0.002075  loss: 2.6777 (2.5965)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.3253  max mem: 5608\n",
            "Epoch: [59]  [ 20/147]  eta: 0:01:27  lr: 0.002068  min_lr: 0.002068  loss: 2.6449 (2.6060)  weight_decay: 0.0500 (0.0500)  time: 0.5171  data: 0.0008  max mem: 5608\n",
            "Epoch: [59]  [ 30/147]  eta: 0:01:14  lr: 0.002064  min_lr: 0.002064  loss: 2.6047 (2.5944)  weight_decay: 0.0500 (0.0500)  time: 0.5154  data: 0.0012  max mem: 5608\n",
            "Epoch: [59]  [ 40/147]  eta: 0:01:04  lr: 0.002057  min_lr: 0.002057  loss: 2.5907 (2.5845)  weight_decay: 0.0500 (0.0500)  time: 0.5107  data: 0.0015  max mem: 5608\n",
            "Epoch: [59]  [ 50/147]  eta: 0:00:56  lr: 0.002053  min_lr: 0.002053  loss: 2.5537 (2.5686)  weight_decay: 0.0500 (0.0500)  time: 0.5111  data: 0.0015  max mem: 5608\n",
            "Epoch: [59]  [ 60/147]  eta: 0:00:49  lr: 0.002046  min_lr: 0.002046  loss: 2.5414 (2.5610)  weight_decay: 0.0500 (0.0500)  time: 0.5165  data: 0.0015  max mem: 5608\n",
            "Epoch: [59]  [ 70/147]  eta: 0:00:43  lr: 0.002042  min_lr: 0.002042  loss: 2.5583 (2.5668)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0011  max mem: 5608\n",
            "Epoch: [59]  [ 80/147]  eta: 0:00:37  lr: 0.002035  min_lr: 0.002035  loss: 2.5631 (2.5568)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0009  max mem: 5608\n",
            "Epoch: [59]  [ 90/147]  eta: 0:00:31  lr: 0.002031  min_lr: 0.002031  loss: 2.5328 (2.5463)  weight_decay: 0.0500 (0.0500)  time: 0.5048  data: 0.0018  max mem: 5608\n",
            "Epoch: [59]  [100/147]  eta: 0:00:25  lr: 0.002024  min_lr: 0.002024  loss: 2.5328 (2.5480)  weight_decay: 0.0500 (0.0500)  time: 0.5061  data: 0.0029  max mem: 5608\n",
            "Epoch: [59]  [110/147]  eta: 0:00:20  lr: 0.002020  min_lr: 0.002020  loss: 2.5759 (2.5503)  weight_decay: 0.0500 (0.0500)  time: 0.4992  data: 0.0032  max mem: 5608\n",
            "Epoch: [59]  [120/147]  eta: 0:00:14  lr: 0.002014  min_lr: 0.002014  loss: 2.6283 (2.5527)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0022  max mem: 5608\n",
            "Epoch: [59]  [130/147]  eta: 0:00:09  lr: 0.002009  min_lr: 0.002009  loss: 2.6283 (2.5579)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0009  max mem: 5608\n",
            "Epoch: [59]  [140/147]  eta: 0:00:03  lr: 0.002003  min_lr: 0.002003  loss: 2.5619 (2.5499)  weight_decay: 0.0500 (0.0500)  time: 0.4950  data: 0.0004  max mem: 5608\n",
            "Epoch: [59]  [146/147]  eta: 0:00:00  lr: 0.002003  min_lr: 0.002003  loss: 2.5563 (2.5502)  weight_decay: 0.0500 (0.0500)  time: 0.4190  data: 0.0002  max mem: 5608\n",
            "Epoch: [59] Total time: 0:01:16 (0.5235 s / it)\n",
            "Averaged stats: lr: 0.002003  min_lr: 0.002003  loss: 2.5563 (2.5502)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:21  loss: 0.5372 (0.5372)  acc1: 88.5417 (88.5417)  acc5: 97.9167 (97.9167)  time: 4.9036  data: 4.6047  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.6461 (0.7866)  acc1: 87.5000 (83.9962)  acc5: 96.8750 (97.2538)  time: 0.7060  data: 0.4495  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.8935 (0.9830)  acc1: 80.2083 (75.0992)  acc5: 96.8750 (96.6766)  time: 0.2855  data: 0.0388  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9103 (0.9697)  acc1: 77.0833 (74.8992)  acc5: 96.8750 (96.7070)  time: 0.2611  data: 0.0219  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8051 (0.9515)  acc1: 78.1250 (75.3121)  acc5: 97.9167 (96.8153)  time: 0.2326  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3831 s / it)\n",
            "* Acc@1 75.312 Acc@5 96.815 loss 0.951\n",
            "Accuracy of the model on the 3925 test images: 75.3%\n",
            "Max accuracy: 75.44%\n",
            "Test:  [ 0/41]  eta: 0:02:20  loss: 3.8512 (3.8512)  acc1: 38.5417 (38.5417)  acc5: 73.9583 (73.9583)  time: 3.4150  data: 3.0957  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.8881 (4.1567)  acc1: 28.1250 (24.9053)  acc5: 73.9583 (75.2841)  time: 0.5592  data: 0.3163  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.8598 (4.7945)  acc1: 8.3333 (16.2698)  acc5: 63.5417 (65.2282)  time: 0.2827  data: 0.0454  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.4944 (4.8946)  acc1: 3.1250 (15.4906)  acc5: 58.3333 (63.6089)  time: 0.2962  data: 0.0506  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4433 (4.5336)  acc1: 14.5833 (21.3248)  acc5: 77.0833 (66.5478)  time: 0.2670  data: 0.0245  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3610 s / it)\n",
            "* Acc@1 21.325 Acc@5 66.548 loss 4.534\n",
            "Accuracy of the model EMA on 3925 test images: 21.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [60]  [  0/147]  eta: 0:06:50  lr: 0.002001  min_lr: 0.002001  loss: 2.5060 (2.5060)  weight_decay: 0.0500 (0.0500)  time: 2.7924  data: 2.1709  max mem: 5608\n",
            "Epoch: [60]  [ 10/147]  eta: 0:01:39  lr: 0.001996  min_lr: 0.001996  loss: 2.6002 (2.4943)  weight_decay: 0.0500 (0.0500)  time: 0.7285  data: 0.1988  max mem: 5608\n",
            "Epoch: [60]  [ 20/147]  eta: 0:01:20  lr: 0.001990  min_lr: 0.001990  loss: 2.6002 (2.5603)  weight_decay: 0.0500 (0.0500)  time: 0.5252  data: 0.0020  max mem: 5608\n",
            "Epoch: [60]  [ 30/147]  eta: 0:01:09  lr: 0.001985  min_lr: 0.001985  loss: 2.5670 (2.5482)  weight_decay: 0.0500 (0.0500)  time: 0.5224  data: 0.0030  max mem: 5608\n",
            "Epoch: [60]  [ 40/147]  eta: 0:01:01  lr: 0.001979  min_lr: 0.001979  loss: 2.6304 (2.5561)  weight_decay: 0.0500 (0.0500)  time: 0.5139  data: 0.0028  max mem: 5608\n",
            "Epoch: [60]  [ 50/147]  eta: 0:00:54  lr: 0.001974  min_lr: 0.001974  loss: 2.6545 (2.5429)  weight_decay: 0.0500 (0.0500)  time: 0.5117  data: 0.0016  max mem: 5608\n",
            "Epoch: [60]  [ 60/147]  eta: 0:00:48  lr: 0.001968  min_lr: 0.001968  loss: 2.5005 (2.5307)  weight_decay: 0.0500 (0.0500)  time: 0.5142  data: 0.0024  max mem: 5608\n",
            "Epoch: [60]  [ 70/147]  eta: 0:00:42  lr: 0.001963  min_lr: 0.001963  loss: 2.6272 (2.5460)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0037  max mem: 5608\n",
            "Epoch: [60]  [ 80/147]  eta: 0:00:36  lr: 0.001957  min_lr: 0.001957  loss: 2.6272 (2.5286)  weight_decay: 0.0500 (0.0500)  time: 0.5089  data: 0.0038  max mem: 5608\n",
            "Epoch: [60]  [ 90/147]  eta: 0:00:30  lr: 0.001953  min_lr: 0.001953  loss: 2.5047 (2.5276)  weight_decay: 0.0500 (0.0500)  time: 0.5124  data: 0.0049  max mem: 5608\n",
            "Epoch: [60]  [100/147]  eta: 0:00:25  lr: 0.001946  min_lr: 0.001946  loss: 2.4743 (2.5206)  weight_decay: 0.0500 (0.0500)  time: 0.5072  data: 0.0047  max mem: 5608\n",
            "Epoch: [60]  [110/147]  eta: 0:00:19  lr: 0.001942  min_lr: 0.001942  loss: 2.4648 (2.5256)  weight_decay: 0.0500 (0.0500)  time: 0.4979  data: 0.0024  max mem: 5608\n",
            "Epoch: [60]  [120/147]  eta: 0:00:14  lr: 0.001935  min_lr: 0.001935  loss: 2.5250 (2.5247)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0020  max mem: 5608\n",
            "Epoch: [60]  [130/147]  eta: 0:00:08  lr: 0.001931  min_lr: 0.001931  loss: 2.5967 (2.5257)  weight_decay: 0.0500 (0.0500)  time: 0.5050  data: 0.0028  max mem: 5608\n",
            "Epoch: [60]  [140/147]  eta: 0:00:03  lr: 0.001924  min_lr: 0.001924  loss: 2.5967 (2.5313)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0015  max mem: 5608\n",
            "Epoch: [60]  [146/147]  eta: 0:00:00  lr: 0.001924  min_lr: 0.001924  loss: 2.5317 (2.5260)  weight_decay: 0.0500 (0.0500)  time: 0.4196  data: 0.0002  max mem: 5608\n",
            "Epoch: [60] Total time: 0:01:16 (0.5174 s / it)\n",
            "Averaged stats: lr: 0.001924  min_lr: 0.001924  loss: 2.5317 (2.5260)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:42  loss: 0.4766 (0.4766)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 3.9688  data: 3.6780  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.7297 (0.6949)  acc1: 86.4583 (86.6477)  acc5: 97.9167 (98.3902)  time: 0.7123  data: 0.4499  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.8350 (0.8787)  acc1: 83.3333 (78.6706)  acc5: 97.9167 (98.1151)  time: 0.3411  data: 0.0891  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9586 (0.9139)  acc1: 76.0417 (77.1169)  acc5: 96.8750 (97.3118)  time: 0.2675  data: 0.0256  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9587 (0.9488)  acc1: 70.8333 (75.5159)  acc5: 96.8750 (96.9682)  time: 0.2349  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3869 s / it)\n",
            "* Acc@1 75.516 Acc@5 96.968 loss 0.949\n",
            "Accuracy of the model on the 3925 test images: 75.5%\n",
            "Max accuracy: 75.52%\n",
            "Test:  [ 0/41]  eta: 0:02:32  loss: 3.8215 (3.8215)  acc1: 38.5417 (38.5417)  acc5: 75.0000 (75.0000)  time: 3.7209  data: 3.3418  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 3.8649 (4.1308)  acc1: 29.1667 (24.6212)  acc5: 75.0000 (76.2311)  time: 0.6422  data: 0.3867  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 4.8419 (4.7747)  acc1: 8.3333 (16.2202)  acc5: 63.5417 (65.9722)  time: 0.3237  data: 0.0809  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.4736 (4.8818)  acc1: 3.1250 (15.3226)  acc5: 59.3750 (64.0457)  time: 0.2936  data: 0.0525  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4494 (4.5160)  acc1: 14.5833 (21.2484)  acc5: 77.0833 (67.0064)  time: 0.2537  data: 0.0172  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3844 s / it)\n",
            "* Acc@1 21.248 Acc@5 67.006 loss 4.516\n",
            "Accuracy of the model EMA on 3925 test images: 21.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [61]  [  0/147]  eta: 0:07:46  lr: 0.001922  min_lr: 0.001922  loss: 2.6749 (2.6749)  weight_decay: 0.0500 (0.0500)  time: 3.1759  data: 2.5718  max mem: 5608\n",
            "Epoch: [61]  [ 10/147]  eta: 0:01:45  lr: 0.001918  min_lr: 0.001918  loss: 2.5278 (2.4857)  weight_decay: 0.0500 (0.0500)  time: 0.7730  data: 0.2355  max mem: 5608\n",
            "Epoch: [61]  [ 20/147]  eta: 0:01:23  lr: 0.001911  min_lr: 0.001911  loss: 2.5278 (2.5214)  weight_decay: 0.0500 (0.0500)  time: 0.5278  data: 0.0021  max mem: 5608\n",
            "Epoch: [61]  [ 30/147]  eta: 0:01:11  lr: 0.001907  min_lr: 0.001907  loss: 2.5586 (2.5513)  weight_decay: 0.0500 (0.0500)  time: 0.5175  data: 0.0020  max mem: 5608\n",
            "Epoch: [61]  [ 40/147]  eta: 0:01:02  lr: 0.001900  min_lr: 0.001900  loss: 2.5672 (2.5405)  weight_decay: 0.0500 (0.0500)  time: 0.5137  data: 0.0013  max mem: 5608\n",
            "Epoch: [61]  [ 50/147]  eta: 0:00:55  lr: 0.001896  min_lr: 0.001896  loss: 2.4911 (2.5405)  weight_decay: 0.0500 (0.0500)  time: 0.5169  data: 0.0026  max mem: 5608\n",
            "Epoch: [61]  [ 60/147]  eta: 0:00:48  lr: 0.001889  min_lr: 0.001889  loss: 2.4740 (2.5332)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0027  max mem: 5608\n",
            "Epoch: [61]  [ 70/147]  eta: 0:00:42  lr: 0.001885  min_lr: 0.001885  loss: 2.4503 (2.5352)  weight_decay: 0.0500 (0.0500)  time: 0.4996  data: 0.0012  max mem: 5608\n",
            "Epoch: [61]  [ 80/147]  eta: 0:00:36  lr: 0.001878  min_lr: 0.001878  loss: 2.4704 (2.5339)  weight_decay: 0.0500 (0.0500)  time: 0.5016  data: 0.0016  max mem: 5608\n",
            "Epoch: [61]  [ 90/147]  eta: 0:00:30  lr: 0.001874  min_lr: 0.001874  loss: 2.6652 (2.5452)  weight_decay: 0.0500 (0.0500)  time: 0.5040  data: 0.0021  max mem: 5608\n",
            "Epoch: [61]  [100/147]  eta: 0:00:25  lr: 0.001868  min_lr: 0.001868  loss: 2.6035 (2.5407)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0020  max mem: 5608\n",
            "Epoch: [61]  [110/147]  eta: 0:00:19  lr: 0.001863  min_lr: 0.001863  loss: 2.4292 (2.5241)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0023  max mem: 5608\n",
            "Epoch: [61]  [120/147]  eta: 0:00:14  lr: 0.001857  min_lr: 0.001857  loss: 2.5491 (2.5332)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0023  max mem: 5608\n",
            "Epoch: [61]  [130/147]  eta: 0:00:08  lr: 0.001852  min_lr: 0.001852  loss: 2.5520 (2.5239)  weight_decay: 0.0500 (0.0500)  time: 0.4996  data: 0.0013  max mem: 5608\n",
            "Epoch: [61]  [140/147]  eta: 0:00:03  lr: 0.001846  min_lr: 0.001846  loss: 2.4022 (2.5253)  weight_decay: 0.0500 (0.0500)  time: 0.4933  data: 0.0005  max mem: 5608\n",
            "Epoch: [61]  [146/147]  eta: 0:00:00  lr: 0.001846  min_lr: 0.001846  loss: 2.4801 (2.5247)  weight_decay: 0.0500 (0.0500)  time: 0.4207  data: 0.0002  max mem: 5608\n",
            "Epoch: [61] Total time: 0:01:16 (0.5186 s / it)\n",
            "Averaged stats: lr: 0.001846  min_lr: 0.001846  loss: 2.4801 (2.5247)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:31  loss: 0.4957 (0.4957)  acc1: 92.7083 (92.7083)  acc5: 97.9167 (97.9167)  time: 5.1641  data: 4.8098  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.6254 (0.6333)  acc1: 85.4167 (86.1742)  acc5: 98.9583 (98.1061)  time: 0.7244  data: 0.4752  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.7146 (0.7899)  acc1: 83.3333 (80.3075)  acc5: 98.9583 (98.1647)  time: 0.3204  data: 0.0770  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 1.0143 (0.8858)  acc1: 71.8750 (76.8817)  acc5: 96.8750 (97.5806)  time: 0.2994  data: 0.0565  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9771 (0.9014)  acc1: 72.9167 (76.6369)  acc5: 95.8333 (97.0701)  time: 0.2332  data: 0.0004  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.4101 s / it)\n",
            "* Acc@1 76.637 Acc@5 97.070 loss 0.901\n",
            "Accuracy of the model on the 3925 test images: 76.6%\n",
            "Max accuracy: 76.64%\n",
            "Test:  [ 0/41]  eta: 0:02:31  loss: 3.7917 (3.7917)  acc1: 38.5417 (38.5417)  acc5: 75.0000 (75.0000)  time: 3.6930  data: 3.4080  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 3.8451 (4.1053)  acc1: 29.1667 (24.4318)  acc5: 78.1250 (76.7992)  time: 0.6233  data: 0.3791  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.8046 (4.7552)  acc1: 8.3333 (15.9722)  acc5: 63.5417 (66.2698)  time: 0.2817  data: 0.0436  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.4523 (4.8672)  acc1: 3.1250 (15.1210)  acc5: 57.2917 (64.2137)  time: 0.2401  data: 0.0056  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4444 (4.4969)  acc1: 14.5833 (21.1720)  acc5: 78.1250 (67.1592)  time: 0.2325  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3544 s / it)\n",
            "* Acc@1 21.172 Acc@5 67.159 loss 4.497\n",
            "Accuracy of the model EMA on 3925 test images: 21.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [62]  [  0/147]  eta: 0:10:16  lr: 0.001844  min_lr: 0.001844  loss: 2.5735 (2.5735)  weight_decay: 0.0500 (0.0500)  time: 4.1926  data: 3.4703  max mem: 5608\n",
            "Epoch: [62]  [ 10/147]  eta: 0:01:58  lr: 0.001839  min_lr: 0.001839  loss: 2.6302 (2.6053)  weight_decay: 0.0500 (0.0500)  time: 0.8666  data: 0.3157  max mem: 5608\n",
            "Epoch: [62]  [ 20/147]  eta: 0:01:28  lr: 0.001833  min_lr: 0.001833  loss: 2.6062 (2.5631)  weight_decay: 0.0500 (0.0500)  time: 0.5237  data: 0.0010  max mem: 5608\n",
            "Epoch: [62]  [ 30/147]  eta: 0:01:15  lr: 0.001828  min_lr: 0.001828  loss: 2.5918 (2.5739)  weight_decay: 0.0500 (0.0500)  time: 0.5192  data: 0.0028  max mem: 5608\n",
            "Epoch: [62]  [ 40/147]  eta: 0:01:05  lr: 0.001822  min_lr: 0.001822  loss: 2.6337 (2.5773)  weight_decay: 0.0500 (0.0500)  time: 0.5224  data: 0.0023  max mem: 5608\n",
            "Epoch: [62]  [ 50/147]  eta: 0:00:57  lr: 0.001818  min_lr: 0.001818  loss: 2.6337 (2.5787)  weight_decay: 0.0500 (0.0500)  time: 0.5143  data: 0.0022  max mem: 5608\n",
            "Epoch: [62]  [ 60/147]  eta: 0:00:50  lr: 0.001811  min_lr: 0.001811  loss: 2.6249 (2.5825)  weight_decay: 0.0500 (0.0500)  time: 0.5096  data: 0.0024  max mem: 5608\n",
            "Epoch: [62]  [ 70/147]  eta: 0:00:43  lr: 0.001807  min_lr: 0.001807  loss: 2.6249 (2.5725)  weight_decay: 0.0500 (0.0500)  time: 0.5086  data: 0.0008  max mem: 5608\n",
            "Epoch: [62]  [ 80/147]  eta: 0:00:37  lr: 0.001800  min_lr: 0.001800  loss: 2.6274 (2.5700)  weight_decay: 0.0500 (0.0500)  time: 0.5031  data: 0.0014  max mem: 5608\n",
            "Epoch: [62]  [ 90/147]  eta: 0:00:31  lr: 0.001796  min_lr: 0.001796  loss: 2.6431 (2.5785)  weight_decay: 0.0500 (0.0500)  time: 0.4996  data: 0.0026  max mem: 5608\n",
            "Epoch: [62]  [100/147]  eta: 0:00:25  lr: 0.001789  min_lr: 0.001789  loss: 2.6114 (2.5640)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0043  max mem: 5608\n",
            "Epoch: [62]  [110/147]  eta: 0:00:20  lr: 0.001785  min_lr: 0.001785  loss: 2.4471 (2.5608)  weight_decay: 0.0500 (0.0500)  time: 0.5019  data: 0.0033  max mem: 5608\n",
            "Epoch: [62]  [120/147]  eta: 0:00:14  lr: 0.001778  min_lr: 0.001778  loss: 2.4326 (2.5481)  weight_decay: 0.0500 (0.0500)  time: 0.4929  data: 0.0007  max mem: 5608\n",
            "Epoch: [62]  [130/147]  eta: 0:00:09  lr: 0.001774  min_lr: 0.001774  loss: 2.4326 (2.5489)  weight_decay: 0.0500 (0.0500)  time: 0.4944  data: 0.0012  max mem: 5608\n",
            "Epoch: [62]  [140/147]  eta: 0:00:03  lr: 0.001768  min_lr: 0.001768  loss: 2.4400 (2.5441)  weight_decay: 0.0500 (0.0500)  time: 0.4952  data: 0.0009  max mem: 5608\n",
            "Epoch: [62]  [146/147]  eta: 0:00:00  lr: 0.001768  min_lr: 0.001768  loss: 2.4400 (2.5414)  weight_decay: 0.0500 (0.0500)  time: 0.4202  data: 0.0002  max mem: 5608\n",
            "Epoch: [62] Total time: 0:01:17 (0.5248 s / it)\n",
            "Averaged stats: lr: 0.001768  min_lr: 0.001768  loss: 2.4400 (2.5414)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:27  loss: 0.7239 (0.7239)  acc1: 84.3750 (84.3750)  acc5: 94.7917 (94.7917)  time: 2.1327  data: 1.8499  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 0.8457 (0.8168)  acc1: 80.2083 (80.1136)  acc5: 96.8750 (96.9697)  time: 0.5354  data: 0.2861  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.8457 (0.8770)  acc1: 78.1250 (77.9762)  acc5: 97.9167 (97.5198)  time: 0.3174  data: 0.0702  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9142 (0.9028)  acc1: 75.0000 (76.7809)  acc5: 96.8750 (97.1774)  time: 0.2856  data: 0.0411  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9366 (0.8936)  acc1: 75.0000 (76.5350)  acc5: 96.8750 (97.2739)  time: 0.2731  data: 0.0384  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3499 s / it)\n",
            "* Acc@1 76.535 Acc@5 97.274 loss 0.894\n",
            "Accuracy of the model on the 3925 test images: 76.5%\n",
            "Max accuracy: 76.64%\n",
            "Test:  [ 0/41]  eta: 0:02:07  loss: 3.7637 (3.7637)  acc1: 38.5417 (38.5417)  acc5: 73.9583 (73.9583)  time: 3.1100  data: 2.8179  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 3.8281 (4.0816)  acc1: 29.1667 (24.1477)  acc5: 78.1250 (76.9886)  time: 0.5049  data: 0.2576  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:07  loss: 4.7678 (4.7366)  acc1: 9.3750 (15.8730)  acc5: 63.5417 (66.4187)  time: 0.2417  data: 0.0019  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.4275 (4.8548)  acc1: 2.0833 (15.0538)  acc5: 56.2500 (64.2473)  time: 0.2385  data: 0.0012  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4461 (4.4796)  acc1: 17.7083 (21.2739)  acc5: 78.1250 (67.2611)  time: 0.2354  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3227 s / it)\n",
            "* Acc@1 21.274 Acc@5 67.261 loss 4.480\n",
            "Accuracy of the model EMA on 3925 test images: 21.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [63]  [  0/147]  eta: 0:09:25  lr: 0.001765  min_lr: 0.001765  loss: 2.2207 (2.2207)  weight_decay: 0.0500 (0.0500)  time: 3.8490  data: 3.2656  max mem: 5608\n",
            "Epoch: [63]  [ 10/147]  eta: 0:01:52  lr: 0.001761  min_lr: 0.001761  loss: 2.4782 (2.4703)  weight_decay: 0.0500 (0.0500)  time: 0.8204  data: 0.2982  max mem: 5608\n",
            "Epoch: [63]  [ 20/147]  eta: 0:01:26  lr: 0.001755  min_lr: 0.001755  loss: 2.5863 (2.5178)  weight_decay: 0.0500 (0.0500)  time: 0.5190  data: 0.0022  max mem: 5608\n",
            "Epoch: [63]  [ 30/147]  eta: 0:01:13  lr: 0.001750  min_lr: 0.001750  loss: 2.5188 (2.5194)  weight_decay: 0.0500 (0.0500)  time: 0.5182  data: 0.0022  max mem: 5608\n",
            "Epoch: [63]  [ 40/147]  eta: 0:01:04  lr: 0.001744  min_lr: 0.001744  loss: 2.5130 (2.5249)  weight_decay: 0.0500 (0.0500)  time: 0.5176  data: 0.0010  max mem: 5608\n",
            "Epoch: [63]  [ 50/147]  eta: 0:00:56  lr: 0.001740  min_lr: 0.001740  loss: 2.5728 (2.5360)  weight_decay: 0.0500 (0.0500)  time: 0.5130  data: 0.0010  max mem: 5608\n",
            "Epoch: [63]  [ 60/147]  eta: 0:00:49  lr: 0.001733  min_lr: 0.001733  loss: 2.5586 (2.5147)  weight_decay: 0.0500 (0.0500)  time: 0.5062  data: 0.0016  max mem: 5608\n",
            "Epoch: [63]  [ 70/147]  eta: 0:00:43  lr: 0.001729  min_lr: 0.001729  loss: 2.3998 (2.4987)  weight_decay: 0.0500 (0.0500)  time: 0.5069  data: 0.0016  max mem: 5608\n",
            "Epoch: [63]  [ 80/147]  eta: 0:00:37  lr: 0.001722  min_lr: 0.001722  loss: 2.4363 (2.5018)  weight_decay: 0.0500 (0.0500)  time: 0.5080  data: 0.0029  max mem: 5608\n",
            "Epoch: [63]  [ 90/147]  eta: 0:00:31  lr: 0.001718  min_lr: 0.001718  loss: 2.4681 (2.4926)  weight_decay: 0.0500 (0.0500)  time: 0.5029  data: 0.0032  max mem: 5608\n",
            "Epoch: [63]  [100/147]  eta: 0:00:25  lr: 0.001711  min_lr: 0.001711  loss: 2.4396 (2.4912)  weight_decay: 0.0500 (0.0500)  time: 0.5020  data: 0.0020  max mem: 5608\n",
            "Epoch: [63]  [110/147]  eta: 0:00:19  lr: 0.001707  min_lr: 0.001707  loss: 2.5425 (2.4980)  weight_decay: 0.0500 (0.0500)  time: 0.5060  data: 0.0027  max mem: 5608\n",
            "Epoch: [63]  [120/147]  eta: 0:00:14  lr: 0.001701  min_lr: 0.001701  loss: 2.5637 (2.5031)  weight_decay: 0.0500 (0.0500)  time: 0.5029  data: 0.0031  max mem: 5608\n",
            "Epoch: [63]  [130/147]  eta: 0:00:09  lr: 0.001696  min_lr: 0.001696  loss: 2.5722 (2.5052)  weight_decay: 0.0500 (0.0500)  time: 0.4972  data: 0.0018  max mem: 5608\n",
            "Epoch: [63]  [140/147]  eta: 0:00:03  lr: 0.001690  min_lr: 0.001690  loss: 2.6167 (2.5150)  weight_decay: 0.0500 (0.0500)  time: 0.4953  data: 0.0005  max mem: 5608\n",
            "Epoch: [63]  [146/147]  eta: 0:00:00  lr: 0.001690  min_lr: 0.001690  loss: 2.6368 (2.5172)  weight_decay: 0.0500 (0.0500)  time: 0.4216  data: 0.0002  max mem: 5608\n",
            "Epoch: [63] Total time: 0:01:16 (0.5226 s / it)\n",
            "Averaged stats: lr: 0.001690  min_lr: 0.001690  loss: 2.6368 (2.5172)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:04  loss: 0.5458 (0.5458)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 3.0273  data: 2.7319  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 0.7378 (0.7846)  acc1: 85.4167 (81.7235)  acc5: 96.8750 (97.6326)  time: 0.5009  data: 0.2578  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.9678 (1.0200)  acc1: 79.1667 (71.9742)  acc5: 96.8750 (97.1726)  time: 0.2503  data: 0.0064  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 0.9678 (0.9506)  acc1: 79.1667 (75.1344)  acc5: 96.8750 (97.0766)  time: 0.2662  data: 0.0218  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8692 (0.9358)  acc1: 79.1667 (76.1529)  acc5: 96.8750 (97.0701)  time: 0.2546  data: 0.0207  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3324 s / it)\n",
            "* Acc@1 76.153 Acc@5 97.070 loss 0.936\n",
            "Accuracy of the model on the 3925 test images: 76.2%\n",
            "Max accuracy: 76.64%\n",
            "Test:  [ 0/41]  eta: 0:02:14  loss: 3.7391 (3.7391)  acc1: 38.5417 (38.5417)  acc5: 73.9583 (73.9583)  time: 3.2709  data: 2.9909  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 3.8080 (4.0574)  acc1: 28.1250 (24.2424)  acc5: 81.2500 (77.9356)  time: 0.5153  data: 0.2734  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.7277 (4.7168)  acc1: 9.3750 (15.9226)  acc5: 67.7083 (67.0635)  time: 0.2416  data: 0.0022  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.4010 (4.8405)  acc1: 2.0833 (15.0874)  acc5: 56.2500 (64.6505)  time: 0.2407  data: 0.0015  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4303 (4.4608)  acc1: 17.7083 (21.4268)  acc5: 78.1250 (67.6688)  time: 0.2351  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3274 s / it)\n",
            "* Acc@1 21.427 Acc@5 67.669 loss 4.461\n",
            "Accuracy of the model EMA on 3925 test images: 21.4%\n",
            "Max EMA accuracy: 21.43%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [64]  [  0/147]  eta: 0:07:58  lr: 0.001688  min_lr: 0.001688  loss: 2.1467 (2.1467)  weight_decay: 0.0500 (0.0500)  time: 3.2570  data: 2.6644  max mem: 5608\n",
            "Epoch: [64]  [ 10/147]  eta: 0:01:46  lr: 0.001683  min_lr: 0.001683  loss: 2.6003 (2.5057)  weight_decay: 0.0500 (0.0500)  time: 0.7756  data: 0.2439  max mem: 5608\n",
            "Epoch: [64]  [ 20/147]  eta: 0:01:22  lr: 0.001677  min_lr: 0.001677  loss: 2.5877 (2.5021)  weight_decay: 0.0500 (0.0500)  time: 0.5210  data: 0.0013  max mem: 5608\n",
            "Epoch: [64]  [ 30/147]  eta: 0:01:11  lr: 0.001673  min_lr: 0.001673  loss: 2.5269 (2.5135)  weight_decay: 0.0500 (0.0500)  time: 0.5149  data: 0.0005  max mem: 5608\n",
            "Epoch: [64]  [ 40/147]  eta: 0:01:02  lr: 0.001666  min_lr: 0.001666  loss: 2.5418 (2.5103)  weight_decay: 0.0500 (0.0500)  time: 0.5111  data: 0.0006  max mem: 5608\n",
            "Epoch: [64]  [ 50/147]  eta: 0:00:55  lr: 0.001662  min_lr: 0.001662  loss: 2.5348 (2.5119)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0014  max mem: 5608\n",
            "Epoch: [64]  [ 60/147]  eta: 0:00:48  lr: 0.001655  min_lr: 0.001655  loss: 2.5348 (2.5073)  weight_decay: 0.0500 (0.0500)  time: 0.5108  data: 0.0022  max mem: 5608\n",
            "Epoch: [64]  [ 70/147]  eta: 0:00:42  lr: 0.001651  min_lr: 0.001651  loss: 2.4835 (2.5044)  weight_decay: 0.0500 (0.0500)  time: 0.5130  data: 0.0023  max mem: 5608\n",
            "Epoch: [64]  [ 80/147]  eta: 0:00:36  lr: 0.001645  min_lr: 0.001645  loss: 2.4835 (2.4972)  weight_decay: 0.0500 (0.0500)  time: 0.5043  data: 0.0016  max mem: 5608\n",
            "Epoch: [64]  [ 90/147]  eta: 0:00:30  lr: 0.001640  min_lr: 0.001640  loss: 2.5614 (2.5036)  weight_decay: 0.0500 (0.0500)  time: 0.5032  data: 0.0015  max mem: 5608\n",
            "Epoch: [64]  [100/147]  eta: 0:00:25  lr: 0.001634  min_lr: 0.001634  loss: 2.5873 (2.5053)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0012  max mem: 5608\n",
            "Epoch: [64]  [110/147]  eta: 0:00:19  lr: 0.001630  min_lr: 0.001630  loss: 2.5370 (2.5030)  weight_decay: 0.0500 (0.0500)  time: 0.5080  data: 0.0005  max mem: 5608\n",
            "Epoch: [64]  [120/147]  eta: 0:00:14  lr: 0.001623  min_lr: 0.001623  loss: 2.5253 (2.5011)  weight_decay: 0.0500 (0.0500)  time: 0.5060  data: 0.0014  max mem: 5608\n",
            "Epoch: [64]  [130/147]  eta: 0:00:09  lr: 0.001619  min_lr: 0.001619  loss: 2.4283 (2.4955)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0018  max mem: 5608\n",
            "Epoch: [64]  [140/147]  eta: 0:00:03  lr: 0.001613  min_lr: 0.001613  loss: 2.5456 (2.5047)  weight_decay: 0.0500 (0.0500)  time: 0.4976  data: 0.0006  max mem: 5608\n",
            "Epoch: [64]  [146/147]  eta: 0:00:00  lr: 0.001613  min_lr: 0.001613  loss: 2.5334 (2.4995)  weight_decay: 0.0500 (0.0500)  time: 0.4199  data: 0.0002  max mem: 5608\n",
            "Epoch: [64] Total time: 0:01:16 (0.5192 s / it)\n",
            "Averaged stats: lr: 0.001613  min_lr: 0.001613  loss: 2.5334 (2.4995)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:43  loss: 0.5156 (0.5156)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.9935  data: 3.6354  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 0.6153 (0.6412)  acc1: 88.5417 (87.0265)  acc5: 97.9167 (98.4849)  time: 0.6093  data: 0.3514  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.7806 (0.8572)  acc1: 81.2500 (78.0258)  acc5: 97.9167 (97.9167)  time: 0.2894  data: 0.0421  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9096 (0.8826)  acc1: 78.1250 (77.3522)  acc5: 96.8750 (97.4126)  time: 0.2822  data: 0.0382  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8977 (0.8896)  acc1: 78.8235 (77.4777)  acc5: 96.8750 (97.2229)  time: 0.2426  data: 0.0077  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3664 s / it)\n",
            "* Acc@1 77.478 Acc@5 97.223 loss 0.890\n",
            "Accuracy of the model on the 3925 test images: 77.5%\n",
            "Max accuracy: 77.48%\n",
            "Test:  [ 0/41]  eta: 0:02:34  loss: 3.7140 (3.7140)  acc1: 38.5417 (38.5417)  acc5: 75.0000 (75.0000)  time: 3.7804  data: 3.4795  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.7863 (4.0342)  acc1: 28.1250 (23.9583)  acc5: 81.2500 (78.3144)  time: 0.5644  data: 0.3269  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.6932 (4.6990)  acc1: 9.3750 (15.8234)  acc5: 67.7083 (67.3115)  time: 0.2441  data: 0.0067  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.3774 (4.8281)  acc1: 2.0833 (14.9530)  acc5: 56.2500 (64.9866)  time: 0.2663  data: 0.0218  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4157 (4.4441)  acc1: 19.7917 (21.5032)  acc5: 79.1667 (68.0000)  time: 0.2618  data: 0.0209  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3484 s / it)\n",
            "* Acc@1 21.503 Acc@5 68.000 loss 4.444\n",
            "Accuracy of the model EMA on 3925 test images: 21.5%\n",
            "Max EMA accuracy: 21.50%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [65]  [  0/147]  eta: 0:07:56  lr: 0.001610  min_lr: 0.001610  loss: 2.3911 (2.3911)  weight_decay: 0.0500 (0.0500)  time: 3.2445  data: 2.6159  max mem: 5608\n",
            "Epoch: [65]  [ 10/147]  eta: 0:01:44  lr: 0.001606  min_lr: 0.001606  loss: 2.5322 (2.5294)  weight_decay: 0.0500 (0.0500)  time: 0.7641  data: 0.2396  max mem: 5608\n",
            "Epoch: [65]  [ 20/147]  eta: 0:01:22  lr: 0.001600  min_lr: 0.001600  loss: 2.5150 (2.5389)  weight_decay: 0.0500 (0.0500)  time: 0.5173  data: 0.0019  max mem: 5608\n",
            "Epoch: [65]  [ 30/147]  eta: 0:01:10  lr: 0.001595  min_lr: 0.001595  loss: 2.5150 (2.5490)  weight_decay: 0.0500 (0.0500)  time: 0.5142  data: 0.0021  max mem: 5608\n",
            "Epoch: [65]  [ 40/147]  eta: 0:01:02  lr: 0.001589  min_lr: 0.001589  loss: 2.5493 (2.5263)  weight_decay: 0.0500 (0.0500)  time: 0.5117  data: 0.0016  max mem: 5608\n",
            "Epoch: [65]  [ 50/147]  eta: 0:00:55  lr: 0.001585  min_lr: 0.001585  loss: 2.4271 (2.5109)  weight_decay: 0.0500 (0.0500)  time: 0.5171  data: 0.0017  max mem: 5608\n",
            "Epoch: [65]  [ 60/147]  eta: 0:00:48  lr: 0.001578  min_lr: 0.001578  loss: 2.4339 (2.5074)  weight_decay: 0.0500 (0.0500)  time: 0.5156  data: 0.0013  max mem: 5608\n",
            "Epoch: [65]  [ 70/147]  eta: 0:00:42  lr: 0.001574  min_lr: 0.001574  loss: 2.6151 (2.5245)  weight_decay: 0.0500 (0.0500)  time: 0.5060  data: 0.0004  max mem: 5608\n",
            "Epoch: [65]  [ 80/147]  eta: 0:00:36  lr: 0.001568  min_lr: 0.001568  loss: 2.5833 (2.5278)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0013  max mem: 5608\n",
            "Epoch: [65]  [ 90/147]  eta: 0:00:30  lr: 0.001563  min_lr: 0.001563  loss: 2.5492 (2.5221)  weight_decay: 0.0500 (0.0500)  time: 0.5049  data: 0.0015  max mem: 5608\n",
            "Epoch: [65]  [100/147]  eta: 0:00:25  lr: 0.001557  min_lr: 0.001557  loss: 2.4569 (2.5086)  weight_decay: 0.0500 (0.0500)  time: 0.4992  data: 0.0010  max mem: 5608\n",
            "Epoch: [65]  [110/147]  eta: 0:00:19  lr: 0.001553  min_lr: 0.001553  loss: 2.4932 (2.5173)  weight_decay: 0.0500 (0.0500)  time: 0.4941  data: 0.0021  max mem: 5608\n",
            "Epoch: [65]  [120/147]  eta: 0:00:14  lr: 0.001546  min_lr: 0.001546  loss: 2.5571 (2.5178)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0040  max mem: 5608\n",
            "Epoch: [65]  [130/147]  eta: 0:00:08  lr: 0.001542  min_lr: 0.001542  loss: 2.5236 (2.5208)  weight_decay: 0.0500 (0.0500)  time: 0.5068  data: 0.0035  max mem: 5608\n",
            "Epoch: [65]  [140/147]  eta: 0:00:03  lr: 0.001536  min_lr: 0.001536  loss: 2.4823 (2.5172)  weight_decay: 0.0500 (0.0500)  time: 0.4962  data: 0.0012  max mem: 5608\n",
            "Epoch: [65]  [146/147]  eta: 0:00:00  lr: 0.001536  min_lr: 0.001536  loss: 2.5304 (2.5206)  weight_decay: 0.0500 (0.0500)  time: 0.4190  data: 0.0002  max mem: 5608\n",
            "Epoch: [65] Total time: 0:01:16 (0.5180 s / it)\n",
            "Averaged stats: lr: 0.001536  min_lr: 0.001536  loss: 2.5304 (2.5206)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:42  loss: 0.5535 (0.5535)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 5.4361  data: 5.0471  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.6715 (0.6812)  acc1: 86.4583 (86.5530)  acc5: 97.9167 (98.2955)  time: 0.7167  data: 0.4610  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.7367 (0.8710)  acc1: 82.2917 (79.1667)  acc5: 97.9167 (98.0159)  time: 0.2422  data: 0.0019  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9477 (0.9020)  acc1: 73.9583 (77.6546)  acc5: 96.8750 (97.3454)  time: 0.2366  data: 0.0007  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8556 (0.8991)  acc1: 76.0417 (77.6815)  acc5: 96.8750 (97.1975)  time: 0.2313  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3724 s / it)\n",
            "* Acc@1 77.682 Acc@5 97.197 loss 0.899\n",
            "Accuracy of the model on the 3925 test images: 77.7%\n",
            "Max accuracy: 77.68%\n",
            "Test:  [ 0/41]  eta: 0:04:13  loss: 3.6890 (3.6890)  acc1: 36.4583 (36.4583)  acc5: 75.0000 (75.0000)  time: 6.1759  data: 5.8810  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:29  loss: 3.7669 (4.0119)  acc1: 28.1250 (23.7689)  acc5: 81.2500 (78.8826)  time: 0.9511  data: 0.7033  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 4.6593 (4.6821)  acc1: 9.3750 (15.7242)  acc5: 69.7917 (67.7083)  time: 0.3356  data: 0.0935  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3549 (4.8169)  acc1: 2.0833 (14.8858)  acc5: 56.2500 (65.2218)  time: 0.2411  data: 0.0008  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4039 (4.4285)  acc1: 20.8333 (21.5541)  acc5: 79.1667 (68.1019)  time: 0.2360  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:18 (0.4414 s / it)\n",
            "* Acc@1 21.554 Acc@5 68.102 loss 4.428\n",
            "Accuracy of the model EMA on 3925 test images: 21.6%\n",
            "Max EMA accuracy: 21.55%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [66]  [  0/147]  eta: 0:06:58  lr: 0.001534  min_lr: 0.001534  loss: 2.6261 (2.6261)  weight_decay: 0.0500 (0.0500)  time: 2.8490  data: 2.1945  max mem: 5608\n",
            "Epoch: [66]  [ 10/147]  eta: 0:01:55  lr: 0.001529  min_lr: 0.001529  loss: 2.4883 (2.4791)  weight_decay: 0.0500 (0.0500)  time: 0.8436  data: 0.2597  max mem: 5608\n",
            "Epoch: [66]  [ 20/147]  eta: 0:01:27  lr: 0.001523  min_lr: 0.001523  loss: 2.6271 (2.5713)  weight_decay: 0.0500 (0.0500)  time: 0.5775  data: 0.0333  max mem: 5608\n",
            "Epoch: [66]  [ 30/147]  eta: 0:01:13  lr: 0.001519  min_lr: 0.001519  loss: 2.6347 (2.5503)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0011  max mem: 5608\n",
            "Epoch: [66]  [ 40/147]  eta: 0:01:04  lr: 0.001513  min_lr: 0.001513  loss: 2.6710 (2.5838)  weight_decay: 0.0500 (0.0500)  time: 0.5184  data: 0.0018  max mem: 5608\n",
            "Epoch: [66]  [ 50/147]  eta: 0:00:56  lr: 0.001508  min_lr: 0.001508  loss: 2.6858 (2.5856)  weight_decay: 0.0500 (0.0500)  time: 0.5208  data: 0.0017  max mem: 5608\n",
            "Epoch: [66]  [ 60/147]  eta: 0:00:49  lr: 0.001502  min_lr: 0.001502  loss: 2.5717 (2.5608)  weight_decay: 0.0500 (0.0500)  time: 0.5120  data: 0.0012  max mem: 5608\n",
            "Epoch: [66]  [ 70/147]  eta: 0:00:43  lr: 0.001498  min_lr: 0.001498  loss: 2.5365 (2.5531)  weight_decay: 0.0500 (0.0500)  time: 0.5068  data: 0.0020  max mem: 5608\n",
            "Epoch: [66]  [ 80/147]  eta: 0:00:37  lr: 0.001491  min_lr: 0.001491  loss: 2.4434 (2.5417)  weight_decay: 0.0500 (0.0500)  time: 0.5071  data: 0.0024  max mem: 5608\n",
            "Epoch: [66]  [ 90/147]  eta: 0:00:31  lr: 0.001487  min_lr: 0.001487  loss: 2.4512 (2.5417)  weight_decay: 0.0500 (0.0500)  time: 0.5010  data: 0.0017  max mem: 5608\n",
            "Epoch: [66]  [100/147]  eta: 0:00:25  lr: 0.001481  min_lr: 0.001481  loss: 2.5828 (2.5316)  weight_decay: 0.0500 (0.0500)  time: 0.4976  data: 0.0025  max mem: 5608\n",
            "Epoch: [66]  [110/147]  eta: 0:00:20  lr: 0.001477  min_lr: 0.001477  loss: 2.4952 (2.5297)  weight_decay: 0.0500 (0.0500)  time: 0.5028  data: 0.0025  max mem: 5608\n",
            "Epoch: [66]  [120/147]  eta: 0:00:14  lr: 0.001470  min_lr: 0.001470  loss: 2.6634 (2.5382)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0029  max mem: 5608\n",
            "Epoch: [66]  [130/147]  eta: 0:00:09  lr: 0.001466  min_lr: 0.001466  loss: 2.4830 (2.5240)  weight_decay: 0.0500 (0.0500)  time: 0.4969  data: 0.0035  max mem: 5608\n",
            "Epoch: [66]  [140/147]  eta: 0:00:03  lr: 0.001460  min_lr: 0.001460  loss: 2.4830 (2.5261)  weight_decay: 0.0500 (0.0500)  time: 0.4944  data: 0.0017  max mem: 5608\n",
            "Epoch: [66]  [146/147]  eta: 0:00:00  lr: 0.001460  min_lr: 0.001460  loss: 2.5083 (2.5278)  weight_decay: 0.0500 (0.0500)  time: 0.4204  data: 0.0003  max mem: 5608\n",
            "Epoch: [66] Total time: 0:01:17 (0.5242 s / it)\n",
            "Averaged stats: lr: 0.001460  min_lr: 0.001460  loss: 2.5083 (2.5278)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:22  loss: 0.5845 (0.5845)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 3.4722  data: 3.1908  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.7360 (0.6855)  acc1: 83.3333 (85.4167)  acc5: 97.9167 (98.1061)  time: 0.5561  data: 0.3103  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.7659 (0.8475)  acc1: 82.2917 (78.6706)  acc5: 97.9167 (97.9167)  time: 0.2550  data: 0.0135  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 0.8343 (0.8547)  acc1: 78.1250 (78.5954)  acc5: 96.8750 (97.6479)  time: 0.2401  data: 0.0025  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9219 (0.8722)  acc1: 76.4706 (78.0127)  acc5: 96.8750 (97.4013)  time: 0.2319  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3355 s / it)\n",
            "* Acc@1 78.013 Acc@5 97.401 loss 0.872\n",
            "Accuracy of the model on the 3925 test images: 78.0%\n",
            "Max accuracy: 78.01%\n",
            "Test:  [ 0/41]  eta: 0:02:58  loss: 3.6663 (3.6663)  acc1: 35.4167 (35.4167)  acc5: 76.0417 (76.0417)  time: 4.3475  data: 4.0705  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 3.7521 (3.9912)  acc1: 27.0833 (23.5795)  acc5: 81.2500 (79.2614)  time: 0.6173  data: 0.3753  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.6259 (4.6656)  acc1: 10.4167 (15.5258)  acc5: 69.7917 (68.0556)  time: 0.2409  data: 0.0046  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.3308 (4.8069)  acc1: 2.0833 (14.6841)  acc5: 56.2500 (65.4234)  time: 0.2355  data: 0.0018  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3931 (4.4137)  acc1: 22.9167 (21.5032)  acc5: 79.1667 (68.3567)  time: 0.2330  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3535 s / it)\n",
            "* Acc@1 21.503 Acc@5 68.357 loss 4.414\n",
            "Accuracy of the model EMA on 3925 test images: 21.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [67]  [  0/147]  eta: 0:09:25  lr: 0.001458  min_lr: 0.001458  loss: 2.4713 (2.4713)  weight_decay: 0.0500 (0.0500)  time: 3.8496  data: 3.1879  max mem: 5608\n",
            "Epoch: [67]  [ 10/147]  eta: 0:01:52  lr: 0.001454  min_lr: 0.001454  loss: 2.5180 (2.5479)  weight_decay: 0.0500 (0.0500)  time: 0.8246  data: 0.2923  max mem: 5608\n",
            "Epoch: [67]  [ 20/147]  eta: 0:01:26  lr: 0.001447  min_lr: 0.001447  loss: 2.6034 (2.5881)  weight_decay: 0.0500 (0.0500)  time: 0.5186  data: 0.0027  max mem: 5608\n",
            "Epoch: [67]  [ 30/147]  eta: 0:01:13  lr: 0.001443  min_lr: 0.001443  loss: 2.5284 (2.5463)  weight_decay: 0.0500 (0.0500)  time: 0.5171  data: 0.0016  max mem: 5608\n",
            "Epoch: [67]  [ 40/147]  eta: 0:01:04  lr: 0.001437  min_lr: 0.001437  loss: 2.4226 (2.5196)  weight_decay: 0.0500 (0.0500)  time: 0.5198  data: 0.0008  max mem: 5608\n",
            "Epoch: [67]  [ 50/147]  eta: 0:00:56  lr: 0.001433  min_lr: 0.001433  loss: 2.4512 (2.5167)  weight_decay: 0.0500 (0.0500)  time: 0.5203  data: 0.0025  max mem: 5608\n",
            "Epoch: [67]  [ 60/147]  eta: 0:00:49  lr: 0.001426  min_lr: 0.001426  loss: 2.4512 (2.5154)  weight_decay: 0.0500 (0.0500)  time: 0.5184  data: 0.0036  max mem: 5608\n",
            "Epoch: [67]  [ 70/147]  eta: 0:00:43  lr: 0.001422  min_lr: 0.001422  loss: 2.4483 (2.5103)  weight_decay: 0.0500 (0.0500)  time: 0.5108  data: 0.0028  max mem: 5608\n",
            "Epoch: [67]  [ 80/147]  eta: 0:00:37  lr: 0.001416  min_lr: 0.001416  loss: 2.4483 (2.4930)  weight_decay: 0.0500 (0.0500)  time: 0.5036  data: 0.0030  max mem: 5608\n",
            "Epoch: [67]  [ 90/147]  eta: 0:00:31  lr: 0.001412  min_lr: 0.001412  loss: 2.3050 (2.4770)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0028  max mem: 5608\n",
            "Epoch: [67]  [100/147]  eta: 0:00:25  lr: 0.001405  min_lr: 0.001405  loss: 2.4872 (2.4923)  weight_decay: 0.0500 (0.0500)  time: 0.5067  data: 0.0033  max mem: 5608\n",
            "Epoch: [67]  [110/147]  eta: 0:00:20  lr: 0.001401  min_lr: 0.001401  loss: 2.5449 (2.4818)  weight_decay: 0.0500 (0.0500)  time: 0.5059  data: 0.0025  max mem: 5608\n",
            "Epoch: [67]  [120/147]  eta: 0:00:14  lr: 0.001395  min_lr: 0.001395  loss: 2.4899 (2.4869)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0008  max mem: 5608\n",
            "Epoch: [67]  [130/147]  eta: 0:00:09  lr: 0.001391  min_lr: 0.001391  loss: 2.6211 (2.4999)  weight_decay: 0.0500 (0.0500)  time: 0.4989  data: 0.0013  max mem: 5608\n",
            "Epoch: [67]  [140/147]  eta: 0:00:03  lr: 0.001385  min_lr: 0.001385  loss: 2.6205 (2.5001)  weight_decay: 0.0500 (0.0500)  time: 0.4989  data: 0.0009  max mem: 5608\n",
            "Epoch: [67]  [146/147]  eta: 0:00:00  lr: 0.001385  min_lr: 0.001385  loss: 2.6140 (2.5018)  weight_decay: 0.0500 (0.0500)  time: 0.4211  data: 0.0002  max mem: 5608\n",
            "Epoch: [67] Total time: 0:01:17 (0.5243 s / it)\n",
            "Averaged stats: lr: 0.001385  min_lr: 0.001385  loss: 2.6140 (2.5018)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:04  loss: 0.5884 (0.5884)  acc1: 89.5833 (89.5833)  acc5: 96.8750 (96.8750)  time: 4.5013  data: 4.2135  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 0.7450 (0.7310)  acc1: 84.3750 (84.0909)  acc5: 97.9167 (97.7273)  time: 0.6318  data: 0.3860  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.7594 (0.9572)  acc1: 82.2917 (73.8591)  acc5: 96.8750 (96.3790)  time: 0.2988  data: 0.0574  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.9198 (0.9613)  acc1: 75.0000 (74.2608)  acc5: 96.8750 (96.5390)  time: 0.3025  data: 0.0559  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8209 (0.9201)  acc1: 79.1667 (75.6943)  acc5: 97.9167 (96.8662)  time: 0.2409  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3831 s / it)\n",
            "* Acc@1 75.694 Acc@5 96.866 loss 0.920\n",
            "Accuracy of the model on the 3925 test images: 75.7%\n",
            "Max accuracy: 78.01%\n",
            "Test:  [ 0/41]  eta: 0:02:31  loss: 3.6411 (3.6411)  acc1: 35.4167 (35.4167)  acc5: 77.0833 (77.0833)  time: 3.6923  data: 3.3959  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.7503 (3.9713)  acc1: 27.0833 (23.7689)  acc5: 81.2500 (79.9242)  time: 0.5503  data: 0.3158  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.5940 (4.6505)  acc1: 11.4583 (15.6746)  acc5: 69.7917 (68.4524)  time: 0.2409  data: 0.0051  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.3092 (4.7983)  acc1: 2.0833 (14.7513)  acc5: 56.2500 (65.7258)  time: 0.2421  data: 0.0013  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3842 (4.4000)  acc1: 25.0000 (21.8089)  acc5: 80.2083 (68.6115)  time: 0.2420  data: 0.0063  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3398 s / it)\n",
            "* Acc@1 21.809 Acc@5 68.611 loss 4.400\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "Max EMA accuracy: 21.81%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [68]  [  0/147]  eta: 0:08:40  lr: 0.001383  min_lr: 0.001383  loss: 2.7097 (2.7097)  weight_decay: 0.0500 (0.0500)  time: 3.5390  data: 2.9459  max mem: 5608\n",
            "Epoch: [68]  [ 10/147]  eta: 0:01:47  lr: 0.001378  min_lr: 0.001378  loss: 2.6770 (2.6422)  weight_decay: 0.0500 (0.0500)  time: 0.7854  data: 0.2684  max mem: 5608\n",
            "Epoch: [68]  [ 20/147]  eta: 0:01:23  lr: 0.001372  min_lr: 0.001372  loss: 2.6259 (2.5939)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0023  max mem: 5608\n",
            "Epoch: [68]  [ 30/147]  eta: 0:01:11  lr: 0.001368  min_lr: 0.001368  loss: 2.6122 (2.5762)  weight_decay: 0.0500 (0.0500)  time: 0.5195  data: 0.0026  max mem: 5608\n",
            "Epoch: [68]  [ 40/147]  eta: 0:01:03  lr: 0.001362  min_lr: 0.001362  loss: 2.6231 (2.5728)  weight_decay: 0.0500 (0.0500)  time: 0.5151  data: 0.0016  max mem: 5608\n",
            "Epoch: [68]  [ 50/147]  eta: 0:00:55  lr: 0.001358  min_lr: 0.001358  loss: 2.6231 (2.5560)  weight_decay: 0.0500 (0.0500)  time: 0.5133  data: 0.0014  max mem: 5608\n",
            "Epoch: [68]  [ 60/147]  eta: 0:00:49  lr: 0.001352  min_lr: 0.001352  loss: 2.6091 (2.5483)  weight_decay: 0.0500 (0.0500)  time: 0.5149  data: 0.0020  max mem: 5608\n",
            "Epoch: [68]  [ 70/147]  eta: 0:00:42  lr: 0.001347  min_lr: 0.001347  loss: 2.6384 (2.5664)  weight_decay: 0.0500 (0.0500)  time: 0.5088  data: 0.0023  max mem: 5608\n",
            "Epoch: [68]  [ 80/147]  eta: 0:00:36  lr: 0.001341  min_lr: 0.001341  loss: 2.6384 (2.5413)  weight_decay: 0.0500 (0.0500)  time: 0.5023  data: 0.0028  max mem: 5608\n",
            "Epoch: [68]  [ 90/147]  eta: 0:00:31  lr: 0.001337  min_lr: 0.001337  loss: 2.3917 (2.5351)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0028  max mem: 5608\n",
            "Epoch: [68]  [100/147]  eta: 0:00:25  lr: 0.001331  min_lr: 0.001331  loss: 2.5106 (2.5266)  weight_decay: 0.0500 (0.0500)  time: 0.5043  data: 0.0020  max mem: 5608\n",
            "Epoch: [68]  [110/147]  eta: 0:00:19  lr: 0.001327  min_lr: 0.001327  loss: 2.5106 (2.5257)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0018  max mem: 5608\n",
            "Epoch: [68]  [120/147]  eta: 0:00:14  lr: 0.001321  min_lr: 0.001321  loss: 2.6096 (2.5285)  weight_decay: 0.0500 (0.0500)  time: 0.4979  data: 0.0013  max mem: 5608\n",
            "Epoch: [68]  [130/147]  eta: 0:00:09  lr: 0.001317  min_lr: 0.001317  loss: 2.5773 (2.5257)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0016  max mem: 5608\n",
            "Epoch: [68]  [140/147]  eta: 0:00:03  lr: 0.001310  min_lr: 0.001310  loss: 2.4663 (2.5225)  weight_decay: 0.0500 (0.0500)  time: 0.5015  data: 0.0009  max mem: 5608\n",
            "Epoch: [68]  [146/147]  eta: 0:00:00  lr: 0.001310  min_lr: 0.001310  loss: 2.4491 (2.5248)  weight_decay: 0.0500 (0.0500)  time: 0.4231  data: 0.0002  max mem: 5608\n",
            "Epoch: [68] Total time: 0:01:16 (0.5202 s / it)\n",
            "Averaged stats: lr: 0.001310  min_lr: 0.001310  loss: 2.4491 (2.5248)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:37  loss: 0.4523 (0.4523)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 2.3804  data: 2.0414  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 0.6277 (0.6255)  acc1: 89.5833 (87.7841)  acc5: 97.9167 (98.4849)  time: 0.5451  data: 0.2815  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.6928 (0.8816)  acc1: 83.3333 (76.5377)  acc5: 97.9167 (96.8750)  time: 0.3431  data: 0.0972  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8334 (0.9035)  acc1: 77.0833 (76.4785)  acc5: 96.8750 (96.8078)  time: 0.3596  data: 0.1192  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8177 (0.8663)  acc1: 81.2500 (77.7070)  acc5: 97.6471 (96.9936)  time: 0.3122  data: 0.0748  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3873 s / it)\n",
            "* Acc@1 77.707 Acc@5 96.994 loss 0.866\n",
            "Accuracy of the model on the 3925 test images: 77.7%\n",
            "Max accuracy: 78.01%\n",
            "Test:  [ 0/41]  eta: 0:02:21  loss: 3.6185 (3.6185)  acc1: 35.4167 (35.4167)  acc5: 78.1250 (78.1250)  time: 3.4602  data: 3.1675  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.7460 (3.9522)  acc1: 26.0417 (23.2955)  acc5: 81.2500 (80.3030)  time: 0.5317  data: 0.2928  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.5641 (4.6363)  acc1: 11.4583 (15.5258)  acc5: 69.7917 (68.7996)  time: 0.2398  data: 0.0038  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.2878 (4.7904)  acc1: 2.0833 (14.6169)  acc5: 57.2917 (65.9946)  time: 0.2411  data: 0.0012  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3792 (4.3872)  acc1: 26.0417 (21.8344)  acc5: 80.2083 (68.8662)  time: 0.2379  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3305 s / it)\n",
            "* Acc@1 21.834 Acc@5 68.866 loss 4.387\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "Max EMA accuracy: 21.83%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [69]  [  0/147]  eta: 0:08:29  lr: 0.001308  min_lr: 0.001308  loss: 2.7044 (2.7044)  weight_decay: 0.0500 (0.0500)  time: 3.4643  data: 2.8750  max mem: 5608\n",
            "Epoch: [69]  [ 10/147]  eta: 0:01:46  lr: 0.001304  min_lr: 0.001304  loss: 2.4065 (2.4379)  weight_decay: 0.0500 (0.0500)  time: 0.7785  data: 0.2617  max mem: 5608\n",
            "Epoch: [69]  [ 20/147]  eta: 0:01:23  lr: 0.001298  min_lr: 0.001298  loss: 2.4641 (2.4501)  weight_decay: 0.0500 (0.0500)  time: 0.5144  data: 0.0011  max mem: 5608\n",
            "Epoch: [69]  [ 30/147]  eta: 0:01:11  lr: 0.001294  min_lr: 0.001294  loss: 2.4713 (2.4408)  weight_decay: 0.0500 (0.0500)  time: 0.5168  data: 0.0020  max mem: 5608\n",
            "Epoch: [69]  [ 40/147]  eta: 0:01:02  lr: 0.001288  min_lr: 0.001288  loss: 2.4214 (2.4334)  weight_decay: 0.0500 (0.0500)  time: 0.5136  data: 0.0019  max mem: 5608\n",
            "Epoch: [69]  [ 50/147]  eta: 0:00:55  lr: 0.001284  min_lr: 0.001284  loss: 2.5710 (2.4709)  weight_decay: 0.0500 (0.0500)  time: 0.5099  data: 0.0012  max mem: 5608\n",
            "Epoch: [69]  [ 60/147]  eta: 0:00:48  lr: 0.001278  min_lr: 0.001278  loss: 2.5674 (2.4594)  weight_decay: 0.0500 (0.0500)  time: 0.5129  data: 0.0014  max mem: 5608\n",
            "Epoch: [69]  [ 70/147]  eta: 0:00:42  lr: 0.001274  min_lr: 0.001274  loss: 2.4691 (2.4638)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0018  max mem: 5608\n",
            "Epoch: [69]  [ 80/147]  eta: 0:00:36  lr: 0.001268  min_lr: 0.001268  loss: 2.5080 (2.4638)  weight_decay: 0.0500 (0.0500)  time: 0.5027  data: 0.0011  max mem: 5608\n",
            "Epoch: [69]  [ 90/147]  eta: 0:00:30  lr: 0.001264  min_lr: 0.001264  loss: 2.4501 (2.4563)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0009  max mem: 5608\n",
            "Epoch: [69]  [100/147]  eta: 0:00:25  lr: 0.001258  min_lr: 0.001258  loss: 2.3760 (2.4534)  weight_decay: 0.0500 (0.0500)  time: 0.5077  data: 0.0026  max mem: 5608\n",
            "Epoch: [69]  [110/147]  eta: 0:00:19  lr: 0.001253  min_lr: 0.001253  loss: 2.5448 (2.4592)  weight_decay: 0.0500 (0.0500)  time: 0.4994  data: 0.0024  max mem: 5608\n",
            "Epoch: [69]  [120/147]  eta: 0:00:14  lr: 0.001247  min_lr: 0.001247  loss: 2.5371 (2.4616)  weight_decay: 0.0500 (0.0500)  time: 0.5000  data: 0.0016  max mem: 5608\n",
            "Epoch: [69]  [130/147]  eta: 0:00:09  lr: 0.001243  min_lr: 0.001243  loss: 2.5320 (2.4579)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0019  max mem: 5608\n",
            "Epoch: [69]  [140/147]  eta: 0:00:03  lr: 0.001237  min_lr: 0.001237  loss: 2.3962 (2.4569)  weight_decay: 0.0500 (0.0500)  time: 0.4965  data: 0.0009  max mem: 5608\n",
            "Epoch: [69]  [146/147]  eta: 0:00:00  lr: 0.001237  min_lr: 0.001237  loss: 2.5330 (2.4569)  weight_decay: 0.0500 (0.0500)  time: 0.4196  data: 0.0002  max mem: 5608\n",
            "Epoch: [69] Total time: 0:01:16 (0.5192 s / it)\n",
            "Averaged stats: lr: 0.001237  min_lr: 0.001237  loss: 2.5330 (2.4569)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:36  loss: 0.4514 (0.4514)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 2.3614  data: 2.0604  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.6025 (0.6241)  acc1: 87.5000 (86.3636)  acc5: 97.9167 (97.8220)  time: 0.6592  data: 0.4027  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.6287 (0.7462)  acc1: 85.4167 (80.7044)  acc5: 97.9167 (98.2639)  time: 0.4132  data: 0.1557  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7806 (0.7796)  acc1: 80.2083 (79.9059)  acc5: 97.9167 (97.8159)  time: 0.2941  data: 0.0451  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8162 (0.7855)  acc1: 78.1250 (79.4140)  acc5: 96.8750 (97.6306)  time: 0.2396  data: 0.0080  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3861 s / it)\n",
            "* Acc@1 79.414 Acc@5 97.631 loss 0.785\n",
            "Accuracy of the model on the 3925 test images: 79.4%\n",
            "Max accuracy: 79.41%\n",
            "Test:  [ 0/41]  eta: 0:02:11  loss: 3.5965 (3.5965)  acc1: 35.4167 (35.4167)  acc5: 78.1250 (78.1250)  time: 3.2135  data: 2.9093  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.7453 (3.9337)  acc1: 25.0000 (23.2008)  acc5: 81.2500 (80.4924)  time: 0.5599  data: 0.3182  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.5324 (4.6212)  acc1: 13.5417 (15.5754)  acc5: 70.8333 (68.9484)  time: 0.3217  data: 0.0868  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.2629 (4.7818)  acc1: 2.0833 (14.6169)  acc5: 58.3333 (66.0618)  time: 0.3525  data: 0.1050  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3746 (4.3739)  acc1: 27.0833 (21.9618)  acc5: 80.2083 (68.9172)  time: 0.2943  data: 0.0478  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3954 s / it)\n",
            "* Acc@1 21.962 Acc@5 68.917 loss 4.374\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "Max EMA accuracy: 21.96%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [70]  [  0/147]  eta: 0:08:09  lr: 0.001235  min_lr: 0.001235  loss: 2.8310 (2.8310)  weight_decay: 0.0500 (0.0500)  time: 3.3310  data: 2.7088  max mem: 5608\n",
            "Epoch: [70]  [ 10/147]  eta: 0:01:49  lr: 0.001231  min_lr: 0.001231  loss: 2.4817 (2.4427)  weight_decay: 0.0500 (0.0500)  time: 0.8010  data: 0.2474  max mem: 5608\n",
            "Epoch: [70]  [ 20/147]  eta: 0:01:24  lr: 0.001225  min_lr: 0.001225  loss: 2.4817 (2.4739)  weight_decay: 0.0500 (0.0500)  time: 0.5317  data: 0.0013  max mem: 5608\n",
            "Epoch: [70]  [ 30/147]  eta: 0:01:11  lr: 0.001221  min_lr: 0.001221  loss: 2.5535 (2.5086)  weight_decay: 0.0500 (0.0500)  time: 0.5128  data: 0.0017  max mem: 5608\n",
            "Epoch: [70]  [ 40/147]  eta: 0:01:03  lr: 0.001215  min_lr: 0.001215  loss: 2.5263 (2.4763)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0019  max mem: 5608\n",
            "Epoch: [70]  [ 50/147]  eta: 0:00:55  lr: 0.001211  min_lr: 0.001211  loss: 2.3930 (2.4609)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0022  max mem: 5608\n",
            "Epoch: [70]  [ 60/147]  eta: 0:00:49  lr: 0.001205  min_lr: 0.001205  loss: 2.5066 (2.4582)  weight_decay: 0.0500 (0.0500)  time: 0.5111  data: 0.0022  max mem: 5608\n",
            "Epoch: [70]  [ 70/147]  eta: 0:00:42  lr: 0.001201  min_lr: 0.001201  loss: 2.5119 (2.4482)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0020  max mem: 5608\n",
            "Epoch: [70]  [ 80/147]  eta: 0:00:36  lr: 0.001195  min_lr: 0.001195  loss: 2.5352 (2.4643)  weight_decay: 0.0500 (0.0500)  time: 0.5082  data: 0.0030  max mem: 5608\n",
            "Epoch: [70]  [ 90/147]  eta: 0:00:31  lr: 0.001191  min_lr: 0.001191  loss: 2.4754 (2.4568)  weight_decay: 0.0500 (0.0500)  time: 0.5068  data: 0.0039  max mem: 5608\n",
            "Epoch: [70]  [100/147]  eta: 0:00:25  lr: 0.001185  min_lr: 0.001185  loss: 2.4540 (2.4587)  weight_decay: 0.0500 (0.0500)  time: 0.4978  data: 0.0021  max mem: 5608\n",
            "Epoch: [70]  [110/147]  eta: 0:00:19  lr: 0.001181  min_lr: 0.001181  loss: 2.4859 (2.4613)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0018  max mem: 5608\n",
            "Epoch: [70]  [120/147]  eta: 0:00:14  lr: 0.001175  min_lr: 0.001175  loss: 2.4885 (2.4612)  weight_decay: 0.0500 (0.0500)  time: 0.5069  data: 0.0037  max mem: 5608\n",
            "Epoch: [70]  [130/147]  eta: 0:00:09  lr: 0.001171  min_lr: 0.001171  loss: 2.5426 (2.4650)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0035  max mem: 5608\n",
            "Epoch: [70]  [140/147]  eta: 0:00:03  lr: 0.001165  min_lr: 0.001165  loss: 2.4832 (2.4612)  weight_decay: 0.0500 (0.0500)  time: 0.4948  data: 0.0014  max mem: 5608\n",
            "Epoch: [70]  [146/147]  eta: 0:00:00  lr: 0.001165  min_lr: 0.001165  loss: 2.5092 (2.4650)  weight_decay: 0.0500 (0.0500)  time: 0.4206  data: 0.0002  max mem: 5608\n",
            "Epoch: [70] Total time: 0:01:16 (0.5219 s / it)\n",
            "Averaged stats: lr: 0.001165  min_lr: 0.001165  loss: 2.5092 (2.4650)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:17  loss: 0.4273 (0.4273)  acc1: 92.7083 (92.7083)  acc5: 97.9167 (97.9167)  time: 4.8238  data: 4.5528  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5664 (0.5748)  acc1: 90.6250 (89.9621)  acc5: 97.9167 (98.1061)  time: 0.6638  data: 0.4226  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.6212 (0.7842)  acc1: 86.4583 (80.0595)  acc5: 97.9167 (98.1151)  time: 0.2444  data: 0.0073  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7709 (0.8179)  acc1: 80.2083 (78.8642)  acc5: 97.9167 (97.7151)  time: 0.2358  data: 0.0026  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8193 (0.8333)  acc1: 79.1667 (78.4204)  acc5: 96.8750 (97.6306)  time: 0.2305  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3635 s / it)\n",
            "* Acc@1 78.420 Acc@5 97.631 loss 0.833\n",
            "Accuracy of the model on the 3925 test images: 78.4%\n",
            "Max accuracy: 79.41%\n",
            "Test:  [ 0/41]  eta: 0:03:23  loss: 3.5763 (3.5763)  acc1: 34.3750 (34.3750)  acc5: 79.1667 (79.1667)  time: 4.9688  data: 4.6570  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.7487 (3.9164)  acc1: 25.0000 (23.1061)  acc5: 81.2500 (80.6818)  time: 0.6655  data: 0.4254  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.4995 (4.6067)  acc1: 14.5833 (15.5754)  acc5: 70.8333 (69.1468)  time: 0.2430  data: 0.0023  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.2370 (4.7729)  acc1: 2.0833 (14.5833)  acc5: 58.3333 (66.1626)  time: 0.2427  data: 0.0013  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3711 (4.3605)  acc1: 27.0833 (22.0382)  acc5: 80.2083 (69.0446)  time: 0.2343  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3703 s / it)\n",
            "* Acc@1 22.038 Acc@5 69.045 loss 4.361\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "Max EMA accuracy: 22.04%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [71]  [  0/147]  eta: 0:09:49  lr: 0.001163  min_lr: 0.001163  loss: 2.6581 (2.6581)  weight_decay: 0.0500 (0.0500)  time: 4.0072  data: 3.4050  max mem: 5608\n",
            "Epoch: [71]  [ 10/147]  eta: 0:01:56  lr: 0.001159  min_lr: 0.001159  loss: 2.4379 (2.4198)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.3252  max mem: 5608\n",
            "Epoch: [71]  [ 20/147]  eta: 0:01:27  lr: 0.001153  min_lr: 0.001153  loss: 2.3876 (2.3802)  weight_decay: 0.0500 (0.0500)  time: 0.5247  data: 0.0094  max mem: 5608\n",
            "Epoch: [71]  [ 30/147]  eta: 0:01:14  lr: 0.001150  min_lr: 0.001150  loss: 2.3590 (2.3994)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0013  max mem: 5608\n",
            "Epoch: [71]  [ 40/147]  eta: 0:01:04  lr: 0.001144  min_lr: 0.001144  loss: 2.3590 (2.3815)  weight_decay: 0.0500 (0.0500)  time: 0.5159  data: 0.0013  max mem: 5608\n",
            "Epoch: [71]  [ 50/147]  eta: 0:00:56  lr: 0.001140  min_lr: 0.001140  loss: 2.5463 (2.4030)  weight_decay: 0.0500 (0.0500)  time: 0.5114  data: 0.0015  max mem: 5608\n",
            "Epoch: [71]  [ 60/147]  eta: 0:00:50  lr: 0.001134  min_lr: 0.001134  loss: 2.5463 (2.4072)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0021  max mem: 5608\n",
            "Epoch: [71]  [ 70/147]  eta: 0:00:43  lr: 0.001130  min_lr: 0.001130  loss: 2.5336 (2.4210)  weight_decay: 0.0500 (0.0500)  time: 0.5138  data: 0.0015  max mem: 5608\n",
            "Epoch: [71]  [ 80/147]  eta: 0:00:37  lr: 0.001124  min_lr: 0.001124  loss: 2.5156 (2.4287)  weight_decay: 0.0500 (0.0500)  time: 0.5125  data: 0.0022  max mem: 5608\n",
            "Epoch: [71]  [ 90/147]  eta: 0:00:31  lr: 0.001120  min_lr: 0.001120  loss: 2.4900 (2.4354)  weight_decay: 0.0500 (0.0500)  time: 0.5096  data: 0.0025  max mem: 5608\n",
            "Epoch: [71]  [100/147]  eta: 0:00:25  lr: 0.001114  min_lr: 0.001114  loss: 2.5261 (2.4386)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0017  max mem: 5608\n",
            "Epoch: [71]  [110/147]  eta: 0:00:20  lr: 0.001110  min_lr: 0.001110  loss: 2.6387 (2.4615)  weight_decay: 0.0500 (0.0500)  time: 0.4993  data: 0.0022  max mem: 5608\n",
            "Epoch: [71]  [120/147]  eta: 0:00:14  lr: 0.001104  min_lr: 0.001104  loss: 2.6776 (2.4651)  weight_decay: 0.0500 (0.0500)  time: 0.4958  data: 0.0015  max mem: 5608\n",
            "Epoch: [71]  [130/147]  eta: 0:00:09  lr: 0.001101  min_lr: 0.001101  loss: 2.4437 (2.4602)  weight_decay: 0.0500 (0.0500)  time: 0.4991  data: 0.0011  max mem: 5608\n",
            "Epoch: [71]  [140/147]  eta: 0:00:03  lr: 0.001095  min_lr: 0.001095  loss: 2.3541 (2.4595)  weight_decay: 0.0500 (0.0500)  time: 0.4977  data: 0.0006  max mem: 5608\n",
            "Epoch: [71]  [146/147]  eta: 0:00:00  lr: 0.001095  min_lr: 0.001095  loss: 2.5094 (2.4631)  weight_decay: 0.0500 (0.0500)  time: 0.4202  data: 0.0002  max mem: 5608\n",
            "Epoch: [71] Total time: 0:01:17 (0.5247 s / it)\n",
            "Averaged stats: lr: 0.001095  min_lr: 0.001095  loss: 2.5094 (2.4631)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:04  loss: 0.5555 (0.5555)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 3.0323  data: 2.5906  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.6176 (0.5970)  acc1: 88.5417 (89.3939)  acc5: 97.9167 (98.2008)  time: 0.5739  data: 0.3093  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.7038 (0.7945)  acc1: 85.4167 (80.9524)  acc5: 98.9583 (98.3631)  time: 0.3450  data: 0.0967  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8564 (0.8124)  acc1: 77.0833 (80.2755)  acc5: 97.9167 (98.0511)  time: 0.3364  data: 0.0887  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7824 (0.8113)  acc1: 80.2083 (80.1529)  acc5: 97.9167 (97.8344)  time: 0.2704  data: 0.0327  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3840 s / it)\n",
            "* Acc@1 80.153 Acc@5 97.834 loss 0.811\n",
            "Accuracy of the model on the 3925 test images: 80.2%\n",
            "Max accuracy: 80.15%\n",
            "Test:  [ 0/41]  eta: 0:01:57  loss: 3.5543 (3.5543)  acc1: 33.3333 (33.3333)  acc5: 79.1667 (79.1667)  time: 2.8726  data: 2.5719  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.7437 (3.8966)  acc1: 25.0000 (23.1061)  acc5: 81.2500 (81.2500)  time: 0.5450  data: 0.2910  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.4670 (4.5902)  acc1: 15.6250 (15.5754)  acc5: 71.8750 (69.3948)  time: 0.3200  data: 0.0688  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.2084 (4.7622)  acc1: 2.0833 (14.4825)  acc5: 57.2917 (66.2970)  time: 0.3254  data: 0.0759  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3689 (4.3460)  acc1: 27.0833 (22.0382)  acc5: 80.2083 (69.1210)  time: 0.2784  data: 0.0387  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3712 s / it)\n",
            "* Acc@1 22.038 Acc@5 69.121 loss 4.346\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "Max EMA accuracy: 22.04%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [72]  [  0/147]  eta: 0:07:23  lr: 0.001093  min_lr: 0.001093  loss: 2.6929 (2.6929)  weight_decay: 0.0500 (0.0500)  time: 3.0202  data: 2.3776  max mem: 5608\n",
            "Epoch: [72]  [ 10/147]  eta: 0:01:43  lr: 0.001089  min_lr: 0.001089  loss: 2.6023 (2.5755)  weight_decay: 0.0500 (0.0500)  time: 0.7530  data: 0.2185  max mem: 5608\n",
            "Epoch: [72]  [ 20/147]  eta: 0:01:21  lr: 0.001083  min_lr: 0.001083  loss: 2.6023 (2.5618)  weight_decay: 0.0500 (0.0500)  time: 0.5253  data: 0.0030  max mem: 5608\n",
            "Epoch: [72]  [ 30/147]  eta: 0:01:10  lr: 0.001079  min_lr: 0.001079  loss: 2.4878 (2.5007)  weight_decay: 0.0500 (0.0500)  time: 0.5161  data: 0.0021  max mem: 5608\n",
            "Epoch: [72]  [ 40/147]  eta: 0:01:01  lr: 0.001073  min_lr: 0.001073  loss: 2.3580 (2.4575)  weight_decay: 0.0500 (0.0500)  time: 0.5087  data: 0.0016  max mem: 5608\n",
            "Epoch: [72]  [ 50/147]  eta: 0:00:54  lr: 0.001070  min_lr: 0.001070  loss: 2.3561 (2.4435)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0022  max mem: 5608\n",
            "Epoch: [72]  [ 60/147]  eta: 0:00:48  lr: 0.001064  min_lr: 0.001064  loss: 2.5168 (2.4472)  weight_decay: 0.0500 (0.0500)  time: 0.5105  data: 0.0016  max mem: 5608\n",
            "Epoch: [72]  [ 70/147]  eta: 0:00:42  lr: 0.001060  min_lr: 0.001060  loss: 2.4448 (2.4395)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0010  max mem: 5608\n",
            "Epoch: [72]  [ 80/147]  eta: 0:00:36  lr: 0.001054  min_lr: 0.001054  loss: 2.4752 (2.4507)  weight_decay: 0.0500 (0.0500)  time: 0.5028  data: 0.0010  max mem: 5608\n",
            "Epoch: [72]  [ 90/147]  eta: 0:00:30  lr: 0.001050  min_lr: 0.001050  loss: 2.6563 (2.4663)  weight_decay: 0.0500 (0.0500)  time: 0.5091  data: 0.0015  max mem: 5608\n",
            "Epoch: [72]  [100/147]  eta: 0:00:25  lr: 0.001045  min_lr: 0.001045  loss: 2.4587 (2.4523)  weight_decay: 0.0500 (0.0500)  time: 0.5054  data: 0.0012  max mem: 5608\n",
            "Epoch: [72]  [110/147]  eta: 0:00:19  lr: 0.001041  min_lr: 0.001041  loss: 2.4587 (2.4581)  weight_decay: 0.0500 (0.0500)  time: 0.4980  data: 0.0006  max mem: 5608\n",
            "Epoch: [72]  [120/147]  eta: 0:00:14  lr: 0.001035  min_lr: 0.001035  loss: 2.4584 (2.4572)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0004  max mem: 5608\n",
            "Epoch: [72]  [130/147]  eta: 0:00:08  lr: 0.001031  min_lr: 0.001031  loss: 2.4684 (2.4655)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0011  max mem: 5608\n",
            "Epoch: [72]  [140/147]  eta: 0:00:03  lr: 0.001025  min_lr: 0.001025  loss: 2.5127 (2.4647)  weight_decay: 0.0500 (0.0500)  time: 0.4962  data: 0.0010  max mem: 5608\n",
            "Epoch: [72]  [146/147]  eta: 0:00:00  lr: 0.001025  min_lr: 0.001025  loss: 2.5265 (2.4668)  weight_decay: 0.0500 (0.0500)  time: 0.4205  data: 0.0002  max mem: 5608\n",
            "Epoch: [72] Total time: 0:01:16 (0.5174 s / it)\n",
            "Averaged stats: lr: 0.001025  min_lr: 0.001025  loss: 2.5265 (2.4668)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:00  loss: 0.4733 (0.4733)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 5.8614  data: 5.5526  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 0.6484 (0.6646)  acc1: 86.4583 (85.7008)  acc5: 97.9167 (98.1061)  time: 0.8518  data: 0.6109  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6956 (0.7757)  acc1: 84.3750 (81.3988)  acc5: 97.9167 (98.3631)  time: 0.3341  data: 0.0930  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7947 (0.8027)  acc1: 83.3333 (81.0820)  acc5: 97.9167 (98.0175)  time: 0.2770  data: 0.0347  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8606 (0.8167)  acc1: 79.1667 (80.7898)  acc5: 96.8750 (97.6815)  time: 0.2331  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:17 (0.4342 s / it)\n",
            "* Acc@1 80.790 Acc@5 97.682 loss 0.817\n",
            "Accuracy of the model on the 3925 test images: 80.8%\n",
            "Max accuracy: 80.79%\n",
            "Test:  [ 0/41]  eta: 0:03:20  loss: 3.5363 (3.5363)  acc1: 33.3333 (33.3333)  acc5: 79.1667 (79.1667)  time: 4.8810  data: 4.5835  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.7394 (3.8783)  acc1: 25.0000 (23.3902)  acc5: 81.2500 (81.3447)  time: 0.6702  data: 0.4339  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.4342 (4.5751)  acc1: 16.6667 (15.7738)  acc5: 71.8750 (69.5437)  time: 0.2485  data: 0.0135  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.1815 (4.7527)  acc1: 2.0833 (14.5833)  acc5: 57.2917 (66.4315)  time: 0.2423  data: 0.0041  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3690 (4.3327)  acc1: 27.0833 (22.2166)  acc5: 80.2083 (69.3503)  time: 0.2353  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3699 s / it)\n",
            "* Acc@1 22.217 Acc@5 69.350 loss 4.333\n",
            "Accuracy of the model EMA on 3925 test images: 22.2%\n",
            "Max EMA accuracy: 22.22%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [73]  [  0/147]  eta: 0:10:16  lr: 0.001024  min_lr: 0.001024  loss: 2.1494 (2.1494)  weight_decay: 0.0500 (0.0500)  time: 4.1933  data: 3.6045  max mem: 5608\n",
            "Epoch: [73]  [ 10/147]  eta: 0:01:56  lr: 0.001020  min_lr: 0.001020  loss: 2.4667 (2.4104)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.3289  max mem: 5608\n",
            "Epoch: [73]  [ 20/147]  eta: 0:01:28  lr: 0.001014  min_lr: 0.001014  loss: 2.3879 (2.3938)  weight_decay: 0.0500 (0.0500)  time: 0.5184  data: 0.0015  max mem: 5608\n",
            "Epoch: [73]  [ 30/147]  eta: 0:01:14  lr: 0.001010  min_lr: 0.001010  loss: 2.3643 (2.4146)  weight_decay: 0.0500 (0.0500)  time: 0.5240  data: 0.0019  max mem: 5608\n",
            "Epoch: [73]  [ 40/147]  eta: 0:01:05  lr: 0.001005  min_lr: 0.001005  loss: 2.4669 (2.4027)  weight_decay: 0.0500 (0.0500)  time: 0.5225  data: 0.0016  max mem: 5608\n",
            "Epoch: [73]  [ 50/147]  eta: 0:00:57  lr: 0.001001  min_lr: 0.001001  loss: 2.4737 (2.4267)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0011  max mem: 5608\n",
            "Epoch: [73]  [ 60/147]  eta: 0:00:50  lr: 0.000995  min_lr: 0.000995  loss: 2.5020 (2.4332)  weight_decay: 0.0500 (0.0500)  time: 0.5105  data: 0.0006  max mem: 5608\n",
            "Epoch: [73]  [ 70/147]  eta: 0:00:43  lr: 0.000991  min_lr: 0.000991  loss: 2.3835 (2.4292)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0004  max mem: 5608\n",
            "Epoch: [73]  [ 80/147]  eta: 0:00:37  lr: 0.000986  min_lr: 0.000986  loss: 2.3835 (2.4341)  weight_decay: 0.0500 (0.0500)  time: 0.5021  data: 0.0007  max mem: 5608\n",
            "Epoch: [73]  [ 90/147]  eta: 0:00:31  lr: 0.000982  min_lr: 0.000982  loss: 2.5065 (2.4383)  weight_decay: 0.0500 (0.0500)  time: 0.4982  data: 0.0009  max mem: 5608\n",
            "Epoch: [73]  [100/147]  eta: 0:00:25  lr: 0.000976  min_lr: 0.000976  loss: 2.5675 (2.4482)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0024  max mem: 5608\n",
            "Epoch: [73]  [110/147]  eta: 0:00:20  lr: 0.000973  min_lr: 0.000973  loss: 2.5671 (2.4502)  weight_decay: 0.0500 (0.0500)  time: 0.5056  data: 0.0026  max mem: 5608\n",
            "Epoch: [73]  [120/147]  eta: 0:00:14  lr: 0.000967  min_lr: 0.000967  loss: 2.4899 (2.4467)  weight_decay: 0.0500 (0.0500)  time: 0.4974  data: 0.0022  max mem: 5608\n",
            "Epoch: [73]  [130/147]  eta: 0:00:09  lr: 0.000963  min_lr: 0.000963  loss: 2.5363 (2.4554)  weight_decay: 0.0500 (0.0500)  time: 0.4987  data: 0.0028  max mem: 5608\n",
            "Epoch: [73]  [140/147]  eta: 0:00:03  lr: 0.000958  min_lr: 0.000958  loss: 2.5072 (2.4530)  weight_decay: 0.0500 (0.0500)  time: 0.4966  data: 0.0015  max mem: 5608\n",
            "Epoch: [73]  [146/147]  eta: 0:00:00  lr: 0.000958  min_lr: 0.000958  loss: 2.5363 (2.4571)  weight_decay: 0.0500 (0.0500)  time: 0.4203  data: 0.0002  max mem: 5608\n",
            "Epoch: [73] Total time: 0:01:17 (0.5249 s / it)\n",
            "Averaged stats: lr: 0.000958  min_lr: 0.000958  loss: 2.5363 (2.4571)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:42  loss: 0.5583 (0.5583)  acc1: 89.5833 (89.5833)  acc5: 96.8750 (96.8750)  time: 3.9561  data: 3.6430  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.6263 (0.6420)  acc1: 88.5417 (87.7841)  acc5: 97.9167 (98.1061)  time: 0.6690  data: 0.4223  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.6497 (0.7843)  acc1: 85.4167 (80.5556)  acc5: 97.9167 (97.9663)  time: 0.3468  data: 0.1009  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8166 (0.8289)  acc1: 79.1667 (79.1331)  acc5: 97.9167 (97.7487)  time: 0.2974  data: 0.0510  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8166 (0.8242)  acc1: 79.1667 (79.3376)  acc5: 97.6471 (97.5796)  time: 0.2360  data: 0.0003  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3904 s / it)\n",
            "* Acc@1 79.338 Acc@5 97.580 loss 0.824\n",
            "Accuracy of the model on the 3925 test images: 79.3%\n",
            "Max accuracy: 80.79%\n",
            "Test:  [ 0/41]  eta: 0:02:36  loss: 3.5181 (3.5181)  acc1: 33.3333 (33.3333)  acc5: 79.1667 (79.1667)  time: 3.8284  data: 3.5222  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.7359 (3.8606)  acc1: 22.9167 (23.3902)  acc5: 81.2500 (81.6288)  time: 0.5705  data: 0.3248  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.4021 (4.5599)  acc1: 17.7083 (15.7738)  acc5: 71.8750 (69.7917)  time: 0.2537  data: 0.0074  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.1524 (4.7427)  acc1: 2.0833 (14.4825)  acc5: 58.3333 (66.6667)  time: 0.2500  data: 0.0050  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3699 (4.3190)  acc1: 28.1250 (22.2930)  acc5: 81.2500 (69.5541)  time: 0.2363  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3463 s / it)\n",
            "* Acc@1 22.293 Acc@5 69.554 loss 4.319\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "Max EMA accuracy: 22.29%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [74]  [  0/147]  eta: 0:08:13  lr: 0.000956  min_lr: 0.000956  loss: 2.6288 (2.6288)  weight_decay: 0.0500 (0.0500)  time: 3.3539  data: 2.7430  max mem: 5608\n",
            "Epoch: [74]  [ 10/147]  eta: 0:01:45  lr: 0.000952  min_lr: 0.000952  loss: 2.6022 (2.5548)  weight_decay: 0.0500 (0.0500)  time: 0.7717  data: 0.2507  max mem: 5608\n",
            "Epoch: [74]  [ 20/147]  eta: 0:01:23  lr: 0.000946  min_lr: 0.000946  loss: 2.4416 (2.4538)  weight_decay: 0.0500 (0.0500)  time: 0.5191  data: 0.0021  max mem: 5608\n",
            "Epoch: [74]  [ 30/147]  eta: 0:01:11  lr: 0.000943  min_lr: 0.000943  loss: 2.3203 (2.4440)  weight_decay: 0.0500 (0.0500)  time: 0.5247  data: 0.0038  max mem: 5608\n",
            "Epoch: [74]  [ 40/147]  eta: 0:01:02  lr: 0.000937  min_lr: 0.000937  loss: 2.3934 (2.4255)  weight_decay: 0.0500 (0.0500)  time: 0.5198  data: 0.0034  max mem: 5608\n",
            "Epoch: [74]  [ 50/147]  eta: 0:00:55  lr: 0.000934  min_lr: 0.000934  loss: 2.3934 (2.4160)  weight_decay: 0.0500 (0.0500)  time: 0.5078  data: 0.0015  max mem: 5608\n",
            "Epoch: [74]  [ 60/147]  eta: 0:00:48  lr: 0.000928  min_lr: 0.000928  loss: 2.4736 (2.4325)  weight_decay: 0.0500 (0.0500)  time: 0.5049  data: 0.0015  max mem: 5608\n",
            "Epoch: [74]  [ 70/147]  eta: 0:00:42  lr: 0.000924  min_lr: 0.000924  loss: 2.5855 (2.4210)  weight_decay: 0.0500 (0.0500)  time: 0.5077  data: 0.0012  max mem: 5608\n",
            "Epoch: [74]  [ 80/147]  eta: 0:00:36  lr: 0.000919  min_lr: 0.000919  loss: 2.6292 (2.4503)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.0013  max mem: 5608\n",
            "Epoch: [74]  [ 90/147]  eta: 0:00:30  lr: 0.000915  min_lr: 0.000915  loss: 2.6763 (2.4575)  weight_decay: 0.0500 (0.0500)  time: 0.4990  data: 0.0014  max mem: 5608\n",
            "Epoch: [74]  [100/147]  eta: 0:00:25  lr: 0.000910  min_lr: 0.000910  loss: 2.5277 (2.4589)  weight_decay: 0.0500 (0.0500)  time: 0.5033  data: 0.0017  max mem: 5608\n",
            "Epoch: [74]  [110/147]  eta: 0:00:19  lr: 0.000906  min_lr: 0.000906  loss: 2.4368 (2.4578)  weight_decay: 0.0500 (0.0500)  time: 0.5046  data: 0.0022  max mem: 5608\n",
            "Epoch: [74]  [120/147]  eta: 0:00:14  lr: 0.000901  min_lr: 0.000901  loss: 2.4753 (2.4584)  weight_decay: 0.0500 (0.0500)  time: 0.4977  data: 0.0012  max mem: 5608\n",
            "Epoch: [74]  [130/147]  eta: 0:00:08  lr: 0.000897  min_lr: 0.000897  loss: 2.4753 (2.4590)  weight_decay: 0.0500 (0.0500)  time: 0.4961  data: 0.0012  max mem: 5608\n",
            "Epoch: [74]  [140/147]  eta: 0:00:03  lr: 0.000891  min_lr: 0.000891  loss: 2.5963 (2.4755)  weight_decay: 0.0500 (0.0500)  time: 0.4965  data: 0.0009  max mem: 5608\n",
            "Epoch: [74]  [146/147]  eta: 0:00:00  lr: 0.000891  min_lr: 0.000891  loss: 2.5841 (2.4784)  weight_decay: 0.0500 (0.0500)  time: 0.4224  data: 0.0003  max mem: 5608\n",
            "Epoch: [74] Total time: 0:01:16 (0.5180 s / it)\n",
            "Averaged stats: lr: 0.000891  min_lr: 0.000891  loss: 2.5841 (2.4784)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:27  loss: 0.4876 (0.4876)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 3.5893  data: 3.2861  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 0.5760 (0.6124)  acc1: 87.5000 (87.8788)  acc5: 97.9167 (98.2955)  time: 0.5446  data: 0.3031  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.7295 (0.8013)  acc1: 85.4167 (79.8115)  acc5: 97.9167 (98.0159)  time: 0.2852  data: 0.0440  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8463 (0.8373)  acc1: 80.2083 (79.2003)  acc5: 96.8750 (97.2446)  time: 0.3484  data: 0.0986  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8084 (0.8294)  acc1: 80.0000 (79.6943)  acc5: 96.8750 (97.3248)  time: 0.2975  data: 0.0571  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3810 s / it)\n",
            "* Acc@1 79.694 Acc@5 97.325 loss 0.829\n",
            "Accuracy of the model on the 3925 test images: 79.7%\n",
            "Max accuracy: 80.79%\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 3.4988 (3.4988)  acc1: 31.2500 (31.2500)  acc5: 79.1667 (79.1667)  time: 3.5015  data: 3.1871  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.7288 (3.8416)  acc1: 22.9167 (23.3902)  acc5: 81.2500 (82.0076)  time: 0.5345  data: 0.2916  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.3696 (4.5438)  acc1: 17.7083 (15.8730)  acc5: 73.9583 (70.1885)  time: 0.2403  data: 0.0016  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 5.1240 (4.7317)  acc1: 2.0833 (14.5161)  acc5: 59.3750 (66.9355)  time: 0.2429  data: 0.0006  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3716 (4.3048)  acc1: 28.1250 (22.3694)  acc5: 81.2500 (69.6815)  time: 0.2385  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3337 s / it)\n",
            "* Acc@1 22.369 Acc@5 69.682 loss 4.305\n",
            "Accuracy of the model EMA on 3925 test images: 22.4%\n",
            "Max EMA accuracy: 22.37%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [75]  [  0/147]  eta: 0:07:29  lr: 0.000890  min_lr: 0.000890  loss: 2.7067 (2.7067)  weight_decay: 0.0500 (0.0500)  time: 3.0602  data: 2.4405  max mem: 5608\n",
            "Epoch: [75]  [ 10/147]  eta: 0:01:43  lr: 0.000886  min_lr: 0.000886  loss: 2.5707 (2.5106)  weight_decay: 0.0500 (0.0500)  time: 0.7560  data: 0.2236  max mem: 5608\n",
            "Epoch: [75]  [ 20/147]  eta: 0:01:21  lr: 0.000881  min_lr: 0.000881  loss: 2.3634 (2.3887)  weight_decay: 0.0500 (0.0500)  time: 0.5207  data: 0.0020  max mem: 5608\n",
            "Epoch: [75]  [ 30/147]  eta: 0:01:10  lr: 0.000877  min_lr: 0.000877  loss: 2.4221 (2.4439)  weight_decay: 0.0500 (0.0500)  time: 0.5168  data: 0.0024  max mem: 5608\n",
            "Epoch: [75]  [ 40/147]  eta: 0:01:01  lr: 0.000872  min_lr: 0.000872  loss: 2.4421 (2.4085)  weight_decay: 0.0500 (0.0500)  time: 0.5117  data: 0.0022  max mem: 5608\n",
            "Epoch: [75]  [ 50/147]  eta: 0:00:54  lr: 0.000868  min_lr: 0.000868  loss: 2.4614 (2.4283)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0013  max mem: 5608\n",
            "Epoch: [75]  [ 60/147]  eta: 0:00:48  lr: 0.000863  min_lr: 0.000863  loss: 2.4614 (2.4267)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0008  max mem: 5608\n",
            "Epoch: [75]  [ 70/147]  eta: 0:00:42  lr: 0.000859  min_lr: 0.000859  loss: 2.3809 (2.4254)  weight_decay: 0.0500 (0.0500)  time: 0.5099  data: 0.0015  max mem: 5608\n",
            "Epoch: [75]  [ 80/147]  eta: 0:00:36  lr: 0.000854  min_lr: 0.000854  loss: 2.2951 (2.4111)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0019  max mem: 5608\n",
            "Epoch: [75]  [ 90/147]  eta: 0:00:30  lr: 0.000850  min_lr: 0.000850  loss: 2.4429 (2.4266)  weight_decay: 0.0500 (0.0500)  time: 0.5010  data: 0.0010  max mem: 5608\n",
            "Epoch: [75]  [100/147]  eta: 0:00:25  lr: 0.000845  min_lr: 0.000845  loss: 2.4895 (2.4131)  weight_decay: 0.0500 (0.0500)  time: 0.5044  data: 0.0007  max mem: 5608\n",
            "Epoch: [75]  [110/147]  eta: 0:00:19  lr: 0.000841  min_lr: 0.000841  loss: 2.4686 (2.4261)  weight_decay: 0.0500 (0.0500)  time: 0.5074  data: 0.0010  max mem: 5608\n",
            "Epoch: [75]  [120/147]  eta: 0:00:14  lr: 0.000836  min_lr: 0.000836  loss: 2.4325 (2.4195)  weight_decay: 0.0500 (0.0500)  time: 0.5085  data: 0.0008  max mem: 5608\n",
            "Epoch: [75]  [130/147]  eta: 0:00:08  lr: 0.000832  min_lr: 0.000832  loss: 2.4141 (2.4266)  weight_decay: 0.0500 (0.0500)  time: 0.5057  data: 0.0015  max mem: 5608\n",
            "Epoch: [75]  [140/147]  eta: 0:00:03  lr: 0.000827  min_lr: 0.000827  loss: 2.5207 (2.4308)  weight_decay: 0.0500 (0.0500)  time: 0.4992  data: 0.0013  max mem: 5608\n",
            "Epoch: [75]  [146/147]  eta: 0:00:00  lr: 0.000827  min_lr: 0.000827  loss: 2.5207 (2.4338)  weight_decay: 0.0500 (0.0500)  time: 0.4220  data: 0.0002  max mem: 5608\n",
            "Epoch: [75] Total time: 0:01:16 (0.5178 s / it)\n",
            "Averaged stats: lr: 0.000827  min_lr: 0.000827  loss: 2.5207 (2.4338)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:25  loss: 0.5939 (0.5939)  acc1: 88.5417 (88.5417)  acc5: 97.9167 (97.9167)  time: 5.0119  data: 4.7070  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.6679 (0.6345)  acc1: 85.4167 (87.5947)  acc5: 97.9167 (98.1061)  time: 0.6923  data: 0.4566  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.7328 (0.8163)  acc1: 83.3333 (79.5635)  acc5: 97.9167 (97.9663)  time: 0.2826  data: 0.0436  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8029 (0.8259)  acc1: 79.1667 (79.6707)  acc5: 97.9167 (97.6142)  time: 0.2815  data: 0.0344  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7523 (0.8124)  acc1: 81.2500 (80.0255)  acc5: 96.8750 (97.7070)  time: 0.2434  data: 0.0067  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3884 s / it)\n",
            "* Acc@1 80.025 Acc@5 97.707 loss 0.812\n",
            "Accuracy of the model on the 3925 test images: 80.0%\n",
            "Max accuracy: 80.79%\n",
            "Test:  [ 0/41]  eta: 0:01:55  loss: 3.4804 (3.4804)  acc1: 30.2083 (30.2083)  acc5: 79.1667 (79.1667)  time: 2.8180  data: 2.5211  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.7175 (3.8245)  acc1: 23.9583 (23.4848)  acc5: 82.2917 (82.1970)  time: 0.5239  data: 0.2855  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.3400 (4.5286)  acc1: 17.7083 (15.9226)  acc5: 76.0417 (70.4365)  time: 0.2736  data: 0.0338  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.0949 (4.7213)  acc1: 2.0833 (14.5833)  acc5: 60.4167 (67.0699)  time: 0.2915  data: 0.0419  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3747 (4.2909)  acc1: 28.1250 (22.5478)  acc5: 80.2083 (69.7325)  time: 0.2817  data: 0.0394  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3527 s / it)\n",
            "* Acc@1 22.548 Acc@5 69.732 loss 4.291\n",
            "Accuracy of the model EMA on 3925 test images: 22.5%\n",
            "Max EMA accuracy: 22.55%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [76]  [  0/147]  eta: 0:07:43  lr: 0.000825  min_lr: 0.000825  loss: 2.4001 (2.4001)  weight_decay: 0.0500 (0.0500)  time: 3.1552  data: 2.5887  max mem: 5608\n",
            "Epoch: [76]  [ 10/147]  eta: 0:01:44  lr: 0.000822  min_lr: 0.000822  loss: 2.4404 (2.4849)  weight_decay: 0.0500 (0.0500)  time: 0.7609  data: 0.2364  max mem: 5608\n",
            "Epoch: [76]  [ 20/147]  eta: 0:01:22  lr: 0.000816  min_lr: 0.000816  loss: 2.4404 (2.4417)  weight_decay: 0.0500 (0.0500)  time: 0.5210  data: 0.0013  max mem: 5608\n",
            "Epoch: [76]  [ 30/147]  eta: 0:01:10  lr: 0.000813  min_lr: 0.000813  loss: 2.4357 (2.4179)  weight_decay: 0.0500 (0.0500)  time: 0.5173  data: 0.0013  max mem: 5608\n",
            "Epoch: [76]  [ 40/147]  eta: 0:01:02  lr: 0.000808  min_lr: 0.000808  loss: 2.3077 (2.4115)  weight_decay: 0.0500 (0.0500)  time: 0.5119  data: 0.0010  max mem: 5608\n",
            "Epoch: [76]  [ 50/147]  eta: 0:00:55  lr: 0.000804  min_lr: 0.000804  loss: 2.3233 (2.4006)  weight_decay: 0.0500 (0.0500)  time: 0.5102  data: 0.0006  max mem: 5608\n",
            "Epoch: [76]  [ 60/147]  eta: 0:00:48  lr: 0.000799  min_lr: 0.000799  loss: 2.3765 (2.4030)  weight_decay: 0.0500 (0.0500)  time: 0.5118  data: 0.0006  max mem: 5608\n",
            "Epoch: [76]  [ 70/147]  eta: 0:00:42  lr: 0.000795  min_lr: 0.000795  loss: 2.3765 (2.3911)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0019  max mem: 5608\n",
            "Epoch: [76]  [ 80/147]  eta: 0:00:36  lr: 0.000790  min_lr: 0.000790  loss: 2.4374 (2.4043)  weight_decay: 0.0500 (0.0500)  time: 0.5010  data: 0.0016  max mem: 5608\n",
            "Epoch: [76]  [ 90/147]  eta: 0:00:30  lr: 0.000787  min_lr: 0.000787  loss: 2.5058 (2.4181)  weight_decay: 0.0500 (0.0500)  time: 0.5069  data: 0.0023  max mem: 5608\n",
            "Epoch: [76]  [100/147]  eta: 0:00:25  lr: 0.000782  min_lr: 0.000782  loss: 2.4288 (2.4140)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0034  max mem: 5608\n",
            "Epoch: [76]  [110/147]  eta: 0:00:19  lr: 0.000778  min_lr: 0.000778  loss: 2.3349 (2.4056)  weight_decay: 0.0500 (0.0500)  time: 0.4988  data: 0.0023  max mem: 5608\n",
            "Epoch: [76]  [120/147]  eta: 0:00:14  lr: 0.000773  min_lr: 0.000773  loss: 2.3457 (2.4045)  weight_decay: 0.0500 (0.0500)  time: 0.5035  data: 0.0020  max mem: 5608\n",
            "Epoch: [76]  [130/147]  eta: 0:00:08  lr: 0.000769  min_lr: 0.000769  loss: 2.4518 (2.4031)  weight_decay: 0.0500 (0.0500)  time: 0.5050  data: 0.0023  max mem: 5608\n",
            "Epoch: [76]  [140/147]  eta: 0:00:03  lr: 0.000764  min_lr: 0.000764  loss: 2.3686 (2.4037)  weight_decay: 0.0500 (0.0500)  time: 0.4958  data: 0.0013  max mem: 5608\n",
            "Epoch: [76]  [146/147]  eta: 0:00:00  lr: 0.000764  min_lr: 0.000764  loss: 2.3686 (2.4007)  weight_decay: 0.0500 (0.0500)  time: 0.4188  data: 0.0002  max mem: 5608\n",
            "Epoch: [76] Total time: 0:01:16 (0.5175 s / it)\n",
            "Averaged stats: lr: 0.000764  min_lr: 0.000764  loss: 2.3686 (2.4007)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:56  loss: 0.5010 (0.5010)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 4.3151  data: 4.0208  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5679 (0.5920)  acc1: 89.5833 (88.2576)  acc5: 97.9167 (98.2955)  time: 0.7026  data: 0.4549  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.6482 (0.7435)  acc1: 86.4583 (81.1012)  acc5: 97.9167 (98.3631)  time: 0.2981  data: 0.0539  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7316 (0.7723)  acc1: 79.1667 (80.2083)  acc5: 97.9167 (97.9503)  time: 0.2466  data: 0.0048  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7162 (0.7628)  acc1: 81.2500 (80.4841)  acc5: 97.9167 (97.9108)  time: 0.2346  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3766 s / it)\n",
            "* Acc@1 80.484 Acc@5 97.911 loss 0.763\n",
            "Accuracy of the model on the 3925 test images: 80.5%\n",
            "Max accuracy: 80.79%\n",
            "Test:  [ 0/41]  eta: 0:04:05  loss: 3.4603 (3.4603)  acc1: 28.1250 (28.1250)  acc5: 79.1667 (79.1667)  time: 5.9796  data: 5.6817  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:28  loss: 3.7041 (3.8071)  acc1: 23.9583 (22.8220)  acc5: 83.3333 (82.7652)  time: 0.9110  data: 0.6652  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.3103 (4.5138)  acc1: 17.7083 (15.6250)  acc5: 77.0833 (70.7837)  time: 0.3687  data: 0.1212  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.0659 (4.7111)  acc1: 2.0833 (14.3481)  acc5: 60.4167 (67.2379)  time: 0.2917  data: 0.0397  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3796 (4.2775)  acc1: 28.1250 (22.4459)  acc5: 80.2083 (69.8854)  time: 0.2426  data: 0.0003  max mem: 5608\n",
            "Test: Total time: 0:00:18 (0.4548 s / it)\n",
            "* Acc@1 22.446 Acc@5 69.885 loss 4.277\n",
            "Accuracy of the model EMA on 3925 test images: 22.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [77]  [  0/147]  eta: 0:08:43  lr: 0.000763  min_lr: 0.000763  loss: 2.3560 (2.3560)  weight_decay: 0.0500 (0.0500)  time: 3.5628  data: 2.9824  max mem: 5608\n",
            "Epoch: [77]  [ 10/147]  eta: 0:01:48  lr: 0.000759  min_lr: 0.000759  loss: 2.6165 (2.4953)  weight_decay: 0.0500 (0.0500)  time: 0.7947  data: 0.2715  max mem: 5608\n",
            "Epoch: [77]  [ 20/147]  eta: 0:01:24  lr: 0.000754  min_lr: 0.000754  loss: 2.5551 (2.4488)  weight_decay: 0.0500 (0.0500)  time: 0.5221  data: 0.0008  max mem: 5608\n",
            "Epoch: [77]  [ 30/147]  eta: 0:01:12  lr: 0.000751  min_lr: 0.000751  loss: 2.4994 (2.4705)  weight_decay: 0.0500 (0.0500)  time: 0.5173  data: 0.0011  max mem: 5608\n",
            "Epoch: [77]  [ 40/147]  eta: 0:01:03  lr: 0.000746  min_lr: 0.000746  loss: 2.3911 (2.4420)  weight_decay: 0.0500 (0.0500)  time: 0.5084  data: 0.0007  max mem: 5608\n",
            "Epoch: [77]  [ 50/147]  eta: 0:00:55  lr: 0.000742  min_lr: 0.000742  loss: 2.3710 (2.4348)  weight_decay: 0.0500 (0.0500)  time: 0.5098  data: 0.0015  max mem: 5608\n",
            "Epoch: [77]  [ 60/147]  eta: 0:00:49  lr: 0.000737  min_lr: 0.000737  loss: 2.4007 (2.4297)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0031  max mem: 5608\n",
            "Epoch: [77]  [ 70/147]  eta: 0:00:42  lr: 0.000734  min_lr: 0.000734  loss: 2.2965 (2.4091)  weight_decay: 0.0500 (0.0500)  time: 0.5035  data: 0.0019  max mem: 5608\n",
            "Epoch: [77]  [ 80/147]  eta: 0:00:36  lr: 0.000729  min_lr: 0.000729  loss: 2.2965 (2.4071)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0015  max mem: 5608\n",
            "Epoch: [77]  [ 90/147]  eta: 0:00:31  lr: 0.000725  min_lr: 0.000725  loss: 2.4716 (2.4222)  weight_decay: 0.0500 (0.0500)  time: 0.5090  data: 0.0032  max mem: 5608\n",
            "Epoch: [77]  [100/147]  eta: 0:00:25  lr: 0.000720  min_lr: 0.000720  loss: 2.4313 (2.4177)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0030  max mem: 5608\n",
            "Epoch: [77]  [110/147]  eta: 0:00:19  lr: 0.000717  min_lr: 0.000717  loss: 2.4313 (2.4189)  weight_decay: 0.0500 (0.0500)  time: 0.4970  data: 0.0023  max mem: 5608\n",
            "Epoch: [77]  [120/147]  eta: 0:00:14  lr: 0.000712  min_lr: 0.000712  loss: 2.4485 (2.4170)  weight_decay: 0.0500 (0.0500)  time: 0.5064  data: 0.0039  max mem: 5608\n",
            "Epoch: [77]  [130/147]  eta: 0:00:09  lr: 0.000709  min_lr: 0.000709  loss: 2.4662 (2.4207)  weight_decay: 0.0500 (0.0500)  time: 0.5057  data: 0.0028  max mem: 5608\n",
            "Epoch: [77]  [140/147]  eta: 0:00:03  lr: 0.000704  min_lr: 0.000704  loss: 2.5559 (2.4256)  weight_decay: 0.0500 (0.0500)  time: 0.4949  data: 0.0002  max mem: 5608\n",
            "Epoch: [77]  [146/147]  eta: 0:00:00  lr: 0.000704  min_lr: 0.000704  loss: 2.5559 (2.4258)  weight_decay: 0.0500 (0.0500)  time: 0.4204  data: 0.0002  max mem: 5608\n",
            "Epoch: [77] Total time: 0:01:16 (0.5214 s / it)\n",
            "Averaged stats: lr: 0.000704  min_lr: 0.000704  loss: 2.5559 (2.4258)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:28  loss: 0.4535 (0.4535)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 5.0823  data: 4.7672  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5881 (0.5983)  acc1: 89.5833 (89.1099)  acc5: 97.9167 (98.0114)  time: 0.6879  data: 0.4340  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.6723 (0.7658)  acc1: 85.4167 (81.5972)  acc5: 97.9167 (98.1151)  time: 0.2476  data: 0.0012  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6916 (0.7822)  acc1: 80.2083 (81.1156)  acc5: 97.9167 (97.6479)  time: 0.2383  data: 0.0009  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6837 (0.7766)  acc1: 83.3333 (81.2739)  acc5: 96.8750 (97.5541)  time: 0.2289  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3670 s / it)\n",
            "* Acc@1 81.274 Acc@5 97.554 loss 0.777\n",
            "Accuracy of the model on the 3925 test images: 81.3%\n",
            "Max accuracy: 81.27%\n",
            "Test:  [ 0/41]  eta: 0:03:44  loss: 3.4425 (3.4425)  acc1: 28.1250 (28.1250)  acc5: 79.1667 (79.1667)  time: 5.4646  data: 5.1586  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.6931 (3.7899)  acc1: 21.8750 (22.6326)  acc5: 83.3333 (83.1439)  time: 0.7087  data: 0.4721  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 4.2791 (4.4997)  acc1: 17.7083 (15.6250)  acc5: 78.1250 (70.9821)  time: 0.2356  data: 0.0056  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.0398 (4.7020)  acc1: 2.0833 (14.3145)  acc5: 59.3750 (67.3387)  time: 0.2357  data: 0.0039  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3859 (4.2650)  acc1: 29.1667 (22.4968)  acc5: 80.2083 (70.0127)  time: 0.2321  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3725 s / it)\n",
            "* Acc@1 22.497 Acc@5 70.013 loss 4.265\n",
            "Accuracy of the model EMA on 3925 test images: 22.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [78]  [  0/147]  eta: 0:11:11  lr: 0.000702  min_lr: 0.000702  loss: 2.5141 (2.5141)  weight_decay: 0.0500 (0.0500)  time: 4.5664  data: 3.8538  max mem: 5608\n",
            "Epoch: [78]  [ 10/147]  eta: 0:02:06  lr: 0.000699  min_lr: 0.000699  loss: 2.2815 (2.2714)  weight_decay: 0.0500 (0.0500)  time: 0.9267  data: 0.3525  max mem: 5608\n",
            "Epoch: [78]  [ 20/147]  eta: 0:01:32  lr: 0.000694  min_lr: 0.000694  loss: 2.3371 (2.3305)  weight_decay: 0.0500 (0.0500)  time: 0.5376  data: 0.0024  max mem: 5608\n",
            "Epoch: [78]  [ 30/147]  eta: 0:01:17  lr: 0.000690  min_lr: 0.000690  loss: 2.3577 (2.3303)  weight_decay: 0.0500 (0.0500)  time: 0.5158  data: 0.0026  max mem: 5608\n",
            "Epoch: [78]  [ 40/147]  eta: 0:01:07  lr: 0.000685  min_lr: 0.000685  loss: 2.4281 (2.3559)  weight_decay: 0.0500 (0.0500)  time: 0.5286  data: 0.0023  max mem: 5608\n",
            "Epoch: [78]  [ 50/147]  eta: 0:00:59  lr: 0.000682  min_lr: 0.000682  loss: 2.4381 (2.3531)  weight_decay: 0.0500 (0.0500)  time: 0.5339  data: 0.0026  max mem: 5608\n",
            "Epoch: [78]  [ 60/147]  eta: 0:00:51  lr: 0.000677  min_lr: 0.000677  loss: 2.4030 (2.3455)  weight_decay: 0.0500 (0.0500)  time: 0.5204  data: 0.0021  max mem: 5608\n",
            "Epoch: [78]  [ 70/147]  eta: 0:00:44  lr: 0.000674  min_lr: 0.000674  loss: 2.4472 (2.3650)  weight_decay: 0.0500 (0.0500)  time: 0.5098  data: 0.0010  max mem: 5608\n",
            "Epoch: [78]  [ 80/147]  eta: 0:00:38  lr: 0.000669  min_lr: 0.000669  loss: 2.4827 (2.3775)  weight_decay: 0.0500 (0.0500)  time: 0.5157  data: 0.0007  max mem: 5608\n",
            "Epoch: [78]  [ 90/147]  eta: 0:00:32  lr: 0.000666  min_lr: 0.000666  loss: 2.3740 (2.3739)  weight_decay: 0.0500 (0.0500)  time: 0.5098  data: 0.0012  max mem: 5608\n",
            "Epoch: [78]  [100/147]  eta: 0:00:26  lr: 0.000661  min_lr: 0.000661  loss: 2.3602 (2.3743)  weight_decay: 0.0500 (0.0500)  time: 0.4973  data: 0.0017  max mem: 5608\n",
            "Epoch: [78]  [110/147]  eta: 0:00:20  lr: 0.000658  min_lr: 0.000658  loss: 2.3631 (2.3730)  weight_decay: 0.0500 (0.0500)  time: 0.5035  data: 0.0015  max mem: 5608\n",
            "Epoch: [78]  [120/147]  eta: 0:00:14  lr: 0.000653  min_lr: 0.000653  loss: 2.3664 (2.3749)  weight_decay: 0.0500 (0.0500)  time: 0.5054  data: 0.0016  max mem: 5608\n",
            "Epoch: [78]  [130/147]  eta: 0:00:09  lr: 0.000650  min_lr: 0.000650  loss: 2.4341 (2.3851)  weight_decay: 0.0500 (0.0500)  time: 0.4966  data: 0.0010  max mem: 5608\n",
            "Epoch: [78]  [140/147]  eta: 0:00:03  lr: 0.000645  min_lr: 0.000645  loss: 2.4913 (2.3845)  weight_decay: 0.0500 (0.0500)  time: 0.4929  data: 0.0003  max mem: 5608\n",
            "Epoch: [78]  [146/147]  eta: 0:00:00  lr: 0.000645  min_lr: 0.000645  loss: 2.4913 (2.3844)  weight_decay: 0.0500 (0.0500)  time: 0.4197  data: 0.0002  max mem: 5608\n",
            "Epoch: [78] Total time: 0:01:18 (0.5346 s / it)\n",
            "Averaged stats: lr: 0.000645  min_lr: 0.000645  loss: 2.4913 (2.3844)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:33  loss: 0.4700 (0.4700)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 2.2912  data: 1.9736  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 0.5932 (0.5830)  acc1: 88.5417 (88.8258)  acc5: 97.9167 (98.2008)  time: 0.6070  data: 0.3614  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.6301 (0.7641)  acc1: 86.4583 (80.1091)  acc5: 98.9583 (98.4623)  time: 0.3384  data: 0.1031  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7338 (0.7629)  acc1: 78.1250 (80.5780)  acc5: 98.9583 (98.0511)  time: 0.2350  data: 0.0030  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6902 (0.7506)  acc1: 82.2917 (81.0446)  acc5: 97.9167 (97.8599)  time: 0.2301  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3477 s / it)\n",
            "* Acc@1 81.045 Acc@5 97.860 loss 0.751\n",
            "Accuracy of the model on the 3925 test images: 81.0%\n",
            "Max accuracy: 81.27%\n",
            "Test:  [ 0/41]  eta: 0:03:08  loss: 3.4256 (3.4256)  acc1: 27.0833 (27.0833)  acc5: 79.1667 (79.1667)  time: 4.5994  data: 4.3166  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 3.6827 (3.7732)  acc1: 21.8750 (22.5379)  acc5: 84.3750 (83.3333)  time: 0.6320  data: 0.3964  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.2491 (4.4845)  acc1: 15.6250 (15.5754)  acc5: 78.1250 (71.3294)  time: 0.2369  data: 0.0036  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 5.0112 (4.6919)  acc1: 2.0833 (14.2809)  acc5: 59.3750 (67.6411)  time: 0.2362  data: 0.0015  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3922 (4.2519)  acc1: 30.2083 (22.6242)  acc5: 81.2500 (70.2930)  time: 0.2326  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3573 s / it)\n",
            "* Acc@1 22.624 Acc@5 70.293 loss 4.252\n",
            "Accuracy of the model EMA on 3925 test images: 22.6%\n",
            "Max EMA accuracy: 22.62%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [79]  [  0/147]  eta: 0:10:09  lr: 0.000643  min_lr: 0.000643  loss: 2.5574 (2.5574)  weight_decay: 0.0500 (0.0500)  time: 4.1436  data: 3.4058  max mem: 5608\n",
            "Epoch: [79]  [ 10/147]  eta: 0:01:59  lr: 0.000640  min_lr: 0.000640  loss: 2.5440 (2.4780)  weight_decay: 0.0500 (0.0500)  time: 0.8721  data: 0.3310  max mem: 5608\n",
            "Epoch: [79]  [ 20/147]  eta: 0:01:29  lr: 0.000635  min_lr: 0.000635  loss: 2.5028 (2.4152)  weight_decay: 0.0500 (0.0500)  time: 0.5304  data: 0.0123  max mem: 5608\n",
            "Epoch: [79]  [ 30/147]  eta: 0:01:15  lr: 0.000632  min_lr: 0.000632  loss: 2.2499 (2.3761)  weight_decay: 0.0500 (0.0500)  time: 0.5221  data: 0.0008  max mem: 5608\n",
            "Epoch: [79]  [ 40/147]  eta: 0:01:05  lr: 0.000627  min_lr: 0.000627  loss: 2.3456 (2.3776)  weight_decay: 0.0500 (0.0500)  time: 0.5242  data: 0.0009  max mem: 5608\n",
            "Epoch: [79]  [ 50/147]  eta: 0:00:57  lr: 0.000624  min_lr: 0.000624  loss: 2.5269 (2.3868)  weight_decay: 0.0500 (0.0500)  time: 0.5165  data: 0.0015  max mem: 5608\n",
            "Epoch: [79]  [ 60/147]  eta: 0:00:50  lr: 0.000619  min_lr: 0.000619  loss: 2.4467 (2.3902)  weight_decay: 0.0500 (0.0500)  time: 0.5173  data: 0.0011  max mem: 5608\n",
            "Epoch: [79]  [ 70/147]  eta: 0:00:44  lr: 0.000616  min_lr: 0.000616  loss: 2.4767 (2.3988)  weight_decay: 0.0500 (0.0500)  time: 0.5162  data: 0.0011  max mem: 5608\n",
            "Epoch: [79]  [ 80/147]  eta: 0:00:37  lr: 0.000612  min_lr: 0.000612  loss: 2.4601 (2.3982)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0019  max mem: 5608\n",
            "Epoch: [79]  [ 90/147]  eta: 0:00:31  lr: 0.000608  min_lr: 0.000608  loss: 2.4325 (2.4050)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0024  max mem: 5608\n",
            "Epoch: [79]  [100/147]  eta: 0:00:25  lr: 0.000604  min_lr: 0.000604  loss: 2.4381 (2.4038)  weight_decay: 0.0500 (0.0500)  time: 0.5049  data: 0.0030  max mem: 5608\n",
            "Epoch: [79]  [110/147]  eta: 0:00:20  lr: 0.000601  min_lr: 0.000601  loss: 2.4226 (2.4054)  weight_decay: 0.0500 (0.0500)  time: 0.5015  data: 0.0024  max mem: 5608\n",
            "Epoch: [79]  [120/147]  eta: 0:00:14  lr: 0.000596  min_lr: 0.000596  loss: 2.4581 (2.4166)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.0024  max mem: 5608\n",
            "Epoch: [79]  [130/147]  eta: 0:00:09  lr: 0.000593  min_lr: 0.000593  loss: 2.4568 (2.4038)  weight_decay: 0.0500 (0.0500)  time: 0.5078  data: 0.0023  max mem: 5608\n",
            "Epoch: [79]  [140/147]  eta: 0:00:03  lr: 0.000588  min_lr: 0.000588  loss: 2.3886 (2.4009)  weight_decay: 0.0500 (0.0500)  time: 0.4983  data: 0.0007  max mem: 5608\n",
            "Epoch: [79]  [146/147]  eta: 0:00:00  lr: 0.000588  min_lr: 0.000588  loss: 2.4297 (2.4010)  weight_decay: 0.0500 (0.0500)  time: 0.4194  data: 0.0002  max mem: 5608\n",
            "Epoch: [79] Total time: 0:01:17 (0.5292 s / it)\n",
            "Averaged stats: lr: 0.000588  min_lr: 0.000588  loss: 2.4297 (2.4010)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:19  loss: 0.4540 (0.4540)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 1.9437  data: 1.6504  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 0.5394 (0.5399)  acc1: 89.5833 (89.9621)  acc5: 97.9167 (98.1061)  time: 0.6093  data: 0.3567  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.5873 (0.7161)  acc1: 87.5000 (81.9444)  acc5: 97.9167 (98.1647)  time: 0.3665  data: 0.1159  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7330 (0.7544)  acc1: 81.2500 (81.1156)  acc5: 97.9167 (97.8495)  time: 0.2637  data: 0.0145  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7408 (0.7588)  acc1: 81.2500 (81.0446)  acc5: 97.9167 (97.7834)  time: 0.2820  data: 0.0429  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3756 s / it)\n",
            "* Acc@1 81.045 Acc@5 97.783 loss 0.759\n",
            "Accuracy of the model on the 3925 test images: 81.0%\n",
            "Max accuracy: 81.27%\n",
            "Test:  [ 0/41]  eta: 0:02:15  loss: 3.4102 (3.4102)  acc1: 27.0833 (27.0833)  acc5: 79.1667 (79.1667)  time: 3.3111  data: 3.0081  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.6736 (3.7569)  acc1: 21.8750 (22.6326)  acc5: 84.3750 (83.4280)  time: 0.5191  data: 0.2751  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.2202 (4.4697)  acc1: 15.6250 (15.6250)  acc5: 78.1250 (71.4286)  time: 0.2433  data: 0.0020  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 4.9837 (4.6819)  acc1: 2.0833 (14.3481)  acc5: 59.3750 (67.6411)  time: 0.2511  data: 0.0023  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3851 (4.2389)  acc1: 30.2083 (22.7261)  acc5: 81.2500 (70.3185)  time: 0.2556  data: 0.0110  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3371 s / it)\n",
            "* Acc@1 22.726 Acc@5 70.318 loss 4.239\n",
            "Accuracy of the model EMA on 3925 test images: 22.7%\n",
            "Max EMA accuracy: 22.73%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [80]  [  0/147]  eta: 0:07:13  lr: 0.000587  min_lr: 0.000587  loss: 2.4502 (2.4502)  weight_decay: 0.0500 (0.0500)  time: 2.9470  data: 2.3680  max mem: 5608\n",
            "Epoch: [80]  [ 10/147]  eta: 0:01:41  lr: 0.000584  min_lr: 0.000584  loss: 2.2455 (2.3181)  weight_decay: 0.0500 (0.0500)  time: 0.7412  data: 0.2171  max mem: 5608\n",
            "Epoch: [80]  [ 20/147]  eta: 0:01:21  lr: 0.000579  min_lr: 0.000579  loss: 2.2861 (2.3472)  weight_decay: 0.0500 (0.0500)  time: 0.5237  data: 0.0033  max mem: 5608\n",
            "Epoch: [80]  [ 30/147]  eta: 0:01:09  lr: 0.000576  min_lr: 0.000576  loss: 2.2936 (2.3511)  weight_decay: 0.0500 (0.0500)  time: 0.5181  data: 0.0030  max mem: 5608\n",
            "Epoch: [80]  [ 40/147]  eta: 0:01:01  lr: 0.000571  min_lr: 0.000571  loss: 2.3662 (2.3506)  weight_decay: 0.0500 (0.0500)  time: 0.5075  data: 0.0016  max mem: 5608\n",
            "Epoch: [80]  [ 50/147]  eta: 0:00:54  lr: 0.000568  min_lr: 0.000568  loss: 2.4279 (2.3685)  weight_decay: 0.0500 (0.0500)  time: 0.5050  data: 0.0019  max mem: 5608\n",
            "Epoch: [80]  [ 60/147]  eta: 0:00:48  lr: 0.000564  min_lr: 0.000564  loss: 2.5149 (2.3889)  weight_decay: 0.0500 (0.0500)  time: 0.5118  data: 0.0020  max mem: 5608\n",
            "Epoch: [80]  [ 70/147]  eta: 0:00:42  lr: 0.000561  min_lr: 0.000561  loss: 2.5157 (2.3983)  weight_decay: 0.0500 (0.0500)  time: 0.5106  data: 0.0012  max mem: 5608\n",
            "Epoch: [80]  [ 80/147]  eta: 0:00:36  lr: 0.000556  min_lr: 0.000556  loss: 2.5157 (2.4107)  weight_decay: 0.0500 (0.0500)  time: 0.5002  data: 0.0006  max mem: 5608\n",
            "Epoch: [80]  [ 90/147]  eta: 0:00:30  lr: 0.000553  min_lr: 0.000553  loss: 2.5977 (2.4266)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0014  max mem: 5608\n",
            "Epoch: [80]  [100/147]  eta: 0:00:25  lr: 0.000549  min_lr: 0.000549  loss: 2.6430 (2.4443)  weight_decay: 0.0500 (0.0500)  time: 0.5094  data: 0.0016  max mem: 5608\n",
            "Epoch: [80]  [110/147]  eta: 0:00:19  lr: 0.000546  min_lr: 0.000546  loss: 2.5396 (2.4372)  weight_decay: 0.0500 (0.0500)  time: 0.5054  data: 0.0014  max mem: 5608\n",
            "Epoch: [80]  [120/147]  eta: 0:00:14  lr: 0.000541  min_lr: 0.000541  loss: 2.3731 (2.4320)  weight_decay: 0.0500 (0.0500)  time: 0.4999  data: 0.0018  max mem: 5608\n",
            "Epoch: [80]  [130/147]  eta: 0:00:08  lr: 0.000538  min_lr: 0.000538  loss: 2.4038 (2.4328)  weight_decay: 0.0500 (0.0500)  time: 0.5047  data: 0.0012  max mem: 5608\n",
            "Epoch: [80]  [140/147]  eta: 0:00:03  lr: 0.000534  min_lr: 0.000534  loss: 2.4812 (2.4265)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0004  max mem: 5608\n",
            "Epoch: [80]  [146/147]  eta: 0:00:00  lr: 0.000534  min_lr: 0.000534  loss: 2.4977 (2.4250)  weight_decay: 0.0500 (0.0500)  time: 0.4232  data: 0.0002  max mem: 5608\n",
            "Epoch: [80] Total time: 0:01:15 (0.5165 s / it)\n",
            "Averaged stats: lr: 0.000534  min_lr: 0.000534  loss: 2.4977 (2.4250)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:23  loss: 0.4671 (0.4671)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 4.9744  data: 4.6840  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5267 (0.5632)  acc1: 88.5417 (89.0152)  acc5: 98.9583 (98.4849)  time: 0.7891  data: 0.5342  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6541 (0.7359)  acc1: 85.4167 (81.6468)  acc5: 97.9167 (98.2639)  time: 0.3662  data: 0.1180  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7464 (0.7587)  acc1: 78.1250 (80.8132)  acc5: 97.9167 (97.8831)  time: 0.2983  data: 0.0584  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6982 (0.7432)  acc1: 82.2917 (81.5032)  acc5: 97.9167 (97.9108)  time: 0.2318  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:17 (0.4223 s / it)\n",
            "* Acc@1 81.503 Acc@5 97.911 loss 0.743\n",
            "Accuracy of the model on the 3925 test images: 81.5%\n",
            "Max accuracy: 81.50%\n",
            "Test:  [ 0/41]  eta: 0:02:25  loss: 3.3946 (3.3946)  acc1: 27.0833 (27.0833)  acc5: 79.1667 (79.1667)  time: 3.5494  data: 3.2653  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 3.6641 (3.7414)  acc1: 22.9167 (22.4432)  acc5: 84.3750 (83.4280)  time: 0.6156  data: 0.3770  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 4.1921 (4.4557)  acc1: 15.6250 (15.6250)  acc5: 78.1250 (71.6766)  time: 0.3586  data: 0.1140  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 4.9562 (4.6727)  acc1: 2.0833 (14.3145)  acc5: 59.3750 (67.8091)  time: 0.3766  data: 0.1291  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3776 (4.2266)  acc1: 30.2083 (22.8790)  acc5: 81.2500 (70.4713)  time: 0.2968  data: 0.0593  max mem: 5608\n",
            "Test: Total time: 0:00:17 (0.4219 s / it)\n",
            "* Acc@1 22.879 Acc@5 70.471 loss 4.227\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "Max EMA accuracy: 22.88%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [81]  [  0/147]  eta: 0:07:48  lr: 0.000532  min_lr: 0.000532  loss: 2.5162 (2.5162)  weight_decay: 0.0500 (0.0500)  time: 3.1857  data: 2.5742  max mem: 5608\n",
            "Epoch: [81]  [ 10/147]  eta: 0:01:44  lr: 0.000529  min_lr: 0.000529  loss: 2.4695 (2.4029)  weight_decay: 0.0500 (0.0500)  time: 0.7637  data: 0.2402  max mem: 5608\n",
            "Epoch: [81]  [ 20/147]  eta: 0:01:22  lr: 0.000525  min_lr: 0.000525  loss: 2.4654 (2.4478)  weight_decay: 0.0500 (0.0500)  time: 0.5237  data: 0.0053  max mem: 5608\n",
            "Epoch: [81]  [ 30/147]  eta: 0:01:10  lr: 0.000522  min_lr: 0.000522  loss: 2.3881 (2.4114)  weight_decay: 0.0500 (0.0500)  time: 0.5185  data: 0.0029  max mem: 5608\n",
            "Epoch: [81]  [ 40/147]  eta: 0:01:02  lr: 0.000518  min_lr: 0.000518  loss: 2.3999 (2.4281)  weight_decay: 0.0500 (0.0500)  time: 0.5091  data: 0.0015  max mem: 5608\n",
            "Epoch: [81]  [ 50/147]  eta: 0:00:55  lr: 0.000515  min_lr: 0.000515  loss: 2.3999 (2.4012)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0013  max mem: 5608\n",
            "Epoch: [81]  [ 60/147]  eta: 0:00:48  lr: 0.000510  min_lr: 0.000510  loss: 2.3800 (2.3920)  weight_decay: 0.0500 (0.0500)  time: 0.5109  data: 0.0022  max mem: 5608\n",
            "Epoch: [81]  [ 70/147]  eta: 0:00:42  lr: 0.000507  min_lr: 0.000507  loss: 2.3914 (2.3881)  weight_decay: 0.0500 (0.0500)  time: 0.5067  data: 0.0022  max mem: 5608\n",
            "Epoch: [81]  [ 80/147]  eta: 0:00:36  lr: 0.000503  min_lr: 0.000503  loss: 2.4764 (2.3974)  weight_decay: 0.0500 (0.0500)  time: 0.4998  data: 0.0012  max mem: 5608\n",
            "Epoch: [81]  [ 90/147]  eta: 0:00:30  lr: 0.000500  min_lr: 0.000500  loss: 2.5318 (2.4169)  weight_decay: 0.0500 (0.0500)  time: 0.5028  data: 0.0018  max mem: 5608\n",
            "Epoch: [81]  [100/147]  eta: 0:00:25  lr: 0.000496  min_lr: 0.000496  loss: 2.5318 (2.4215)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0023  max mem: 5608\n",
            "Epoch: [81]  [110/147]  eta: 0:00:19  lr: 0.000493  min_lr: 0.000493  loss: 2.4714 (2.4220)  weight_decay: 0.0500 (0.0500)  time: 0.5024  data: 0.0026  max mem: 5608\n",
            "Epoch: [81]  [120/147]  eta: 0:00:14  lr: 0.000489  min_lr: 0.000489  loss: 2.4847 (2.4250)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0030  max mem: 5608\n",
            "Epoch: [81]  [130/147]  eta: 0:00:08  lr: 0.000486  min_lr: 0.000486  loss: 2.4847 (2.4266)  weight_decay: 0.0500 (0.0500)  time: 0.5050  data: 0.0020  max mem: 5608\n",
            "Epoch: [81]  [140/147]  eta: 0:00:03  lr: 0.000481  min_lr: 0.000481  loss: 2.4233 (2.4256)  weight_decay: 0.0500 (0.0500)  time: 0.5009  data: 0.0008  max mem: 5608\n",
            "Epoch: [81]  [146/147]  eta: 0:00:00  lr: 0.000481  min_lr: 0.000481  loss: 2.3882 (2.4246)  weight_decay: 0.0500 (0.0500)  time: 0.4216  data: 0.0003  max mem: 5608\n",
            "Epoch: [81] Total time: 0:01:16 (0.5180 s / it)\n",
            "Averaged stats: lr: 0.000481  min_lr: 0.000481  loss: 2.3882 (2.4246)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:05  loss: 0.4675 (0.4675)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 4.5141  data: 4.2365  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5540 (0.5687)  acc1: 90.6250 (89.6780)  acc5: 97.9167 (98.4849)  time: 0.7763  data: 0.5322  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6266 (0.7531)  acc1: 86.4583 (81.5476)  acc5: 97.9167 (98.0159)  time: 0.3675  data: 0.1234  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7410 (0.7673)  acc1: 80.2083 (81.2164)  acc5: 97.9167 (98.0175)  time: 0.2832  data: 0.0426  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7410 (0.7608)  acc1: 80.2083 (81.3758)  acc5: 97.9167 (97.9873)  time: 0.2314  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.4125 s / it)\n",
            "* Acc@1 81.376 Acc@5 97.987 loss 0.761\n",
            "Accuracy of the model on the 3925 test images: 81.4%\n",
            "Max accuracy: 81.50%\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 3.3792 (3.3792)  acc1: 26.0417 (26.0417)  acc5: 79.1667 (79.1667)  time: 3.4980  data: 3.2118  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.6546 (3.7264)  acc1: 22.9167 (22.6326)  acc5: 84.3750 (83.7121)  time: 0.5684  data: 0.3210  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.1650 (4.4417)  acc1: 15.6250 (15.6746)  acc5: 78.1250 (72.0734)  time: 0.3226  data: 0.0768  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.9274 (4.6637)  acc1: 2.0833 (14.3145)  acc5: 59.3750 (68.0444)  time: 0.3165  data: 0.0708  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3750 (4.2147)  acc1: 30.2083 (22.9299)  acc5: 81.2500 (70.7516)  time: 0.2481  data: 0.0100  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3734 s / it)\n",
            "* Acc@1 22.930 Acc@5 70.752 loss 4.215\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "Max EMA accuracy: 22.93%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [82]  [  0/147]  eta: 0:08:24  lr: 0.000480  min_lr: 0.000480  loss: 1.9074 (1.9074)  weight_decay: 0.0500 (0.0500)  time: 3.4312  data: 2.8569  max mem: 5608\n",
            "Epoch: [82]  [ 10/147]  eta: 0:01:47  lr: 0.000477  min_lr: 0.000477  loss: 2.3674 (2.3150)  weight_decay: 0.0500 (0.0500)  time: 0.7823  data: 0.2610  max mem: 5608\n",
            "Epoch: [82]  [ 20/147]  eta: 0:01:23  lr: 0.000473  min_lr: 0.000473  loss: 2.3260 (2.3066)  weight_decay: 0.0500 (0.0500)  time: 0.5178  data: 0.0016  max mem: 5608\n",
            "Epoch: [82]  [ 30/147]  eta: 0:01:11  lr: 0.000470  min_lr: 0.000470  loss: 2.3260 (2.3267)  weight_decay: 0.0500 (0.0500)  time: 0.5139  data: 0.0012  max mem: 5608\n",
            "Epoch: [82]  [ 40/147]  eta: 0:01:02  lr: 0.000466  min_lr: 0.000466  loss: 2.5353 (2.3532)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0005  max mem: 5608\n",
            "Epoch: [82]  [ 50/147]  eta: 0:00:55  lr: 0.000463  min_lr: 0.000463  loss: 2.2921 (2.3510)  weight_decay: 0.0500 (0.0500)  time: 0.5160  data: 0.0017  max mem: 5608\n",
            "Epoch: [82]  [ 60/147]  eta: 0:00:49  lr: 0.000459  min_lr: 0.000459  loss: 2.2445 (2.3376)  weight_decay: 0.0500 (0.0500)  time: 0.5209  data: 0.0026  max mem: 5608\n",
            "Epoch: [82]  [ 70/147]  eta: 0:00:42  lr: 0.000456  min_lr: 0.000456  loss: 2.3755 (2.3541)  weight_decay: 0.0500 (0.0500)  time: 0.5157  data: 0.0019  max mem: 5608\n",
            "Epoch: [82]  [ 80/147]  eta: 0:00:36  lr: 0.000452  min_lr: 0.000452  loss: 2.4135 (2.3542)  weight_decay: 0.0500 (0.0500)  time: 0.5073  data: 0.0019  max mem: 5608\n",
            "Epoch: [82]  [ 90/147]  eta: 0:00:31  lr: 0.000449  min_lr: 0.000449  loss: 2.3889 (2.3453)  weight_decay: 0.0500 (0.0500)  time: 0.5075  data: 0.0020  max mem: 5608\n",
            "Epoch: [82]  [100/147]  eta: 0:00:25  lr: 0.000445  min_lr: 0.000445  loss: 2.3650 (2.3481)  weight_decay: 0.0500 (0.0500)  time: 0.5051  data: 0.0015  max mem: 5608\n",
            "Epoch: [82]  [110/147]  eta: 0:00:19  lr: 0.000442  min_lr: 0.000442  loss: 2.3347 (2.3501)  weight_decay: 0.0500 (0.0500)  time: 0.4993  data: 0.0010  max mem: 5608\n",
            "Epoch: [82]  [120/147]  eta: 0:00:14  lr: 0.000438  min_lr: 0.000438  loss: 2.2177 (2.3417)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.0010  max mem: 5608\n",
            "Epoch: [82]  [130/147]  eta: 0:00:09  lr: 0.000436  min_lr: 0.000436  loss: 2.2417 (2.3402)  weight_decay: 0.0500 (0.0500)  time: 0.5062  data: 0.0016  max mem: 5608\n",
            "Epoch: [82]  [140/147]  eta: 0:00:03  lr: 0.000432  min_lr: 0.000432  loss: 2.3480 (2.3442)  weight_decay: 0.0500 (0.0500)  time: 0.4977  data: 0.0011  max mem: 5608\n",
            "Epoch: [82]  [146/147]  eta: 0:00:00  lr: 0.000432  min_lr: 0.000432  loss: 2.3091 (2.3468)  weight_decay: 0.0500 (0.0500)  time: 0.4200  data: 0.0002  max mem: 5608\n",
            "Epoch: [82] Total time: 0:01:16 (0.5213 s / it)\n",
            "Averaged stats: lr: 0.000432  min_lr: 0.000432  loss: 2.3091 (2.3468)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:52  loss: 0.4526 (0.4526)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 5.6780  data: 5.3944  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.4964 (0.5094)  acc1: 90.6250 (90.2462)  acc5: 97.9167 (98.4849)  time: 0.7547  data: 0.5107  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5563 (0.6901)  acc1: 86.4583 (82.6389)  acc5: 97.9167 (98.4127)  time: 0.2535  data: 0.0148  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.8006 (0.7357)  acc1: 77.0833 (81.2500)  acc5: 97.9167 (98.1519)  time: 0.2407  data: 0.0037  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8006 (0.7345)  acc1: 79.1667 (81.1975)  acc5: 97.9167 (97.9873)  time: 0.2321  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3850 s / it)\n",
            "* Acc@1 81.197 Acc@5 97.987 loss 0.734\n",
            "Accuracy of the model on the 3925 test images: 81.2%\n",
            "Max accuracy: 81.50%\n",
            "Test:  [ 0/41]  eta: 0:02:52  loss: 3.3643 (3.3643)  acc1: 26.0417 (26.0417)  acc5: 79.1667 (79.1667)  time: 4.1962  data: 3.8223  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.6455 (3.7114)  acc1: 22.9167 (22.1591)  acc5: 84.3750 (83.9015)  time: 0.7053  data: 0.4558  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.1386 (4.4271)  acc1: 15.6250 (15.4762)  acc5: 79.1667 (72.2222)  time: 0.3654  data: 0.1281  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.8984 (4.6536)  acc1: 2.0833 (14.1465)  acc5: 59.3750 (68.0780)  time: 0.3046  data: 0.0686  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3684 (4.2019)  acc1: 30.2083 (22.8280)  acc5: 81.2500 (70.8025)  time: 0.2328  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.4041 s / it)\n",
            "* Acc@1 22.828 Acc@5 70.803 loss 4.202\n",
            "Accuracy of the model EMA on 3925 test images: 22.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [83]  [  0/147]  eta: 0:07:25  lr: 0.000430  min_lr: 0.000430  loss: 2.6270 (2.6270)  weight_decay: 0.0500 (0.0500)  time: 3.0302  data: 2.4416  max mem: 5608\n",
            "Epoch: [83]  [ 10/147]  eta: 0:01:45  lr: 0.000428  min_lr: 0.000428  loss: 2.5364 (2.4532)  weight_decay: 0.0500 (0.0500)  time: 0.7674  data: 0.2245  max mem: 5608\n",
            "Epoch: [83]  [ 20/147]  eta: 0:01:22  lr: 0.000424  min_lr: 0.000424  loss: 2.5547 (2.4963)  weight_decay: 0.0500 (0.0500)  time: 0.5334  data: 0.0024  max mem: 5608\n",
            "Epoch: [83]  [ 30/147]  eta: 0:01:11  lr: 0.000421  min_lr: 0.000421  loss: 2.4661 (2.4283)  weight_decay: 0.0500 (0.0500)  time: 0.5188  data: 0.0017  max mem: 5608\n",
            "Epoch: [83]  [ 40/147]  eta: 0:01:02  lr: 0.000417  min_lr: 0.000417  loss: 2.2242 (2.3776)  weight_decay: 0.0500 (0.0500)  time: 0.5167  data: 0.0014  max mem: 5608\n",
            "Epoch: [83]  [ 50/147]  eta: 0:00:55  lr: 0.000414  min_lr: 0.000414  loss: 2.3537 (2.3778)  weight_decay: 0.0500 (0.0500)  time: 0.5232  data: 0.0027  max mem: 5608\n",
            "Epoch: [83]  [ 60/147]  eta: 0:00:49  lr: 0.000410  min_lr: 0.000410  loss: 2.4463 (2.3991)  weight_decay: 0.0500 (0.0500)  time: 0.5175  data: 0.0033  max mem: 5608\n",
            "Epoch: [83]  [ 70/147]  eta: 0:00:42  lr: 0.000408  min_lr: 0.000408  loss: 2.4255 (2.3875)  weight_decay: 0.0500 (0.0500)  time: 0.5084  data: 0.0031  max mem: 5608\n",
            "Epoch: [83]  [ 80/147]  eta: 0:00:36  lr: 0.000404  min_lr: 0.000404  loss: 2.3543 (2.3939)  weight_decay: 0.0500 (0.0500)  time: 0.5122  data: 0.0034  max mem: 5608\n",
            "Epoch: [83]  [ 90/147]  eta: 0:00:31  lr: 0.000401  min_lr: 0.000401  loss: 2.4870 (2.3981)  weight_decay: 0.0500 (0.0500)  time: 0.5129  data: 0.0031  max mem: 5608\n",
            "Epoch: [83]  [100/147]  eta: 0:00:25  lr: 0.000397  min_lr: 0.000397  loss: 2.4870 (2.4017)  weight_decay: 0.0500 (0.0500)  time: 0.5009  data: 0.0026  max mem: 5608\n",
            "Epoch: [83]  [110/147]  eta: 0:00:19  lr: 0.000394  min_lr: 0.000394  loss: 2.4247 (2.4034)  weight_decay: 0.0500 (0.0500)  time: 0.4983  data: 0.0020  max mem: 5608\n",
            "Epoch: [83]  [120/147]  eta: 0:00:14  lr: 0.000391  min_lr: 0.000391  loss: 2.4980 (2.4077)  weight_decay: 0.0500 (0.0500)  time: 0.5056  data: 0.0034  max mem: 5608\n",
            "Epoch: [83]  [130/147]  eta: 0:00:09  lr: 0.000388  min_lr: 0.000388  loss: 2.5249 (2.4159)  weight_decay: 0.0500 (0.0500)  time: 0.5003  data: 0.0033  max mem: 5608\n",
            "Epoch: [83]  [140/147]  eta: 0:00:03  lr: 0.000384  min_lr: 0.000384  loss: 2.4057 (2.4110)  weight_decay: 0.0500 (0.0500)  time: 0.4926  data: 0.0009  max mem: 5608\n",
            "Epoch: [83]  [146/147]  eta: 0:00:00  lr: 0.000384  min_lr: 0.000384  loss: 2.3835 (2.4110)  weight_decay: 0.0500 (0.0500)  time: 0.4197  data: 0.0002  max mem: 5608\n",
            "Epoch: [83] Total time: 0:01:16 (0.5229 s / it)\n",
            "Averaged stats: lr: 0.000384  min_lr: 0.000384  loss: 2.3835 (2.4110)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:22  loss: 0.4400 (0.4400)  acc1: 92.7083 (92.7083)  acc5: 96.8750 (96.8750)  time: 6.3975  data: 6.0956  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 0.5765 (0.5633)  acc1: 89.5833 (90.0568)  acc5: 97.9167 (98.3902)  time: 0.8186  data: 0.5700  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6067 (0.7173)  acc1: 87.5000 (82.9365)  acc5: 97.9167 (98.0655)  time: 0.2543  data: 0.0146  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6925 (0.7393)  acc1: 81.2500 (82.0565)  acc5: 97.9167 (98.0847)  time: 0.2411  data: 0.0060  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7090 (0.7411)  acc1: 83.3333 (82.1147)  acc5: 97.9167 (97.9108)  time: 0.2319  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.4023 s / it)\n",
            "* Acc@1 82.115 Acc@5 97.911 loss 0.741\n",
            "Accuracy of the model on the 3925 test images: 82.1%\n",
            "Max accuracy: 82.11%\n",
            "Test:  [ 0/41]  eta: 0:03:52  loss: 3.3508 (3.3508)  acc1: 26.0417 (26.0417)  acc5: 79.1667 (79.1667)  time: 5.6715  data: 5.3622  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 3.6371 (3.6961)  acc1: 23.9583 (22.7273)  acc5: 84.3750 (84.1856)  time: 0.7692  data: 0.5251  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 4.1119 (4.4121)  acc1: 15.6250 (15.7242)  acc5: 80.2083 (72.4702)  time: 0.2595  data: 0.0221  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.8695 (4.6432)  acc1: 2.0833 (14.2137)  acc5: 59.3750 (68.1452)  time: 0.2399  data: 0.0015  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3615 (4.1890)  acc1: 28.1250 (22.9299)  acc5: 81.2500 (70.8535)  time: 0.2359  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3893 s / it)\n",
            "* Acc@1 22.930 Acc@5 70.854 loss 4.189\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "Max EMA accuracy: 22.93%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [84]  [  0/147]  eta: 0:11:50  lr: 0.000383  min_lr: 0.000383  loss: 2.4261 (2.4261)  weight_decay: 0.0500 (0.0500)  time: 4.8334  data: 4.0513  max mem: 5608\n",
            "Epoch: [84]  [ 10/147]  eta: 0:02:11  lr: 0.000380  min_lr: 0.000380  loss: 2.4280 (2.3466)  weight_decay: 0.0500 (0.0500)  time: 0.9631  data: 0.3693  max mem: 5608\n",
            "Epoch: [84]  [ 20/147]  eta: 0:01:35  lr: 0.000376  min_lr: 0.000376  loss: 2.4280 (2.3828)  weight_decay: 0.0500 (0.0500)  time: 0.5447  data: 0.0020  max mem: 5608\n",
            "Epoch: [84]  [ 30/147]  eta: 0:01:18  lr: 0.000374  min_lr: 0.000374  loss: 2.3806 (2.3945)  weight_decay: 0.0500 (0.0500)  time: 0.5162  data: 0.0026  max mem: 5608\n",
            "Epoch: [84]  [ 40/147]  eta: 0:01:08  lr: 0.000370  min_lr: 0.000370  loss: 2.3317 (2.3807)  weight_decay: 0.0500 (0.0500)  time: 0.5190  data: 0.0024  max mem: 5608\n",
            "Epoch: [84]  [ 50/147]  eta: 0:00:59  lr: 0.000368  min_lr: 0.000368  loss: 2.4131 (2.3922)  weight_decay: 0.0500 (0.0500)  time: 0.5143  data: 0.0019  max mem: 5608\n",
            "Epoch: [84]  [ 60/147]  eta: 0:00:51  lr: 0.000364  min_lr: 0.000364  loss: 2.4657 (2.4065)  weight_decay: 0.0500 (0.0500)  time: 0.5116  data: 0.0011  max mem: 5608\n",
            "Epoch: [84]  [ 70/147]  eta: 0:00:44  lr: 0.000361  min_lr: 0.000361  loss: 2.5365 (2.4135)  weight_decay: 0.0500 (0.0500)  time: 0.5143  data: 0.0016  max mem: 5608\n",
            "Epoch: [84]  [ 80/147]  eta: 0:00:38  lr: 0.000358  min_lr: 0.000358  loss: 2.5365 (2.4171)  weight_decay: 0.0500 (0.0500)  time: 0.5071  data: 0.0016  max mem: 5608\n",
            "Epoch: [84]  [ 90/147]  eta: 0:00:32  lr: 0.000355  min_lr: 0.000355  loss: 2.3669 (2.4126)  weight_decay: 0.0500 (0.0500)  time: 0.4973  data: 0.0021  max mem: 5608\n",
            "Epoch: [84]  [100/147]  eta: 0:00:26  lr: 0.000351  min_lr: 0.000351  loss: 2.3740 (2.4084)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0033  max mem: 5608\n",
            "Epoch: [84]  [110/147]  eta: 0:00:20  lr: 0.000349  min_lr: 0.000349  loss: 2.4223 (2.4077)  weight_decay: 0.0500 (0.0500)  time: 0.5074  data: 0.0024  max mem: 5608\n",
            "Epoch: [84]  [120/147]  eta: 0:00:14  lr: 0.000345  min_lr: 0.000345  loss: 2.3255 (2.3906)  weight_decay: 0.0500 (0.0500)  time: 0.4988  data: 0.0013  max mem: 5608\n",
            "Epoch: [84]  [130/147]  eta: 0:00:09  lr: 0.000343  min_lr: 0.000343  loss: 2.2288 (2.3851)  weight_decay: 0.0500 (0.0500)  time: 0.4961  data: 0.0007  max mem: 5608\n",
            "Epoch: [84]  [140/147]  eta: 0:00:03  lr: 0.000339  min_lr: 0.000339  loss: 2.3811 (2.3937)  weight_decay: 0.0500 (0.0500)  time: 0.4961  data: 0.0002  max mem: 5608\n",
            "Epoch: [84]  [146/147]  eta: 0:00:00  lr: 0.000339  min_lr: 0.000339  loss: 2.3724 (2.3926)  weight_decay: 0.0500 (0.0500)  time: 0.4210  data: 0.0002  max mem: 5608\n",
            "Epoch: [84] Total time: 0:01:18 (0.5330 s / it)\n",
            "Averaged stats: lr: 0.000339  min_lr: 0.000339  loss: 2.3724 (2.3926)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:16  loss: 0.4818 (0.4818)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 3.3323  data: 3.0467  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 0.5270 (0.5356)  acc1: 89.5833 (90.0568)  acc5: 97.9167 (98.1061)  time: 0.5258  data: 0.2809  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.5728 (0.6753)  acc1: 88.5417 (84.0278)  acc5: 97.9167 (98.4127)  time: 0.2636  data: 0.0215  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6349 (0.7029)  acc1: 80.2083 (82.9301)  acc5: 97.9167 (98.1519)  time: 0.3054  data: 0.0621  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7028 (0.7178)  acc1: 80.2083 (82.2675)  acc5: 97.9167 (97.9363)  time: 0.2813  data: 0.0429  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3564 s / it)\n",
            "* Acc@1 82.268 Acc@5 97.936 loss 0.718\n",
            "Accuracy of the model on the 3925 test images: 82.3%\n",
            "Max accuracy: 82.27%\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 3.3359 (3.3359)  acc1: 26.0417 (26.0417)  acc5: 79.1667 (79.1667)  time: 3.4986  data: 3.2097  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.6271 (3.6805)  acc1: 23.9583 (22.6326)  acc5: 85.4167 (84.5644)  time: 0.5401  data: 0.2929  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 4.0840 (4.3971)  acc1: 15.6250 (15.7738)  acc5: 80.2083 (72.6687)  time: 0.2477  data: 0.0014  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 4.8510 (4.6324)  acc1: 2.0833 (14.2137)  acc5: 59.3750 (68.2460)  time: 0.2502  data: 0.0076  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3521 (4.1759)  acc1: 28.1250 (22.9554)  acc5: 81.2500 (70.9299)  time: 0.2407  data: 0.0069  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3374 s / it)\n",
            "* Acc@1 22.955 Acc@5 70.930 loss 4.176\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "Max EMA accuracy: 22.96%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [85]  [  0/147]  eta: 0:07:10  lr: 0.000338  min_lr: 0.000338  loss: 2.7196 (2.7196)  weight_decay: 0.0500 (0.0500)  time: 2.9265  data: 2.2938  max mem: 5608\n",
            "Epoch: [85]  [ 10/147]  eta: 0:01:48  lr: 0.000336  min_lr: 0.000336  loss: 2.5118 (2.5131)  weight_decay: 0.0500 (0.0500)  time: 0.7883  data: 0.2093  max mem: 5608\n",
            "Epoch: [85]  [ 20/147]  eta: 0:01:24  lr: 0.000332  min_lr: 0.000332  loss: 2.5003 (2.4870)  weight_decay: 0.0500 (0.0500)  time: 0.5532  data: 0.0037  max mem: 5608\n",
            "Epoch: [85]  [ 30/147]  eta: 0:01:12  lr: 0.000330  min_lr: 0.000330  loss: 2.4992 (2.4617)  weight_decay: 0.0500 (0.0500)  time: 0.5245  data: 0.0036  max mem: 5608\n",
            "Epoch: [85]  [ 40/147]  eta: 0:01:03  lr: 0.000326  min_lr: 0.000326  loss: 2.3384 (2.4069)  weight_decay: 0.0500 (0.0500)  time: 0.5150  data: 0.0021  max mem: 5608\n",
            "Epoch: [85]  [ 50/147]  eta: 0:00:55  lr: 0.000324  min_lr: 0.000324  loss: 2.3384 (2.3961)  weight_decay: 0.0500 (0.0500)  time: 0.5123  data: 0.0036  max mem: 5608\n",
            "Epoch: [85]  [ 60/147]  eta: 0:00:49  lr: 0.000320  min_lr: 0.000320  loss: 2.4482 (2.4047)  weight_decay: 0.0500 (0.0500)  time: 0.5143  data: 0.0032  max mem: 5608\n",
            "Epoch: [85]  [ 70/147]  eta: 0:00:42  lr: 0.000318  min_lr: 0.000318  loss: 2.5080 (2.4167)  weight_decay: 0.0500 (0.0500)  time: 0.5110  data: 0.0029  max mem: 5608\n",
            "Epoch: [85]  [ 80/147]  eta: 0:00:36  lr: 0.000314  min_lr: 0.000314  loss: 2.5028 (2.4123)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0020  max mem: 5608\n",
            "Epoch: [85]  [ 90/147]  eta: 0:00:31  lr: 0.000312  min_lr: 0.000312  loss: 2.4803 (2.4190)  weight_decay: 0.0500 (0.0500)  time: 0.5036  data: 0.0017  max mem: 5608\n",
            "Epoch: [85]  [100/147]  eta: 0:00:25  lr: 0.000308  min_lr: 0.000308  loss: 2.4803 (2.4031)  weight_decay: 0.0500 (0.0500)  time: 0.5073  data: 0.0030  max mem: 5608\n",
            "Epoch: [85]  [110/147]  eta: 0:00:19  lr: 0.000306  min_lr: 0.000306  loss: 2.3041 (2.3957)  weight_decay: 0.0500 (0.0500)  time: 0.5008  data: 0.0031  max mem: 5608\n",
            "Epoch: [85]  [120/147]  eta: 0:00:14  lr: 0.000303  min_lr: 0.000303  loss: 2.3041 (2.3872)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0024  max mem: 5608\n",
            "Epoch: [85]  [130/147]  eta: 0:00:09  lr: 0.000300  min_lr: 0.000300  loss: 2.3202 (2.3902)  weight_decay: 0.0500 (0.0500)  time: 0.5010  data: 0.0020  max mem: 5608\n",
            "Epoch: [85]  [140/147]  eta: 0:00:03  lr: 0.000297  min_lr: 0.000297  loss: 2.5653 (2.3996)  weight_decay: 0.0500 (0.0500)  time: 0.4965  data: 0.0010  max mem: 5608\n",
            "Epoch: [85]  [146/147]  eta: 0:00:00  lr: 0.000297  min_lr: 0.000297  loss: 2.5524 (2.3930)  weight_decay: 0.0500 (0.0500)  time: 0.4185  data: 0.0002  max mem: 5608\n",
            "Epoch: [85] Total time: 0:01:16 (0.5211 s / it)\n",
            "Averaged stats: lr: 0.000297  min_lr: 0.000297  loss: 2.5524 (2.3930)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:10  loss: 0.4495 (0.4495)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 4.6473  data: 4.3056  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5286 (0.5270)  acc1: 90.6250 (89.9621)  acc5: 97.9167 (98.2955)  time: 0.7331  data: 0.4847  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5721 (0.7003)  acc1: 88.5417 (82.7877)  acc5: 97.9167 (98.4127)  time: 0.3305  data: 0.0896  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7529 (0.7135)  acc1: 80.2083 (82.0229)  acc5: 97.9167 (98.2191)  time: 0.2797  data: 0.0384  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6952 (0.7050)  acc1: 83.3333 (82.3949)  acc5: 97.9167 (98.1147)  time: 0.2354  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3981 s / it)\n",
            "* Acc@1 82.395 Acc@5 98.115 loss 0.705\n",
            "Accuracy of the model on the 3925 test images: 82.4%\n",
            "Max accuracy: 82.39%\n",
            "Test:  [ 0/41]  eta: 0:02:06  loss: 3.3190 (3.3190)  acc1: 26.0417 (26.0417)  acc5: 79.1667 (79.1667)  time: 3.0735  data: 2.8103  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 3.6153 (3.6650)  acc1: 23.9583 (22.7273)  acc5: 85.4167 (84.7538)  time: 0.6147  data: 0.3749  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 4.0565 (4.3823)  acc1: 14.5833 (15.8730)  acc5: 80.2083 (72.7679)  time: 0.3500  data: 0.1108  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.8622 (4.6223)  acc1: 2.0833 (14.2473)  acc5: 60.4167 (68.2796)  time: 0.3158  data: 0.0763  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3462 (4.1634)  acc1: 27.0833 (22.9809)  acc5: 81.2500 (71.0064)  time: 0.2677  data: 0.0312  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3870 s / it)\n",
            "* Acc@1 22.981 Acc@5 71.006 loss 4.163\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "Max EMA accuracy: 22.98%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [86]  [  0/147]  eta: 0:07:01  lr: 0.000296  min_lr: 0.000296  loss: 2.5262 (2.5262)  weight_decay: 0.0500 (0.0500)  time: 2.8696  data: 2.2794  max mem: 5608\n",
            "Epoch: [86]  [ 10/147]  eta: 0:01:42  lr: 0.000293  min_lr: 0.000293  loss: 2.4981 (2.3950)  weight_decay: 0.0500 (0.0500)  time: 0.7515  data: 0.2127  max mem: 5608\n",
            "Epoch: [86]  [ 20/147]  eta: 0:01:21  lr: 0.000290  min_lr: 0.000290  loss: 2.3551 (2.4108)  weight_decay: 0.0500 (0.0500)  time: 0.5316  data: 0.0043  max mem: 5608\n",
            "Epoch: [86]  [ 30/147]  eta: 0:01:10  lr: 0.000288  min_lr: 0.000288  loss: 2.3586 (2.3878)  weight_decay: 0.0500 (0.0500)  time: 0.5162  data: 0.0017  max mem: 5608\n",
            "Epoch: [86]  [ 40/147]  eta: 0:01:01  lr: 0.000284  min_lr: 0.000284  loss: 2.4186 (2.4126)  weight_decay: 0.0500 (0.0500)  time: 0.5110  data: 0.0014  max mem: 5608\n",
            "Epoch: [86]  [ 50/147]  eta: 0:00:54  lr: 0.000282  min_lr: 0.000282  loss: 2.4320 (2.3950)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0017  max mem: 5608\n",
            "Epoch: [86]  [ 60/147]  eta: 0:00:48  lr: 0.000279  min_lr: 0.000279  loss: 2.5473 (2.4226)  weight_decay: 0.0500 (0.0500)  time: 0.5062  data: 0.0015  max mem: 5608\n",
            "Epoch: [86]  [ 70/147]  eta: 0:00:42  lr: 0.000277  min_lr: 0.000277  loss: 2.5685 (2.4249)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0017  max mem: 5608\n",
            "Epoch: [86]  [ 80/147]  eta: 0:00:36  lr: 0.000273  min_lr: 0.000273  loss: 2.4438 (2.4272)  weight_decay: 0.0500 (0.0500)  time: 0.5050  data: 0.0018  max mem: 5608\n",
            "Epoch: [86]  [ 90/147]  eta: 0:00:30  lr: 0.000271  min_lr: 0.000271  loss: 2.4438 (2.4228)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0017  max mem: 5608\n",
            "Epoch: [86]  [100/147]  eta: 0:00:25  lr: 0.000268  min_lr: 0.000268  loss: 2.3835 (2.4207)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0037  max mem: 5608\n",
            "Epoch: [86]  [110/147]  eta: 0:00:19  lr: 0.000266  min_lr: 0.000266  loss: 2.3366 (2.4132)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0042  max mem: 5608\n",
            "Epoch: [86]  [120/147]  eta: 0:00:14  lr: 0.000262  min_lr: 0.000262  loss: 2.2699 (2.4074)  weight_decay: 0.0500 (0.0500)  time: 0.5070  data: 0.0028  max mem: 5608\n",
            "Epoch: [86]  [130/147]  eta: 0:00:08  lr: 0.000260  min_lr: 0.000260  loss: 2.3005 (2.4004)  weight_decay: 0.0500 (0.0500)  time: 0.5048  data: 0.0027  max mem: 5608\n",
            "Epoch: [86]  [140/147]  eta: 0:00:03  lr: 0.000257  min_lr: 0.000257  loss: 2.3847 (2.4047)  weight_decay: 0.0500 (0.0500)  time: 0.4974  data: 0.0013  max mem: 5608\n",
            "Epoch: [86]  [146/147]  eta: 0:00:00  lr: 0.000257  min_lr: 0.000257  loss: 2.3847 (2.4024)  weight_decay: 0.0500 (0.0500)  time: 0.4223  data: 0.0002  max mem: 5608\n",
            "Epoch: [86] Total time: 0:01:16 (0.5202 s / it)\n",
            "Averaged stats: lr: 0.000257  min_lr: 0.000257  loss: 2.3847 (2.4024)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:35  loss: 0.4865 (0.4865)  acc1: 89.5833 (89.5833)  acc5: 96.8750 (96.8750)  time: 5.2492  data: 4.9543  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5750 (0.5686)  acc1: 88.5417 (89.3939)  acc5: 97.9167 (98.1061)  time: 0.6992  data: 0.4533  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.6039 (0.7307)  acc1: 87.5000 (82.0933)  acc5: 97.9167 (98.1647)  time: 0.2440  data: 0.0053  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7009 (0.7383)  acc1: 81.2500 (81.8548)  acc5: 97.9167 (98.0847)  time: 0.2393  data: 0.0038  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6859 (0.7217)  acc1: 85.4167 (82.4459)  acc5: 97.9167 (98.0637)  time: 0.2327  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3746 s / it)\n",
            "* Acc@1 82.446 Acc@5 98.064 loss 0.722\n",
            "Accuracy of the model on the 3925 test images: 82.4%\n",
            "Max accuracy: 82.45%\n",
            "Test:  [ 0/41]  eta: 0:03:21  loss: 3.3029 (3.3029)  acc1: 26.0417 (26.0417)  acc5: 80.2083 (80.2083)  time: 4.9060  data: 4.5943  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.6039 (3.6499)  acc1: 23.9583 (22.8220)  acc5: 85.4167 (85.1326)  time: 0.6667  data: 0.4286  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.0297 (4.3674)  acc1: 14.5833 (15.7738)  acc5: 80.2083 (72.9167)  time: 0.2421  data: 0.0080  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.8554 (4.6119)  acc1: 2.0833 (14.1801)  acc5: 60.4167 (68.3132)  time: 0.2396  data: 0.0021  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3400 (4.1508)  acc1: 27.0833 (23.0064)  acc5: 81.2500 (71.0064)  time: 0.2356  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3626 s / it)\n",
            "* Acc@1 23.006 Acc@5 71.006 loss 4.151\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "Max EMA accuracy: 23.01%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [87]  [  0/147]  eta: 0:10:47  lr: 0.000256  min_lr: 0.000256  loss: 2.6101 (2.6101)  weight_decay: 0.0500 (0.0500)  time: 4.4042  data: 3.6804  max mem: 5608\n",
            "Epoch: [87]  [ 10/147]  eta: 0:02:04  lr: 0.000254  min_lr: 0.000254  loss: 2.2211 (2.2899)  weight_decay: 0.0500 (0.0500)  time: 0.9074  data: 0.3375  max mem: 5608\n",
            "Epoch: [87]  [ 20/147]  eta: 0:01:31  lr: 0.000251  min_lr: 0.000251  loss: 2.2211 (2.3447)  weight_decay: 0.0500 (0.0500)  time: 0.5349  data: 0.0022  max mem: 5608\n",
            "Epoch: [87]  [ 30/147]  eta: 0:01:16  lr: 0.000249  min_lr: 0.000249  loss: 2.4272 (2.3680)  weight_decay: 0.0500 (0.0500)  time: 0.5151  data: 0.0014  max mem: 5608\n",
            "Epoch: [87]  [ 40/147]  eta: 0:01:06  lr: 0.000245  min_lr: 0.000245  loss: 2.1619 (2.3113)  weight_decay: 0.0500 (0.0500)  time: 0.5191  data: 0.0012  max mem: 5608\n",
            "Epoch: [87]  [ 50/147]  eta: 0:00:58  lr: 0.000243  min_lr: 0.000243  loss: 2.2976 (2.3283)  weight_decay: 0.0500 (0.0500)  time: 0.5144  data: 0.0011  max mem: 5608\n",
            "Epoch: [87]  [ 60/147]  eta: 0:00:50  lr: 0.000240  min_lr: 0.000240  loss: 2.4038 (2.3273)  weight_decay: 0.0500 (0.0500)  time: 0.5097  data: 0.0013  max mem: 5608\n",
            "Epoch: [87]  [ 70/147]  eta: 0:00:44  lr: 0.000238  min_lr: 0.000238  loss: 2.3560 (2.3256)  weight_decay: 0.0500 (0.0500)  time: 0.5137  data: 0.0017  max mem: 5608\n",
            "Epoch: [87]  [ 80/147]  eta: 0:00:37  lr: 0.000235  min_lr: 0.000235  loss: 2.4379 (2.3381)  weight_decay: 0.0500 (0.0500)  time: 0.5088  data: 0.0028  max mem: 5608\n",
            "Epoch: [87]  [ 90/147]  eta: 0:00:31  lr: 0.000233  min_lr: 0.000233  loss: 2.3780 (2.3386)  weight_decay: 0.0500 (0.0500)  time: 0.4995  data: 0.0029  max mem: 5608\n",
            "Epoch: [87]  [100/147]  eta: 0:00:26  lr: 0.000230  min_lr: 0.000230  loss: 2.3228 (2.3336)  weight_decay: 0.0500 (0.0500)  time: 0.5053  data: 0.0022  max mem: 5608\n",
            "Epoch: [87]  [110/147]  eta: 0:00:20  lr: 0.000228  min_lr: 0.000228  loss: 2.2373 (2.3326)  weight_decay: 0.0500 (0.0500)  time: 0.5063  data: 0.0017  max mem: 5608\n",
            "Epoch: [87]  [120/147]  eta: 0:00:14  lr: 0.000225  min_lr: 0.000225  loss: 2.3446 (2.3462)  weight_decay: 0.0500 (0.0500)  time: 0.4975  data: 0.0016  max mem: 5608\n",
            "Epoch: [87]  [130/147]  eta: 0:00:09  lr: 0.000223  min_lr: 0.000223  loss: 2.3446 (2.3492)  weight_decay: 0.0500 (0.0500)  time: 0.4960  data: 0.0011  max mem: 5608\n",
            "Epoch: [87]  [140/147]  eta: 0:00:03  lr: 0.000220  min_lr: 0.000220  loss: 2.2952 (2.3451)  weight_decay: 0.0500 (0.0500)  time: 0.4963  data: 0.0003  max mem: 5608\n",
            "Epoch: [87]  [146/147]  eta: 0:00:00  lr: 0.000220  min_lr: 0.000220  loss: 2.2952 (2.3430)  weight_decay: 0.0500 (0.0500)  time: 0.4207  data: 0.0003  max mem: 5608\n",
            "Epoch: [87] Total time: 0:01:17 (0.5288 s / it)\n",
            "Averaged stats: lr: 0.000220  min_lr: 0.000220  loss: 2.2952 (2.3430)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:37  loss: 0.4686 (0.4686)  acc1: 91.6667 (91.6667)  acc5: 96.8750 (96.8750)  time: 3.8379  data: 3.5646  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.5283 (0.5369)  acc1: 90.6250 (90.0568)  acc5: 98.9583 (98.3902)  time: 0.5711  data: 0.3298  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.5880 (0.6967)  acc1: 87.5000 (83.7302)  acc5: 98.9583 (98.4127)  time: 0.2501  data: 0.0040  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7074 (0.7150)  acc1: 81.2500 (82.9973)  acc5: 97.9167 (98.1855)  time: 0.2956  data: 0.0477  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6993 (0.7147)  acc1: 83.3333 (83.0064)  acc5: 97.9167 (98.0382)  time: 0.2829  data: 0.0474  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3733 s / it)\n",
            "* Acc@1 83.006 Acc@5 98.038 loss 0.715\n",
            "Accuracy of the model on the 3925 test images: 83.0%\n",
            "Max accuracy: 83.01%\n",
            "Test:  [ 0/41]  eta: 0:03:16  loss: 3.2864 (3.2864)  acc1: 25.0000 (25.0000)  acc5: 81.2500 (81.2500)  time: 4.7903  data: 4.4890  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.5917 (3.6342)  acc1: 25.0000 (22.9167)  acc5: 85.4167 (85.3220)  time: 0.6539  data: 0.4088  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 4.0019 (4.3522)  acc1: 14.5833 (15.7242)  acc5: 80.2083 (72.9663)  time: 0.2405  data: 0.0015  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.8244 (4.6010)  acc1: 2.0833 (14.1129)  acc5: 60.4167 (68.2796)  time: 0.2396  data: 0.0012  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3323 (4.1380)  acc1: 27.0833 (23.0573)  acc5: 81.2500 (71.0318)  time: 0.2370  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3634 s / it)\n",
            "* Acc@1 23.057 Acc@5 71.032 loss 4.138\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "Max EMA accuracy: 23.06%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [88]  [  0/147]  eta: 0:08:38  lr: 0.000219  min_lr: 0.000219  loss: 2.4698 (2.4698)  weight_decay: 0.0500 (0.0500)  time: 3.5252  data: 2.8968  max mem: 5608\n",
            "Epoch: [88]  [ 10/147]  eta: 0:01:52  lr: 0.000217  min_lr: 0.000217  loss: 2.4936 (2.4201)  weight_decay: 0.0500 (0.0500)  time: 0.8246  data: 0.2985  max mem: 5608\n",
            "Epoch: [88]  [ 20/147]  eta: 0:01:26  lr: 0.000214  min_lr: 0.000214  loss: 2.5509 (2.4658)  weight_decay: 0.0500 (0.0500)  time: 0.5384  data: 0.0203  max mem: 5608\n",
            "Epoch: [88]  [ 30/147]  eta: 0:01:13  lr: 0.000212  min_lr: 0.000212  loss: 2.4729 (2.4115)  weight_decay: 0.0500 (0.0500)  time: 0.5224  data: 0.0033  max mem: 5608\n",
            "Epoch: [88]  [ 40/147]  eta: 0:01:04  lr: 0.000209  min_lr: 0.000209  loss: 2.4178 (2.4442)  weight_decay: 0.0500 (0.0500)  time: 0.5150  data: 0.0037  max mem: 5608\n",
            "Epoch: [88]  [ 50/147]  eta: 0:00:56  lr: 0.000207  min_lr: 0.000207  loss: 2.4531 (2.4238)  weight_decay: 0.0500 (0.0500)  time: 0.5052  data: 0.0020  max mem: 5608\n",
            "Epoch: [88]  [ 60/147]  eta: 0:00:49  lr: 0.000204  min_lr: 0.000204  loss: 2.2797 (2.3952)  weight_decay: 0.0500 (0.0500)  time: 0.5089  data: 0.0008  max mem: 5608\n",
            "Epoch: [88]  [ 70/147]  eta: 0:00:43  lr: 0.000202  min_lr: 0.000202  loss: 2.3370 (2.3981)  weight_decay: 0.0500 (0.0500)  time: 0.5080  data: 0.0010  max mem: 5608\n",
            "Epoch: [88]  [ 80/147]  eta: 0:00:37  lr: 0.000200  min_lr: 0.000200  loss: 2.4358 (2.4067)  weight_decay: 0.0500 (0.0500)  time: 0.5013  data: 0.0027  max mem: 5608\n",
            "Epoch: [88]  [ 90/147]  eta: 0:00:31  lr: 0.000198  min_lr: 0.000198  loss: 2.4358 (2.4096)  weight_decay: 0.0500 (0.0500)  time: 0.5025  data: 0.0026  max mem: 5608\n",
            "Epoch: [88]  [100/147]  eta: 0:00:25  lr: 0.000195  min_lr: 0.000195  loss: 2.3354 (2.4005)  weight_decay: 0.0500 (0.0500)  time: 0.5035  data: 0.0010  max mem: 5608\n",
            "Epoch: [88]  [110/147]  eta: 0:00:19  lr: 0.000193  min_lr: 0.000193  loss: 2.4314 (2.4087)  weight_decay: 0.0500 (0.0500)  time: 0.5004  data: 0.0009  max mem: 5608\n",
            "Epoch: [88]  [120/147]  eta: 0:00:14  lr: 0.000190  min_lr: 0.000190  loss: 2.3643 (2.3953)  weight_decay: 0.0500 (0.0500)  time: 0.5022  data: 0.0010  max mem: 5608\n",
            "Epoch: [88]  [130/147]  eta: 0:00:09  lr: 0.000188  min_lr: 0.000188  loss: 2.3408 (2.4017)  weight_decay: 0.0500 (0.0500)  time: 0.5070  data: 0.0009  max mem: 5608\n",
            "Epoch: [88]  [140/147]  eta: 0:00:03  lr: 0.000186  min_lr: 0.000186  loss: 2.5671 (2.4128)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0005  max mem: 5608\n",
            "Epoch: [88]  [146/147]  eta: 0:00:00  lr: 0.000186  min_lr: 0.000186  loss: 2.5671 (2.4176)  weight_decay: 0.0500 (0.0500)  time: 0.4242  data: 0.0002  max mem: 5608\n",
            "Epoch: [88] Total time: 0:01:16 (0.5230 s / it)\n",
            "Averaged stats: lr: 0.000186  min_lr: 0.000186  loss: 2.5671 (2.4176)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:46  loss: 0.4523 (0.4523)  acc1: 91.6667 (91.6667)  acc5: 96.8750 (96.8750)  time: 4.0671  data: 3.7421  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5143 (0.5309)  acc1: 91.6667 (90.5303)  acc5: 97.9167 (98.1061)  time: 0.6749  data: 0.4247  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.6016 (0.7044)  acc1: 86.4583 (83.1349)  acc5: 97.9167 (97.8671)  time: 0.3465  data: 0.0897  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6953 (0.7401)  acc1: 78.1250 (82.1237)  acc5: 97.9167 (97.7151)  time: 0.3024  data: 0.0450  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6953 (0.7305)  acc1: 83.5294 (82.4459)  acc5: 97.9167 (97.7325)  time: 0.2389  data: 0.0018  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3957 s / it)\n",
            "* Acc@1 82.446 Acc@5 97.732 loss 0.731\n",
            "Accuracy of the model on the 3925 test images: 82.4%\n",
            "Max accuracy: 83.01%\n",
            "Test:  [ 0/41]  eta: 0:02:45  loss: 3.2699 (3.2699)  acc1: 22.9167 (22.9167)  acc5: 81.2500 (81.2500)  time: 4.0431  data: 3.7459  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 3.5789 (3.6178)  acc1: 23.9583 (23.1061)  acc5: 85.4167 (85.4167)  time: 0.5962  data: 0.3475  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 3.9736 (4.3366)  acc1: 13.5417 (15.8234)  acc5: 81.2500 (73.0655)  time: 0.2508  data: 0.0045  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.7946 (4.5894)  acc1: 2.0833 (14.1801)  acc5: 60.4167 (68.3468)  time: 0.2684  data: 0.0183  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3218 (4.1248)  acc1: 27.0833 (23.1847)  acc5: 81.2500 (71.1338)  time: 0.2607  data: 0.0181  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3575 s / it)\n",
            "* Acc@1 23.185 Acc@5 71.134 loss 4.125\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "Max EMA accuracy: 23.18%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [89]  [  0/147]  eta: 0:05:57  lr: 0.000185  min_lr: 0.000185  loss: 2.3505 (2.3505)  weight_decay: 0.0500 (0.0500)  time: 2.4291  data: 1.8531  max mem: 5608\n",
            "Epoch: [89]  [ 10/147]  eta: 0:01:37  lr: 0.000183  min_lr: 0.000183  loss: 2.5218 (2.4157)  weight_decay: 0.0500 (0.0500)  time: 0.7136  data: 0.1689  max mem: 5608\n",
            "Epoch: [89]  [ 20/147]  eta: 0:01:18  lr: 0.000180  min_lr: 0.000180  loss: 2.5218 (2.4316)  weight_decay: 0.0500 (0.0500)  time: 0.5302  data: 0.0008  max mem: 5608\n",
            "Epoch: [89]  [ 30/147]  eta: 0:01:08  lr: 0.000178  min_lr: 0.000178  loss: 2.3698 (2.3932)  weight_decay: 0.0500 (0.0500)  time: 0.5141  data: 0.0008  max mem: 5608\n",
            "Epoch: [89]  [ 40/147]  eta: 0:01:00  lr: 0.000176  min_lr: 0.000176  loss: 2.4544 (2.4154)  weight_decay: 0.0500 (0.0500)  time: 0.5097  data: 0.0012  max mem: 5608\n",
            "Epoch: [89]  [ 50/147]  eta: 0:00:54  lr: 0.000174  min_lr: 0.000174  loss: 2.4946 (2.3892)  weight_decay: 0.0500 (0.0500)  time: 0.5179  data: 0.0019  max mem: 5608\n",
            "Epoch: [89]  [ 60/147]  eta: 0:00:48  lr: 0.000171  min_lr: 0.000171  loss: 2.3463 (2.3853)  weight_decay: 0.0500 (0.0500)  time: 0.5226  data: 0.0018  max mem: 5608\n",
            "Epoch: [89]  [ 70/147]  eta: 0:00:42  lr: 0.000169  min_lr: 0.000169  loss: 2.4137 (2.3879)  weight_decay: 0.0500 (0.0500)  time: 0.5136  data: 0.0026  max mem: 5608\n",
            "Epoch: [89]  [ 80/147]  eta: 0:00:36  lr: 0.000167  min_lr: 0.000167  loss: 2.4137 (2.3821)  weight_decay: 0.0500 (0.0500)  time: 0.5058  data: 0.0025  max mem: 5608\n",
            "Epoch: [89]  [ 90/147]  eta: 0:00:30  lr: 0.000165  min_lr: 0.000165  loss: 2.4686 (2.3897)  weight_decay: 0.0500 (0.0500)  time: 0.5051  data: 0.0013  max mem: 5608\n",
            "Epoch: [89]  [100/147]  eta: 0:00:25  lr: 0.000163  min_lr: 0.000163  loss: 2.4386 (2.3783)  weight_decay: 0.0500 (0.0500)  time: 0.5108  data: 0.0022  max mem: 5608\n",
            "Epoch: [89]  [110/147]  eta: 0:00:19  lr: 0.000161  min_lr: 0.000161  loss: 2.3366 (2.3876)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0025  max mem: 5608\n",
            "Epoch: [89]  [120/147]  eta: 0:00:14  lr: 0.000158  min_lr: 0.000158  loss: 2.4316 (2.3817)  weight_decay: 0.0500 (0.0500)  time: 0.5001  data: 0.0022  max mem: 5608\n",
            "Epoch: [89]  [130/147]  eta: 0:00:08  lr: 0.000157  min_lr: 0.000157  loss: 2.3978 (2.3747)  weight_decay: 0.0500 (0.0500)  time: 0.5023  data: 0.0019  max mem: 5608\n",
            "Epoch: [89]  [140/147]  eta: 0:00:03  lr: 0.000154  min_lr: 0.000154  loss: 2.4104 (2.3792)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0007  max mem: 5608\n",
            "Epoch: [89]  [146/147]  eta: 0:00:00  lr: 0.000154  min_lr: 0.000154  loss: 2.5193 (2.3845)  weight_decay: 0.0500 (0.0500)  time: 0.4214  data: 0.0002  max mem: 5608\n",
            "Epoch: [89] Total time: 0:01:15 (0.5163 s / it)\n",
            "Averaged stats: lr: 0.000154  min_lr: 0.000154  loss: 2.5193 (2.3845)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:31  loss: 0.4515 (0.4515)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 5.1539  data: 4.8619  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5277 (0.5213)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (98.2955)  time: 0.7361  data: 0.4886  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5607 (0.6765)  acc1: 88.5417 (83.8790)  acc5: 97.9167 (98.2143)  time: 0.3477  data: 0.0942  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6934 (0.7170)  acc1: 80.2083 (82.3925)  acc5: 97.9167 (98.0511)  time: 0.3167  data: 0.0686  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6967 (0.7145)  acc1: 84.7059 (82.6242)  acc5: 97.9167 (97.9873)  time: 0.2302  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:17 (0.4167 s / it)\n",
            "* Acc@1 82.624 Acc@5 97.987 loss 0.714\n",
            "Accuracy of the model on the 3925 test images: 82.6%\n",
            "Max accuracy: 83.01%\n",
            "Test:  [ 0/41]  eta: 0:02:37  loss: 3.2549 (3.2549)  acc1: 21.8750 (21.8750)  acc5: 81.2500 (81.2500)  time: 3.8438  data: 3.5468  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.5676 (3.6015)  acc1: 22.9167 (22.9167)  acc5: 85.4167 (85.4167)  time: 0.5714  data: 0.3332  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 3.9449 (4.3209)  acc1: 13.5417 (15.7242)  acc5: 81.2500 (73.2143)  time: 0.2804  data: 0.0461  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.7638 (4.5774)  acc1: 2.0833 (14.0457)  acc5: 61.4583 (68.3468)  time: 0.2847  data: 0.0469  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3101 (4.1113)  acc1: 26.0417 (23.1592)  acc5: 81.2500 (71.2102)  time: 0.2431  data: 0.0068  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3591 s / it)\n",
            "* Acc@1 23.159 Acc@5 71.210 loss 4.111\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [90]  [  0/147]  eta: 0:08:33  lr: 0.000153  min_lr: 0.000153  loss: 1.9405 (1.9405)  weight_decay: 0.0500 (0.0500)  time: 3.4963  data: 2.8911  max mem: 5608\n",
            "Epoch: [90]  [ 10/147]  eta: 0:01:47  lr: 0.000152  min_lr: 0.000152  loss: 2.2393 (2.3003)  weight_decay: 0.0500 (0.0500)  time: 0.7819  data: 0.2644  max mem: 5608\n",
            "Epoch: [90]  [ 20/147]  eta: 0:01:23  lr: 0.000149  min_lr: 0.000149  loss: 2.4090 (2.3621)  weight_decay: 0.0500 (0.0500)  time: 0.5179  data: 0.0020  max mem: 5608\n",
            "Epoch: [90]  [ 30/147]  eta: 0:01:11  lr: 0.000147  min_lr: 0.000147  loss: 2.3402 (2.3433)  weight_decay: 0.0500 (0.0500)  time: 0.5201  data: 0.0022  max mem: 5608\n",
            "Epoch: [90]  [ 40/147]  eta: 0:01:03  lr: 0.000145  min_lr: 0.000145  loss: 2.4459 (2.3836)  weight_decay: 0.0500 (0.0500)  time: 0.5155  data: 0.0017  max mem: 5608\n",
            "Epoch: [90]  [ 50/147]  eta: 0:00:55  lr: 0.000143  min_lr: 0.000143  loss: 2.5202 (2.3871)  weight_decay: 0.0500 (0.0500)  time: 0.5158  data: 0.0014  max mem: 5608\n",
            "Epoch: [90]  [ 60/147]  eta: 0:00:49  lr: 0.000141  min_lr: 0.000141  loss: 2.4296 (2.3763)  weight_decay: 0.0500 (0.0500)  time: 0.5164  data: 0.0016  max mem: 5608\n",
            "Epoch: [90]  [ 70/147]  eta: 0:00:42  lr: 0.000139  min_lr: 0.000139  loss: 2.4211 (2.3857)  weight_decay: 0.0500 (0.0500)  time: 0.5104  data: 0.0020  max mem: 5608\n",
            "Epoch: [90]  [ 80/147]  eta: 0:00:36  lr: 0.000137  min_lr: 0.000137  loss: 2.4768 (2.3925)  weight_decay: 0.0500 (0.0500)  time: 0.5072  data: 0.0013  max mem: 5608\n",
            "Epoch: [90]  [ 90/147]  eta: 0:00:31  lr: 0.000135  min_lr: 0.000135  loss: 2.4796 (2.3929)  weight_decay: 0.0500 (0.0500)  time: 0.5101  data: 0.0013  max mem: 5608\n",
            "Epoch: [90]  [100/147]  eta: 0:00:25  lr: 0.000133  min_lr: 0.000133  loss: 2.3491 (2.3885)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0019  max mem: 5608\n",
            "Epoch: [90]  [110/147]  eta: 0:00:19  lr: 0.000131  min_lr: 0.000131  loss: 2.3031 (2.3790)  weight_decay: 0.0500 (0.0500)  time: 0.4970  data: 0.0012  max mem: 5608\n",
            "Epoch: [90]  [120/147]  eta: 0:00:14  lr: 0.000129  min_lr: 0.000129  loss: 2.2390 (2.3698)  weight_decay: 0.0500 (0.0500)  time: 0.4978  data: 0.0014  max mem: 5608\n",
            "Epoch: [90]  [130/147]  eta: 0:00:09  lr: 0.000128  min_lr: 0.000128  loss: 2.2893 (2.3688)  weight_decay: 0.0500 (0.0500)  time: 0.5009  data: 0.0013  max mem: 5608\n",
            "Epoch: [90]  [140/147]  eta: 0:00:03  lr: 0.000125  min_lr: 0.000125  loss: 2.3752 (2.3627)  weight_decay: 0.0500 (0.0500)  time: 0.4988  data: 0.0006  max mem: 5608\n",
            "Epoch: [90]  [146/147]  eta: 0:00:00  lr: 0.000125  min_lr: 0.000125  loss: 2.4132 (2.3647)  weight_decay: 0.0500 (0.0500)  time: 0.4212  data: 0.0002  max mem: 5608\n",
            "Epoch: [90] Total time: 0:01:16 (0.5208 s / it)\n",
            "Averaged stats: lr: 0.000125  min_lr: 0.000125  loss: 2.4132 (2.3647)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:45  loss: 0.4887 (0.4887)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 5.4953  data: 5.1754  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.4997 (0.5052)  acc1: 90.6250 (90.7197)  acc5: 97.9167 (98.2008)  time: 0.7850  data: 0.5018  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5477 (0.6701)  acc1: 88.5417 (83.4821)  acc5: 97.9167 (98.3135)  time: 0.3027  data: 0.0426  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6980 (0.6936)  acc1: 82.2917 (82.7285)  acc5: 97.9167 (98.2191)  time: 0.2613  data: 0.0255  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7294 (0.7032)  acc1: 82.3529 (82.6497)  acc5: 97.9167 (98.0637)  time: 0.2306  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.4040 s / it)\n",
            "* Acc@1 82.650 Acc@5 98.064 loss 0.703\n",
            "Accuracy of the model on the 3925 test images: 82.6%\n",
            "Max accuracy: 83.01%\n",
            "Test:  [ 0/41]  eta: 0:02:26  loss: 3.2388 (3.2388)  acc1: 21.8750 (21.8750)  acc5: 81.2500 (81.2500)  time: 3.5828  data: 3.2967  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.5551 (3.5853)  acc1: 21.8750 (22.6326)  acc5: 86.4583 (85.7008)  time: 0.6755  data: 0.4371  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.9167 (4.3050)  acc1: 13.5417 (15.5258)  acc5: 81.2500 (73.4623)  time: 0.3719  data: 0.1368  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.7328 (4.5656)  acc1: 2.0833 (13.8105)  acc5: 61.4583 (68.4812)  time: 0.3114  data: 0.0712  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3003 (4.0982)  acc1: 23.9583 (22.9809)  acc5: 81.2500 (71.3376)  time: 0.2492  data: 0.0101  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.4006 s / it)\n",
            "* Acc@1 22.981 Acc@5 71.338 loss 4.098\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [91]  [  0/147]  eta: 0:06:46  lr: 0.000125  min_lr: 0.000125  loss: 1.8961 (1.8961)  weight_decay: 0.0500 (0.0500)  time: 2.7663  data: 2.1789  max mem: 5608\n",
            "Epoch: [91]  [ 10/147]  eta: 0:01:44  lr: 0.000123  min_lr: 0.000123  loss: 2.1565 (2.2883)  weight_decay: 0.0500 (0.0500)  time: 0.7644  data: 0.2024  max mem: 5608\n",
            "Epoch: [91]  [ 20/147]  eta: 0:01:22  lr: 0.000121  min_lr: 0.000121  loss: 2.4145 (2.3103)  weight_decay: 0.0500 (0.0500)  time: 0.5442  data: 0.0032  max mem: 5608\n",
            "Epoch: [91]  [ 30/147]  eta: 0:01:10  lr: 0.000119  min_lr: 0.000119  loss: 2.4145 (2.3368)  weight_decay: 0.0500 (0.0500)  time: 0.5186  data: 0.0022  max mem: 5608\n",
            "Epoch: [91]  [ 40/147]  eta: 0:01:02  lr: 0.000117  min_lr: 0.000117  loss: 2.5180 (2.3831)  weight_decay: 0.0500 (0.0500)  time: 0.5159  data: 0.0021  max mem: 5608\n",
            "Epoch: [91]  [ 50/147]  eta: 0:00:55  lr: 0.000116  min_lr: 0.000116  loss: 2.5202 (2.4039)  weight_decay: 0.0500 (0.0500)  time: 0.5174  data: 0.0009  max mem: 5608\n",
            "Epoch: [91]  [ 60/147]  eta: 0:00:48  lr: 0.000114  min_lr: 0.000114  loss: 2.5010 (2.4098)  weight_decay: 0.0500 (0.0500)  time: 0.5100  data: 0.0012  max mem: 5608\n",
            "Epoch: [91]  [ 70/147]  eta: 0:00:42  lr: 0.000112  min_lr: 0.000112  loss: 2.4506 (2.4128)  weight_decay: 0.0500 (0.0500)  time: 0.5013  data: 0.0015  max mem: 5608\n",
            "Epoch: [91]  [ 80/147]  eta: 0:00:36  lr: 0.000110  min_lr: 0.000110  loss: 2.5053 (2.4168)  weight_decay: 0.0500 (0.0500)  time: 0.5057  data: 0.0017  max mem: 5608\n",
            "Epoch: [91]  [ 90/147]  eta: 0:00:30  lr: 0.000109  min_lr: 0.000109  loss: 2.5133 (2.4144)  weight_decay: 0.0500 (0.0500)  time: 0.5069  data: 0.0037  max mem: 5608\n",
            "Epoch: [91]  [100/147]  eta: 0:00:25  lr: 0.000106  min_lr: 0.000106  loss: 2.5301 (2.4228)  weight_decay: 0.0500 (0.0500)  time: 0.4985  data: 0.0036  max mem: 5608\n",
            "Epoch: [91]  [110/147]  eta: 0:00:19  lr: 0.000105  min_lr: 0.000105  loss: 2.5301 (2.4322)  weight_decay: 0.0500 (0.0500)  time: 0.5003  data: 0.0028  max mem: 5608\n",
            "Epoch: [91]  [120/147]  eta: 0:00:14  lr: 0.000103  min_lr: 0.000103  loss: 2.4854 (2.4300)  weight_decay: 0.0500 (0.0500)  time: 0.5066  data: 0.0030  max mem: 5608\n",
            "Epoch: [91]  [130/147]  eta: 0:00:08  lr: 0.000102  min_lr: 0.000102  loss: 2.4854 (2.4373)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0017  max mem: 5608\n",
            "Epoch: [91]  [140/147]  eta: 0:00:03  lr: 0.000100  min_lr: 0.000100  loss: 2.4770 (2.4321)  weight_decay: 0.0500 (0.0500)  time: 0.4946  data: 0.0004  max mem: 5608\n",
            "Epoch: [91]  [146/147]  eta: 0:00:00  lr: 0.000100  min_lr: 0.000100  loss: 2.4189 (2.4282)  weight_decay: 0.0500 (0.0500)  time: 0.4214  data: 0.0002  max mem: 5608\n",
            "Epoch: [91] Total time: 0:01:16 (0.5202 s / it)\n",
            "Averaged stats: lr: 0.000100  min_lr: 0.000100  loss: 2.4189 (2.4282)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:06  loss: 0.5099 (0.5099)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 4.5503  data: 4.2510  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5397 (0.5516)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (98.3902)  time: 0.7096  data: 0.4726  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5992 (0.7107)  acc1: 87.5000 (83.7302)  acc5: 97.9167 (98.2639)  time: 0.2809  data: 0.0492  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7195 (0.7262)  acc1: 81.2500 (82.9301)  acc5: 97.9167 (98.1519)  time: 0.2354  data: 0.0018  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6776 (0.7224)  acc1: 84.3750 (83.1338)  acc5: 97.9167 (98.0382)  time: 0.2317  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3760 s / it)\n",
            "* Acc@1 83.134 Acc@5 98.038 loss 0.722\n",
            "Accuracy of the model on the 3925 test images: 83.1%\n",
            "Max accuracy: 83.13%\n",
            "Test:  [ 0/41]  eta: 0:03:33  loss: 3.2226 (3.2226)  acc1: 22.9167 (22.9167)  acc5: 82.2917 (82.2917)  time: 5.2081  data: 4.9019  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 3.5423 (3.5689)  acc1: 22.9167 (22.7273)  acc5: 86.4583 (86.0795)  time: 0.7331  data: 0.4909  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 3.8886 (4.2888)  acc1: 13.5417 (15.5754)  acc5: 81.2500 (73.5119)  time: 0.2639  data: 0.0264  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.7020 (4.5535)  acc1: 3.1250 (13.9113)  acc5: 61.4583 (68.4140)  time: 0.2382  data: 0.0020  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2898 (4.0849)  acc1: 23.9583 (23.1338)  acc5: 81.2500 (71.3121)  time: 0.2333  data: 0.0005  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3870 s / it)\n",
            "* Acc@1 23.134 Acc@5 71.312 loss 4.085\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [92]  [  0/147]  eta: 0:12:25  lr: 0.000099  min_lr: 0.000099  loss: 2.2911 (2.2911)  weight_decay: 0.0500 (0.0500)  time: 5.0711  data: 4.3212  max mem: 5608\n",
            "Epoch: [92]  [ 10/147]  eta: 0:02:14  lr: 0.000098  min_lr: 0.000098  loss: 2.5168 (2.4586)  weight_decay: 0.0500 (0.0500)  time: 0.9818  data: 0.3934  max mem: 5608\n",
            "Epoch: [92]  [ 20/147]  eta: 0:01:36  lr: 0.000096  min_lr: 0.000096  loss: 2.4831 (2.4435)  weight_decay: 0.0500 (0.0500)  time: 0.5442  data: 0.0006  max mem: 5608\n",
            "Epoch: [92]  [ 30/147]  eta: 0:01:19  lr: 0.000094  min_lr: 0.000094  loss: 2.3420 (2.4166)  weight_decay: 0.0500 (0.0500)  time: 0.5184  data: 0.0008  max mem: 5608\n",
            "Epoch: [92]  [ 40/147]  eta: 0:01:09  lr: 0.000092  min_lr: 0.000092  loss: 2.5000 (2.4079)  weight_decay: 0.0500 (0.0500)  time: 0.5254  data: 0.0013  max mem: 5608\n",
            "Epoch: [92]  [ 50/147]  eta: 0:01:00  lr: 0.000091  min_lr: 0.000091  loss: 2.3937 (2.3642)  weight_decay: 0.0500 (0.0500)  time: 0.5196  data: 0.0015  max mem: 5608\n",
            "Epoch: [92]  [ 60/147]  eta: 0:00:52  lr: 0.000089  min_lr: 0.000089  loss: 2.3873 (2.3835)  weight_decay: 0.0500 (0.0500)  time: 0.5130  data: 0.0028  max mem: 5608\n",
            "Epoch: [92]  [ 70/147]  eta: 0:00:45  lr: 0.000088  min_lr: 0.000088  loss: 2.5082 (2.3722)  weight_decay: 0.0500 (0.0500)  time: 0.5147  data: 0.0024  max mem: 5608\n",
            "Epoch: [92]  [ 80/147]  eta: 0:00:38  lr: 0.000086  min_lr: 0.000086  loss: 2.2824 (2.3612)  weight_decay: 0.0500 (0.0500)  time: 0.5073  data: 0.0006  max mem: 5608\n",
            "Epoch: [92]  [ 90/147]  eta: 0:00:32  lr: 0.000085  min_lr: 0.000085  loss: 2.3299 (2.3709)  weight_decay: 0.0500 (0.0500)  time: 0.4993  data: 0.0009  max mem: 5608\n",
            "Epoch: [92]  [100/147]  eta: 0:00:26  lr: 0.000083  min_lr: 0.000083  loss: 2.3935 (2.3593)  weight_decay: 0.0500 (0.0500)  time: 0.5041  data: 0.0010  max mem: 5608\n",
            "Epoch: [92]  [110/147]  eta: 0:00:20  lr: 0.000081  min_lr: 0.000081  loss: 2.4392 (2.3604)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0010  max mem: 5608\n",
            "Epoch: [92]  [120/147]  eta: 0:00:14  lr: 0.000080  min_lr: 0.000080  loss: 2.4392 (2.3587)  weight_decay: 0.0500 (0.0500)  time: 0.4974  data: 0.0016  max mem: 5608\n",
            "Epoch: [92]  [130/147]  eta: 0:00:09  lr: 0.000078  min_lr: 0.000078  loss: 2.4450 (2.3692)  weight_decay: 0.0500 (0.0500)  time: 0.4942  data: 0.0017  max mem: 5608\n",
            "Epoch: [92]  [140/147]  eta: 0:00:03  lr: 0.000077  min_lr: 0.000077  loss: 2.4986 (2.3693)  weight_decay: 0.0500 (0.0500)  time: 0.4937  data: 0.0009  max mem: 5608\n",
            "Epoch: [92]  [146/147]  eta: 0:00:00  lr: 0.000077  min_lr: 0.000077  loss: 2.4348 (2.3695)  weight_decay: 0.0500 (0.0500)  time: 0.4200  data: 0.0002  max mem: 5608\n",
            "Epoch: [92] Total time: 0:01:18 (0.5351 s / it)\n",
            "Averaged stats: lr: 0.000077  min_lr: 0.000077  loss: 2.4348 (2.3695)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:41  loss: 0.4683 (0.4683)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 3.9506  data: 3.6313  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.4921 (0.5156)  acc1: 90.6250 (90.7197)  acc5: 97.9167 (98.4849)  time: 0.5767  data: 0.3331  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.5698 (0.6673)  acc1: 88.5417 (84.5734)  acc5: 97.9167 (98.3631)  time: 0.2456  data: 0.0056  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7087 (0.6994)  acc1: 80.2083 (83.1317)  acc5: 97.9167 (98.1855)  time: 0.2489  data: 0.0040  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6965 (0.6990)  acc1: 84.3750 (83.3121)  acc5: 97.9167 (98.0382)  time: 0.2386  data: 0.0008  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3474 s / it)\n",
            "* Acc@1 83.312 Acc@5 98.038 loss 0.699\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:02:30  loss: 3.2061 (3.2061)  acc1: 22.9167 (22.9167)  acc5: 82.2917 (82.2917)  time: 3.6636  data: 3.3913  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 3.5291 (3.5522)  acc1: 22.9167 (22.7273)  acc5: 86.4583 (86.1742)  time: 0.5527  data: 0.3102  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 3.8608 (4.2723)  acc1: 13.5417 (15.4762)  acc5: 81.2500 (73.6111)  time: 0.2404  data: 0.0026  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 4.6941 (4.5408)  acc1: 3.1250 (13.8441)  acc5: 61.4583 (68.4476)  time: 0.2452  data: 0.0027  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2779 (4.0712)  acc1: 23.9583 (23.1083)  acc5: 81.2500 (71.3631)  time: 0.2422  data: 0.0011  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3397 s / it)\n",
            "* Acc@1 23.108 Acc@5 71.363 loss 4.071\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [93]  [  0/147]  eta: 0:08:10  lr: 0.000076  min_lr: 0.000076  loss: 2.0198 (2.0198)  weight_decay: 0.0500 (0.0500)  time: 3.3390  data: 2.6626  max mem: 5608\n",
            "Epoch: [93]  [ 10/147]  eta: 0:01:48  lr: 0.000075  min_lr: 0.000075  loss: 2.4001 (2.3317)  weight_decay: 0.0500 (0.0500)  time: 0.7929  data: 0.2594  max mem: 5608\n",
            "Epoch: [93]  [ 20/147]  eta: 0:01:24  lr: 0.000073  min_lr: 0.000073  loss: 2.4034 (2.3534)  weight_decay: 0.0500 (0.0500)  time: 0.5288  data: 0.0104  max mem: 5608\n",
            "Epoch: [93]  [ 30/147]  eta: 0:01:12  lr: 0.000072  min_lr: 0.000072  loss: 2.3909 (2.3280)  weight_decay: 0.0500 (0.0500)  time: 0.5232  data: 0.0031  max mem: 5608\n",
            "Epoch: [93]  [ 40/147]  eta: 0:01:03  lr: 0.000070  min_lr: 0.000070  loss: 2.2173 (2.3173)  weight_decay: 0.0500 (0.0500)  time: 0.5225  data: 0.0025  max mem: 5608\n",
            "Epoch: [93]  [ 50/147]  eta: 0:00:56  lr: 0.000069  min_lr: 0.000069  loss: 2.3475 (2.3417)  weight_decay: 0.0500 (0.0500)  time: 0.5142  data: 0.0005  max mem: 5608\n",
            "Epoch: [93]  [ 60/147]  eta: 0:00:49  lr: 0.000067  min_lr: 0.000067  loss: 2.5325 (2.3713)  weight_decay: 0.0500 (0.0500)  time: 0.5160  data: 0.0021  max mem: 5608\n",
            "Epoch: [93]  [ 70/147]  eta: 0:00:43  lr: 0.000066  min_lr: 0.000066  loss: 2.5206 (2.3686)  weight_decay: 0.0500 (0.0500)  time: 0.5134  data: 0.0027  max mem: 5608\n",
            "Epoch: [93]  [ 80/147]  eta: 0:00:36  lr: 0.000065  min_lr: 0.000065  loss: 2.4825 (2.3829)  weight_decay: 0.0500 (0.0500)  time: 0.5017  data: 0.0011  max mem: 5608\n",
            "Epoch: [93]  [ 90/147]  eta: 0:00:31  lr: 0.000064  min_lr: 0.000064  loss: 2.4385 (2.3773)  weight_decay: 0.0500 (0.0500)  time: 0.4986  data: 0.0009  max mem: 5608\n",
            "Epoch: [93]  [100/147]  eta: 0:00:25  lr: 0.000062  min_lr: 0.000062  loss: 2.3068 (2.3678)  weight_decay: 0.0500 (0.0500)  time: 0.5039  data: 0.0020  max mem: 5608\n",
            "Epoch: [93]  [110/147]  eta: 0:00:19  lr: 0.000061  min_lr: 0.000061  loss: 2.4527 (2.3806)  weight_decay: 0.0500 (0.0500)  time: 0.5091  data: 0.0031  max mem: 5608\n",
            "Epoch: [93]  [120/147]  eta: 0:00:14  lr: 0.000059  min_lr: 0.000059  loss: 2.4325 (2.3747)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0020  max mem: 5608\n",
            "Epoch: [93]  [130/147]  eta: 0:00:09  lr: 0.000058  min_lr: 0.000058  loss: 2.2771 (2.3691)  weight_decay: 0.0500 (0.0500)  time: 0.4998  data: 0.0011  max mem: 5608\n",
            "Epoch: [93]  [140/147]  eta: 0:00:03  lr: 0.000057  min_lr: 0.000057  loss: 2.3614 (2.3665)  weight_decay: 0.0500 (0.0500)  time: 0.4988  data: 0.0008  max mem: 5608\n",
            "Epoch: [93]  [146/147]  eta: 0:00:00  lr: 0.000057  min_lr: 0.000057  loss: 2.3777 (2.3663)  weight_decay: 0.0500 (0.0500)  time: 0.4206  data: 0.0002  max mem: 5608\n",
            "Epoch: [93] Total time: 0:01:16 (0.5226 s / it)\n",
            "Averaged stats: lr: 0.000057  min_lr: 0.000057  loss: 2.3777 (2.3663)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:06  loss: 0.4778 (0.4778)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 3.0901  data: 2.7754  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 0.5397 (0.5361)  acc1: 90.6250 (90.4356)  acc5: 97.9167 (98.5795)  time: 0.5356  data: 0.2968  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.5811 (0.6877)  acc1: 87.5000 (83.8790)  acc5: 97.9167 (98.3631)  time: 0.3249  data: 0.0832  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7042 (0.7071)  acc1: 81.2500 (82.9301)  acc5: 97.9167 (98.2191)  time: 0.3425  data: 0.0984  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6400 (0.7009)  acc1: 84.3750 (83.2611)  acc5: 97.9167 (98.1656)  time: 0.2730  data: 0.0397  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3767 s / it)\n",
            "* Acc@1 83.261 Acc@5 98.166 loss 0.701\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 3.1901 (3.1901)  acc1: 21.8750 (21.8750)  acc5: 82.2917 (82.2917)  time: 3.1816  data: 2.9093  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.5161 (3.5357)  acc1: 21.8750 (22.7273)  acc5: 86.4583 (86.2689)  time: 0.5470  data: 0.3104  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 3.8457 (4.2558)  acc1: 12.5000 (15.5258)  acc5: 81.2500 (73.8095)  time: 0.2653  data: 0.0271  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 4.6938 (4.5282)  acc1: 3.1250 (13.9113)  acc5: 59.3750 (68.4476)  time: 0.2452  data: 0.0019  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2660 (4.0577)  acc1: 23.9583 (23.1847)  acc5: 81.2500 (71.4140)  time: 0.2406  data: 0.0022  max mem: 5608\n",
            "Test: Total time: 0:00:13 (0.3409 s / it)\n",
            "* Acc@1 23.185 Acc@5 71.414 loss 4.058\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "Max EMA accuracy: 23.18%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [94]  [  0/147]  eta: 0:06:46  lr: 0.000056  min_lr: 0.000056  loss: 2.6146 (2.6146)  weight_decay: 0.0500 (0.0500)  time: 2.7678  data: 2.1684  max mem: 5608\n",
            "Epoch: [94]  [ 10/147]  eta: 0:01:40  lr: 0.000055  min_lr: 0.000055  loss: 2.4709 (2.4311)  weight_decay: 0.0500 (0.0500)  time: 0.7334  data: 0.2064  max mem: 5608\n",
            "Epoch: [94]  [ 20/147]  eta: 0:01:20  lr: 0.000054  min_lr: 0.000054  loss: 2.4884 (2.4454)  weight_decay: 0.0500 (0.0500)  time: 0.5249  data: 0.0065  max mem: 5608\n",
            "Epoch: [94]  [ 30/147]  eta: 0:01:09  lr: 0.000053  min_lr: 0.000053  loss: 2.5351 (2.4462)  weight_decay: 0.0500 (0.0500)  time: 0.5217  data: 0.0026  max mem: 5608\n",
            "Epoch: [94]  [ 40/147]  eta: 0:01:01  lr: 0.000051  min_lr: 0.000051  loss: 2.5351 (2.4698)  weight_decay: 0.0500 (0.0500)  time: 0.5173  data: 0.0018  max mem: 5608\n",
            "Epoch: [94]  [ 50/147]  eta: 0:00:54  lr: 0.000050  min_lr: 0.000050  loss: 2.4870 (2.4289)  weight_decay: 0.0500 (0.0500)  time: 0.5087  data: 0.0012  max mem: 5608\n",
            "Epoch: [94]  [ 60/147]  eta: 0:00:48  lr: 0.000049  min_lr: 0.000049  loss: 2.2045 (2.4155)  weight_decay: 0.0500 (0.0500)  time: 0.5113  data: 0.0015  max mem: 5608\n",
            "Epoch: [94]  [ 70/147]  eta: 0:00:42  lr: 0.000048  min_lr: 0.000048  loss: 2.4916 (2.4128)  weight_decay: 0.0500 (0.0500)  time: 0.5109  data: 0.0023  max mem: 5608\n",
            "Epoch: [94]  [ 80/147]  eta: 0:00:36  lr: 0.000047  min_lr: 0.000047  loss: 2.4618 (2.4076)  weight_decay: 0.0500 (0.0500)  time: 0.5055  data: 0.0040  max mem: 5608\n",
            "Epoch: [94]  [ 90/147]  eta: 0:00:30  lr: 0.000046  min_lr: 0.000046  loss: 2.4100 (2.3977)  weight_decay: 0.0500 (0.0500)  time: 0.5086  data: 0.0035  max mem: 5608\n",
            "Epoch: [94]  [100/147]  eta: 0:00:25  lr: 0.000044  min_lr: 0.000044  loss: 2.4371 (2.3957)  weight_decay: 0.0500 (0.0500)  time: 0.5103  data: 0.0020  max mem: 5608\n",
            "Epoch: [94]  [110/147]  eta: 0:00:19  lr: 0.000043  min_lr: 0.000043  loss: 2.5098 (2.4021)  weight_decay: 0.0500 (0.0500)  time: 0.5014  data: 0.0018  max mem: 5608\n",
            "Epoch: [94]  [120/147]  eta: 0:00:14  lr: 0.000042  min_lr: 0.000042  loss: 2.4689 (2.4029)  weight_decay: 0.0500 (0.0500)  time: 0.4977  data: 0.0021  max mem: 5608\n",
            "Epoch: [94]  [130/147]  eta: 0:00:08  lr: 0.000041  min_lr: 0.000041  loss: 2.4340 (2.4001)  weight_decay: 0.0500 (0.0500)  time: 0.5016  data: 0.0017  max mem: 5608\n",
            "Epoch: [94]  [140/147]  eta: 0:00:03  lr: 0.000040  min_lr: 0.000040  loss: 2.4241 (2.3966)  weight_decay: 0.0500 (0.0500)  time: 0.4982  data: 0.0002  max mem: 5608\n",
            "Epoch: [94]  [146/147]  eta: 0:00:00  lr: 0.000040  min_lr: 0.000040  loss: 2.4539 (2.3991)  weight_decay: 0.0500 (0.0500)  time: 0.4206  data: 0.0002  max mem: 5608\n",
            "Epoch: [94] Total time: 0:01:15 (0.5170 s / it)\n",
            "Averaged stats: lr: 0.000040  min_lr: 0.000040  loss: 2.4539 (2.3991)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 0.4743 (0.4743)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.4900  data: 3.1872  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5400 (0.5356)  acc1: 90.6250 (90.4356)  acc5: 97.9167 (98.4849)  time: 0.6536  data: 0.4050  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5770 (0.6877)  acc1: 87.5000 (84.0278)  acc5: 98.9583 (98.4623)  time: 0.3446  data: 0.1057  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6655 (0.7095)  acc1: 82.2917 (83.0645)  acc5: 97.9167 (98.2527)  time: 0.3137  data: 0.0791  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6667 (0.7047)  acc1: 84.7059 (83.2102)  acc5: 97.9167 (98.1911)  time: 0.2683  data: 0.0369  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3953 s / it)\n",
            "* Acc@1 83.210 Acc@5 98.191 loss 0.705\n",
            "Accuracy of the model on the 3925 test images: 83.2%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:02:06  loss: 3.1746 (3.1746)  acc1: 21.8750 (21.8750)  acc5: 82.2917 (82.2917)  time: 3.0822  data: 2.7900  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:16  loss: 3.5034 (3.5197)  acc1: 21.8750 (22.2538)  acc5: 86.4583 (86.4583)  time: 0.5346  data: 0.2983  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 3.8322 (4.2394)  acc1: 12.5000 (15.2778)  acc5: 81.2500 (74.0079)  time: 0.2688  data: 0.0252  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.6931 (4.5153)  acc1: 3.1250 (13.7097)  acc5: 58.3333 (68.5484)  time: 0.3135  data: 0.0673  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2535 (4.0440)  acc1: 22.9167 (23.0573)  acc5: 81.2500 (71.5414)  time: 0.3451  data: 0.1107  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3914 s / it)\n",
            "* Acc@1 23.057 Acc@5 71.541 loss 4.044\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [95]  [  0/147]  eta: 0:10:48  lr: 0.000039  min_lr: 0.000039  loss: 2.0635 (2.0635)  weight_decay: 0.0500 (0.0500)  time: 4.4135  data: 3.8148  max mem: 5608\n",
            "Epoch: [95]  [ 10/147]  eta: 0:01:59  lr: 0.000039  min_lr: 0.000039  loss: 2.0635 (2.1423)  weight_decay: 0.0500 (0.0500)  time: 0.8709  data: 0.3506  max mem: 5608\n",
            "Epoch: [95]  [ 20/147]  eta: 0:01:29  lr: 0.000037  min_lr: 0.000037  loss: 2.2809 (2.2845)  weight_decay: 0.0500 (0.0500)  time: 0.5176  data: 0.0039  max mem: 5608\n",
            "Epoch: [95]  [ 30/147]  eta: 0:01:15  lr: 0.000036  min_lr: 0.000036  loss: 2.5469 (2.3352)  weight_decay: 0.0500 (0.0500)  time: 0.5186  data: 0.0031  max mem: 5608\n",
            "Epoch: [95]  [ 40/147]  eta: 0:01:05  lr: 0.000035  min_lr: 0.000035  loss: 2.3289 (2.3473)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0014  max mem: 5608\n",
            "Epoch: [95]  [ 50/147]  eta: 0:00:57  lr: 0.000034  min_lr: 0.000034  loss: 2.3289 (2.3573)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0007  max mem: 5608\n",
            "Epoch: [95]  [ 60/147]  eta: 0:00:50  lr: 0.000033  min_lr: 0.000033  loss: 2.3082 (2.3437)  weight_decay: 0.0500 (0.0500)  time: 0.5156  data: 0.0023  max mem: 5608\n",
            "Epoch: [95]  [ 70/147]  eta: 0:00:43  lr: 0.000033  min_lr: 0.000033  loss: 2.3082 (2.3523)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0022  max mem: 5608\n",
            "Epoch: [95]  [ 80/147]  eta: 0:00:37  lr: 0.000031  min_lr: 0.000031  loss: 2.4711 (2.3618)  weight_decay: 0.0500 (0.0500)  time: 0.5015  data: 0.0007  max mem: 5608\n",
            "Epoch: [95]  [ 90/147]  eta: 0:00:31  lr: 0.000031  min_lr: 0.000031  loss: 2.4094 (2.3634)  weight_decay: 0.0500 (0.0500)  time: 0.5026  data: 0.0015  max mem: 5608\n",
            "Epoch: [95]  [100/147]  eta: 0:00:25  lr: 0.000030  min_lr: 0.000030  loss: 2.3944 (2.3672)  weight_decay: 0.0500 (0.0500)  time: 0.5062  data: 0.0032  max mem: 5608\n",
            "Epoch: [95]  [110/147]  eta: 0:00:20  lr: 0.000029  min_lr: 0.000029  loss: 2.4180 (2.3604)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0036  max mem: 5608\n",
            "Epoch: [95]  [120/147]  eta: 0:00:14  lr: 0.000028  min_lr: 0.000028  loss: 2.2254 (2.3548)  weight_decay: 0.0500 (0.0500)  time: 0.4971  data: 0.0031  max mem: 5608\n",
            "Epoch: [95]  [130/147]  eta: 0:00:09  lr: 0.000027  min_lr: 0.000027  loss: 2.3227 (2.3557)  weight_decay: 0.0500 (0.0500)  time: 0.5005  data: 0.0022  max mem: 5608\n",
            "Epoch: [95]  [140/147]  eta: 0:00:03  lr: 0.000026  min_lr: 0.000026  loss: 2.4130 (2.3566)  weight_decay: 0.0500 (0.0500)  time: 0.4976  data: 0.0009  max mem: 5608\n",
            "Epoch: [95]  [146/147]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 2.4130 (2.3550)  weight_decay: 0.0500 (0.0500)  time: 0.4198  data: 0.0002  max mem: 5608\n",
            "Epoch: [95] Total time: 0:01:17 (0.5261 s / it)\n",
            "Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 2.4130 (2.3550)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:58  loss: 0.4726 (0.4726)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 2.8798  data: 2.5958  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:17  loss: 0.5112 (0.5297)  acc1: 89.5833 (90.0568)  acc5: 97.9167 (98.4849)  time: 0.5661  data: 0.3238  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5759 (0.6801)  acc1: 87.5000 (83.8790)  acc5: 97.9167 (98.4623)  time: 0.3603  data: 0.1175  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6508 (0.7001)  acc1: 81.2500 (83.1653)  acc5: 97.9167 (98.3199)  time: 0.3413  data: 0.0947  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6913 (0.6982)  acc1: 84.7059 (83.2611)  acc5: 97.9167 (98.2166)  time: 0.2642  data: 0.0256  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3853 s / it)\n",
            "* Acc@1 83.261 Acc@5 98.217 loss 0.698\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 3.1589 (3.1589)  acc1: 20.8333 (20.8333)  acc5: 82.2917 (82.2917)  time: 3.1900  data: 2.8748  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 3.4902 (3.5038)  acc1: 20.8333 (22.0644)  acc5: 87.5000 (86.7424)  time: 0.5146  data: 0.2716  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 3.8187 (4.2231)  acc1: 13.5417 (15.0298)  acc5: 81.2500 (74.2560)  time: 0.2777  data: 0.0356  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.6923 (4.5024)  acc1: 3.1250 (13.4745)  acc5: 58.3333 (68.6492)  time: 0.3315  data: 0.0806  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2404 (4.0303)  acc1: 21.8750 (22.9554)  acc5: 81.2500 (71.6433)  time: 0.2950  data: 0.0507  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3682 s / it)\n",
            "* Acc@1 22.955 Acc@5 71.643 loss 4.030\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [96]  [  0/147]  eta: 0:06:53  lr: 0.000026  min_lr: 0.000026  loss: 2.4585 (2.4585)  weight_decay: 0.0500 (0.0500)  time: 2.8097  data: 2.1979  max mem: 5608\n",
            "Epoch: [96]  [ 10/147]  eta: 0:01:40  lr: 0.000025  min_lr: 0.000025  loss: 2.3839 (2.3052)  weight_decay: 0.0500 (0.0500)  time: 0.7310  data: 0.2018  max mem: 5608\n",
            "Epoch: [96]  [ 20/147]  eta: 0:01:19  lr: 0.000024  min_lr: 0.000024  loss: 2.3839 (2.3762)  weight_decay: 0.0500 (0.0500)  time: 0.5198  data: 0.0034  max mem: 5608\n",
            "Epoch: [96]  [ 30/147]  eta: 0:01:09  lr: 0.000023  min_lr: 0.000023  loss: 2.5244 (2.3776)  weight_decay: 0.0500 (0.0500)  time: 0.5171  data: 0.0061  max mem: 5608\n",
            "Epoch: [96]  [ 40/147]  eta: 0:01:01  lr: 0.000022  min_lr: 0.000022  loss: 2.5232 (2.3976)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0057  max mem: 5608\n",
            "Epoch: [96]  [ 50/147]  eta: 0:00:54  lr: 0.000022  min_lr: 0.000022  loss: 2.5232 (2.4232)  weight_decay: 0.0500 (0.0500)  time: 0.5110  data: 0.0041  max mem: 5608\n",
            "Epoch: [96]  [ 60/147]  eta: 0:00:48  lr: 0.000021  min_lr: 0.000021  loss: 2.5209 (2.4228)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0039  max mem: 5608\n",
            "Epoch: [96]  [ 70/147]  eta: 0:00:42  lr: 0.000020  min_lr: 0.000020  loss: 2.3721 (2.4043)  weight_decay: 0.0500 (0.0500)  time: 0.5091  data: 0.0026  max mem: 5608\n",
            "Epoch: [96]  [ 80/147]  eta: 0:00:36  lr: 0.000019  min_lr: 0.000019  loss: 2.3875 (2.4082)  weight_decay: 0.0500 (0.0500)  time: 0.5034  data: 0.0017  max mem: 5608\n",
            "Epoch: [96]  [ 90/147]  eta: 0:00:30  lr: 0.000019  min_lr: 0.000019  loss: 2.3991 (2.3958)  weight_decay: 0.0500 (0.0500)  time: 0.5131  data: 0.0050  max mem: 5608\n",
            "Epoch: [96]  [100/147]  eta: 0:00:25  lr: 0.000018  min_lr: 0.000018  loss: 2.1911 (2.3706)  weight_decay: 0.0500 (0.0500)  time: 0.5195  data: 0.0077  max mem: 5608\n",
            "Epoch: [96]  [110/147]  eta: 0:00:19  lr: 0.000017  min_lr: 0.000017  loss: 2.2049 (2.3755)  weight_decay: 0.0500 (0.0500)  time: 0.5075  data: 0.0048  max mem: 5608\n",
            "Epoch: [96]  [120/147]  eta: 0:00:14  lr: 0.000016  min_lr: 0.000016  loss: 2.4392 (2.3826)  weight_decay: 0.0500 (0.0500)  time: 0.4972  data: 0.0021  max mem: 5608\n",
            "Epoch: [96]  [130/147]  eta: 0:00:08  lr: 0.000016  min_lr: 0.000016  loss: 2.4392 (2.3875)  weight_decay: 0.0500 (0.0500)  time: 0.5003  data: 0.0021  max mem: 5608\n",
            "Epoch: [96]  [140/147]  eta: 0:00:03  lr: 0.000015  min_lr: 0.000015  loss: 2.4955 (2.3919)  weight_decay: 0.0500 (0.0500)  time: 0.4992  data: 0.0015  max mem: 5608\n",
            "Epoch: [96]  [146/147]  eta: 0:00:00  lr: 0.000015  min_lr: 0.000015  loss: 2.5124 (2.3925)  weight_decay: 0.0500 (0.0500)  time: 0.4215  data: 0.0002  max mem: 5608\n",
            "Epoch: [96] Total time: 0:01:16 (0.5175 s / it)\n",
            "Averaged stats: lr: 0.000015  min_lr: 0.000015  loss: 2.5124 (2.3925)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 0.4662 (0.4662)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 3.1847  data: 2.8970  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 0.5289 (0.5309)  acc1: 90.6250 (90.2462)  acc5: 97.9167 (98.3902)  time: 0.5819  data: 0.3418  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:09  loss: 0.5752 (0.6847)  acc1: 88.5417 (83.8790)  acc5: 97.9167 (98.3631)  time: 0.3333  data: 0.0944  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6655 (0.7028)  acc1: 82.2917 (83.1317)  acc5: 97.9167 (98.2863)  time: 0.3307  data: 0.0910  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6849 (0.6998)  acc1: 84.7059 (83.2866)  acc5: 97.9167 (98.1656)  time: 0.2734  data: 0.0398  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3831 s / it)\n",
            "* Acc@1 83.287 Acc@5 98.166 loss 0.700\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:02:09  loss: 3.1429 (3.1429)  acc1: 20.8333 (20.8333)  acc5: 82.2917 (82.2917)  time: 3.1531  data: 2.8607  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:15  loss: 3.4767 (3.4878)  acc1: 20.8333 (21.5909)  acc5: 87.5000 (86.9318)  time: 0.5088  data: 0.2651  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 3.8049 (4.2067)  acc1: 12.5000 (14.9802)  acc5: 81.2500 (74.3552)  time: 0.2489  data: 0.0067  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.6916 (4.4893)  acc1: 3.1250 (13.3401)  acc5: 57.2917 (68.5484)  time: 0.2940  data: 0.0474  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2269 (4.0166)  acc1: 19.7917 (22.9045)  acc5: 81.2500 (71.6178)  time: 0.2850  data: 0.0436  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3515 s / it)\n",
            "* Acc@1 22.904 Acc@5 71.618 loss 4.017\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [97]  [  0/147]  eta: 0:07:39  lr: 0.000015  min_lr: 0.000015  loss: 2.6348 (2.6348)  weight_decay: 0.0500 (0.0500)  time: 3.1270  data: 2.5397  max mem: 5608\n",
            "Epoch: [97]  [ 10/147]  eta: 0:01:43  lr: 0.000014  min_lr: 0.000014  loss: 2.5398 (2.4049)  weight_decay: 0.0500 (0.0500)  time: 0.7561  data: 0.2318  max mem: 5608\n",
            "Epoch: [97]  [ 20/147]  eta: 0:01:21  lr: 0.000014  min_lr: 0.000014  loss: 2.5354 (2.4595)  weight_decay: 0.0500 (0.0500)  time: 0.5188  data: 0.0019  max mem: 5608\n",
            "Epoch: [97]  [ 30/147]  eta: 0:01:10  lr: 0.000013  min_lr: 0.000013  loss: 2.4037 (2.4212)  weight_decay: 0.0500 (0.0500)  time: 0.5157  data: 0.0022  max mem: 5608\n",
            "Epoch: [97]  [ 40/147]  eta: 0:01:01  lr: 0.000012  min_lr: 0.000012  loss: 2.2971 (2.4046)  weight_decay: 0.0500 (0.0500)  time: 0.5092  data: 0.0015  max mem: 5608\n",
            "Epoch: [97]  [ 50/147]  eta: 0:00:54  lr: 0.000012  min_lr: 0.000012  loss: 2.2610 (2.3703)  weight_decay: 0.0500 (0.0500)  time: 0.5052  data: 0.0017  max mem: 5608\n",
            "Epoch: [97]  [ 60/147]  eta: 0:00:48  lr: 0.000011  min_lr: 0.000011  loss: 2.3264 (2.3725)  weight_decay: 0.0500 (0.0500)  time: 0.5081  data: 0.0014  max mem: 5608\n",
            "Epoch: [97]  [ 70/147]  eta: 0:00:42  lr: 0.000011  min_lr: 0.000011  loss: 2.3011 (2.3585)  weight_decay: 0.0500 (0.0500)  time: 0.5058  data: 0.0017  max mem: 5608\n",
            "Epoch: [97]  [ 80/147]  eta: 0:00:36  lr: 0.000010  min_lr: 0.000010  loss: 2.3057 (2.3672)  weight_decay: 0.0500 (0.0500)  time: 0.5011  data: 0.0031  max mem: 5608\n",
            "Epoch: [97]  [ 90/147]  eta: 0:00:30  lr: 0.000010  min_lr: 0.000010  loss: 2.4743 (2.3781)  weight_decay: 0.0500 (0.0500)  time: 0.5049  data: 0.0039  max mem: 5608\n",
            "Epoch: [97]  [100/147]  eta: 0:00:25  lr: 0.000009  min_lr: 0.000009  loss: 2.5042 (2.3866)  weight_decay: 0.0500 (0.0500)  time: 0.5119  data: 0.0038  max mem: 5608\n",
            "Epoch: [97]  [110/147]  eta: 0:00:19  lr: 0.000009  min_lr: 0.000009  loss: 2.4741 (2.3849)  weight_decay: 0.0500 (0.0500)  time: 0.5078  data: 0.0029  max mem: 5608\n",
            "Epoch: [97]  [120/147]  eta: 0:00:14  lr: 0.000008  min_lr: 0.000008  loss: 2.3407 (2.3773)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0024  max mem: 5608\n",
            "Epoch: [97]  [130/147]  eta: 0:00:08  lr: 0.000008  min_lr: 0.000008  loss: 2.4036 (2.3857)  weight_decay: 0.0500 (0.0500)  time: 0.5052  data: 0.0030  max mem: 5608\n",
            "Epoch: [97]  [140/147]  eta: 0:00:03  lr: 0.000007  min_lr: 0.000007  loss: 2.4898 (2.3879)  weight_decay: 0.0500 (0.0500)  time: 0.4997  data: 0.0017  max mem: 5608\n",
            "Epoch: [97]  [146/147]  eta: 0:00:00  lr: 0.000007  min_lr: 0.000007  loss: 2.4898 (2.3862)  weight_decay: 0.0500 (0.0500)  time: 0.4216  data: 0.0003  max mem: 5608\n",
            "Epoch: [97] Total time: 0:01:16 (0.5177 s / it)\n",
            "Averaged stats: lr: 0.000007  min_lr: 0.000007  loss: 2.4898 (2.3862)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:50  loss: 0.4720 (0.4720)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 4.1650  data: 3.8501  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5372 (0.5342)  acc1: 90.6250 (90.0568)  acc5: 97.9167 (98.3902)  time: 0.6678  data: 0.4148  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5725 (0.6851)  acc1: 88.5417 (83.8790)  acc5: 97.9167 (98.3631)  time: 0.3162  data: 0.0722  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6611 (0.7046)  acc1: 83.3333 (83.1317)  acc5: 97.9167 (98.2191)  time: 0.2805  data: 0.0408  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6675 (0.7011)  acc1: 83.5294 (83.2611)  acc5: 97.9167 (98.1656)  time: 0.2382  data: 0.0043  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3868 s / it)\n",
            "* Acc@1 83.261 Acc@5 98.166 loss 0.701\n",
            "Accuracy of the model on the 3925 test images: 83.3%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:04:15  loss: 3.1269 (3.1269)  acc1: 20.8333 (20.8333)  acc5: 82.2917 (82.2917)  time: 6.2241  data: 5.9107  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 3.4629 (3.4719)  acc1: 20.8333 (21.7803)  acc5: 87.5000 (87.4053)  time: 0.8559  data: 0.5986  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 3.7909 (4.1903)  acc1: 12.5000 (15.0298)  acc5: 81.2500 (74.4048)  time: 0.3393  data: 0.0931  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 4.6808 (4.4762)  acc1: 3.1250 (13.3065)  acc5: 55.2083 (68.5148)  time: 0.3066  data: 0.0625  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2134 (4.0029)  acc1: 19.7917 (22.9299)  acc5: 81.2500 (71.6178)  time: 0.2435  data: 0.0031  max mem: 5608\n",
            "Test: Total time: 0:00:18 (0.4455 s / it)\n",
            "* Acc@1 22.930 Acc@5 71.618 loss 4.003\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [98]  [  0/147]  eta: 0:07:54  lr: 0.000007  min_lr: 0.000007  loss: 2.5114 (2.5114)  weight_decay: 0.0500 (0.0500)  time: 3.2279  data: 2.6480  max mem: 5608\n",
            "Epoch: [98]  [ 10/147]  eta: 0:01:44  lr: 0.000007  min_lr: 0.000007  loss: 2.4174 (2.3343)  weight_decay: 0.0500 (0.0500)  time: 0.7652  data: 0.2421  max mem: 5608\n",
            "Epoch: [98]  [ 20/147]  eta: 0:01:22  lr: 0.000006  min_lr: 0.000006  loss: 2.3364 (2.3507)  weight_decay: 0.0500 (0.0500)  time: 0.5221  data: 0.0017  max mem: 5608\n",
            "Epoch: [98]  [ 30/147]  eta: 0:01:10  lr: 0.000006  min_lr: 0.000006  loss: 2.3364 (2.3525)  weight_decay: 0.0500 (0.0500)  time: 0.5182  data: 0.0016  max mem: 5608\n",
            "Epoch: [98]  [ 40/147]  eta: 0:01:02  lr: 0.000006  min_lr: 0.000006  loss: 2.4226 (2.3715)  weight_decay: 0.0500 (0.0500)  time: 0.5112  data: 0.0017  max mem: 5608\n",
            "Epoch: [98]  [ 50/147]  eta: 0:00:55  lr: 0.000005  min_lr: 0.000005  loss: 2.4226 (2.3791)  weight_decay: 0.0500 (0.0500)  time: 0.5130  data: 0.0017  max mem: 5608\n",
            "Epoch: [98]  [ 60/147]  eta: 0:00:48  lr: 0.000005  min_lr: 0.000005  loss: 2.4418 (2.3865)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0011  max mem: 5608\n",
            "Epoch: [98]  [ 70/147]  eta: 0:00:42  lr: 0.000005  min_lr: 0.000005  loss: 2.3994 (2.3800)  weight_decay: 0.0500 (0.0500)  time: 0.5052  data: 0.0013  max mem: 5608\n",
            "Epoch: [98]  [ 80/147]  eta: 0:00:36  lr: 0.000004  min_lr: 0.000004  loss: 2.2889 (2.3733)  weight_decay: 0.0500 (0.0500)  time: 0.5044  data: 0.0020  max mem: 5608\n",
            "Epoch: [98]  [ 90/147]  eta: 0:00:30  lr: 0.000004  min_lr: 0.000004  loss: 2.2889 (2.3653)  weight_decay: 0.0500 (0.0500)  time: 0.5091  data: 0.0034  max mem: 5608\n",
            "Epoch: [98]  [100/147]  eta: 0:00:25  lr: 0.000004  min_lr: 0.000004  loss: 2.2591 (2.3547)  weight_decay: 0.0500 (0.0500)  time: 0.5042  data: 0.0034  max mem: 5608\n",
            "Epoch: [98]  [110/147]  eta: 0:00:19  lr: 0.000003  min_lr: 0.000003  loss: 2.4247 (2.3646)  weight_decay: 0.0500 (0.0500)  time: 0.4965  data: 0.0020  max mem: 5608\n",
            "Epoch: [98]  [120/147]  eta: 0:00:14  lr: 0.000003  min_lr: 0.000003  loss: 2.4774 (2.3671)  weight_decay: 0.0500 (0.0500)  time: 0.5034  data: 0.0027  max mem: 5608\n",
            "Epoch: [98]  [130/147]  eta: 0:00:09  lr: 0.000003  min_lr: 0.000003  loss: 2.4552 (2.3671)  weight_decay: 0.0500 (0.0500)  time: 0.5053  data: 0.0020  max mem: 5608\n",
            "Epoch: [98]  [140/147]  eta: 0:00:03  lr: 0.000003  min_lr: 0.000003  loss: 2.4304 (2.3685)  weight_decay: 0.0500 (0.0500)  time: 0.4954  data: 0.0003  max mem: 5608\n",
            "Epoch: [98]  [146/147]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000003  loss: 2.4631 (2.3684)  weight_decay: 0.0500 (0.0500)  time: 0.4183  data: 0.0002  max mem: 5608\n",
            "Epoch: [98] Total time: 0:01:16 (0.5180 s / it)\n",
            "Averaged stats: lr: 0.000003  min_lr: 0.000003  loss: 2.4631 (2.3684)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:41  loss: 0.4788 (0.4788)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 5.4098  data: 5.0813  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5321 (0.5345)  acc1: 90.6250 (90.3409)  acc5: 97.9167 (98.3902)  time: 0.7748  data: 0.5239  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5727 (0.6839)  acc1: 88.5417 (83.9286)  acc5: 97.9167 (98.4127)  time: 0.2760  data: 0.0365  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.6624 (0.7039)  acc1: 83.3333 (83.0645)  acc5: 97.9167 (98.2527)  time: 0.2365  data: 0.0025  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6697 (0.7009)  acc1: 83.5294 (83.1847)  acc5: 97.9167 (98.1656)  time: 0.2307  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3897 s / it)\n",
            "* Acc@1 83.185 Acc@5 98.166 loss 0.701\n",
            "Accuracy of the model on the 3925 test images: 83.2%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:03:38  loss: 3.1108 (3.1108)  acc1: 20.8333 (20.8333)  acc5: 82.2917 (82.2917)  time: 5.3218  data: 5.0487  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 3.4490 (3.4560)  acc1: 20.8333 (21.7803)  acc5: 87.5000 (87.5000)  time: 0.7725  data: 0.5233  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.7768 (4.1737)  acc1: 12.5000 (15.0794)  acc5: 81.2500 (74.4048)  time: 0.2895  data: 0.0454  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.6480 (4.4629)  acc1: 3.1250 (13.3065)  acc5: 55.2083 (68.5484)  time: 0.2494  data: 0.0100  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1997 (3.9891)  acc1: 19.7917 (22.9809)  acc5: 82.2917 (71.6433)  time: 0.2348  data: 0.0001  max mem: 5608\n",
            "Test: Total time: 0:00:16 (0.3950 s / it)\n",
            "* Acc@1 22.981 Acc@5 71.643 loss 3.989\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [99]  [  0/147]  eta: 0:07:55  lr: 0.000003  min_lr: 0.000003  loss: 2.6437 (2.6437)  weight_decay: 0.0500 (0.0500)  time: 3.2360  data: 2.6444  max mem: 5608\n",
            "Epoch: [99]  [ 10/147]  eta: 0:01:47  lr: 0.000002  min_lr: 0.000002  loss: 2.4442 (2.4293)  weight_decay: 0.0500 (0.0500)  time: 0.7881  data: 0.2422  max mem: 5608\n",
            "Epoch: [99]  [ 20/147]  eta: 0:01:23  lr: 0.000002  min_lr: 0.000002  loss: 2.4123 (2.4066)  weight_decay: 0.0500 (0.0500)  time: 0.5317  data: 0.0023  max mem: 5608\n",
            "Epoch: [99]  [ 30/147]  eta: 0:01:11  lr: 0.000002  min_lr: 0.000002  loss: 2.4898 (2.4098)  weight_decay: 0.0500 (0.0500)  time: 0.5155  data: 0.0024  max mem: 5608\n",
            "Epoch: [99]  [ 40/147]  eta: 0:01:03  lr: 0.000002  min_lr: 0.000002  loss: 2.4898 (2.4114)  weight_decay: 0.0500 (0.0500)  time: 0.5145  data: 0.0018  max mem: 5608\n",
            "Epoch: [99]  [ 50/147]  eta: 0:00:55  lr: 0.000002  min_lr: 0.000002  loss: 2.4263 (2.4061)  weight_decay: 0.0500 (0.0500)  time: 0.5167  data: 0.0014  max mem: 5608\n",
            "Epoch: [99]  [ 60/147]  eta: 0:00:49  lr: 0.000002  min_lr: 0.000002  loss: 2.4263 (2.4103)  weight_decay: 0.0500 (0.0500)  time: 0.5153  data: 0.0024  max mem: 5608\n",
            "Epoch: [99]  [ 70/147]  eta: 0:00:42  lr: 0.000001  min_lr: 0.000001  loss: 2.4083 (2.3971)  weight_decay: 0.0500 (0.0500)  time: 0.5151  data: 0.0044  max mem: 5608\n",
            "Epoch: [99]  [ 80/147]  eta: 0:00:37  lr: 0.000001  min_lr: 0.000001  loss: 2.4201 (2.3963)  weight_decay: 0.0500 (0.0500)  time: 0.5186  data: 0.0049  max mem: 5608\n",
            "Epoch: [99]  [ 90/147]  eta: 0:00:31  lr: 0.000001  min_lr: 0.000001  loss: 2.4326 (2.3973)  weight_decay: 0.0500 (0.0500)  time: 0.5121  data: 0.0041  max mem: 5608\n",
            "Epoch: [99]  [100/147]  eta: 0:00:25  lr: 0.000001  min_lr: 0.000001  loss: 2.4249 (2.3946)  weight_decay: 0.0500 (0.0500)  time: 0.5012  data: 0.0033  max mem: 5608\n",
            "Epoch: [99]  [110/147]  eta: 0:00:19  lr: 0.000001  min_lr: 0.000001  loss: 2.2385 (2.3803)  weight_decay: 0.0500 (0.0500)  time: 0.5016  data: 0.0028  max mem: 5608\n",
            "Epoch: [99]  [120/147]  eta: 0:00:14  lr: 0.000001  min_lr: 0.000001  loss: 2.3661 (2.3798)  weight_decay: 0.0500 (0.0500)  time: 0.5068  data: 0.0050  max mem: 5608\n",
            "Epoch: [99]  [130/147]  eta: 0:00:09  lr: 0.000001  min_lr: 0.000001  loss: 2.4521 (2.3790)  weight_decay: 0.0500 (0.0500)  time: 0.5030  data: 0.0055  max mem: 5608\n",
            "Epoch: [99]  [140/147]  eta: 0:00:03  lr: 0.000001  min_lr: 0.000001  loss: 2.4859 (2.3794)  weight_decay: 0.0500 (0.0500)  time: 0.4940  data: 0.0020  max mem: 5608\n",
            "Epoch: [99]  [146/147]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.4859 (2.3779)  weight_decay: 0.0500 (0.0500)  time: 0.4195  data: 0.0002  max mem: 5608\n",
            "Epoch: [99] Total time: 0:01:17 (0.5241 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.4859 (2.3779)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:39  loss: 0.4772 (0.4772)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.8831  data: 3.5906  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:18  loss: 0.5319 (0.5330)  acc1: 90.6250 (90.3409)  acc5: 97.9167 (98.3902)  time: 0.5896  data: 0.3482  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:08  loss: 0.5705 (0.6834)  acc1: 88.5417 (83.9286)  acc5: 97.9167 (98.4127)  time: 0.2499  data: 0.0135  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:03  loss: 0.6623 (0.7040)  acc1: 83.3333 (83.0645)  acc5: 97.9167 (98.2527)  time: 0.2372  data: 0.0016  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6697 (0.7012)  acc1: 83.5294 (83.1847)  acc5: 97.9167 (98.1656)  time: 0.2315  data: 0.0002  max mem: 5608\n",
            "Test: Total time: 0:00:14 (0.3455 s / it)\n",
            "* Acc@1 83.185 Acc@5 98.166 loss 0.701\n",
            "Accuracy of the model on the 3925 test images: 83.2%\n",
            "Max accuracy: 83.31%\n",
            "Test:  [ 0/41]  eta: 0:03:25  loss: 3.0946 (3.0946)  acc1: 20.8333 (20.8333)  acc5: 83.3333 (83.3333)  time: 5.0232  data: 4.6781  max mem: 5608\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.4348 (3.4400)  acc1: 21.8750 (21.9697)  acc5: 89.5833 (87.7841)  time: 0.7015  data: 0.4553  max mem: 5608\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 3.7624 (4.1571)  acc1: 13.5417 (15.1786)  acc5: 81.2500 (74.7520)  time: 0.2585  data: 0.0244  max mem: 5608\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 4.6152 (4.4494)  acc1: 3.1250 (13.2728)  acc5: 55.2083 (68.8172)  time: 0.2440  data: 0.0116  max mem: 5608\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1854 (3.9753)  acc1: 16.6667 (23.0318)  acc5: 82.2917 (71.8471)  time: 0.2356  data: 0.0037  max mem: 5608\n",
            "Test: Total time: 0:00:15 (0.3727 s / it)\n",
            "* Acc@1 23.032 Acc@5 71.847 loss 3.975\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/result_tiny2)... Done. 13.1s\n",
            "Training time 1:32:27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▂▃▃▄▃▃▄▄▅▅▅▅▆▅▅▆▇▇▆▇▇▇▇▇▇▇▇████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema ▁▁▁▁▂▂▂▂▂▁▂▂▃▂▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇██▇███▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▂▁▂▄▅▃▄▅▅▅▆▅▆▆▅▅▇▇▇▇▇▇▆▇▇▇▇▇███▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema ▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss █▇▆▆▅▆▅▅▅▄▄▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema ██▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss ███▇▇▇▇▆▆▆▆▆▆▆▅▆▄▄▄▄▃▃▃▂▃▃▁▃▂▃▁▃▂▃▂▂▁▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss █▄▄▇▇▅▇▇▇▆▂▃▅▅▆▅▆▃▃▃▅▄▇▆▅▄▁▆▅▄▇▂▆▇▃▆▂▅▃▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 83.18472\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema 23.03185\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 98.16561\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema 71.84714\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.70124\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema 3.97526\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 2.37785\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 3599\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 2.37718\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 28589128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhopeful-monkey-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/b0irt2b1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230305_041426-b0irt2b1/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python main.py --model convnext_tiny --eval true \\\n",
        "                --resume /content/drive/MyDrive/results/tiny2-checkpoint-best.pth \\\n",
        "                --input_size 160 --drop_path 0.1 \\\n",
        "                --data_path /content/imagenette2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Qv8EuJai4Y",
        "outputId": "239facfe-6af2-4987-b67e-827abc09ceeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/drive/MyDrive/results/tiny2-checkpoint-best.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7fb5fb373c70>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7fb5fb373820>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fb5fb465d60>\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 147\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 2940\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/drive/MyDrive/results/tiny2-checkpoint-best.pth\n",
            "With optim & sched!\n",
            "Eval only mode\n",
            "Test:  [ 0/41]  eta: 0:04:14  loss: 0.4683 (0.4683)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 6.2047  data: 3.2807  max mem: 2077\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.4921 (0.5156)  acc1: 90.6250 (90.7197)  acc5: 97.9167 (98.4849)  time: 0.7610  data: 0.3037  max mem: 2077\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5698 (0.6673)  acc1: 88.5417 (84.5734)  acc5: 97.9167 (98.3631)  time: 0.2235  data: 0.0067  max mem: 2077\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7087 (0.6994)  acc1: 80.2083 (83.1317)  acc5: 97.9167 (98.1855)  time: 0.2287  data: 0.0038  max mem: 2077\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6965 (0.6990)  acc1: 84.3750 (83.3121)  acc5: 97.9167 (98.0382)  time: 0.2239  data: 0.0002  max mem: 2077\n",
            "Test: Total time: 0:00:15 (0.3781 s / it)\n",
            "* Acc@1 83.312 Acc@5 98.038 loss 0.699\n",
            "Accuracy of the network on 3925 test images: 83.31210%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConvNeXt-T -- Batch 32, Augmentation Modified\n",
        "- Batch size: 32\n",
        "- Epochs: 100\n",
        "- Update Freq: 4\n",
        "- Input Size: 160 (Imagenette2-160)\n",
        "- Learning rate: 0.004\n",
        "- Drop: 0.2\n",
        "\n",
        "Augmentation Edit:\n",
        "- color_jitter: 0.5 (default: 0.4)\n",
        "- smoothing: 0.2 (default: 0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "n7zxkRNVZPl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I tried to get back with 32 Batch Size but modified the augmentation variable a bit. The result is the highest amongst all."
      ],
      "metadata": {
        "id": "x67uzt5AZHH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/result_tiny3\n",
        "%cd /content/ConvNeXt\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_tiny \\\n",
        "                                    --epochs 100 \\\n",
        "                                    --batch_size 32 \\\n",
        "                                    --lr 4e-3 \\\n",
        "                                    --update_freq 4 \\\n",
        "                                    --model_ema true \\\n",
        "                                    --model_ema_eval true \\\n",
        "                                    --aa original \\\n",
        "                                    --drop_path 0.1 \\\n",
        "                                    --color_jitter 0.5 \\\n",
        "                                    --smoothing 0.2 \\\n",
        "                                    --opt adamw \\\n",
        "                                    --train_interpolation bicubic \\\n",
        "                                    --input_size 160 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --nb_classes 10 \\\n",
        "                                    --output_dir /content/result_tiny3 \\\n",
        "                                    --log_dir /content/result_tiny3 \\\n",
        "                                    --enable_wandb true --wandb_ckpt true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-a0NTE7bQDH",
        "outputId": "17e1fa1b-9248-4660-f765-24a0136a3fa7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: [38]  [110/295]  eta: 0:00:52  lr: 0.003502  min_lr: 0.003502  loss: 3.2387 (3.2897)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0010  max mem: 3500\n",
            "Epoch: [38]  [120/295]  eta: 0:00:49  lr: 0.003500  min_lr: 0.003500  loss: 3.3178 (3.2900)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0022  max mem: 3500\n",
            "Epoch: [38]  [130/295]  eta: 0:00:46  lr: 0.003498  min_lr: 0.003498  loss: 3.3256 (3.2933)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0023  max mem: 3500\n",
            "Epoch: [38]  [140/295]  eta: 0:00:43  lr: 0.003496  min_lr: 0.003496  loss: 3.3386 (3.2940)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0015  max mem: 3500\n",
            "Epoch: [38]  [150/295]  eta: 0:00:40  lr: 0.003495  min_lr: 0.003495  loss: 3.2107 (3.2884)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0018  max mem: 3500\n",
            "Epoch: [38]  [160/295]  eta: 0:00:37  lr: 0.003493  min_lr: 0.003493  loss: 3.2248 (3.2892)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0020  max mem: 3500\n",
            "Epoch: [38]  [170/295]  eta: 0:00:34  lr: 0.003491  min_lr: 0.003491  loss: 3.3396 (3.2912)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0016  max mem: 3500\n",
            "Epoch: [38]  [180/295]  eta: 0:00:32  lr: 0.003489  min_lr: 0.003489  loss: 3.3530 (3.2906)  weight_decay: 0.0500 (0.0500)  time: 0.2819  data: 0.0036  max mem: 3500\n",
            "Epoch: [38]  [190/295]  eta: 0:00:29  lr: 0.003488  min_lr: 0.003488  loss: 3.2399 (3.2931)  weight_decay: 0.0500 (0.0500)  time: 0.2861  data: 0.0044  max mem: 3500\n",
            "Epoch: [38]  [200/295]  eta: 0:00:26  lr: 0.003485  min_lr: 0.003485  loss: 3.4286 (3.2991)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0017  max mem: 3500\n",
            "Epoch: [38]  [210/295]  eta: 0:00:23  lr: 0.003484  min_lr: 0.003484  loss: 3.3811 (3.2976)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0006  max mem: 3500\n",
            "Epoch: [38]  [220/295]  eta: 0:00:20  lr: 0.003482  min_lr: 0.003482  loss: 3.3101 (3.2999)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0019  max mem: 3500\n",
            "Epoch: [38]  [230/295]  eta: 0:00:18  lr: 0.003480  min_lr: 0.003480  loss: 3.3101 (3.3012)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0031  max mem: 3500\n",
            "Epoch: [38]  [240/295]  eta: 0:00:15  lr: 0.003478  min_lr: 0.003478  loss: 3.3157 (3.3000)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0032  max mem: 3500\n",
            "Epoch: [38]  [250/295]  eta: 0:00:12  lr: 0.003477  min_lr: 0.003477  loss: 3.3157 (3.3001)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0027  max mem: 3500\n",
            "Epoch: [38]  [260/295]  eta: 0:00:09  lr: 0.003475  min_lr: 0.003475  loss: 3.2568 (3.2968)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0032  max mem: 3500\n",
            "Epoch: [38]  [270/295]  eta: 0:00:06  lr: 0.003473  min_lr: 0.003473  loss: 3.2267 (3.2930)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0037  max mem: 3500\n",
            "Epoch: [38]  [280/295]  eta: 0:00:04  lr: 0.003471  min_lr: 0.003471  loss: 3.2895 (3.2953)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0023  max mem: 3500\n",
            "Epoch: [38]  [290/295]  eta: 0:00:01  lr: 0.003470  min_lr: 0.003470  loss: 3.3188 (3.2976)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0008  max mem: 3500\n",
            "Epoch: [38]  [294/295]  eta: 0:00:00  lr: 0.003470  min_lr: 0.003470  loss: 3.3010 (3.2967)  weight_decay: 0.0500 (0.0500)  time: 0.2202  data: 0.0002  max mem: 3500\n",
            "Epoch: [38] Total time: 0:01:20 (0.2737 s / it)\n",
            "Averaged stats: lr: 0.003470  min_lr: 0.003470  loss: 3.3010 (3.2967)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:24  loss: 0.9774 (0.9774)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 2.4920  data: 2.3223  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 1.1607 (1.1249)  acc1: 75.0000 (73.2955)  acc5: 95.8333 (96.4015)  time: 0.3942  data: 0.2466  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 1.1572 (1.1349)  acc1: 75.0000 (74.4048)  acc5: 97.9167 (97.0238)  time: 0.1821  data: 0.0267  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 1.2426 (1.2810)  acc1: 66.6667 (68.0780)  acc5: 97.9167 (96.5726)  time: 0.1668  data: 0.0160  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.2265 (1.2311)  acc1: 70.8333 (69.6138)  acc5: 95.8333 (96.6463)  time: 0.1698  data: 0.0203  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.0710 (1.2172)  acc1: 72.9167 (70.0980)  acc5: 97.9167 (96.5686)  time: 0.1562  data: 0.0128  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.2257 (1.2302)  acc1: 70.8333 (70.1161)  acc5: 97.9167 (96.4481)  time: 0.1293  data: 0.0023  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.2399 (1.2348)  acc1: 68.7500 (69.8357)  acc5: 97.9167 (96.1561)  time: 0.1307  data: 0.0011  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0155 (1.2107)  acc1: 77.0833 (70.8591)  acc5: 95.8333 (96.2963)  time: 0.1238  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0155 (1.2121)  acc1: 77.0833 (70.8280)  acc5: 95.8333 (96.2293)  time: 0.1227  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1847 s / it)\n",
            "* Acc@1 70.828 Acc@5 96.229 loss 1.212\n",
            "Accuracy of the model on the 3925 test images: 70.8%\n",
            "Max accuracy: 71.01%\n",
            "Test:  [ 0/82]  eta: 0:02:56  loss: 3.9974 (3.9974)  acc1: 14.5833 (14.5833)  acc5: 77.0833 (77.0833)  time: 2.1496  data: 1.9808  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 3.8811 (3.9144)  acc1: 14.5833 (12.8788)  acc5: 81.2500 (79.9242)  time: 0.3124  data: 0.1843  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 3.8437 (3.9781)  acc1: 16.6667 (16.8651)  acc5: 81.2500 (79.3651)  time: 0.1325  data: 0.0030  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.4773 (4.4211)  acc1: 14.5833 (13.3065)  acc5: 70.8333 (70.3629)  time: 0.1803  data: 0.0190  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.6161 (4.6704)  acc1: 2.0833 (11.8394)  acc5: 52.0833 (66.2602)  time: 0.2272  data: 0.0438  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 4.9072 (4.6426)  acc1: 10.4167 (14.3382)  acc5: 58.3333 (66.4624)  time: 0.2211  data: 0.0438  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5643 (4.7548)  acc1: 8.3333 (12.6708)  acc5: 64.5833 (64.6858)  time: 0.2153  data: 0.0393  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6946 (4.7355)  acc1: 6.2500 (13.4683)  acc5: 75.0000 (64.1139)  time: 0.1706  data: 0.0223  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 3.0077 (4.4025)  acc1: 35.4167 (20.3704)  acc5: 87.5000 (67.2840)  time: 0.1207  data: 0.0013  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.9569 (4.3733)  acc1: 39.5833 (20.8917)  acc5: 89.1892 (67.4904)  time: 0.1184  data: 0.0010  max mem: 3500\n",
            "Test: Total time: 0:00:16 (0.2031 s / it)\n",
            "* Acc@1 20.892 Acc@5 67.490 loss 4.373\n",
            "Accuracy of the model EMA on 3925 test images: 20.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [39]  [  0/295]  eta: 0:07:41  lr: 0.003469  min_lr: 0.003469  loss: 3.1675 (3.1675)  weight_decay: 0.0500 (0.0500)  time: 1.5643  data: 1.1663  max mem: 3500\n",
            "Epoch: [39]  [ 10/295]  eta: 0:02:04  lr: 0.003467  min_lr: 0.003467  loss: 3.2898 (3.2997)  weight_decay: 0.0500 (0.0500)  time: 0.4386  data: 0.1092  max mem: 3500\n",
            "Epoch: [39]  [ 20/295]  eta: 0:01:38  lr: 0.003465  min_lr: 0.003465  loss: 3.3028 (3.3069)  weight_decay: 0.0500 (0.0500)  time: 0.2981  data: 0.0031  max mem: 3500\n",
            "Epoch: [39]  [ 30/295]  eta: 0:01:29  lr: 0.003464  min_lr: 0.003464  loss: 3.3669 (3.3048)  weight_decay: 0.0500 (0.0500)  time: 0.2835  data: 0.0042  max mem: 3500\n",
            "Epoch: [39]  [ 40/295]  eta: 0:01:23  lr: 0.003461  min_lr: 0.003461  loss: 3.3120 (3.3219)  weight_decay: 0.0500 (0.0500)  time: 0.2962  data: 0.0046  max mem: 3500\n",
            "Epoch: [39]  [ 50/295]  eta: 0:01:17  lr: 0.003460  min_lr: 0.003460  loss: 3.3785 (3.3266)  weight_decay: 0.0500 (0.0500)  time: 0.2799  data: 0.0027  max mem: 3500\n",
            "Epoch: [39]  [ 60/295]  eta: 0:01:12  lr: 0.003458  min_lr: 0.003458  loss: 3.3557 (3.3259)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0019  max mem: 3500\n",
            "Epoch: [39]  [ 70/295]  eta: 0:01:07  lr: 0.003456  min_lr: 0.003456  loss: 3.3243 (3.3323)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0027  max mem: 3500\n",
            "Epoch: [39]  [ 80/295]  eta: 0:01:03  lr: 0.003454  min_lr: 0.003454  loss: 3.3740 (3.3329)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0024  max mem: 3500\n",
            "Epoch: [39]  [ 90/295]  eta: 0:01:00  lr: 0.003453  min_lr: 0.003453  loss: 3.3382 (3.3320)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0019  max mem: 3500\n",
            "Epoch: [39]  [100/295]  eta: 0:00:56  lr: 0.003450  min_lr: 0.003450  loss: 3.2429 (3.3194)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0027  max mem: 3500\n",
            "Epoch: [39]  [110/295]  eta: 0:00:53  lr: 0.003449  min_lr: 0.003449  loss: 3.2432 (3.3173)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0045  max mem: 3500\n",
            "Epoch: [39]  [120/295]  eta: 0:00:50  lr: 0.003447  min_lr: 0.003447  loss: 3.3444 (3.3129)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0054  max mem: 3500\n",
            "Epoch: [39]  [130/295]  eta: 0:00:47  lr: 0.003445  min_lr: 0.003445  loss: 3.3104 (3.3086)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0028  max mem: 3500\n",
            "Epoch: [39]  [140/295]  eta: 0:00:43  lr: 0.003443  min_lr: 0.003443  loss: 3.3050 (3.3072)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0015  max mem: 3500\n",
            "Epoch: [39]  [150/295]  eta: 0:00:40  lr: 0.003441  min_lr: 0.003441  loss: 3.3454 (3.3108)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0012  max mem: 3500\n",
            "Epoch: [39]  [160/295]  eta: 0:00:37  lr: 0.003439  min_lr: 0.003439  loss: 3.3454 (3.3082)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0012  max mem: 3500\n",
            "Epoch: [39]  [170/295]  eta: 0:00:35  lr: 0.003438  min_lr: 0.003438  loss: 3.3141 (3.3133)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0030  max mem: 3500\n",
            "Epoch: [39]  [180/295]  eta: 0:00:32  lr: 0.003435  min_lr: 0.003435  loss: 3.3784 (3.3154)  weight_decay: 0.0500 (0.0500)  time: 0.2766  data: 0.0038  max mem: 3500\n",
            "Epoch: [39]  [190/295]  eta: 0:00:29  lr: 0.003434  min_lr: 0.003434  loss: 3.3784 (3.3203)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0029  max mem: 3500\n",
            "Epoch: [39]  [200/295]  eta: 0:00:26  lr: 0.003432  min_lr: 0.003432  loss: 3.3558 (3.3179)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0030  max mem: 3500\n",
            "Epoch: [39]  [210/295]  eta: 0:00:23  lr: 0.003430  min_lr: 0.003430  loss: 3.2694 (3.3132)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0029  max mem: 3500\n",
            "Epoch: [39]  [220/295]  eta: 0:00:20  lr: 0.003428  min_lr: 0.003428  loss: 3.2641 (3.3101)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0021  max mem: 3500\n",
            "Epoch: [39]  [230/295]  eta: 0:00:18  lr: 0.003426  min_lr: 0.003426  loss: 3.2740 (3.3091)  weight_decay: 0.0500 (0.0500)  time: 0.2782  data: 0.0027  max mem: 3500\n",
            "Epoch: [39]  [240/295]  eta: 0:00:15  lr: 0.003424  min_lr: 0.003424  loss: 3.2740 (3.3067)  weight_decay: 0.0500 (0.0500)  time: 0.2792  data: 0.0039  max mem: 3500\n",
            "Epoch: [39]  [250/295]  eta: 0:00:12  lr: 0.003423  min_lr: 0.003423  loss: 3.2358 (3.3065)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0031  max mem: 3500\n",
            "Epoch: [39]  [260/295]  eta: 0:00:09  lr: 0.003420  min_lr: 0.003420  loss: 3.1403 (3.3015)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0011  max mem: 3500\n",
            "Epoch: [39]  [270/295]  eta: 0:00:06  lr: 0.003419  min_lr: 0.003419  loss: 3.1758 (3.2997)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0009  max mem: 3500\n",
            "Epoch: [39]  [280/295]  eta: 0:00:04  lr: 0.003417  min_lr: 0.003417  loss: 3.2276 (3.2965)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0012  max mem: 3500\n",
            "Epoch: [39]  [290/295]  eta: 0:00:01  lr: 0.003415  min_lr: 0.003415  loss: 3.2276 (3.2952)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0009  max mem: 3500\n",
            "Epoch: [39]  [294/295]  eta: 0:00:00  lr: 0.003415  min_lr: 0.003415  loss: 3.2276 (3.2957)  weight_decay: 0.0500 (0.0500)  time: 0.2211  data: 0.0002  max mem: 3500\n",
            "Epoch: [39] Total time: 0:01:20 (0.2744 s / it)\n",
            "Averaged stats: lr: 0.003415  min_lr: 0.003415  loss: 3.2276 (3.2957)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:22  loss: 1.0483 (1.0483)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 2.4728  data: 2.3107  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 1.0676 (1.1065)  acc1: 75.0000 (75.1894)  acc5: 93.7500 (95.0758)  time: 0.3929  data: 0.2473  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.9801 (1.0043)  acc1: 81.2500 (79.2659)  acc5: 95.8333 (96.4286)  time: 0.1620  data: 0.0249  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.9211 (1.2777)  acc1: 79.1667 (65.7930)  acc5: 97.9167 (95.2957)  time: 0.1336  data: 0.0060  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.1466 (1.2395)  acc1: 68.7500 (67.3272)  acc5: 95.8333 (95.8333)  time: 0.1266  data: 0.0030  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.0590 (1.2002)  acc1: 75.0000 (68.8317)  acc5: 97.9167 (96.2010)  time: 0.1258  data: 0.0042  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.0194 (1.1631)  acc1: 77.0833 (70.2869)  acc5: 97.9167 (96.5505)  time: 0.1251  data: 0.0060  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.2678 (1.1926)  acc1: 68.7500 (69.6009)  acc5: 95.8333 (96.2148)  time: 0.1207  data: 0.0036  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2678 (1.1610)  acc1: 68.7500 (70.7562)  acc5: 95.8333 (96.2449)  time: 0.1178  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2263 (1.1604)  acc1: 68.7500 (70.8280)  acc5: 95.8333 (96.1529)  time: 0.1165  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1658 s / it)\n",
            "* Acc@1 70.828 Acc@5 96.153 loss 1.160\n",
            "Accuracy of the model on the 3925 test images: 70.8%\n",
            "Max accuracy: 71.01%\n",
            "Test:  [ 0/82]  eta: 0:03:03  loss: 3.9484 (3.9484)  acc1: 14.5833 (14.5833)  acc5: 77.0833 (77.0833)  time: 2.2394  data: 2.0720  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 3.8576 (3.8746)  acc1: 12.5000 (12.1212)  acc5: 81.2500 (80.8712)  time: 0.4202  data: 0.2696  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.7957 (3.9357)  acc1: 16.6667 (16.3690)  acc5: 81.2500 (80.3571)  time: 0.2062  data: 0.0589  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 4.4375 (4.3855)  acc1: 14.5833 (12.9032)  acc5: 70.8333 (71.2366)  time: 0.1780  data: 0.0322  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.5732 (4.6357)  acc1: 2.0833 (11.4837)  acc5: 52.0833 (67.1240)  time: 0.1615  data: 0.0185  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 4.8724 (4.6205)  acc1: 8.3333 (13.8480)  acc5: 58.3333 (67.0343)  time: 0.1692  data: 0.0242  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5920 (4.7369)  acc1: 8.3333 (12.2268)  acc5: 62.5000 (65.1639)  time: 0.1938  data: 0.0461  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6998 (4.7096)  acc1: 4.1667 (13.2629)  acc5: 75.0000 (64.7300)  time: 0.1880  data: 0.0442  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.8947 (4.3725)  acc1: 39.5833 (20.2932)  acc5: 89.5833 (68.0041)  time: 0.1531  data: 0.0235  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.8369 (4.3432)  acc1: 41.6667 (20.8408)  acc5: 89.5833 (68.2038)  time: 0.1500  data: 0.0234  max mem: 3500\n",
            "Test: Total time: 0:00:17 (0.2097 s / it)\n",
            "* Acc@1 20.841 Acc@5 68.204 loss 4.343\n",
            "Accuracy of the model EMA on 3925 test images: 20.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [40]  [  0/295]  eta: 0:09:52  lr: 0.003414  min_lr: 0.003414  loss: 3.0569 (3.0569)  weight_decay: 0.0500 (0.0500)  time: 2.0070  data: 1.6720  max mem: 3500\n",
            "Epoch: [40]  [ 10/295]  eta: 0:02:08  lr: 0.003413  min_lr: 0.003413  loss: 3.0569 (3.1916)  weight_decay: 0.0500 (0.0500)  time: 0.4507  data: 0.1539  max mem: 3500\n",
            "Epoch: [40]  [ 20/295]  eta: 0:01:41  lr: 0.003411  min_lr: 0.003411  loss: 3.1372 (3.1793)  weight_decay: 0.0500 (0.0500)  time: 0.2857  data: 0.0046  max mem: 3500\n",
            "Epoch: [40]  [ 30/295]  eta: 0:01:29  lr: 0.003409  min_lr: 0.003409  loss: 3.2057 (3.2217)  weight_decay: 0.0500 (0.0500)  time: 0.2751  data: 0.0050  max mem: 3500\n",
            "Epoch: [40]  [ 40/295]  eta: 0:01:21  lr: 0.003407  min_lr: 0.003407  loss: 3.2649 (3.2219)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0019  max mem: 3500\n",
            "Epoch: [40]  [ 50/295]  eta: 0:01:15  lr: 0.003405  min_lr: 0.003405  loss: 3.2937 (3.2512)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0014  max mem: 3500\n",
            "Epoch: [40]  [ 60/295]  eta: 0:01:10  lr: 0.003403  min_lr: 0.003403  loss: 3.3404 (3.2556)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0018  max mem: 3500\n",
            "Epoch: [40]  [ 70/295]  eta: 0:01:06  lr: 0.003401  min_lr: 0.003401  loss: 3.2752 (3.2623)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0018  max mem: 3500\n",
            "Epoch: [40]  [ 80/295]  eta: 0:01:03  lr: 0.003399  min_lr: 0.003399  loss: 3.3316 (3.2755)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0021  max mem: 3500\n",
            "Epoch: [40]  [ 90/295]  eta: 0:00:59  lr: 0.003398  min_lr: 0.003398  loss: 3.3545 (3.2754)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0034  max mem: 3500\n",
            "Epoch: [40]  [100/295]  eta: 0:00:56  lr: 0.003395  min_lr: 0.003395  loss: 3.3222 (3.2738)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0028  max mem: 3500\n",
            "Epoch: [40]  [110/295]  eta: 0:00:53  lr: 0.003394  min_lr: 0.003394  loss: 3.2618 (3.2730)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0011  max mem: 3500\n",
            "Epoch: [40]  [120/295]  eta: 0:00:49  lr: 0.003391  min_lr: 0.003391  loss: 3.1887 (3.2698)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0012  max mem: 3500\n",
            "Epoch: [40]  [130/295]  eta: 0:00:46  lr: 0.003390  min_lr: 0.003390  loss: 3.2437 (3.2751)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0013  max mem: 3500\n",
            "Epoch: [40]  [140/295]  eta: 0:00:43  lr: 0.003387  min_lr: 0.003387  loss: 3.2393 (3.2702)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0027  max mem: 3500\n",
            "Epoch: [40]  [150/295]  eta: 0:00:40  lr: 0.003386  min_lr: 0.003386  loss: 3.1205 (3.2560)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0046  max mem: 3500\n",
            "Epoch: [40]  [160/295]  eta: 0:00:37  lr: 0.003384  min_lr: 0.003384  loss: 3.2534 (3.2579)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0051  max mem: 3500\n",
            "Epoch: [40]  [170/295]  eta: 0:00:34  lr: 0.003382  min_lr: 0.003382  loss: 3.2929 (3.2572)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0034  max mem: 3500\n",
            "Epoch: [40]  [180/295]  eta: 0:00:31  lr: 0.003380  min_lr: 0.003380  loss: 3.3633 (3.2632)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0020  max mem: 3500\n",
            "Epoch: [40]  [190/295]  eta: 0:00:29  lr: 0.003378  min_lr: 0.003378  loss: 3.3648 (3.2634)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0020  max mem: 3500\n",
            "Epoch: [40]  [200/295]  eta: 0:00:26  lr: 0.003376  min_lr: 0.003376  loss: 3.2577 (3.2637)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0015  max mem: 3500\n",
            "Epoch: [40]  [210/295]  eta: 0:00:23  lr: 0.003374  min_lr: 0.003374  loss: 3.2577 (3.2664)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0024  max mem: 3500\n",
            "Epoch: [40]  [220/295]  eta: 0:00:20  lr: 0.003372  min_lr: 0.003372  loss: 3.2692 (3.2682)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0029  max mem: 3500\n",
            "Epoch: [40]  [230/295]  eta: 0:00:17  lr: 0.003370  min_lr: 0.003370  loss: 3.3105 (3.2686)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0035  max mem: 3500\n",
            "Epoch: [40]  [240/295]  eta: 0:00:15  lr: 0.003368  min_lr: 0.003368  loss: 3.4461 (3.2720)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0031  max mem: 3500\n",
            "Epoch: [40]  [250/295]  eta: 0:00:12  lr: 0.003366  min_lr: 0.003366  loss: 3.3312 (3.2693)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0019  max mem: 3500\n",
            "Epoch: [40]  [260/295]  eta: 0:00:09  lr: 0.003364  min_lr: 0.003364  loss: 3.3312 (3.2692)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0017  max mem: 3500\n",
            "Epoch: [40]  [270/295]  eta: 0:00:06  lr: 0.003362  min_lr: 0.003362  loss: 3.3194 (3.2694)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0030  max mem: 3500\n",
            "Epoch: [40]  [280/295]  eta: 0:00:04  lr: 0.003360  min_lr: 0.003360  loss: 3.3366 (3.2718)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0037  max mem: 3500\n",
            "Epoch: [40]  [290/295]  eta: 0:00:01  lr: 0.003359  min_lr: 0.003359  loss: 3.3366 (3.2717)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0014  max mem: 3500\n",
            "Epoch: [40]  [294/295]  eta: 0:00:00  lr: 0.003359  min_lr: 0.003359  loss: 3.3274 (3.2715)  weight_decay: 0.0500 (0.0500)  time: 0.2236  data: 0.0002  max mem: 3500\n",
            "Epoch: [40] Total time: 0:01:20 (0.2714 s / it)\n",
            "Averaged stats: lr: 0.003359  min_lr: 0.003359  loss: 3.3274 (3.2715)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:11  loss: 0.9198 (0.9198)  acc1: 81.2500 (81.2500)  acc5: 95.8333 (95.8333)  time: 2.3308  data: 2.1623  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 1.0022 (1.0089)  acc1: 79.1667 (78.4091)  acc5: 95.8333 (94.8864)  time: 0.3260  data: 0.2015  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.9046 (0.9522)  acc1: 81.2500 (81.3492)  acc5: 95.8333 (96.3294)  time: 0.1258  data: 0.0069  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.9740 (1.2217)  acc1: 79.1667 (67.8763)  acc5: 95.8333 (95.1613)  time: 0.1247  data: 0.0074  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.0075 (1.1665)  acc1: 77.0833 (70.5793)  acc5: 95.8333 (95.9350)  time: 0.1228  data: 0.0056  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.9960 (1.1725)  acc1: 79.1667 (70.6291)  acc5: 100.0000 (96.4052)  time: 0.1231  data: 0.0047  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.2516 (1.1910)  acc1: 68.7500 (70.4577)  acc5: 97.9167 (96.0383)  time: 0.1336  data: 0.0042  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.2583 (1.2109)  acc1: 64.5833 (69.5129)  acc5: 93.7500 (95.8040)  time: 0.1422  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1623 (1.1712)  acc1: 68.7500 (70.9619)  acc5: 97.9167 (96.0134)  time: 0.1299  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1296 (1.1703)  acc1: 70.8333 (70.9809)  acc5: 97.9167 (95.9745)  time: 0.1248  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1613 s / it)\n",
            "* Acc@1 70.981 Acc@5 95.975 loss 1.170\n",
            "Accuracy of the model on the 3925 test images: 71.0%\n",
            "Max accuracy: 71.01%\n",
            "Test:  [ 0/82]  eta: 0:03:38  loss: 3.9016 (3.9016)  acc1: 12.5000 (12.5000)  acc5: 77.0833 (77.0833)  time: 2.6659  data: 2.4995  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 3.8337 (3.8364)  acc1: 12.5000 (11.9318)  acc5: 81.2500 (81.4394)  time: 0.3700  data: 0.2463  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 3.7516 (3.8968)  acc1: 16.6667 (15.8730)  acc5: 81.2500 (81.0516)  time: 0.1319  data: 0.0125  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.4014 (4.3521)  acc1: 14.5833 (12.6344)  acc5: 70.8333 (71.7742)  time: 0.1249  data: 0.0039  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.5215 (4.6011)  acc1: 2.0833 (11.2297)  acc5: 50.0000 (67.4797)  time: 0.1248  data: 0.0045  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8290 (4.5987)  acc1: 8.3333 (13.6029)  acc5: 60.4167 (67.3203)  time: 0.1237  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6273 (4.7183)  acc1: 6.2500 (11.9194)  acc5: 62.5000 (65.3347)  time: 0.1236  data: 0.0034  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.6932 (4.6837)  acc1: 4.1667 (13.1162)  acc5: 75.0000 (64.8768)  time: 0.1205  data: 0.0013  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.7897 (4.3428)  acc1: 43.7500 (20.1903)  acc5: 89.5833 (68.1584)  time: 0.1181  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.7241 (4.3133)  acc1: 45.8333 (20.7389)  acc5: 89.5833 (68.3567)  time: 0.1166  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1633 s / it)\n",
            "* Acc@1 20.739 Acc@5 68.357 loss 4.313\n",
            "Accuracy of the model EMA on 3925 test images: 20.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [41]  [  0/295]  eta: 0:15:54  lr: 0.003358  min_lr: 0.003358  loss: 3.0342 (3.0342)  weight_decay: 0.0500 (0.0500)  time: 3.2370  data: 2.5900  max mem: 3500\n",
            "Epoch: [41]  [ 10/295]  eta: 0:02:40  lr: 0.003356  min_lr: 0.003356  loss: 3.1326 (3.2423)  weight_decay: 0.0500 (0.0500)  time: 0.5647  data: 0.2402  max mem: 3500\n",
            "Epoch: [41]  [ 20/295]  eta: 0:01:55  lr: 0.003354  min_lr: 0.003354  loss: 3.3460 (3.3035)  weight_decay: 0.0500 (0.0500)  time: 0.2796  data: 0.0035  max mem: 3500\n",
            "Epoch: [41]  [ 30/295]  eta: 0:01:38  lr: 0.003352  min_lr: 0.003352  loss: 3.3110 (3.3036)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0027  max mem: 3500\n",
            "Epoch: [41]  [ 40/295]  eta: 0:01:27  lr: 0.003350  min_lr: 0.003350  loss: 3.3246 (3.3302)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0031  max mem: 3500\n",
            "Epoch: [41]  [ 50/295]  eta: 0:01:20  lr: 0.003348  min_lr: 0.003348  loss: 3.3225 (3.3071)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0018  max mem: 3500\n",
            "Epoch: [41]  [ 60/295]  eta: 0:01:15  lr: 0.003346  min_lr: 0.003346  loss: 3.2885 (3.3128)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0014  max mem: 3500\n",
            "Epoch: [41]  [ 70/295]  eta: 0:01:10  lr: 0.003344  min_lr: 0.003344  loss: 3.3334 (3.3065)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0028  max mem: 3500\n",
            "Epoch: [41]  [ 80/295]  eta: 0:01:06  lr: 0.003342  min_lr: 0.003342  loss: 3.2889 (3.3049)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0026  max mem: 3500\n",
            "Epoch: [41]  [ 90/295]  eta: 0:01:02  lr: 0.003340  min_lr: 0.003340  loss: 3.3258 (3.3087)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0014  max mem: 3500\n",
            "Epoch: [41]  [100/295]  eta: 0:00:58  lr: 0.003338  min_lr: 0.003338  loss: 3.3786 (3.3097)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0016  max mem: 3500\n",
            "Epoch: [41]  [110/295]  eta: 0:00:54  lr: 0.003336  min_lr: 0.003336  loss: 3.3609 (3.3097)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0021  max mem: 3500\n",
            "Epoch: [41]  [120/295]  eta: 0:00:51  lr: 0.003334  min_lr: 0.003334  loss: 3.2743 (3.3112)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0046  max mem: 3500\n",
            "Epoch: [41]  [130/295]  eta: 0:00:48  lr: 0.003332  min_lr: 0.003332  loss: 3.2561 (3.3110)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0054  max mem: 3500\n",
            "Epoch: [41]  [140/295]  eta: 0:00:44  lr: 0.003330  min_lr: 0.003330  loss: 3.3649 (3.3174)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0025  max mem: 3500\n",
            "Epoch: [41]  [150/295]  eta: 0:00:41  lr: 0.003328  min_lr: 0.003328  loss: 3.3515 (3.3165)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0013  max mem: 3500\n",
            "Epoch: [41]  [160/295]  eta: 0:00:38  lr: 0.003326  min_lr: 0.003326  loss: 3.2528 (3.3058)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0013  max mem: 3500\n",
            "Epoch: [41]  [170/295]  eta: 0:00:35  lr: 0.003324  min_lr: 0.003324  loss: 3.2739 (3.3095)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0031  max mem: 3500\n",
            "Epoch: [41]  [180/295]  eta: 0:00:32  lr: 0.003322  min_lr: 0.003322  loss: 3.2723 (3.3005)  weight_decay: 0.0500 (0.0500)  time: 0.2749  data: 0.0070  max mem: 3500\n",
            "Epoch: [41]  [190/295]  eta: 0:00:29  lr: 0.003320  min_lr: 0.003320  loss: 3.2064 (3.2995)  weight_decay: 0.0500 (0.0500)  time: 0.2793  data: 0.0075  max mem: 3500\n",
            "Epoch: [41]  [200/295]  eta: 0:00:27  lr: 0.003318  min_lr: 0.003318  loss: 3.2224 (3.2971)  weight_decay: 0.0500 (0.0500)  time: 0.2803  data: 0.0060  max mem: 3500\n",
            "Epoch: [41]  [210/295]  eta: 0:00:24  lr: 0.003316  min_lr: 0.003316  loss: 3.3268 (3.2965)  weight_decay: 0.0500 (0.0500)  time: 0.2790  data: 0.0048  max mem: 3500\n",
            "Epoch: [41]  [220/295]  eta: 0:00:21  lr: 0.003314  min_lr: 0.003314  loss: 3.2024 (3.2867)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0047  max mem: 3500\n",
            "Epoch: [41]  [230/295]  eta: 0:00:18  lr: 0.003312  min_lr: 0.003312  loss: 3.2449 (3.2870)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0045  max mem: 3500\n",
            "Epoch: [41]  [240/295]  eta: 0:00:15  lr: 0.003310  min_lr: 0.003310  loss: 3.2858 (3.2871)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0026  max mem: 3500\n",
            "Epoch: [41]  [250/295]  eta: 0:00:12  lr: 0.003308  min_lr: 0.003308  loss: 3.2407 (3.2836)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0019  max mem: 3500\n",
            "Epoch: [41]  [260/295]  eta: 0:00:09  lr: 0.003306  min_lr: 0.003306  loss: 3.2742 (3.2840)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0031  max mem: 3500\n",
            "Epoch: [41]  [270/295]  eta: 0:00:06  lr: 0.003304  min_lr: 0.003304  loss: 3.3383 (3.2879)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0042  max mem: 3500\n",
            "Epoch: [41]  [280/295]  eta: 0:00:04  lr: 0.003302  min_lr: 0.003302  loss: 3.3628 (3.2906)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0034  max mem: 3500\n",
            "Epoch: [41]  [290/295]  eta: 0:00:01  lr: 0.003300  min_lr: 0.003300  loss: 3.3737 (3.2928)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0013  max mem: 3500\n",
            "Epoch: [41]  [294/295]  eta: 0:00:00  lr: 0.003300  min_lr: 0.003300  loss: 3.3628 (3.2922)  weight_decay: 0.0500 (0.0500)  time: 0.2209  data: 0.0002  max mem: 3500\n",
            "Epoch: [41] Total time: 0:01:21 (0.2773 s / it)\n",
            "Averaged stats: lr: 0.003300  min_lr: 0.003300  loss: 3.3628 (3.2922)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:00  loss: 0.9820 (0.9820)  acc1: 81.2500 (81.2500)  acc5: 91.6667 (91.6667)  time: 2.1971  data: 2.0259  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 1.1727 (1.1418)  acc1: 77.0833 (75.5682)  acc5: 93.7500 (95.2652)  time: 0.3140  data: 0.1885  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 1.2067 (1.2313)  acc1: 75.0000 (73.4127)  acc5: 95.8333 (95.6349)  time: 0.1251  data: 0.0045  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 1.5102 (1.4496)  acc1: 58.3333 (61.5591)  acc5: 93.7500 (94.6909)  time: 0.1365  data: 0.0052  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.4401 (1.3172)  acc1: 64.5833 (67.1240)  acc5: 95.8333 (95.6809)  time: 0.1534  data: 0.0037  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.9718 (1.2975)  acc1: 79.1667 (68.2190)  acc5: 97.9167 (95.5882)  time: 0.1550  data: 0.0012  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.2188 (1.2798)  acc1: 77.0833 (69.3648)  acc5: 95.8333 (95.6626)  time: 0.1592  data: 0.0018  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.3288 (1.2942)  acc1: 64.5833 (68.6326)  acc5: 95.8333 (95.5986)  time: 0.1611  data: 0.0016  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2194 (1.2519)  acc1: 70.8333 (70.3447)  acc5: 97.9167 (95.9877)  time: 0.1373  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2035 (1.2495)  acc1: 70.8333 (70.4204)  acc5: 97.9167 (95.9490)  time: 0.1282  data: 0.0005  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1738 s / it)\n",
            "* Acc@1 70.420 Acc@5 95.949 loss 1.249\n",
            "Accuracy of the model on the 3925 test images: 70.4%\n",
            "Max accuracy: 71.01%\n",
            "Test:  [ 0/82]  eta: 0:02:11  loss: 3.8500 (3.8500)  acc1: 12.5000 (12.5000)  acc5: 77.0833 (77.0833)  time: 1.6005  data: 1.4367  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.8058 (3.7979)  acc1: 10.4167 (11.1742)  acc5: 81.2500 (82.0076)  time: 0.3007  data: 0.1743  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.7036 (3.8599)  acc1: 16.6667 (15.0794)  acc5: 81.2500 (81.8452)  time: 0.1464  data: 0.0249  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.3692 (4.3217)  acc1: 14.5833 (12.1640)  acc5: 72.9167 (72.4462)  time: 0.1236  data: 0.0030  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.4695 (4.5688)  acc1: 2.0833 (10.8232)  acc5: 52.0833 (68.0894)  time: 0.1258  data: 0.0037  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.7869 (4.5798)  acc1: 8.3333 (13.0719)  acc5: 56.2500 (67.5654)  time: 0.1248  data: 0.0031  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6710 (4.7023)  acc1: 4.1667 (11.3046)  acc5: 60.4167 (65.5055)  time: 0.1231  data: 0.0041  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.6882 (4.6600)  acc1: 2.0833 (12.6467)  acc5: 72.9167 (65.0528)  time: 0.1217  data: 0.0031  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.6879 (4.3155)  acc1: 43.7500 (19.8045)  acc5: 89.5833 (68.3385)  time: 0.1191  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.6144 (4.2859)  acc1: 45.8333 (20.3567)  acc5: 89.5833 (68.5350)  time: 0.1172  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1533 s / it)\n",
            "* Acc@1 20.357 Acc@5 68.535 loss 4.286\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [42]  [  0/295]  eta: 0:13:02  lr: 0.003299  min_lr: 0.003299  loss: 3.3365 (3.3365)  weight_decay: 0.0500 (0.0500)  time: 2.6510  data: 2.0170  max mem: 3500\n",
            "Epoch: [42]  [ 10/295]  eta: 0:02:26  lr: 0.003297  min_lr: 0.003297  loss: 3.3365 (3.3039)  weight_decay: 0.0500 (0.0500)  time: 0.5124  data: 0.1865  max mem: 3500\n",
            "Epoch: [42]  [ 20/295]  eta: 0:01:47  lr: 0.003295  min_lr: 0.003295  loss: 3.2490 (3.2886)  weight_decay: 0.0500 (0.0500)  time: 0.2798  data: 0.0023  max mem: 3500\n",
            "Epoch: [42]  [ 30/295]  eta: 0:01:32  lr: 0.003293  min_lr: 0.003293  loss: 3.2600 (3.2826)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0015  max mem: 3500\n",
            "Epoch: [42]  [ 40/295]  eta: 0:01:23  lr: 0.003291  min_lr: 0.003291  loss: 3.1614 (3.2475)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0013  max mem: 3500\n",
            "Epoch: [42]  [ 50/295]  eta: 0:01:17  lr: 0.003289  min_lr: 0.003289  loss: 3.1894 (3.2534)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0019  max mem: 3500\n",
            "Epoch: [42]  [ 60/295]  eta: 0:01:13  lr: 0.003287  min_lr: 0.003287  loss: 3.3113 (3.2667)  weight_decay: 0.0500 (0.0500)  time: 0.2751  data: 0.0038  max mem: 3500\n",
            "Epoch: [42]  [ 70/295]  eta: 0:01:08  lr: 0.003285  min_lr: 0.003285  loss: 3.3391 (3.2720)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0036  max mem: 3500\n",
            "Epoch: [42]  [ 80/295]  eta: 0:01:04  lr: 0.003283  min_lr: 0.003283  loss: 3.2730 (3.2672)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0026  max mem: 3500\n",
            "Epoch: [42]  [ 90/295]  eta: 0:01:00  lr: 0.003281  min_lr: 0.003281  loss: 3.2804 (3.2716)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0014  max mem: 3500\n",
            "Epoch: [42]  [100/295]  eta: 0:00:57  lr: 0.003279  min_lr: 0.003279  loss: 3.3198 (3.2795)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0015  max mem: 3500\n",
            "Epoch: [42]  [110/295]  eta: 0:00:53  lr: 0.003277  min_lr: 0.003277  loss: 3.3305 (3.2790)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0026  max mem: 3500\n",
            "Epoch: [42]  [120/295]  eta: 0:00:50  lr: 0.003274  min_lr: 0.003274  loss: 3.1721 (3.2703)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0053  max mem: 3500\n",
            "Epoch: [42]  [130/295]  eta: 0:00:47  lr: 0.003273  min_lr: 0.003273  loss: 3.2211 (3.2783)  weight_decay: 0.0500 (0.0500)  time: 0.2749  data: 0.0060  max mem: 3500\n",
            "Epoch: [42]  [140/295]  eta: 0:00:44  lr: 0.003270  min_lr: 0.003270  loss: 3.2514 (3.2742)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0032  max mem: 3500\n",
            "Epoch: [42]  [150/295]  eta: 0:00:41  lr: 0.003269  min_lr: 0.003269  loss: 3.2884 (3.2800)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0016  max mem: 3500\n",
            "Epoch: [42]  [160/295]  eta: 0:00:38  lr: 0.003266  min_lr: 0.003266  loss: 3.3218 (3.2809)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0010  max mem: 3500\n",
            "Epoch: [42]  [170/295]  eta: 0:00:35  lr: 0.003264  min_lr: 0.003264  loss: 3.2090 (3.2720)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0018  max mem: 3500\n",
            "Epoch: [42]  [180/295]  eta: 0:00:32  lr: 0.003262  min_lr: 0.003262  loss: 3.1797 (3.2725)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0030  max mem: 3500\n",
            "Epoch: [42]  [190/295]  eta: 0:00:29  lr: 0.003260  min_lr: 0.003260  loss: 3.2502 (3.2686)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0039  max mem: 3500\n",
            "Epoch: [42]  [200/295]  eta: 0:00:26  lr: 0.003258  min_lr: 0.003258  loss: 3.2587 (3.2685)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0032  max mem: 3500\n",
            "Epoch: [42]  [210/295]  eta: 0:00:23  lr: 0.003256  min_lr: 0.003256  loss: 3.2771 (3.2716)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0026  max mem: 3500\n",
            "Epoch: [42]  [220/295]  eta: 0:00:20  lr: 0.003254  min_lr: 0.003254  loss: 3.2751 (3.2696)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0025  max mem: 3500\n",
            "Epoch: [42]  [230/295]  eta: 0:00:18  lr: 0.003252  min_lr: 0.003252  loss: 3.2701 (3.2696)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0023  max mem: 3500\n",
            "Epoch: [42]  [240/295]  eta: 0:00:15  lr: 0.003249  min_lr: 0.003249  loss: 3.3462 (3.2727)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0024  max mem: 3500\n",
            "Epoch: [42]  [250/295]  eta: 0:00:12  lr: 0.003248  min_lr: 0.003248  loss: 3.3465 (3.2757)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0027  max mem: 3500\n",
            "Epoch: [42]  [260/295]  eta: 0:00:09  lr: 0.003245  min_lr: 0.003245  loss: 3.3040 (3.2763)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0028  max mem: 3500\n",
            "Epoch: [42]  [270/295]  eta: 0:00:06  lr: 0.003243  min_lr: 0.003243  loss: 3.2468 (3.2739)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0027  max mem: 3500\n",
            "Epoch: [42]  [280/295]  eta: 0:00:04  lr: 0.003241  min_lr: 0.003241  loss: 3.3205 (3.2778)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0018  max mem: 3500\n",
            "Epoch: [42]  [290/295]  eta: 0:00:01  lr: 0.003239  min_lr: 0.003239  loss: 3.2027 (3.2722)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0006  max mem: 3500\n",
            "Epoch: [42]  [294/295]  eta: 0:00:00  lr: 0.003239  min_lr: 0.003239  loss: 3.2934 (3.2724)  weight_decay: 0.0500 (0.0500)  time: 0.2194  data: 0.0002  max mem: 3500\n",
            "Epoch: [42] Total time: 0:01:20 (0.2733 s / it)\n",
            "Averaged stats: lr: 0.003239  min_lr: 0.003239  loss: 3.2934 (3.2724)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:41  loss: 0.7555 (0.7555)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 1.9704  data: 1.8068  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.8027 (0.8962)  acc1: 85.4167 (81.4394)  acc5: 95.8333 (96.2121)  time: 0.3292  data: 0.1702  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.8412 (0.9001)  acc1: 85.4167 (82.0437)  acc5: 97.9167 (96.5278)  time: 0.1926  data: 0.0289  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 1.0645 (1.1713)  acc1: 75.0000 (69.5565)  acc5: 95.8333 (95.6317)  time: 0.2005  data: 0.0370  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.1178 (1.1497)  acc1: 72.9167 (71.4939)  acc5: 95.8333 (96.0874)  time: 0.1809  data: 0.0250  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.1178 (1.1670)  acc1: 77.0833 (71.4461)  acc5: 97.9167 (96.5686)  time: 0.1730  data: 0.0233  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.2795 (1.2117)  acc1: 66.6667 (69.6380)  acc5: 97.9167 (96.0041)  time: 0.1467  data: 0.0113  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.3765 (1.2176)  acc1: 64.5833 (69.0434)  acc5: 93.7500 (95.8920)  time: 0.1250  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9841 (1.1719)  acc1: 79.1667 (70.9105)  acc5: 97.9167 (96.1677)  time: 0.1199  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9841 (1.1705)  acc1: 79.1667 (70.9554)  acc5: 97.9167 (96.1529)  time: 0.1176  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1854 s / it)\n",
            "* Acc@1 70.955 Acc@5 96.153 loss 1.170\n",
            "Accuracy of the model on the 3925 test images: 71.0%\n",
            "Max accuracy: 71.01%\n",
            "Test:  [ 0/82]  eta: 0:03:46  loss: 3.8003 (3.8003)  acc1: 12.5000 (12.5000)  acc5: 77.0833 (77.0833)  time: 2.7635  data: 2.6051  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 3.7753 (3.7571)  acc1: 10.4167 (10.9848)  acc5: 81.2500 (82.3864)  time: 0.4118  data: 0.2520  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.6547 (3.8203)  acc1: 16.6667 (15.0794)  acc5: 81.2500 (82.4405)  time: 0.1807  data: 0.0217  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 4.3394 (4.2901)  acc1: 16.6667 (12.3656)  acc5: 72.9167 (72.9167)  time: 0.2035  data: 0.0424  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 5.4185 (4.5359)  acc1: 2.0833 (11.0264)  acc5: 52.0833 (68.3435)  time: 0.2161  data: 0.0528  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 4.7886 (4.5590)  acc1: 8.3333 (13.1944)  acc5: 56.2500 (67.6879)  time: 0.1958  data: 0.0390  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:05  loss: 4.6837 (4.6824)  acc1: 4.1667 (11.4071)  acc5: 60.4167 (65.6079)  time: 0.1730  data: 0.0188  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6837 (4.6323)  acc1: 2.0833 (12.8815)  acc5: 75.0000 (65.1702)  time: 0.1622  data: 0.0037  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.5966 (4.2850)  acc1: 45.8333 (20.0874)  acc5: 91.6667 (68.4928)  time: 0.1389  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.5155 (4.2553)  acc1: 45.8333 (20.6369)  acc5: 91.6667 (68.6879)  time: 0.1349  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:17 (0.2143 s / it)\n",
            "* Acc@1 20.637 Acc@5 68.688 loss 4.255\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [43]  [  0/295]  eta: 0:07:53  lr: 0.003238  min_lr: 0.003238  loss: 2.9105 (2.9105)  weight_decay: 0.0500 (0.0500)  time: 1.6058  data: 1.3038  max mem: 3500\n",
            "Epoch: [43]  [ 10/295]  eta: 0:01:55  lr: 0.003237  min_lr: 0.003237  loss: 3.2248 (3.2258)  weight_decay: 0.0500 (0.0500)  time: 0.4069  data: 0.1241  max mem: 3500\n",
            "Epoch: [43]  [ 20/295]  eta: 0:01:33  lr: 0.003234  min_lr: 0.003234  loss: 3.2334 (3.2406)  weight_decay: 0.0500 (0.0500)  time: 0.2750  data: 0.0035  max mem: 3500\n",
            "Epoch: [43]  [ 30/295]  eta: 0:01:23  lr: 0.003232  min_lr: 0.003232  loss: 3.3045 (3.2733)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0021  max mem: 3500\n",
            "Epoch: [43]  [ 40/295]  eta: 0:01:17  lr: 0.003230  min_lr: 0.003230  loss: 3.3535 (3.2812)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0035  max mem: 3500\n",
            "Epoch: [43]  [ 50/295]  eta: 0:01:13  lr: 0.003228  min_lr: 0.003228  loss: 3.3388 (3.2755)  weight_decay: 0.0500 (0.0500)  time: 0.2741  data: 0.0033  max mem: 3500\n",
            "Epoch: [43]  [ 60/295]  eta: 0:01:08  lr: 0.003226  min_lr: 0.003226  loss: 3.2952 (3.2815)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0023  max mem: 3500\n",
            "Epoch: [43]  [ 70/295]  eta: 0:01:05  lr: 0.003224  min_lr: 0.003224  loss: 3.2893 (3.2815)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0016  max mem: 3500\n",
            "Epoch: [43]  [ 80/295]  eta: 0:01:01  lr: 0.003221  min_lr: 0.003221  loss: 3.2420 (3.2817)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0016  max mem: 3500\n",
            "Epoch: [43]  [ 90/295]  eta: 0:00:58  lr: 0.003220  min_lr: 0.003220  loss: 3.3393 (3.2854)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0014  max mem: 3500\n",
            "Epoch: [43]  [100/295]  eta: 0:00:55  lr: 0.003217  min_lr: 0.003217  loss: 3.3650 (3.2925)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0021  max mem: 3500\n",
            "Epoch: [43]  [110/295]  eta: 0:00:52  lr: 0.003215  min_lr: 0.003215  loss: 3.3353 (3.2819)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0026  max mem: 3500\n",
            "Epoch: [43]  [120/295]  eta: 0:00:49  lr: 0.003213  min_lr: 0.003213  loss: 3.1650 (3.2757)  weight_decay: 0.0500 (0.0500)  time: 0.2747  data: 0.0040  max mem: 3500\n",
            "Epoch: [43]  [130/295]  eta: 0:00:46  lr: 0.003211  min_lr: 0.003211  loss: 3.2140 (3.2694)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0042  max mem: 3500\n",
            "Epoch: [43]  [140/295]  eta: 0:00:43  lr: 0.003209  min_lr: 0.003209  loss: 3.1806 (3.2627)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0026  max mem: 3500\n",
            "Epoch: [43]  [150/295]  eta: 0:00:40  lr: 0.003207  min_lr: 0.003207  loss: 3.2653 (3.2641)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0023  max mem: 3500\n",
            "Epoch: [43]  [160/295]  eta: 0:00:37  lr: 0.003204  min_lr: 0.003204  loss: 3.2979 (3.2658)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0029  max mem: 3500\n",
            "Epoch: [43]  [170/295]  eta: 0:00:34  lr: 0.003203  min_lr: 0.003203  loss: 3.2266 (3.2650)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0046  max mem: 3500\n",
            "Epoch: [43]  [180/295]  eta: 0:00:31  lr: 0.003200  min_lr: 0.003200  loss: 3.3785 (3.2730)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0059  max mem: 3500\n",
            "Epoch: [43]  [190/295]  eta: 0:00:28  lr: 0.003198  min_lr: 0.003198  loss: 3.3714 (3.2704)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0043  max mem: 3500\n",
            "Epoch: [43]  [200/295]  eta: 0:00:26  lr: 0.003196  min_lr: 0.003196  loss: 3.2623 (3.2718)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0024  max mem: 3500\n",
            "Epoch: [43]  [210/295]  eta: 0:00:23  lr: 0.003194  min_lr: 0.003194  loss: 3.3396 (3.2755)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0027  max mem: 3500\n",
            "Epoch: [43]  [220/295]  eta: 0:00:20  lr: 0.003191  min_lr: 0.003191  loss: 3.2995 (3.2732)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0023  max mem: 3500\n",
            "Epoch: [43]  [230/295]  eta: 0:00:17  lr: 0.003190  min_lr: 0.003190  loss: 3.3137 (3.2766)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0020  max mem: 3500\n",
            "Epoch: [43]  [240/295]  eta: 0:00:15  lr: 0.003187  min_lr: 0.003187  loss: 3.3650 (3.2804)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0035  max mem: 3500\n",
            "Epoch: [43]  [250/295]  eta: 0:00:12  lr: 0.003185  min_lr: 0.003185  loss: 3.3288 (3.2812)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0050  max mem: 3500\n",
            "Epoch: [43]  [260/295]  eta: 0:00:09  lr: 0.003183  min_lr: 0.003183  loss: 3.3083 (3.2844)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0032  max mem: 3500\n",
            "Epoch: [43]  [270/295]  eta: 0:00:06  lr: 0.003181  min_lr: 0.003181  loss: 3.3169 (3.2824)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0014  max mem: 3500\n",
            "Epoch: [43]  [280/295]  eta: 0:00:04  lr: 0.003178  min_lr: 0.003178  loss: 3.3127 (3.2802)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0011  max mem: 3500\n",
            "Epoch: [43]  [290/295]  eta: 0:00:01  lr: 0.003177  min_lr: 0.003177  loss: 3.3167 (3.2819)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0004  max mem: 3500\n",
            "Epoch: [43]  [294/295]  eta: 0:00:00  lr: 0.003177  min_lr: 0.003177  loss: 3.3167 (3.2830)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0002  max mem: 3500\n",
            "Epoch: [43] Total time: 0:01:19 (0.2703 s / it)\n",
            "Averaged stats: lr: 0.003177  min_lr: 0.003177  loss: 3.3167 (3.2830)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:58  loss: 0.7794 (0.7794)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.6404  data: 3.4400  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:34  loss: 0.8136 (0.8646)  acc1: 85.4167 (82.7652)  acc5: 97.9167 (97.3485)  time: 0.4798  data: 0.3153  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.8482 (0.8904)  acc1: 83.3333 (82.2421)  acc5: 97.9167 (97.5198)  time: 0.1452  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.9555 (1.1950)  acc1: 70.8333 (67.8763)  acc5: 95.8333 (96.1694)  time: 0.1245  data: 0.0024  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.3240 (1.2235)  acc1: 64.5833 (68.1911)  acc5: 93.7500 (95.4776)  time: 0.1238  data: 0.0037  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.2782 (1.2231)  acc1: 70.8333 (68.2190)  acc5: 95.8333 (95.7108)  time: 0.1252  data: 0.0036  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.1265 (1.1941)  acc1: 70.8333 (69.5697)  acc5: 95.8333 (95.7309)  time: 0.1257  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0270 (1.1897)  acc1: 77.0833 (70.0117)  acc5: 95.8333 (95.6866)  time: 0.1216  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0265 (1.1719)  acc1: 77.0833 (71.1420)  acc5: 97.9167 (95.8591)  time: 0.1175  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0265 (1.1739)  acc1: 77.0833 (71.1338)  acc5: 97.9167 (95.7707)  time: 0.1165  data: 0.0004  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1758 s / it)\n",
            "* Acc@1 71.134 Acc@5 95.771 loss 1.174\n",
            "Accuracy of the model on the 3925 test images: 71.1%\n",
            "Max accuracy: 71.13%\n",
            "Test:  [ 0/82]  eta: 0:04:22  loss: 3.7628 (3.7628)  acc1: 12.5000 (12.5000)  acc5: 77.0833 (77.0833)  time: 3.2058  data: 2.9897  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:33  loss: 3.7576 (3.7263)  acc1: 8.3333 (9.8485)  acc5: 81.2500 (82.5758)  time: 0.4628  data: 0.2975  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:20  loss: 3.6195 (3.7848)  acc1: 14.5833 (14.4841)  acc5: 81.2500 (82.7381)  time: 0.1841  data: 0.0274  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 4.3041 (4.2601)  acc1: 14.5833 (11.9624)  acc5: 75.0000 (73.1183)  time: 0.1606  data: 0.0145  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.3559 (4.5016)  acc1: 2.0833 (10.6707)  acc5: 54.1667 (68.6992)  time: 0.1347  data: 0.0022  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.8293 (4.5374)  acc1: 6.2500 (12.8268)  acc5: 56.2500 (67.8105)  time: 0.1274  data: 0.0027  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6781 (4.6611)  acc1: 4.1667 (11.0997)  acc5: 60.4167 (65.6421)  time: 0.1253  data: 0.0053  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6781 (4.6031)  acc1: 2.0833 (12.7934)  acc5: 77.0833 (65.3462)  time: 0.1220  data: 0.0035  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.5073 (4.2539)  acc1: 45.8333 (20.0103)  acc5: 91.6667 (68.7243)  time: 0.1195  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.4179 (4.2243)  acc1: 50.0000 (20.5605)  acc5: 91.6667 (68.9172)  time: 0.1177  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1822 s / it)\n",
            "* Acc@1 20.561 Acc@5 68.917 loss 4.224\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [44]  [  0/295]  eta: 0:09:57  lr: 0.003176  min_lr: 0.003176  loss: 2.9538 (2.9538)  weight_decay: 0.0500 (0.0500)  time: 2.0269  data: 1.6114  max mem: 3500\n",
            "Epoch: [44]  [ 10/295]  eta: 0:02:05  lr: 0.003174  min_lr: 0.003174  loss: 3.2692 (3.2779)  weight_decay: 0.0500 (0.0500)  time: 0.4404  data: 0.1497  max mem: 3500\n",
            "Epoch: [44]  [ 20/295]  eta: 0:01:39  lr: 0.003171  min_lr: 0.003171  loss: 3.2692 (3.2590)  weight_decay: 0.0500 (0.0500)  time: 0.2792  data: 0.0038  max mem: 3500\n",
            "Epoch: [44]  [ 30/295]  eta: 0:01:28  lr: 0.003170  min_lr: 0.003170  loss: 3.3003 (3.2763)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0032  max mem: 3500\n",
            "Epoch: [44]  [ 40/295]  eta: 0:01:20  lr: 0.003167  min_lr: 0.003167  loss: 3.3131 (3.2643)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0018  max mem: 3500\n",
            "Epoch: [44]  [ 50/295]  eta: 0:01:15  lr: 0.003165  min_lr: 0.003165  loss: 3.2616 (3.2628)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0013  max mem: 3500\n",
            "Epoch: [44]  [ 60/295]  eta: 0:01:10  lr: 0.003163  min_lr: 0.003163  loss: 3.2435 (3.2511)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0015  max mem: 3500\n",
            "Epoch: [44]  [ 70/295]  eta: 0:01:06  lr: 0.003161  min_lr: 0.003161  loss: 3.2435 (3.2551)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0017  max mem: 3500\n",
            "Epoch: [44]  [ 80/295]  eta: 0:01:03  lr: 0.003158  min_lr: 0.003158  loss: 3.3208 (3.2629)  weight_decay: 0.0500 (0.0500)  time: 0.2747  data: 0.0028  max mem: 3500\n",
            "Epoch: [44]  [ 90/295]  eta: 0:00:59  lr: 0.003157  min_lr: 0.003157  loss: 3.2807 (3.2495)  weight_decay: 0.0500 (0.0500)  time: 0.2751  data: 0.0029  max mem: 3500\n",
            "Epoch: [44]  [100/295]  eta: 0:00:56  lr: 0.003154  min_lr: 0.003154  loss: 3.2572 (3.2479)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0014  max mem: 3500\n",
            "Epoch: [44]  [110/295]  eta: 0:00:53  lr: 0.003152  min_lr: 0.003152  loss: 3.2572 (3.2410)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0014  max mem: 3500\n",
            "Epoch: [44]  [120/295]  eta: 0:00:49  lr: 0.003150  min_lr: 0.003150  loss: 3.1922 (3.2363)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0021  max mem: 3500\n",
            "Epoch: [44]  [130/295]  eta: 0:00:46  lr: 0.003148  min_lr: 0.003148  loss: 3.1243 (3.2362)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0017  max mem: 3500\n",
            "Epoch: [44]  [140/295]  eta: 0:00:43  lr: 0.003145  min_lr: 0.003145  loss: 3.2856 (3.2408)  weight_decay: 0.0500 (0.0500)  time: 0.2766  data: 0.0044  max mem: 3500\n",
            "Epoch: [44]  [150/295]  eta: 0:00:41  lr: 0.003143  min_lr: 0.003143  loss: 3.2828 (3.2443)  weight_decay: 0.0500 (0.0500)  time: 0.2789  data: 0.0045  max mem: 3500\n",
            "Epoch: [44]  [160/295]  eta: 0:00:38  lr: 0.003141  min_lr: 0.003141  loss: 3.2828 (3.2497)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0035  max mem: 3500\n",
            "Epoch: [44]  [170/295]  eta: 0:00:35  lr: 0.003139  min_lr: 0.003139  loss: 3.3335 (3.2507)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0046  max mem: 3500\n",
            "Epoch: [44]  [180/295]  eta: 0:00:32  lr: 0.003136  min_lr: 0.003136  loss: 3.3526 (3.2587)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0022  max mem: 3500\n",
            "Epoch: [44]  [190/295]  eta: 0:00:29  lr: 0.003135  min_lr: 0.003135  loss: 3.4147 (3.2647)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0012  max mem: 3500\n",
            "Epoch: [44]  [200/295]  eta: 0:00:26  lr: 0.003132  min_lr: 0.003132  loss: 3.2542 (3.2635)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0012  max mem: 3500\n",
            "Epoch: [44]  [210/295]  eta: 0:00:23  lr: 0.003130  min_lr: 0.003130  loss: 3.2383 (3.2635)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0022  max mem: 3500\n",
            "Epoch: [44]  [220/295]  eta: 0:00:20  lr: 0.003127  min_lr: 0.003127  loss: 3.2531 (3.2633)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0044  max mem: 3500\n",
            "Epoch: [44]  [230/295]  eta: 0:00:18  lr: 0.003126  min_lr: 0.003126  loss: 3.2531 (3.2637)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0049  max mem: 3500\n",
            "Epoch: [44]  [240/295]  eta: 0:00:15  lr: 0.003123  min_lr: 0.003123  loss: 3.3010 (3.2660)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0047  max mem: 3500\n",
            "Epoch: [44]  [250/295]  eta: 0:00:12  lr: 0.003121  min_lr: 0.003121  loss: 3.2815 (3.2660)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0028  max mem: 3500\n",
            "Epoch: [44]  [260/295]  eta: 0:00:09  lr: 0.003119  min_lr: 0.003119  loss: 3.2311 (3.2668)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0013  max mem: 3500\n",
            "Epoch: [44]  [270/295]  eta: 0:00:06  lr: 0.003117  min_lr: 0.003117  loss: 3.3081 (3.2670)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0020  max mem: 3500\n",
            "Epoch: [44]  [280/295]  eta: 0:00:04  lr: 0.003114  min_lr: 0.003114  loss: 3.2591 (3.2644)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0016  max mem: 3500\n",
            "Epoch: [44]  [290/295]  eta: 0:00:01  lr: 0.003112  min_lr: 0.003112  loss: 3.1273 (3.2600)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0006  max mem: 3500\n",
            "Epoch: [44]  [294/295]  eta: 0:00:00  lr: 0.003112  min_lr: 0.003112  loss: 3.1273 (3.2593)  weight_decay: 0.0500 (0.0500)  time: 0.2232  data: 0.0005  max mem: 3500\n",
            "Epoch: [44] Total time: 0:01:20 (0.2728 s / it)\n",
            "Averaged stats: lr: 0.003112  min_lr: 0.003112  loss: 3.1273 (3.2593)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:44  loss: 0.9034 (0.9034)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 2.0020  data: 1.8155  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.9034 (0.9442)  acc1: 83.3333 (80.1136)  acc5: 95.8333 (95.0758)  time: 0.2940  data: 0.1670  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.8758 (0.9039)  acc1: 81.2500 (81.6468)  acc5: 97.9167 (96.7262)  time: 0.1245  data: 0.0039  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.0144 (1.2216)  acc1: 70.8333 (67.1371)  acc5: 97.9167 (95.1613)  time: 0.1233  data: 0.0041  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.0368 (1.1350)  acc1: 68.7500 (70.6301)  acc5: 97.9167 (95.8333)  time: 0.1234  data: 0.0033  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8941 (1.1615)  acc1: 79.1667 (70.2206)  acc5: 97.9167 (96.1601)  time: 0.1246  data: 0.0040  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.2031 (1.1554)  acc1: 68.7500 (70.4235)  acc5: 97.9167 (96.0383)  time: 0.1226  data: 0.0038  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.3515 (1.2005)  acc1: 60.4167 (68.6620)  acc5: 95.8333 (95.6866)  time: 0.1207  data: 0.0027  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2221 (1.1682)  acc1: 64.5833 (69.9846)  acc5: 97.9167 (96.0134)  time: 0.1189  data: 0.0010  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2030 (1.1673)  acc1: 68.7500 (70.0127)  acc5: 97.9167 (95.9745)  time: 0.1172  data: 0.0004  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1522 s / it)\n",
            "* Acc@1 70.013 Acc@5 95.975 loss 1.167\n",
            "Accuracy of the model on the 3925 test images: 70.0%\n",
            "Max accuracy: 71.13%\n",
            "Test:  [ 0/82]  eta: 0:04:13  loss: 3.7186 (3.7186)  acc1: 12.5000 (12.5000)  acc5: 77.0833 (77.0833)  time: 3.0858  data: 2.8991  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 3.7186 (3.6887)  acc1: 8.3333 (9.4697)  acc5: 83.3333 (83.7121)  time: 0.4171  data: 0.2643  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 3.5746 (3.7447)  acc1: 14.5833 (14.4841)  acc5: 83.3333 (83.8294)  time: 0.1447  data: 0.0024  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 4.2653 (4.2274)  acc1: 14.5833 (11.9624)  acc5: 77.0833 (74.2608)  time: 0.1315  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 5.2988 (4.4666)  acc1: 4.1667 (10.6707)  acc5: 54.1667 (69.7154)  time: 0.1233  data: 0.0019  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.8774 (4.5168)  acc1: 6.2500 (12.5000)  acc5: 56.2500 (68.3824)  time: 0.1237  data: 0.0027  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6817 (4.6426)  acc1: 4.1667 (10.8265)  acc5: 58.3333 (66.2227)  time: 0.1235  data: 0.0029  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6817 (4.5777)  acc1: 2.0833 (12.6467)  acc5: 77.0833 (65.9038)  time: 0.1208  data: 0.0013  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.4241 (4.2260)  acc1: 47.9167 (19.9074)  acc5: 91.6667 (69.2901)  time: 0.1188  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.3282 (4.1963)  acc1: 50.0000 (20.4586)  acc5: 91.6667 (69.4777)  time: 0.1177  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1686 s / it)\n",
            "* Acc@1 20.459 Acc@5 69.478 loss 4.196\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [45]  [  0/295]  eta: 0:10:23  lr: 0.003111  min_lr: 0.003111  loss: 3.5337 (3.5337)  weight_decay: 0.0500 (0.0500)  time: 2.1130  data: 1.6892  max mem: 3500\n",
            "Epoch: [45]  [ 10/295]  eta: 0:02:14  lr: 0.003110  min_lr: 0.003110  loss: 3.3744 (3.4106)  weight_decay: 0.0500 (0.0500)  time: 0.4703  data: 0.1567  max mem: 3500\n",
            "Epoch: [45]  [ 20/295]  eta: 0:01:44  lr: 0.003107  min_lr: 0.003107  loss: 3.3355 (3.3182)  weight_decay: 0.0500 (0.0500)  time: 0.2920  data: 0.0032  max mem: 3500\n",
            "Epoch: [45]  [ 30/295]  eta: 0:01:30  lr: 0.003105  min_lr: 0.003105  loss: 3.3135 (3.3297)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0025  max mem: 3500\n",
            "Epoch: [45]  [ 40/295]  eta: 0:01:22  lr: 0.003102  min_lr: 0.003102  loss: 3.3619 (3.3447)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0016  max mem: 3500\n",
            "Epoch: [45]  [ 50/295]  eta: 0:01:16  lr: 0.003101  min_lr: 0.003101  loss: 3.3765 (3.3450)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0014  max mem: 3500\n",
            "Epoch: [45]  [ 60/295]  eta: 0:01:11  lr: 0.003098  min_lr: 0.003098  loss: 3.2903 (3.3172)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0016  max mem: 3500\n",
            "Epoch: [45]  [ 70/295]  eta: 0:01:07  lr: 0.003096  min_lr: 0.003096  loss: 3.2099 (3.3074)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0009  max mem: 3500\n",
            "Epoch: [45]  [ 80/295]  eta: 0:01:03  lr: 0.003093  min_lr: 0.003093  loss: 3.3323 (3.3083)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0011  max mem: 3500\n",
            "Epoch: [45]  [ 90/295]  eta: 0:01:00  lr: 0.003092  min_lr: 0.003092  loss: 3.2735 (3.2965)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0021  max mem: 3500\n",
            "Epoch: [45]  [100/295]  eta: 0:00:56  lr: 0.003089  min_lr: 0.003089  loss: 3.2529 (3.2937)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0020  max mem: 3500\n",
            "Epoch: [45]  [110/295]  eta: 0:00:53  lr: 0.003087  min_lr: 0.003087  loss: 3.2806 (3.2942)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0019  max mem: 3500\n",
            "Epoch: [45]  [120/295]  eta: 0:00:49  lr: 0.003084  min_lr: 0.003084  loss: 3.2328 (3.2861)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0022  max mem: 3500\n",
            "Epoch: [45]  [130/295]  eta: 0:00:46  lr: 0.003083  min_lr: 0.003083  loss: 3.3419 (3.2873)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0020  max mem: 3500\n",
            "Epoch: [45]  [140/295]  eta: 0:00:43  lr: 0.003080  min_lr: 0.003080  loss: 3.3419 (3.2826)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0035  max mem: 3500\n",
            "Epoch: [45]  [150/295]  eta: 0:00:40  lr: 0.003078  min_lr: 0.003078  loss: 3.2802 (3.2819)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0040  max mem: 3500\n",
            "Epoch: [45]  [160/295]  eta: 0:00:38  lr: 0.003075  min_lr: 0.003075  loss: 3.2535 (3.2783)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0040  max mem: 3500\n",
            "Epoch: [45]  [170/295]  eta: 0:00:35  lr: 0.003074  min_lr: 0.003074  loss: 3.2535 (3.2795)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0039  max mem: 3500\n",
            "Epoch: [45]  [180/295]  eta: 0:00:32  lr: 0.003071  min_lr: 0.003071  loss: 3.3298 (3.2774)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0019  max mem: 3500\n",
            "Epoch: [45]  [190/295]  eta: 0:00:29  lr: 0.003069  min_lr: 0.003069  loss: 3.4195 (3.2839)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0015  max mem: 3500\n",
            "Epoch: [45]  [200/295]  eta: 0:00:26  lr: 0.003066  min_lr: 0.003066  loss: 3.2644 (3.2768)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0024  max mem: 3500\n",
            "Epoch: [45]  [210/295]  eta: 0:00:23  lr: 0.003064  min_lr: 0.003064  loss: 3.3045 (3.2819)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0030  max mem: 3500\n",
            "Epoch: [45]  [220/295]  eta: 0:00:20  lr: 0.003062  min_lr: 0.003062  loss: 3.2593 (3.2750)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0034  max mem: 3500\n",
            "Epoch: [45]  [230/295]  eta: 0:00:17  lr: 0.003060  min_lr: 0.003060  loss: 3.1672 (3.2721)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0031  max mem: 3500\n",
            "Epoch: [45]  [240/295]  eta: 0:00:15  lr: 0.003057  min_lr: 0.003057  loss: 3.3196 (3.2746)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0014  max mem: 3500\n",
            "Epoch: [45]  [250/295]  eta: 0:00:12  lr: 0.003055  min_lr: 0.003055  loss: 3.2908 (3.2715)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0012  max mem: 3500\n",
            "Epoch: [45]  [260/295]  eta: 0:00:09  lr: 0.003053  min_lr: 0.003053  loss: 3.2962 (3.2748)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0016  max mem: 3500\n",
            "Epoch: [45]  [270/295]  eta: 0:00:06  lr: 0.003051  min_lr: 0.003051  loss: 3.3248 (3.2749)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0021  max mem: 3500\n",
            "Epoch: [45]  [280/295]  eta: 0:00:04  lr: 0.003048  min_lr: 0.003048  loss: 3.2556 (3.2740)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0024  max mem: 3500\n",
            "Epoch: [45]  [290/295]  eta: 0:00:01  lr: 0.003046  min_lr: 0.003046  loss: 3.2609 (3.2751)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0010  max mem: 3500\n",
            "Epoch: [45]  [294/295]  eta: 0:00:00  lr: 0.003046  min_lr: 0.003046  loss: 3.2609 (3.2737)  weight_decay: 0.0500 (0.0500)  time: 0.2214  data: 0.0002  max mem: 3500\n",
            "Epoch: [45] Total time: 0:01:20 (0.2720 s / it)\n",
            "Averaged stats: lr: 0.003046  min_lr: 0.003046  loss: 3.2609 (3.2737)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:13  loss: 0.8518 (0.8518)  acc1: 83.3333 (83.3333)  acc5: 91.6667 (91.6667)  time: 2.3626  data: 2.1971  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 0.8719 (0.8930)  acc1: 83.3333 (82.5758)  acc5: 95.8333 (96.0227)  time: 0.3347  data: 0.2031  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.8719 (0.8727)  acc1: 83.3333 (83.4325)  acc5: 95.8333 (96.9246)  time: 0.1348  data: 0.0073  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.9159 (1.0867)  acc1: 79.1667 (73.7231)  acc5: 97.9167 (96.6398)  time: 0.1850  data: 0.0093  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.9892 (1.0523)  acc1: 75.0000 (75.2033)  acc5: 97.9167 (97.0020)  time: 0.2091  data: 0.0065  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.0300 (1.0718)  acc1: 77.0833 (75.2860)  acc5: 97.9167 (97.0588)  time: 0.1740  data: 0.0044  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.1073 (1.0716)  acc1: 72.9167 (75.3415)  acc5: 97.9167 (96.9604)  time: 0.1911  data: 0.0319  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.4336 (1.1380)  acc1: 58.3333 (72.4472)  acc5: 95.8333 (96.6843)  time: 0.1986  data: 0.0436  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4440 (1.1327)  acc1: 56.2500 (72.9167)  acc5: 95.8333 (96.8364)  time: 0.1473  data: 0.0134  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3908 (1.1329)  acc1: 58.3333 (72.9172)  acc5: 95.8333 (96.7643)  time: 0.1444  data: 0.0134  max mem: 3500\n",
            "Test: Total time: 0:00:16 (0.2052 s / it)\n",
            "* Acc@1 72.917 Acc@5 96.764 loss 1.133\n",
            "Accuracy of the model on the 3925 test images: 72.9%\n",
            "Max accuracy: 72.92%\n",
            "Test:  [ 0/82]  eta: 0:03:28  loss: 3.6658 (3.6658)  acc1: 14.5833 (14.5833)  acc5: 77.0833 (77.0833)  time: 2.5457  data: 2.3810  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 3.6658 (3.6505)  acc1: 8.3333 (9.8485)  acc5: 83.3333 (84.4697)  time: 0.3678  data: 0.2365  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 3.5197 (3.7099)  acc1: 16.6667 (14.5833)  acc5: 83.3333 (84.7222)  time: 0.1364  data: 0.0121  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 4.2270 (4.1976)  acc1: 14.5833 (12.0296)  acc5: 77.0833 (74.7984)  time: 0.1232  data: 0.0026  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.2307 (4.4308)  acc1: 4.1667 (10.7724)  acc5: 54.1667 (70.2236)  time: 0.1261  data: 0.0036  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.9195 (4.4937)  acc1: 6.2500 (12.5409)  acc5: 56.2500 (68.7092)  time: 0.1257  data: 0.0043  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6945 (4.6199)  acc1: 4.1667 (10.8607)  acc5: 58.3333 (66.5642)  time: 0.1227  data: 0.0044  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.6709 (4.5488)  acc1: 2.0833 (12.8815)  acc5: 75.0000 (66.1972)  time: 0.1207  data: 0.0029  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.3444 (4.1954)  acc1: 47.9167 (20.1132)  acc5: 93.7500 (69.7016)  time: 0.1185  data: 0.0006  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.2421 (4.1657)  acc1: 52.0833 (20.6624)  acc5: 93.7500 (69.8854)  time: 0.1169  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1610 s / it)\n",
            "* Acc@1 20.662 Acc@5 69.885 loss 4.166\n",
            "Accuracy of the model EMA on 3925 test images: 20.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [46]  [  0/295]  eta: 0:13:55  lr: 0.003045  min_lr: 0.003045  loss: 3.2542 (3.2542)  weight_decay: 0.0500 (0.0500)  time: 2.8323  data: 2.2079  max mem: 3500\n",
            "Epoch: [46]  [ 10/295]  eta: 0:02:37  lr: 0.003043  min_lr: 0.003043  loss: 3.2327 (3.2404)  weight_decay: 0.0500 (0.0500)  time: 0.5519  data: 0.2037  max mem: 3500\n",
            "Epoch: [46]  [ 20/295]  eta: 0:01:54  lr: 0.003041  min_lr: 0.003041  loss: 3.2279 (3.2668)  weight_decay: 0.0500 (0.0500)  time: 0.2938  data: 0.0020  max mem: 3500\n",
            "Epoch: [46]  [ 30/295]  eta: 0:01:36  lr: 0.003039  min_lr: 0.003039  loss: 3.2279 (3.2536)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0019  max mem: 3500\n",
            "Epoch: [46]  [ 40/295]  eta: 0:01:27  lr: 0.003036  min_lr: 0.003036  loss: 3.2390 (3.2733)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0019  max mem: 3500\n",
            "Epoch: [46]  [ 50/295]  eta: 0:01:20  lr: 0.003034  min_lr: 0.003034  loss: 3.3105 (3.2657)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0013  max mem: 3500\n",
            "Epoch: [46]  [ 60/295]  eta: 0:01:14  lr: 0.003031  min_lr: 0.003031  loss: 3.3239 (3.2681)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0025  max mem: 3500\n",
            "Epoch: [46]  [ 70/295]  eta: 0:01:10  lr: 0.003030  min_lr: 0.003030  loss: 3.3498 (3.2818)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0029  max mem: 3500\n",
            "Epoch: [46]  [ 80/295]  eta: 0:01:05  lr: 0.003027  min_lr: 0.003027  loss: 3.2483 (3.2745)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0030  max mem: 3500\n",
            "Epoch: [46]  [ 90/295]  eta: 0:01:01  lr: 0.003025  min_lr: 0.003025  loss: 3.1862 (3.2640)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0026  max mem: 3500\n",
            "Epoch: [46]  [100/295]  eta: 0:00:58  lr: 0.003022  min_lr: 0.003022  loss: 3.3034 (3.2729)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0013  max mem: 3500\n",
            "Epoch: [46]  [110/295]  eta: 0:00:54  lr: 0.003020  min_lr: 0.003020  loss: 3.3740 (3.2692)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0016  max mem: 3500\n",
            "Epoch: [46]  [120/295]  eta: 0:00:51  lr: 0.003018  min_lr: 0.003018  loss: 3.1771 (3.2640)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0017  max mem: 3500\n",
            "Epoch: [46]  [130/295]  eta: 0:00:48  lr: 0.003016  min_lr: 0.003016  loss: 3.2355 (3.2655)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0022  max mem: 3500\n",
            "Epoch: [46]  [140/295]  eta: 0:00:44  lr: 0.003013  min_lr: 0.003013  loss: 3.2596 (3.2636)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0041  max mem: 3500\n",
            "Epoch: [46]  [150/295]  eta: 0:00:41  lr: 0.003011  min_lr: 0.003011  loss: 3.2116 (3.2577)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0031  max mem: 3500\n",
            "Epoch: [46]  [160/295]  eta: 0:00:38  lr: 0.003008  min_lr: 0.003008  loss: 3.2667 (3.2632)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0009  max mem: 3500\n",
            "Epoch: [46]  [170/295]  eta: 0:00:35  lr: 0.003006  min_lr: 0.003006  loss: 3.3576 (3.2691)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0011  max mem: 3500\n",
            "Epoch: [46]  [180/295]  eta: 0:00:32  lr: 0.003004  min_lr: 0.003004  loss: 3.3129 (3.2624)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0015  max mem: 3500\n",
            "Epoch: [46]  [190/295]  eta: 0:00:29  lr: 0.003002  min_lr: 0.003002  loss: 3.2059 (3.2629)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0023  max mem: 3500\n",
            "Epoch: [46]  [200/295]  eta: 0:00:26  lr: 0.002999  min_lr: 0.002999  loss: 3.2996 (3.2614)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0031  max mem: 3500\n",
            "Epoch: [46]  [210/295]  eta: 0:00:23  lr: 0.002997  min_lr: 0.002997  loss: 3.2712 (3.2621)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0042  max mem: 3500\n",
            "Epoch: [46]  [220/295]  eta: 0:00:21  lr: 0.002994  min_lr: 0.002994  loss: 3.2447 (3.2611)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0035  max mem: 3500\n",
            "Epoch: [46]  [230/295]  eta: 0:00:18  lr: 0.002992  min_lr: 0.002992  loss: 3.1805 (3.2592)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0020  max mem: 3500\n",
            "Epoch: [46]  [240/295]  eta: 0:00:15  lr: 0.002990  min_lr: 0.002990  loss: 3.1904 (3.2575)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0014  max mem: 3500\n",
            "Epoch: [46]  [250/295]  eta: 0:00:12  lr: 0.002988  min_lr: 0.002988  loss: 3.1904 (3.2575)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0009  max mem: 3500\n",
            "Epoch: [46]  [260/295]  eta: 0:00:09  lr: 0.002985  min_lr: 0.002985  loss: 3.2254 (3.2575)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0010  max mem: 3500\n",
            "Epoch: [46]  [270/295]  eta: 0:00:06  lr: 0.002983  min_lr: 0.002983  loss: 3.1334 (3.2534)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0018  max mem: 3500\n",
            "Epoch: [46]  [280/295]  eta: 0:00:04  lr: 0.002980  min_lr: 0.002980  loss: 3.1362 (3.2550)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0022  max mem: 3500\n",
            "Epoch: [46]  [290/295]  eta: 0:00:01  lr: 0.002978  min_lr: 0.002978  loss: 3.1791 (3.2526)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0010  max mem: 3500\n",
            "Epoch: [46]  [294/295]  eta: 0:00:00  lr: 0.002978  min_lr: 0.002978  loss: 3.1791 (3.2523)  weight_decay: 0.0500 (0.0500)  time: 0.2192  data: 0.0002  max mem: 3500\n",
            "Epoch: [46] Total time: 0:01:21 (0.2746 s / it)\n",
            "Averaged stats: lr: 0.002978  min_lr: 0.002978  loss: 3.1791 (3.2523)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:59  loss: 0.9593 (0.9593)  acc1: 79.1667 (79.1667)  acc5: 95.8333 (95.8333)  time: 2.1926  data: 2.0235  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.9540 (0.9619)  acc1: 79.1667 (80.1136)  acc5: 95.8333 (96.5909)  time: 0.3154  data: 0.1868  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.8947 (0.9025)  acc1: 83.3333 (83.4325)  acc5: 97.9167 (97.5198)  time: 0.1404  data: 0.0050  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.9369 (1.1933)  acc1: 79.1667 (70.2285)  acc5: 97.9167 (95.0269)  time: 0.1605  data: 0.0041  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.9819 (1.1446)  acc1: 77.0833 (72.4594)  acc5: 95.8333 (95.4776)  time: 0.1818  data: 0.0220  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.9819 (1.1353)  acc1: 77.0833 (72.5899)  acc5: 97.9167 (96.0376)  time: 0.1915  data: 0.0311  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.0815 (1.1221)  acc1: 72.9167 (72.7118)  acc5: 97.9167 (96.1066)  time: 0.1829  data: 0.0111  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.1611 (1.1354)  acc1: 72.9167 (72.3005)  acc5: 95.8333 (95.9800)  time: 0.1538  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1090 (1.1213)  acc1: 72.9167 (72.8395)  acc5: 95.8333 (96.1163)  time: 0.1239  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1090 (1.1235)  acc1: 72.9167 (72.8153)  acc5: 95.8333 (96.0764)  time: 0.1179  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1867 s / it)\n",
            "* Acc@1 72.815 Acc@5 96.076 loss 1.124\n",
            "Accuracy of the model on the 3925 test images: 72.8%\n",
            "Max accuracy: 72.92%\n",
            "Test:  [ 0/82]  eta: 0:02:30  loss: 3.6113 (3.6113)  acc1: 14.5833 (14.5833)  acc5: 79.1667 (79.1667)  time: 1.8324  data: 1.6555  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.6113 (3.6124)  acc1: 8.3333 (9.6591)  acc5: 83.3333 (84.6591)  time: 0.2814  data: 0.1519  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.4669 (3.6755)  acc1: 16.6667 (14.2857)  acc5: 85.4167 (85.1191)  time: 0.1239  data: 0.0018  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.1863 (4.1697)  acc1: 16.6667 (11.8280)  acc5: 79.1667 (74.9328)  time: 0.1222  data: 0.0020  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 5.1686 (4.3986)  acc1: 4.1667 (10.7215)  acc5: 54.1667 (70.5285)  time: 0.1245  data: 0.0034  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.9322 (4.4735)  acc1: 8.3333 (12.3366)  acc5: 56.2500 (68.7909)  time: 0.1272  data: 0.0053  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.7441 (4.6015)  acc1: 4.1667 (10.6557)  acc5: 56.2500 (66.6325)  time: 0.1437  data: 0.0048  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.6623 (4.5255)  acc1: 2.0833 (12.7347)  acc5: 75.0000 (66.2852)  time: 0.1485  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.2740 (4.1698)  acc1: 47.9167 (20.0874)  acc5: 93.7500 (69.8302)  time: 0.1284  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.1654 (4.1400)  acc1: 54.1667 (20.6369)  acc5: 93.7500 (70.0127)  time: 0.1265  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1572 s / it)\n",
            "* Acc@1 20.637 Acc@5 70.013 loss 4.140\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [47]  [  0/295]  eta: 0:12:36  lr: 0.002977  min_lr: 0.002977  loss: 3.2640 (3.2640)  weight_decay: 0.0500 (0.0500)  time: 2.5659  data: 2.1760  max mem: 3500\n",
            "Epoch: [47]  [ 10/295]  eta: 0:02:19  lr: 0.002976  min_lr: 0.002976  loss: 3.3345 (3.3312)  weight_decay: 0.0500 (0.0500)  time: 0.4896  data: 0.1996  max mem: 3500\n",
            "Epoch: [47]  [ 20/295]  eta: 0:01:44  lr: 0.002973  min_lr: 0.002973  loss: 3.2511 (3.2749)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0015  max mem: 3500\n",
            "Epoch: [47]  [ 30/295]  eta: 0:01:30  lr: 0.002971  min_lr: 0.002971  loss: 3.1687 (3.2298)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0007  max mem: 3500\n",
            "Epoch: [47]  [ 40/295]  eta: 0:01:22  lr: 0.002968  min_lr: 0.002968  loss: 3.2479 (3.2500)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0008  max mem: 3500\n",
            "Epoch: [47]  [ 50/295]  eta: 0:01:17  lr: 0.002966  min_lr: 0.002966  loss: 3.2526 (3.2459)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0010  max mem: 3500\n",
            "Epoch: [47]  [ 60/295]  eta: 0:01:12  lr: 0.002963  min_lr: 0.002963  loss: 3.2654 (3.2636)  weight_decay: 0.0500 (0.0500)  time: 0.2771  data: 0.0028  max mem: 3500\n",
            "Epoch: [47]  [ 70/295]  eta: 0:01:08  lr: 0.002962  min_lr: 0.002962  loss: 3.3560 (3.2738)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0030  max mem: 3500\n",
            "Epoch: [47]  [ 80/295]  eta: 0:01:04  lr: 0.002959  min_lr: 0.002959  loss: 3.3579 (3.2891)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0017  max mem: 3500\n",
            "Epoch: [47]  [ 90/295]  eta: 0:01:00  lr: 0.002957  min_lr: 0.002957  loss: 3.3105 (3.2791)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0015  max mem: 3500\n",
            "Epoch: [47]  [100/295]  eta: 0:00:57  lr: 0.002954  min_lr: 0.002954  loss: 3.2872 (3.2815)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0017  max mem: 3500\n",
            "Epoch: [47]  [110/295]  eta: 0:00:53  lr: 0.002952  min_lr: 0.002952  loss: 3.3096 (3.2836)  weight_decay: 0.0500 (0.0500)  time: 0.2759  data: 0.0022  max mem: 3500\n",
            "Epoch: [47]  [120/295]  eta: 0:00:50  lr: 0.002949  min_lr: 0.002949  loss: 3.3095 (3.2846)  weight_decay: 0.0500 (0.0500)  time: 0.2815  data: 0.0057  max mem: 3500\n",
            "Epoch: [47]  [130/295]  eta: 0:00:47  lr: 0.002947  min_lr: 0.002947  loss: 3.2919 (3.2780)  weight_decay: 0.0500 (0.0500)  time: 0.2799  data: 0.0068  max mem: 3500\n",
            "Epoch: [47]  [140/295]  eta: 0:00:44  lr: 0.002944  min_lr: 0.002944  loss: 3.3322 (3.2860)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0030  max mem: 3500\n",
            "Epoch: [47]  [150/295]  eta: 0:00:41  lr: 0.002943  min_lr: 0.002943  loss: 3.3390 (3.2840)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0020  max mem: 3500\n",
            "Epoch: [47]  [160/295]  eta: 0:00:38  lr: 0.002940  min_lr: 0.002940  loss: 3.3052 (3.2820)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0017  max mem: 3500\n",
            "Epoch: [47]  [170/295]  eta: 0:00:35  lr: 0.002938  min_lr: 0.002938  loss: 3.3052 (3.2830)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0013  max mem: 3500\n",
            "Epoch: [47]  [180/295]  eta: 0:00:32  lr: 0.002935  min_lr: 0.002935  loss: 3.2883 (3.2808)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0019  max mem: 3500\n",
            "Epoch: [47]  [190/295]  eta: 0:00:29  lr: 0.002933  min_lr: 0.002933  loss: 3.2196 (3.2795)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0027  max mem: 3500\n",
            "Epoch: [47]  [200/295]  eta: 0:00:26  lr: 0.002930  min_lr: 0.002930  loss: 3.2632 (3.2770)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0024  max mem: 3500\n",
            "Epoch: [47]  [210/295]  eta: 0:00:23  lr: 0.002928  min_lr: 0.002928  loss: 3.1547 (3.2738)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0024  max mem: 3500\n",
            "Epoch: [47]  [220/295]  eta: 0:00:20  lr: 0.002925  min_lr: 0.002925  loss: 3.2748 (3.2734)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0025  max mem: 3500\n",
            "Epoch: [47]  [230/295]  eta: 0:00:18  lr: 0.002924  min_lr: 0.002924  loss: 3.2701 (3.2685)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0030  max mem: 3500\n",
            "Epoch: [47]  [240/295]  eta: 0:00:15  lr: 0.002921  min_lr: 0.002921  loss: 3.2524 (3.2703)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0024  max mem: 3500\n",
            "Epoch: [47]  [250/295]  eta: 0:00:12  lr: 0.002919  min_lr: 0.002919  loss: 3.2758 (3.2711)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0011  max mem: 3500\n",
            "Epoch: [47]  [260/295]  eta: 0:00:09  lr: 0.002916  min_lr: 0.002916  loss: 3.3204 (3.2735)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0025  max mem: 3500\n",
            "Epoch: [47]  [270/295]  eta: 0:00:06  lr: 0.002914  min_lr: 0.002914  loss: 3.3204 (3.2728)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0037  max mem: 3500\n",
            "Epoch: [47]  [280/295]  eta: 0:00:04  lr: 0.002911  min_lr: 0.002911  loss: 3.3054 (3.2747)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0021  max mem: 3500\n",
            "Epoch: [47]  [290/295]  eta: 0:00:01  lr: 0.002909  min_lr: 0.002909  loss: 3.2094 (3.2709)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0003  max mem: 3500\n",
            "Epoch: [47]  [294/295]  eta: 0:00:00  lr: 0.002909  min_lr: 0.002909  loss: 3.2094 (3.2713)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0002  max mem: 3500\n",
            "Epoch: [47] Total time: 0:01:20 (0.2742 s / it)\n",
            "Averaged stats: lr: 0.002909  min_lr: 0.002909  loss: 3.2094 (3.2713)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:35  loss: 0.7538 (0.7538)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 1.8990  data: 1.7331  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.8321 (0.8648)  acc1: 85.4167 (84.0909)  acc5: 95.8333 (96.9697)  time: 0.3218  data: 0.1766  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.9637 (0.9407)  acc1: 79.1667 (81.8452)  acc5: 97.9167 (97.2222)  time: 0.1717  data: 0.0324  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 1.1063 (1.0741)  acc1: 70.8333 (76.0753)  acc5: 97.9167 (97.5806)  time: 0.1843  data: 0.0432  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.1785 (1.0851)  acc1: 70.8333 (75.9654)  acc5: 97.9167 (97.2561)  time: 0.1817  data: 0.0258  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.1469 (1.1158)  acc1: 72.9167 (75.4085)  acc5: 95.8333 (97.0180)  time: 0.1616  data: 0.0086  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.0631 (1.0942)  acc1: 72.9167 (76.2295)  acc5: 95.8333 (96.7896)  time: 0.1380  data: 0.0073  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.2541 (1.1316)  acc1: 68.7500 (74.6479)  acc5: 95.8333 (96.4202)  time: 0.1238  data: 0.0033  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2013 (1.0981)  acc1: 70.8333 (75.5658)  acc5: 97.9167 (96.6564)  time: 0.1193  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1752 (1.0968)  acc1: 70.8333 (75.5414)  acc5: 97.9167 (96.6115)  time: 0.1182  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1780 s / it)\n",
            "* Acc@1 75.541 Acc@5 96.611 loss 1.097\n",
            "Accuracy of the model on the 3925 test images: 75.5%\n",
            "Max accuracy: 75.54%\n",
            "Test:  [ 0/82]  eta: 0:02:37  loss: 3.5559 (3.5559)  acc1: 14.5833 (14.5833)  acc5: 79.1667 (79.1667)  time: 1.9156  data: 1.7542  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.5559 (3.5697)  acc1: 10.4167 (9.8485)  acc5: 83.3333 (85.2273)  time: 0.2863  data: 0.1609  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.4121 (3.6364)  acc1: 16.6667 (14.3849)  acc5: 87.5000 (85.8135)  time: 0.1220  data: 0.0012  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 4.1478 (4.1370)  acc1: 14.5833 (11.6935)  acc5: 79.1667 (75.4032)  time: 0.1407  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 5.1030 (4.3619)  acc1: 4.1667 (10.7215)  acc5: 54.1667 (70.9858)  time: 0.1607  data: 0.0024  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.9001 (4.4507)  acc1: 8.3333 (12.3366)  acc5: 56.2500 (69.2402)  time: 0.1642  data: 0.0106  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.7919 (4.5798)  acc1: 4.1667 (10.6216)  acc5: 56.2500 (67.0424)  time: 0.1794  data: 0.0324  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6560 (4.4987)  acc1: 2.0833 (12.7641)  acc5: 75.0000 (66.6080)  time: 0.1753  data: 0.0340  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.2059 (4.1414)  acc1: 47.9167 (20.1132)  acc5: 93.7500 (70.1389)  time: 0.1390  data: 0.0121  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.0954 (4.1116)  acc1: 54.1667 (20.6624)  acc5: 93.7500 (70.3185)  time: 0.1305  data: 0.0054  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1767 s / it)\n",
            "* Acc@1 20.662 Acc@5 70.318 loss 4.112\n",
            "Accuracy of the model EMA on 3925 test images: 20.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [48]  [  0/295]  eta: 0:10:13  lr: 0.002908  min_lr: 0.002908  loss: 3.1985 (3.1985)  weight_decay: 0.0500 (0.0500)  time: 2.0783  data: 1.7125  max mem: 3500\n",
            "Epoch: [48]  [ 10/295]  eta: 0:02:02  lr: 0.002906  min_lr: 0.002906  loss: 3.2757 (3.2544)  weight_decay: 0.0500 (0.0500)  time: 0.4307  data: 0.1562  max mem: 3500\n",
            "Epoch: [48]  [ 20/295]  eta: 0:01:36  lr: 0.002903  min_lr: 0.002903  loss: 3.3356 (3.2744)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0008  max mem: 3500\n",
            "Epoch: [48]  [ 30/295]  eta: 0:01:25  lr: 0.002902  min_lr: 0.002902  loss: 3.3247 (3.2836)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0010  max mem: 3500\n",
            "Epoch: [48]  [ 40/295]  eta: 0:01:19  lr: 0.002899  min_lr: 0.002899  loss: 3.3247 (3.2947)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0017  max mem: 3500\n",
            "Epoch: [48]  [ 50/295]  eta: 0:01:14  lr: 0.002897  min_lr: 0.002897  loss: 3.3165 (3.2861)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0023  max mem: 3500\n",
            "Epoch: [48]  [ 60/295]  eta: 0:01:10  lr: 0.002894  min_lr: 0.002894  loss: 3.0992 (3.2535)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0021  max mem: 3500\n",
            "Epoch: [48]  [ 70/295]  eta: 0:01:05  lr: 0.002892  min_lr: 0.002892  loss: 3.1475 (3.2483)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0017  max mem: 3500\n",
            "Epoch: [48]  [ 80/295]  eta: 0:01:02  lr: 0.002889  min_lr: 0.002889  loss: 3.3278 (3.2535)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0009  max mem: 3500\n",
            "Epoch: [48]  [ 90/295]  eta: 0:00:58  lr: 0.002887  min_lr: 0.002887  loss: 3.2831 (3.2551)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0005  max mem: 3500\n",
            "Epoch: [48]  [100/295]  eta: 0:00:55  lr: 0.002884  min_lr: 0.002884  loss: 3.2804 (3.2541)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0021  max mem: 3500\n",
            "Epoch: [48]  [110/295]  eta: 0:00:52  lr: 0.002882  min_lr: 0.002882  loss: 3.2020 (3.2473)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0037  max mem: 3500\n",
            "Epoch: [48]  [120/295]  eta: 0:00:49  lr: 0.002879  min_lr: 0.002879  loss: 3.3138 (3.2651)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0032  max mem: 3500\n",
            "Epoch: [48]  [130/295]  eta: 0:00:46  lr: 0.002877  min_lr: 0.002877  loss: 3.3468 (3.2609)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0018  max mem: 3500\n",
            "Epoch: [48]  [140/295]  eta: 0:00:43  lr: 0.002875  min_lr: 0.002875  loss: 3.1780 (3.2585)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0012  max mem: 3500\n",
            "Epoch: [48]  [150/295]  eta: 0:00:40  lr: 0.002873  min_lr: 0.002873  loss: 3.2035 (3.2565)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0012  max mem: 3500\n",
            "Epoch: [48]  [160/295]  eta: 0:00:37  lr: 0.002870  min_lr: 0.002870  loss: 3.2761 (3.2576)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0014  max mem: 3500\n",
            "Epoch: [48]  [170/295]  eta: 0:00:34  lr: 0.002868  min_lr: 0.002868  loss: 3.2447 (3.2492)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0017  max mem: 3500\n",
            "Epoch: [48]  [180/295]  eta: 0:00:31  lr: 0.002865  min_lr: 0.002865  loss: 3.1400 (3.2465)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0028  max mem: 3500\n",
            "Epoch: [48]  [190/295]  eta: 0:00:28  lr: 0.002863  min_lr: 0.002863  loss: 3.1810 (3.2421)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0031  max mem: 3500\n",
            "Epoch: [48]  [200/295]  eta: 0:00:26  lr: 0.002860  min_lr: 0.002860  loss: 3.2001 (3.2428)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0014  max mem: 3500\n",
            "Epoch: [48]  [210/295]  eta: 0:00:23  lr: 0.002858  min_lr: 0.002858  loss: 3.3564 (3.2472)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0006  max mem: 3500\n",
            "Epoch: [48]  [220/295]  eta: 0:00:20  lr: 0.002855  min_lr: 0.002855  loss: 3.3091 (3.2462)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0005  max mem: 3500\n",
            "Epoch: [48]  [230/295]  eta: 0:00:17  lr: 0.002853  min_lr: 0.002853  loss: 3.2755 (3.2460)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0008  max mem: 3500\n",
            "Epoch: [48]  [240/295]  eta: 0:00:15  lr: 0.002850  min_lr: 0.002850  loss: 3.2670 (3.2470)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0016  max mem: 3500\n",
            "Epoch: [48]  [250/295]  eta: 0:00:12  lr: 0.002848  min_lr: 0.002848  loss: 3.2760 (3.2479)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0022  max mem: 3500\n",
            "Epoch: [48]  [260/295]  eta: 0:00:09  lr: 0.002845  min_lr: 0.002845  loss: 3.2324 (3.2439)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0018  max mem: 3500\n",
            "Epoch: [48]  [270/295]  eta: 0:00:06  lr: 0.002843  min_lr: 0.002843  loss: 3.1825 (3.2439)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0015  max mem: 3500\n",
            "Epoch: [48]  [280/295]  eta: 0:00:04  lr: 0.002841  min_lr: 0.002841  loss: 3.2578 (3.2476)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0011  max mem: 3500\n",
            "Epoch: [48]  [290/295]  eta: 0:00:01  lr: 0.002839  min_lr: 0.002839  loss: 3.2285 (3.2452)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0003  max mem: 3500\n",
            "Epoch: [48]  [294/295]  eta: 0:00:00  lr: 0.002839  min_lr: 0.002839  loss: 3.2285 (3.2443)  weight_decay: 0.0500 (0.0500)  time: 0.2231  data: 0.0002  max mem: 3500\n",
            "Epoch: [48] Total time: 0:01:19 (0.2708 s / it)\n",
            "Averaged stats: lr: 0.002839  min_lr: 0.002839  loss: 3.2285 (3.2443)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:05:10  loss: 0.6403 (0.6403)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 3.7836  data: 3.6153  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:34  loss: 0.6403 (0.7470)  acc1: 89.5833 (86.9318)  acc5: 97.9167 (97.7273)  time: 0.4828  data: 0.3319  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:20  loss: 0.9236 (0.8671)  acc1: 83.3333 (83.2341)  acc5: 97.9167 (98.3135)  time: 0.1521  data: 0.0107  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 1.0308 (1.1640)  acc1: 75.0000 (70.1613)  acc5: 95.8333 (96.3038)  time: 0.1362  data: 0.0107  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.9591 (1.0921)  acc1: 75.0000 (73.0691)  acc5: 95.8333 (96.7988)  time: 0.1213  data: 0.0037  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8985 (1.0996)  acc1: 81.2500 (73.6111)  acc5: 97.9167 (96.8137)  time: 0.1236  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9867 (1.0791)  acc1: 75.0000 (74.3169)  acc5: 97.9167 (97.0287)  time: 0.1254  data: 0.0034  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.1631 (1.1072)  acc1: 70.8333 (73.1514)  acc5: 97.9167 (96.8897)  time: 0.1218  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1631 (1.0863)  acc1: 70.8333 (73.7654)  acc5: 95.8333 (96.8621)  time: 0.1180  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1631 (1.0872)  acc1: 70.8333 (73.7325)  acc5: 95.8333 (96.7643)  time: 0.1165  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1780 s / it)\n",
            "* Acc@1 73.732 Acc@5 96.764 loss 1.087\n",
            "Accuracy of the model on the 3925 test images: 73.7%\n",
            "Max accuracy: 75.54%\n",
            "Test:  [ 0/82]  eta: 0:02:36  loss: 3.5063 (3.5063)  acc1: 12.5000 (12.5000)  acc5: 79.1667 (79.1667)  time: 1.9114  data: 1.7341  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.5063 (3.5316)  acc1: 10.4167 (9.4697)  acc5: 85.4167 (85.7955)  time: 0.3025  data: 0.1625  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 3.3718 (3.6018)  acc1: 16.6667 (14.2857)  acc5: 87.5000 (86.3095)  time: 0.1626  data: 0.0205  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.1164 (4.1079)  acc1: 16.6667 (11.6935)  acc5: 79.1667 (75.8737)  time: 0.1877  data: 0.0472  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 5.0313 (4.3263)  acc1: 4.1667 (10.6707)  acc5: 54.1667 (71.5447)  time: 0.1913  data: 0.0528  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.9091 (4.4271)  acc1: 8.3333 (12.1324)  acc5: 54.1667 (69.6078)  time: 0.1725  data: 0.0248  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.8240 (4.5560)  acc1: 4.1667 (10.4167)  acc5: 54.1667 (67.4522)  time: 0.1427  data: 0.0038  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6426 (4.4695)  acc1: 0.0000 (12.7054)  acc5: 75.0000 (66.9601)  time: 0.1280  data: 0.0025  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.1336 (4.1110)  acc1: 47.9167 (20.1646)  acc5: 95.8333 (70.4990)  time: 0.1218  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 2.0217 (4.0813)  acc1: 56.2500 (20.7134)  acc5: 95.8333 (70.6752)  time: 0.1192  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1801 s / it)\n",
            "* Acc@1 20.713 Acc@5 70.675 loss 4.081\n",
            "Accuracy of the model EMA on 3925 test images: 20.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [49]  [  0/295]  eta: 0:09:32  lr: 0.002838  min_lr: 0.002838  loss: 3.2091 (3.2091)  weight_decay: 0.0500 (0.0500)  time: 1.9391  data: 1.5805  max mem: 3500\n",
            "Epoch: [49]  [ 10/295]  eta: 0:02:00  lr: 0.002836  min_lr: 0.002836  loss: 3.2134 (3.2083)  weight_decay: 0.0500 (0.0500)  time: 0.4237  data: 0.1450  max mem: 3500\n",
            "Epoch: [49]  [ 20/295]  eta: 0:01:36  lr: 0.002833  min_lr: 0.002833  loss: 3.1869 (3.1746)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0023  max mem: 3500\n",
            "Epoch: [49]  [ 30/295]  eta: 0:01:26  lr: 0.002831  min_lr: 0.002831  loss: 3.1869 (3.1865)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0035  max mem: 3500\n",
            "Epoch: [49]  [ 40/295]  eta: 0:01:19  lr: 0.002828  min_lr: 0.002828  loss: 3.2221 (3.2082)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0045  max mem: 3500\n",
            "Epoch: [49]  [ 50/295]  eta: 0:01:14  lr: 0.002826  min_lr: 0.002826  loss: 3.2575 (3.2176)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0027  max mem: 3500\n",
            "Epoch: [49]  [ 60/295]  eta: 0:01:09  lr: 0.002823  min_lr: 0.002823  loss: 3.2156 (3.2178)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0010  max mem: 3500\n",
            "Epoch: [49]  [ 70/295]  eta: 0:01:05  lr: 0.002821  min_lr: 0.002821  loss: 3.2156 (3.2118)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0015  max mem: 3500\n",
            "Epoch: [49]  [ 80/295]  eta: 0:01:01  lr: 0.002818  min_lr: 0.002818  loss: 3.2397 (3.2151)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0017  max mem: 3500\n",
            "Epoch: [49]  [ 90/295]  eta: 0:00:58  lr: 0.002816  min_lr: 0.002816  loss: 3.2340 (3.2078)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0028  max mem: 3500\n",
            "Epoch: [49]  [100/295]  eta: 0:00:55  lr: 0.002813  min_lr: 0.002813  loss: 3.0787 (3.2083)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0031  max mem: 3500\n",
            "Epoch: [49]  [110/295]  eta: 0:00:52  lr: 0.002811  min_lr: 0.002811  loss: 3.2452 (3.2107)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0032  max mem: 3500\n",
            "Epoch: [49]  [120/295]  eta: 0:00:49  lr: 0.002808  min_lr: 0.002808  loss: 3.2646 (3.2152)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0019  max mem: 3500\n",
            "Epoch: [49]  [130/295]  eta: 0:00:46  lr: 0.002806  min_lr: 0.002806  loss: 3.1777 (3.2097)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0012  max mem: 3500\n",
            "Epoch: [49]  [140/295]  eta: 0:00:43  lr: 0.002803  min_lr: 0.002803  loss: 3.1777 (3.2101)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0016  max mem: 3500\n",
            "Epoch: [49]  [150/295]  eta: 0:00:40  lr: 0.002801  min_lr: 0.002801  loss: 3.2543 (3.2116)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0015  max mem: 3500\n",
            "Epoch: [49]  [160/295]  eta: 0:00:37  lr: 0.002798  min_lr: 0.002798  loss: 3.2694 (3.2130)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0030  max mem: 3500\n",
            "Epoch: [49]  [170/295]  eta: 0:00:34  lr: 0.002796  min_lr: 0.002796  loss: 3.2736 (3.2205)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0031  max mem: 3500\n",
            "Epoch: [49]  [180/295]  eta: 0:00:31  lr: 0.002793  min_lr: 0.002793  loss: 3.3684 (3.2233)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0030  max mem: 3500\n",
            "Epoch: [49]  [190/295]  eta: 0:00:28  lr: 0.002791  min_lr: 0.002791  loss: 3.2351 (3.2240)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0029  max mem: 3500\n",
            "Epoch: [49]  [200/295]  eta: 0:00:26  lr: 0.002788  min_lr: 0.002788  loss: 3.2501 (3.2264)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0017  max mem: 3500\n",
            "Epoch: [49]  [210/295]  eta: 0:00:23  lr: 0.002786  min_lr: 0.002786  loss: 3.2915 (3.2285)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0023  max mem: 3500\n",
            "Epoch: [49]  [220/295]  eta: 0:00:20  lr: 0.002784  min_lr: 0.002784  loss: 3.2915 (3.2320)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0032  max mem: 3500\n",
            "Epoch: [49]  [230/295]  eta: 0:00:17  lr: 0.002782  min_lr: 0.002782  loss: 3.3495 (3.2371)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0041  max mem: 3500\n",
            "Epoch: [49]  [240/295]  eta: 0:00:15  lr: 0.002779  min_lr: 0.002779  loss: 3.3746 (3.2417)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0056  max mem: 3500\n",
            "Epoch: [49]  [250/295]  eta: 0:00:12  lr: 0.002777  min_lr: 0.002777  loss: 3.2756 (3.2400)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0041  max mem: 3500\n",
            "Epoch: [49]  [260/295]  eta: 0:00:09  lr: 0.002774  min_lr: 0.002774  loss: 3.2756 (3.2431)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0022  max mem: 3500\n",
            "Epoch: [49]  [270/295]  eta: 0:00:06  lr: 0.002772  min_lr: 0.002772  loss: 3.3195 (3.2413)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0019  max mem: 3500\n",
            "Epoch: [49]  [280/295]  eta: 0:00:04  lr: 0.002769  min_lr: 0.002769  loss: 3.2071 (3.2417)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0008  max mem: 3500\n",
            "Epoch: [49]  [290/295]  eta: 0:00:01  lr: 0.002767  min_lr: 0.002767  loss: 3.3078 (3.2428)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0004  max mem: 3500\n",
            "Epoch: [49]  [294/295]  eta: 0:00:00  lr: 0.002767  min_lr: 0.002767  loss: 3.2133 (3.2424)  weight_decay: 0.0500 (0.0500)  time: 0.2217  data: 0.0002  max mem: 3500\n",
            "Epoch: [49] Total time: 0:01:19 (0.2702 s / it)\n",
            "Averaged stats: lr: 0.002767  min_lr: 0.002767  loss: 3.2133 (3.2424)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:33  loss: 0.6268 (0.6268)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 2.6051  data: 2.4380  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.6268 (0.7350)  acc1: 89.5833 (87.5000)  acc5: 95.8333 (96.7803)  time: 0.3728  data: 0.2472  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.8502 (0.8461)  acc1: 81.2500 (83.3333)  acc5: 97.9167 (97.2222)  time: 0.1382  data: 0.0158  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 1.0451 (1.1187)  acc1: 72.9167 (71.1022)  acc5: 95.8333 (96.6398)  time: 0.1282  data: 0.0055  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.0620 (1.0913)  acc1: 70.8333 (72.9675)  acc5: 95.8333 (96.9004)  time: 0.1265  data: 0.0059  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 1.0214 (1.1496)  acc1: 79.1667 (71.4461)  acc5: 95.8333 (96.1601)  time: 0.1247  data: 0.0069  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.1310 (1.1298)  acc1: 72.9167 (72.5068)  acc5: 95.8333 (96.1407)  time: 0.1233  data: 0.0068  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.2265 (1.1562)  acc1: 66.6667 (71.5962)  acc5: 95.8333 (95.9507)  time: 0.1192  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1426 (1.1100)  acc1: 72.9167 (73.3025)  acc5: 97.9167 (96.2963)  time: 0.1176  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1236 (1.1069)  acc1: 72.9167 (73.3503)  acc5: 97.9167 (96.2548)  time: 0.1164  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1626 s / it)\n",
            "* Acc@1 73.350 Acc@5 96.255 loss 1.107\n",
            "Accuracy of the model on the 3925 test images: 73.4%\n",
            "Max accuracy: 75.54%\n",
            "Test:  [ 0/82]  eta: 0:04:22  loss: 3.4512 (3.4512)  acc1: 10.4167 (10.4167)  acc5: 85.4167 (85.4167)  time: 3.1972  data: 2.9351  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 3.4512 (3.4890)  acc1: 10.4167 (9.6591)  acc5: 85.4167 (86.3636)  time: 0.4527  data: 0.2967  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.3582 (3.5678)  acc1: 16.6667 (14.1865)  acc5: 87.5000 (86.9048)  time: 0.1575  data: 0.0186  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 4.0946 (4.0791)  acc1: 16.6667 (11.6935)  acc5: 81.2500 (76.2097)  time: 0.1374  data: 0.0113  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.9732 (4.2933)  acc1: 4.1667 (10.7215)  acc5: 54.1667 (71.8496)  time: 0.1311  data: 0.0103  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.8819 (4.4052)  acc1: 10.4167 (12.0098)  acc5: 54.1667 (69.5261)  time: 0.1247  data: 0.0043  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.8507 (4.5343)  acc1: 2.0833 (10.2459)  acc5: 52.0833 (67.4863)  time: 0.1252  data: 0.0056  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6353 (4.4421)  acc1: 0.0000 (12.7054)  acc5: 75.0000 (67.0775)  time: 0.1222  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 2.0631 (4.0822)  acc1: 47.9167 (20.2161)  acc5: 95.8333 (70.6276)  time: 0.1189  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.9518 (4.0525)  acc1: 56.2500 (20.7643)  acc5: 95.8333 (70.8026)  time: 0.1172  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1747 s / it)\n",
            "* Acc@1 20.764 Acc@5 70.803 loss 4.053\n",
            "Accuracy of the model EMA on 3925 test images: 20.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [50]  [  0/295]  eta: 0:08:16  lr: 0.002766  min_lr: 0.002766  loss: 3.5730 (3.5730)  weight_decay: 0.0500 (0.0500)  time: 1.6828  data: 1.2766  max mem: 3500\n",
            "Epoch: [50]  [ 10/295]  eta: 0:02:09  lr: 0.002764  min_lr: 0.002764  loss: 3.2815 (3.2968)  weight_decay: 0.0500 (0.0500)  time: 0.4529  data: 0.1176  max mem: 3500\n",
            "Epoch: [50]  [ 20/295]  eta: 0:01:41  lr: 0.002761  min_lr: 0.002761  loss: 3.2764 (3.2850)  weight_decay: 0.0500 (0.0500)  time: 0.3015  data: 0.0033  max mem: 3500\n",
            "Epoch: [50]  [ 30/295]  eta: 0:01:28  lr: 0.002759  min_lr: 0.002759  loss: 3.2390 (3.2792)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0047  max mem: 3500\n",
            "Epoch: [50]  [ 40/295]  eta: 0:01:20  lr: 0.002756  min_lr: 0.002756  loss: 3.3545 (3.3031)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0029  max mem: 3500\n",
            "Epoch: [50]  [ 50/295]  eta: 0:01:15  lr: 0.002754  min_lr: 0.002754  loss: 3.3358 (3.3014)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0009  max mem: 3500\n",
            "Epoch: [50]  [ 60/295]  eta: 0:01:10  lr: 0.002751  min_lr: 0.002751  loss: 3.2495 (3.2763)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0017  max mem: 3500\n",
            "Epoch: [50]  [ 70/295]  eta: 0:01:06  lr: 0.002749  min_lr: 0.002749  loss: 3.1738 (3.2659)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0023  max mem: 3500\n",
            "Epoch: [50]  [ 80/295]  eta: 0:01:02  lr: 0.002746  min_lr: 0.002746  loss: 3.0851 (3.2473)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0009  max mem: 3500\n",
            "Epoch: [50]  [ 90/295]  eta: 0:00:59  lr: 0.002744  min_lr: 0.002744  loss: 3.0851 (3.2367)  weight_decay: 0.0500 (0.0500)  time: 0.2789  data: 0.0018  max mem: 3500\n",
            "Epoch: [50]  [100/295]  eta: 0:00:56  lr: 0.002741  min_lr: 0.002741  loss: 3.1866 (3.2396)  weight_decay: 0.0500 (0.0500)  time: 0.2792  data: 0.0035  max mem: 3500\n",
            "Epoch: [50]  [110/295]  eta: 0:00:53  lr: 0.002739  min_lr: 0.002739  loss: 3.3240 (3.2487)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0037  max mem: 3500\n",
            "Epoch: [50]  [120/295]  eta: 0:00:50  lr: 0.002736  min_lr: 0.002736  loss: 3.3011 (3.2466)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0024  max mem: 3500\n",
            "Epoch: [50]  [130/295]  eta: 0:00:46  lr: 0.002734  min_lr: 0.002734  loss: 3.2778 (3.2466)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0014  max mem: 3500\n",
            "Epoch: [50]  [140/295]  eta: 0:00:43  lr: 0.002731  min_lr: 0.002731  loss: 3.2542 (3.2450)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0017  max mem: 3500\n",
            "Epoch: [50]  [150/295]  eta: 0:00:40  lr: 0.002729  min_lr: 0.002729  loss: 3.2542 (3.2498)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0022  max mem: 3500\n",
            "Epoch: [50]  [160/295]  eta: 0:00:37  lr: 0.002726  min_lr: 0.002726  loss: 3.2971 (3.2461)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0032  max mem: 3500\n",
            "Epoch: [50]  [170/295]  eta: 0:00:35  lr: 0.002724  min_lr: 0.002724  loss: 3.2064 (3.2411)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0043  max mem: 3500\n",
            "Epoch: [50]  [180/295]  eta: 0:00:32  lr: 0.002721  min_lr: 0.002721  loss: 3.2390 (3.2453)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0045  max mem: 3500\n",
            "Epoch: [50]  [190/295]  eta: 0:00:29  lr: 0.002719  min_lr: 0.002719  loss: 3.2390 (3.2424)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0022  max mem: 3500\n",
            "Epoch: [50]  [200/295]  eta: 0:00:26  lr: 0.002716  min_lr: 0.002716  loss: 3.2079 (3.2394)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0012  max mem: 3500\n",
            "Epoch: [50]  [210/295]  eta: 0:00:23  lr: 0.002714  min_lr: 0.002714  loss: 3.3152 (3.2408)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0024  max mem: 3500\n",
            "Epoch: [50]  [220/295]  eta: 0:00:20  lr: 0.002711  min_lr: 0.002711  loss: 3.2681 (3.2410)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0019  max mem: 3500\n",
            "Epoch: [50]  [230/295]  eta: 0:00:17  lr: 0.002709  min_lr: 0.002709  loss: 3.2058 (3.2389)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0026  max mem: 3500\n",
            "Epoch: [50]  [240/295]  eta: 0:00:15  lr: 0.002706  min_lr: 0.002706  loss: 3.2361 (3.2419)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0035  max mem: 3500\n",
            "Epoch: [50]  [250/295]  eta: 0:00:12  lr: 0.002704  min_lr: 0.002704  loss: 3.3534 (3.2426)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0034  max mem: 3500\n",
            "Epoch: [50]  [260/295]  eta: 0:00:09  lr: 0.002701  min_lr: 0.002701  loss: 3.2859 (3.2456)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0029  max mem: 3500\n",
            "Epoch: [50]  [270/295]  eta: 0:00:06  lr: 0.002699  min_lr: 0.002699  loss: 3.3289 (3.2468)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0025  max mem: 3500\n",
            "Epoch: [50]  [280/295]  eta: 0:00:04  lr: 0.002696  min_lr: 0.002696  loss: 3.3361 (3.2507)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0016  max mem: 3500\n",
            "Epoch: [50]  [290/295]  eta: 0:00:01  lr: 0.002694  min_lr: 0.002694  loss: 3.2594 (3.2509)  weight_decay: 0.0500 (0.0500)  time: 0.2576  data: 0.0003  max mem: 3500\n",
            "Epoch: [50]  [294/295]  eta: 0:00:00  lr: 0.002694  min_lr: 0.002694  loss: 3.2517 (3.2492)  weight_decay: 0.0500 (0.0500)  time: 0.2201  data: 0.0003  max mem: 3500\n",
            "Epoch: [50] Total time: 0:01:20 (0.2721 s / it)\n",
            "Averaged stats: lr: 0.002694  min_lr: 0.002694  loss: 3.2517 (3.2492)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:16  loss: 0.9241 (0.9241)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 2.3975  data: 2.2354  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.8694 (0.8907)  acc1: 85.4167 (84.2803)  acc5: 97.9167 (96.5909)  time: 0.3790  data: 0.2553  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.8147 (0.8427)  acc1: 85.4167 (85.6151)  acc5: 97.9167 (97.6190)  time: 0.1499  data: 0.0295  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8973 (1.0672)  acc1: 79.1667 (75.0672)  acc5: 97.9167 (97.2446)  time: 0.1237  data: 0.0025  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8654 (0.9936)  acc1: 79.1667 (77.4390)  acc5: 97.9167 (97.5610)  time: 0.1237  data: 0.0026  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8111 (0.9851)  acc1: 83.3333 (78.0229)  acc5: 97.9167 (97.7124)  time: 0.1233  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9830 (1.0115)  acc1: 79.1667 (76.8443)  acc5: 97.9167 (97.5410)  time: 0.1257  data: 0.0046  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 1.4093 (1.0761)  acc1: 58.3333 (74.0610)  acc5: 97.9167 (97.2124)  time: 0.1224  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3348 (1.0645)  acc1: 60.4167 (74.5628)  acc5: 97.9167 (97.2737)  time: 0.1177  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2924 (1.0652)  acc1: 62.5000 (74.5478)  acc5: 97.9167 (97.2484)  time: 0.1167  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1637 s / it)\n",
            "* Acc@1 74.548 Acc@5 97.248 loss 1.065\n",
            "Accuracy of the model on the 3925 test images: 74.5%\n",
            "Max accuracy: 75.54%\n",
            "Test:  [ 0/82]  eta: 0:03:58  loss: 3.4054 (3.4054)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 2.9080  data: 2.7407  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 3.4054 (3.4539)  acc1: 10.4167 (9.8485)  acc5: 87.5000 (87.1212)  time: 0.4152  data: 0.2675  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 3.3460 (3.5384)  acc1: 14.5833 (13.7897)  acc5: 87.5000 (87.6984)  time: 0.1806  data: 0.0355  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 4.0750 (4.0555)  acc1: 14.5833 (11.3575)  acc5: 81.2500 (76.6801)  time: 0.1604  data: 0.0268  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.9081 (4.2625)  acc1: 2.0833 (10.3659)  acc5: 56.2500 (72.4085)  time: 0.1264  data: 0.0037  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.8254 (4.3845)  acc1: 10.4167 (11.5605)  acc5: 56.2500 (69.7712)  time: 0.1259  data: 0.0057  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.8743 (4.5140)  acc1: 2.0833 (9.8702)  acc5: 52.0833 (67.6571)  time: 0.1245  data: 0.0061  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.6273 (4.4163)  acc1: 0.0000 (12.4413)  acc5: 75.0000 (67.2829)  time: 0.1220  data: 0.0028  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.9959 (4.0550)  acc1: 47.9167 (19.9846)  acc5: 95.8333 (70.8076)  time: 0.1188  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8831 (4.0253)  acc1: 56.2500 (20.5350)  acc5: 95.8333 (70.9809)  time: 0.1175  data: 0.0003  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1760 s / it)\n",
            "* Acc@1 20.535 Acc@5 70.981 loss 4.025\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [51]  [  0/295]  eta: 0:10:37  lr: 0.002693  min_lr: 0.002693  loss: 3.0215 (3.0215)  weight_decay: 0.0500 (0.0500)  time: 2.1620  data: 1.7320  max mem: 3500\n",
            "Epoch: [51]  [ 10/295]  eta: 0:02:10  lr: 0.002691  min_lr: 0.002691  loss: 3.2765 (3.2436)  weight_decay: 0.0500 (0.0500)  time: 0.4575  data: 0.1594  max mem: 3500\n",
            "Epoch: [51]  [ 20/295]  eta: 0:01:41  lr: 0.002688  min_lr: 0.002688  loss: 3.2054 (3.2405)  weight_decay: 0.0500 (0.0500)  time: 0.2801  data: 0.0022  max mem: 3500\n",
            "Epoch: [51]  [ 30/295]  eta: 0:01:29  lr: 0.002685  min_lr: 0.002685  loss: 3.2584 (3.2455)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0024  max mem: 3500\n",
            "Epoch: [51]  [ 40/295]  eta: 0:01:21  lr: 0.002682  min_lr: 0.002682  loss: 3.2584 (3.2444)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0016  max mem: 3500\n",
            "Epoch: [51]  [ 50/295]  eta: 0:01:15  lr: 0.002680  min_lr: 0.002680  loss: 3.2538 (3.2527)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0007  max mem: 3500\n",
            "Epoch: [51]  [ 60/295]  eta: 0:01:10  lr: 0.002677  min_lr: 0.002677  loss: 3.2780 (3.2495)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0010  max mem: 3500\n",
            "Epoch: [51]  [ 70/295]  eta: 0:01:06  lr: 0.002675  min_lr: 0.002675  loss: 3.2865 (3.2599)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0017  max mem: 3500\n",
            "Epoch: [51]  [ 80/295]  eta: 0:01:03  lr: 0.002672  min_lr: 0.002672  loss: 3.2590 (3.2456)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0038  max mem: 3500\n",
            "Epoch: [51]  [ 90/295]  eta: 0:00:59  lr: 0.002670  min_lr: 0.002670  loss: 3.2550 (3.2431)  weight_decay: 0.0500 (0.0500)  time: 0.2741  data: 0.0046  max mem: 3500\n",
            "Epoch: [51]  [100/295]  eta: 0:00:56  lr: 0.002667  min_lr: 0.002667  loss: 3.1788 (3.2353)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0027  max mem: 3500\n",
            "Epoch: [51]  [110/295]  eta: 0:00:53  lr: 0.002665  min_lr: 0.002665  loss: 3.1788 (3.2392)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0015  max mem: 3500\n",
            "Epoch: [51]  [120/295]  eta: 0:00:49  lr: 0.002662  min_lr: 0.002662  loss: 3.3478 (3.2493)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0015  max mem: 3500\n",
            "Epoch: [51]  [130/295]  eta: 0:00:46  lr: 0.002660  min_lr: 0.002660  loss: 3.2244 (3.2398)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0011  max mem: 3500\n",
            "Epoch: [51]  [140/295]  eta: 0:00:43  lr: 0.002657  min_lr: 0.002657  loss: 3.0765 (3.2413)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0011  max mem: 3500\n",
            "Epoch: [51]  [150/295]  eta: 0:00:40  lr: 0.002655  min_lr: 0.002655  loss: 3.2061 (3.2424)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0025  max mem: 3500\n",
            "Epoch: [51]  [160/295]  eta: 0:00:37  lr: 0.002652  min_lr: 0.002652  loss: 3.2061 (3.2404)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0026  max mem: 3500\n",
            "Epoch: [51]  [170/295]  eta: 0:00:34  lr: 0.002650  min_lr: 0.002650  loss: 3.1916 (3.2391)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0013  max mem: 3500\n",
            "Epoch: [51]  [180/295]  eta: 0:00:31  lr: 0.002647  min_lr: 0.002647  loss: 3.2688 (3.2448)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0010  max mem: 3500\n",
            "Epoch: [51]  [190/295]  eta: 0:00:29  lr: 0.002645  min_lr: 0.002645  loss: 3.2623 (3.2439)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0015  max mem: 3500\n",
            "Epoch: [51]  [200/295]  eta: 0:00:26  lr: 0.002642  min_lr: 0.002642  loss: 3.2895 (3.2480)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0021  max mem: 3500\n",
            "Epoch: [51]  [210/295]  eta: 0:00:23  lr: 0.002640  min_lr: 0.002640  loss: 3.2897 (3.2489)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0023  max mem: 3500\n",
            "Epoch: [51]  [220/295]  eta: 0:00:20  lr: 0.002637  min_lr: 0.002637  loss: 3.2835 (3.2510)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0024  max mem: 3500\n",
            "Epoch: [51]  [230/295]  eta: 0:00:17  lr: 0.002635  min_lr: 0.002635  loss: 3.2321 (3.2445)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0023  max mem: 3500\n",
            "Epoch: [51]  [240/295]  eta: 0:00:15  lr: 0.002632  min_lr: 0.002632  loss: 3.1916 (3.2450)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0014  max mem: 3500\n",
            "Epoch: [51]  [250/295]  eta: 0:00:12  lr: 0.002630  min_lr: 0.002630  loss: 3.1916 (3.2391)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0010  max mem: 3500\n",
            "Epoch: [51]  [260/295]  eta: 0:00:09  lr: 0.002627  min_lr: 0.002627  loss: 3.0524 (3.2330)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0008  max mem: 3500\n",
            "Epoch: [51]  [270/295]  eta: 0:00:06  lr: 0.002625  min_lr: 0.002625  loss: 3.1447 (3.2329)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0007  max mem: 3500\n",
            "Epoch: [51]  [280/295]  eta: 0:00:04  lr: 0.002621  min_lr: 0.002621  loss: 3.1471 (3.2317)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0014  max mem: 3500\n",
            "Epoch: [51]  [290/295]  eta: 0:00:01  lr: 0.002619  min_lr: 0.002619  loss: 3.0399 (3.2253)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0009  max mem: 3500\n",
            "Epoch: [51]  [294/295]  eta: 0:00:00  lr: 0.002619  min_lr: 0.002619  loss: 3.1032 (3.2256)  weight_decay: 0.0500 (0.0500)  time: 0.2257  data: 0.0002  max mem: 3500\n",
            "Epoch: [51] Total time: 0:01:20 (0.2721 s / it)\n",
            "Averaged stats: lr: 0.002619  min_lr: 0.002619  loss: 3.1032 (3.2256)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:31  loss: 0.9022 (0.9022)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 3.3059  data: 3.1188  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 0.9389 (0.9404)  acc1: 83.3333 (82.5758)  acc5: 95.8333 (96.2121)  time: 0.4204  data: 0.2853  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 0.8768 (0.8966)  acc1: 81.2500 (82.2421)  acc5: 97.9167 (97.3214)  time: 0.1276  data: 0.0040  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.9206 (1.0538)  acc1: 75.0000 (74.2608)  acc5: 97.9167 (97.4462)  time: 0.1238  data: 0.0061  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.9070 (1.0093)  acc1: 75.0000 (76.0671)  acc5: 97.9167 (97.5610)  time: 0.1234  data: 0.0065  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.9586 (1.0788)  acc1: 75.0000 (73.5703)  acc5: 95.8333 (97.0180)  time: 0.1210  data: 0.0050  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9626 (1.0439)  acc1: 72.9167 (75.0000)  acc5: 95.8333 (96.9945)  time: 0.1200  data: 0.0035  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9626 (1.0499)  acc1: 72.9167 (74.3838)  acc5: 95.8333 (96.8897)  time: 0.1204  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9459 (1.0118)  acc1: 75.0000 (75.4115)  acc5: 97.9167 (97.1193)  time: 0.1191  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9363 (1.0106)  acc1: 75.0000 (75.4140)  acc5: 97.9167 (97.0701)  time: 0.1169  data: 0.0004  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1673 s / it)\n",
            "* Acc@1 75.414 Acc@5 97.070 loss 1.011\n",
            "Accuracy of the model on the 3925 test images: 75.4%\n",
            "Max accuracy: 75.54%\n",
            "Test:  [ 0/82]  eta: 0:03:59  loss: 3.3519 (3.3519)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 2.9181  data: 2.7231  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 3.3519 (3.4161)  acc1: 10.4167 (9.0909)  acc5: 89.5833 (88.6364)  time: 0.3834  data: 0.2503  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.3275 (3.5074)  acc1: 14.5833 (13.2937)  acc5: 89.5833 (88.3929)  time: 0.1275  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 4.0500 (4.0287)  acc1: 14.5833 (10.9543)  acc5: 81.2500 (77.1505)  time: 0.1248  data: 0.0032  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.8465 (4.2301)  acc1: 2.0833 (10.0102)  acc5: 54.1667 (72.9167)  time: 0.1244  data: 0.0038  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.8328 (4.3611)  acc1: 10.4167 (11.1928)  acc5: 58.3333 (70.0980)  time: 0.1244  data: 0.0034  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.8959 (4.4898)  acc1: 2.0833 (9.5628)  acc5: 52.0833 (67.8962)  time: 0.1250  data: 0.0036  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.6038 (4.3874)  acc1: 0.0000 (12.2066)  acc5: 75.0000 (67.5176)  time: 0.1223  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.9356 (4.0257)  acc1: 50.0000 (19.8045)  acc5: 95.8333 (71.0648)  time: 0.1191  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.8219 (3.9960)  acc1: 56.2500 (20.3567)  acc5: 95.8333 (71.2357)  time: 0.1179  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1622 s / it)\n",
            "* Acc@1 20.357 Acc@5 71.236 loss 3.996\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [52]  [  0/295]  eta: 0:12:07  lr: 0.002618  min_lr: 0.002618  loss: 3.2129 (3.2129)  weight_decay: 0.0500 (0.0500)  time: 2.4653  data: 1.7830  max mem: 3500\n",
            "Epoch: [52]  [ 10/295]  eta: 0:02:34  lr: 0.002616  min_lr: 0.002616  loss: 3.2259 (3.2446)  weight_decay: 0.0500 (0.0500)  time: 0.5430  data: 0.1636  max mem: 3500\n",
            "Epoch: [52]  [ 20/295]  eta: 0:01:53  lr: 0.002613  min_lr: 0.002613  loss: 3.2504 (3.3131)  weight_decay: 0.0500 (0.0500)  time: 0.3115  data: 0.0016  max mem: 3500\n",
            "Epoch: [52]  [ 30/295]  eta: 0:01:36  lr: 0.002611  min_lr: 0.002611  loss: 3.2797 (3.2876)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0012  max mem: 3500\n",
            "Epoch: [52]  [ 40/295]  eta: 0:01:26  lr: 0.002608  min_lr: 0.002608  loss: 3.3181 (3.3071)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0009  max mem: 3500\n",
            "Epoch: [52]  [ 50/295]  eta: 0:01:19  lr: 0.002606  min_lr: 0.002606  loss: 3.2996 (3.2884)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0011  max mem: 3500\n",
            "Epoch: [52]  [ 60/295]  eta: 0:01:14  lr: 0.002603  min_lr: 0.002603  loss: 3.1605 (3.2677)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0014  max mem: 3500\n",
            "Epoch: [52]  [ 70/295]  eta: 0:01:09  lr: 0.002601  min_lr: 0.002601  loss: 3.2314 (3.2695)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0017  max mem: 3500\n",
            "Epoch: [52]  [ 80/295]  eta: 0:01:05  lr: 0.002598  min_lr: 0.002598  loss: 3.2520 (3.2555)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0020  max mem: 3500\n",
            "Epoch: [52]  [ 90/295]  eta: 0:01:01  lr: 0.002596  min_lr: 0.002596  loss: 3.2093 (3.2524)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0023  max mem: 3500\n",
            "Epoch: [52]  [100/295]  eta: 0:00:57  lr: 0.002593  min_lr: 0.002593  loss: 3.2093 (3.2429)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0020  max mem: 3500\n",
            "Epoch: [52]  [110/295]  eta: 0:00:54  lr: 0.002591  min_lr: 0.002591  loss: 3.0540 (3.2270)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0019  max mem: 3500\n",
            "Epoch: [52]  [120/295]  eta: 0:00:50  lr: 0.002588  min_lr: 0.002588  loss: 3.0814 (3.2242)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0015  max mem: 3500\n",
            "Epoch: [52]  [130/295]  eta: 0:00:47  lr: 0.002586  min_lr: 0.002586  loss: 3.1814 (3.2192)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0015  max mem: 3500\n",
            "Epoch: [52]  [140/295]  eta: 0:00:44  lr: 0.002582  min_lr: 0.002582  loss: 3.2290 (3.2192)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0019  max mem: 3500\n",
            "Epoch: [52]  [150/295]  eta: 0:00:41  lr: 0.002580  min_lr: 0.002580  loss: 3.2338 (3.2194)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0026  max mem: 3500\n",
            "Epoch: [52]  [160/295]  eta: 0:00:38  lr: 0.002577  min_lr: 0.002577  loss: 3.2376 (3.2197)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0036  max mem: 3500\n",
            "Epoch: [52]  [170/295]  eta: 0:00:35  lr: 0.002575  min_lr: 0.002575  loss: 3.1884 (3.2164)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0023  max mem: 3500\n",
            "Epoch: [52]  [180/295]  eta: 0:00:32  lr: 0.002572  min_lr: 0.002572  loss: 3.1705 (3.2151)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0012  max mem: 3500\n",
            "Epoch: [52]  [190/295]  eta: 0:00:29  lr: 0.002570  min_lr: 0.002570  loss: 3.2292 (3.2147)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0015  max mem: 3500\n",
            "Epoch: [52]  [200/295]  eta: 0:00:26  lr: 0.002567  min_lr: 0.002567  loss: 3.2593 (3.2209)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0011  max mem: 3500\n",
            "Epoch: [52]  [210/295]  eta: 0:00:23  lr: 0.002565  min_lr: 0.002565  loss: 3.3070 (3.2217)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0020  max mem: 3500\n",
            "Epoch: [52]  [220/295]  eta: 0:00:20  lr: 0.002562  min_lr: 0.002562  loss: 3.2916 (3.2246)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0027  max mem: 3500\n",
            "Epoch: [52]  [230/295]  eta: 0:00:18  lr: 0.002560  min_lr: 0.002560  loss: 3.2916 (3.2247)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0015  max mem: 3500\n",
            "Epoch: [52]  [240/295]  eta: 0:00:15  lr: 0.002557  min_lr: 0.002557  loss: 3.1437 (3.2209)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0006  max mem: 3500\n",
            "Epoch: [52]  [250/295]  eta: 0:00:12  lr: 0.002555  min_lr: 0.002555  loss: 3.0849 (3.2178)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0014  max mem: 3500\n",
            "Epoch: [52]  [260/295]  eta: 0:00:09  lr: 0.002552  min_lr: 0.002552  loss: 3.1622 (3.2163)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0024  max mem: 3500\n",
            "Epoch: [52]  [270/295]  eta: 0:00:06  lr: 0.002549  min_lr: 0.002549  loss: 3.1304 (3.2133)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0026  max mem: 3500\n",
            "Epoch: [52]  [280/295]  eta: 0:00:04  lr: 0.002546  min_lr: 0.002546  loss: 3.1223 (3.2102)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0022  max mem: 3500\n",
            "Epoch: [52]  [290/295]  eta: 0:00:01  lr: 0.002544  min_lr: 0.002544  loss: 3.1680 (3.2098)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0009  max mem: 3500\n",
            "Epoch: [52]  [294/295]  eta: 0:00:00  lr: 0.002544  min_lr: 0.002544  loss: 3.1680 (3.2093)  weight_decay: 0.0500 (0.0500)  time: 0.2203  data: 0.0002  max mem: 3500\n",
            "Epoch: [52] Total time: 0:01:20 (0.2741 s / it)\n",
            "Averaged stats: lr: 0.002544  min_lr: 0.002544  loss: 3.1680 (3.2093)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:17  loss: 0.6708 (0.6708)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 1.6824  data: 1.5202  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 0.6708 (0.6963)  acc1: 89.5833 (88.0682)  acc5: 97.9167 (98.2955)  time: 0.2680  data: 0.1432  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.7028 (0.7325)  acc1: 87.5000 (86.8056)  acc5: 100.0000 (98.6111)  time: 0.1259  data: 0.0048  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.9120 (0.9742)  acc1: 79.1667 (76.1425)  acc5: 97.9167 (98.1183)  time: 0.1253  data: 0.0024  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.9120 (0.9321)  acc1: 79.1667 (77.3882)  acc5: 97.9167 (98.0183)  time: 0.1347  data: 0.0026  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8428 (0.9471)  acc1: 79.1667 (77.0016)  acc5: 97.9167 (97.9984)  time: 0.1534  data: 0.0024  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9733 (0.9570)  acc1: 72.9167 (76.8443)  acc5: 97.9167 (97.6434)  time: 0.1528  data: 0.0007  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.2875 (1.0176)  acc1: 60.4167 (74.3545)  acc5: 95.8333 (97.1244)  time: 0.1692  data: 0.0311  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1386 (0.9831)  acc1: 66.6667 (75.5144)  acc5: 97.9167 (97.3251)  time: 0.1596  data: 0.0306  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1318 (0.9817)  acc1: 68.7500 (75.5414)  acc5: 97.9167 (97.2994)  time: 0.1438  data: 0.0159  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1686 s / it)\n",
            "* Acc@1 75.541 Acc@5 97.299 loss 0.982\n",
            "Accuracy of the model on the 3925 test images: 75.5%\n",
            "Max accuracy: 75.54%\n",
            "Test:  [ 0/82]  eta: 0:01:52  loss: 3.2969 (3.2969)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 1.3753  data: 1.2651  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.2969 (3.3774)  acc1: 8.3333 (8.9015)  acc5: 89.5833 (89.7727)  time: 0.2819  data: 0.1609  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.3081 (3.4760)  acc1: 14.5833 (12.8968)  acc5: 89.5833 (88.9881)  time: 0.1489  data: 0.0265  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 4.0255 (4.0020)  acc1: 14.5833 (10.4839)  acc5: 81.2500 (77.6882)  time: 0.1240  data: 0.0021  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 4.8387 (4.1971)  acc1: 2.0833 (9.7561)  acc5: 54.1667 (73.3740)  time: 0.1219  data: 0.0025  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.7822 (4.3381)  acc1: 10.4167 (10.9477)  acc5: 60.4167 (70.4248)  time: 0.1237  data: 0.0058  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.9190 (4.4671)  acc1: 2.0833 (9.3579)  acc5: 52.0833 (68.1011)  time: 0.1235  data: 0.0059  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5903 (4.3604)  acc1: 0.0000 (12.0599)  acc5: 75.0000 (67.7523)  time: 0.1198  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.8749 (3.9982)  acc1: 52.0833 (19.7016)  acc5: 95.8333 (71.3220)  time: 0.1184  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.7633 (3.9686)  acc1: 58.3333 (20.2548)  acc5: 95.8333 (71.4904)  time: 0.1165  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1501 s / it)\n",
            "* Acc@1 20.255 Acc@5 71.490 loss 3.969\n",
            "Accuracy of the model EMA on 3925 test images: 20.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [53]  [  0/295]  eta: 0:14:02  lr: 0.002543  min_lr: 0.002543  loss: 3.0056 (3.0056)  weight_decay: 0.0500 (0.0500)  time: 2.8560  data: 2.1790  max mem: 3500\n",
            "Epoch: [53]  [ 10/295]  eta: 0:02:36  lr: 0.002541  min_lr: 0.002541  loss: 3.0221 (3.1471)  weight_decay: 0.0500 (0.0500)  time: 0.5475  data: 0.2003  max mem: 3500\n",
            "Epoch: [53]  [ 20/295]  eta: 0:01:52  lr: 0.002538  min_lr: 0.002538  loss: 3.1350 (3.1515)  weight_decay: 0.0500 (0.0500)  time: 0.2886  data: 0.0020  max mem: 3500\n",
            "Epoch: [53]  [ 30/295]  eta: 0:01:36  lr: 0.002536  min_lr: 0.002536  loss: 3.1066 (3.1437)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0014  max mem: 3500\n",
            "Epoch: [53]  [ 40/295]  eta: 0:01:26  lr: 0.002533  min_lr: 0.002533  loss: 3.2212 (3.1628)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0012  max mem: 3500\n",
            "Epoch: [53]  [ 50/295]  eta: 0:01:19  lr: 0.002531  min_lr: 0.002531  loss: 3.2712 (3.1874)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0019  max mem: 3500\n",
            "Epoch: [53]  [ 60/295]  eta: 0:01:14  lr: 0.002528  min_lr: 0.002528  loss: 3.2800 (3.1902)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0022  max mem: 3500\n",
            "Epoch: [53]  [ 70/295]  eta: 0:01:09  lr: 0.002526  min_lr: 0.002526  loss: 3.2072 (3.1888)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0018  max mem: 3500\n",
            "Epoch: [53]  [ 80/295]  eta: 0:01:05  lr: 0.002523  min_lr: 0.002523  loss: 3.2072 (3.1990)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0014  max mem: 3500\n",
            "Epoch: [53]  [ 90/295]  eta: 0:01:01  lr: 0.002520  min_lr: 0.002520  loss: 3.2671 (3.2135)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0024  max mem: 3500\n",
            "Epoch: [53]  [100/295]  eta: 0:00:58  lr: 0.002517  min_lr: 0.002517  loss: 3.2261 (3.2131)  weight_decay: 0.0500 (0.0500)  time: 0.2760  data: 0.0034  max mem: 3500\n",
            "Epoch: [53]  [110/295]  eta: 0:00:54  lr: 0.002515  min_lr: 0.002515  loss: 3.0935 (3.1996)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0034  max mem: 3500\n",
            "Epoch: [53]  [120/295]  eta: 0:00:51  lr: 0.002512  min_lr: 0.002512  loss: 3.1816 (3.2044)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0038  max mem: 3500\n",
            "Epoch: [53]  [130/295]  eta: 0:00:48  lr: 0.002510  min_lr: 0.002510  loss: 3.2642 (3.2045)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0030  max mem: 3500\n",
            "Epoch: [53]  [140/295]  eta: 0:00:45  lr: 0.002507  min_lr: 0.002507  loss: 3.2150 (3.2051)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0022  max mem: 3500\n",
            "Epoch: [53]  [150/295]  eta: 0:00:41  lr: 0.002505  min_lr: 0.002505  loss: 3.1836 (3.2055)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0017  max mem: 3500\n",
            "Epoch: [53]  [160/295]  eta: 0:00:38  lr: 0.002502  min_lr: 0.002502  loss: 3.1772 (3.2053)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0015  max mem: 3500\n",
            "Epoch: [53]  [170/295]  eta: 0:00:35  lr: 0.002500  min_lr: 0.002500  loss: 3.1187 (3.1993)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0013  max mem: 3500\n",
            "Epoch: [53]  [180/295]  eta: 0:00:32  lr: 0.002497  min_lr: 0.002497  loss: 3.1145 (3.2023)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0015  max mem: 3500\n",
            "Epoch: [53]  [190/295]  eta: 0:00:29  lr: 0.002494  min_lr: 0.002494  loss: 3.1008 (3.1956)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0021  max mem: 3500\n",
            "Epoch: [53]  [200/295]  eta: 0:00:26  lr: 0.002491  min_lr: 0.002491  loss: 3.0712 (3.1952)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0024  max mem: 3500\n",
            "Epoch: [53]  [210/295]  eta: 0:00:23  lr: 0.002489  min_lr: 0.002489  loss: 3.2665 (3.1961)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0014  max mem: 3500\n",
            "Epoch: [53]  [220/295]  eta: 0:00:21  lr: 0.002486  min_lr: 0.002486  loss: 3.3075 (3.2001)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0007  max mem: 3500\n",
            "Epoch: [53]  [230/295]  eta: 0:00:18  lr: 0.002484  min_lr: 0.002484  loss: 3.1718 (3.1968)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0012  max mem: 3500\n",
            "Epoch: [53]  [240/295]  eta: 0:00:15  lr: 0.002481  min_lr: 0.002481  loss: 3.1512 (3.1994)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0008  max mem: 3500\n",
            "Epoch: [53]  [250/295]  eta: 0:00:12  lr: 0.002479  min_lr: 0.002479  loss: 3.2866 (3.2019)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0015  max mem: 3500\n",
            "Epoch: [53]  [260/295]  eta: 0:00:09  lr: 0.002476  min_lr: 0.002476  loss: 3.1287 (3.1997)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0029  max mem: 3500\n",
            "Epoch: [53]  [270/295]  eta: 0:00:06  lr: 0.002474  min_lr: 0.002474  loss: 3.0926 (3.1967)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0027  max mem: 3500\n",
            "Epoch: [53]  [280/295]  eta: 0:00:04  lr: 0.002470  min_lr: 0.002470  loss: 3.0862 (3.1935)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0013  max mem: 3500\n",
            "Epoch: [53]  [290/295]  eta: 0:00:01  lr: 0.002468  min_lr: 0.002468  loss: 3.0768 (3.1921)  weight_decay: 0.0500 (0.0500)  time: 0.2570  data: 0.0002  max mem: 3500\n",
            "Epoch: [53]  [294/295]  eta: 0:00:00  lr: 0.002468  min_lr: 0.002468  loss: 3.0872 (3.1924)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0002  max mem: 3500\n",
            "Epoch: [53] Total time: 0:01:21 (0.2747 s / it)\n",
            "Averaged stats: lr: 0.002468  min_lr: 0.002468  loss: 3.0872 (3.1924)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:10  loss: 0.7042 (0.7042)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 1.5916  data: 1.4294  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.6676 (0.7139)  acc1: 87.5000 (87.1212)  acc5: 97.9167 (97.1591)  time: 0.3141  data: 0.1603  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.7515 (0.8248)  acc1: 85.4167 (82.8373)  acc5: 97.9167 (97.9167)  time: 0.2001  data: 0.0463  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 1.2090 (1.0184)  acc1: 68.7500 (74.6640)  acc5: 97.9167 (97.5806)  time: 0.2210  data: 0.0607  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 1.2649 (1.0445)  acc1: 64.5833 (74.6443)  acc5: 95.8333 (97.3069)  time: 0.1938  data: 0.0329  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.0735 (1.0233)  acc1: 75.0000 (75.3268)  acc5: 97.9167 (97.4265)  time: 0.1477  data: 0.0023  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8811 (0.9877)  acc1: 79.1667 (76.6393)  acc5: 97.9167 (97.5751)  time: 0.1297  data: 0.0013  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.1194 (1.0218)  acc1: 70.8333 (75.4695)  acc5: 95.8333 (97.3005)  time: 0.1212  data: 0.0015  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1278 (1.0024)  acc1: 70.8333 (76.1574)  acc5: 95.8333 (97.3765)  time: 0.1182  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0764 (1.0033)  acc1: 70.8333 (76.1529)  acc5: 95.8333 (97.3248)  time: 0.1163  data: 0.0004  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1824 s / it)\n",
            "* Acc@1 76.153 Acc@5 97.325 loss 1.003\n",
            "Accuracy of the model on the 3925 test images: 76.2%\n",
            "Max accuracy: 76.15%\n",
            "Test:  [ 0/82]  eta: 0:02:47  loss: 3.2478 (3.2478)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 2.0457  data: 1.8550  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.2478 (3.3430)  acc1: 8.3333 (8.5227)  acc5: 89.5833 (90.1515)  time: 0.2987  data: 0.1709  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.2836 (3.4478)  acc1: 14.5833 (12.4008)  acc5: 89.5833 (89.4841)  time: 0.1277  data: 0.0040  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 3.9963 (3.9760)  acc1: 14.5833 (10.2151)  acc5: 81.2500 (77.8226)  time: 0.1403  data: 0.0029  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.8395 (4.1625)  acc1: 2.0833 (9.6545)  acc5: 54.1667 (73.5772)  time: 0.1562  data: 0.0115  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.7080 (4.3127)  acc1: 10.4167 (10.7026)  acc5: 62.5000 (70.5065)  time: 0.1739  data: 0.0319  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.9389 (4.4406)  acc1: 2.0833 (9.1530)  acc5: 52.0833 (68.2036)  time: 0.1852  data: 0.0342  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5652 (4.3301)  acc1: 0.0000 (11.9131)  acc5: 75.0000 (67.8991)  time: 0.1650  data: 0.0146  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.8204 (3.9680)  acc1: 52.0833 (19.5730)  acc5: 95.8333 (71.4763)  time: 0.1310  data: 0.0009  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.7114 (3.9386)  acc1: 60.4167 (20.1274)  acc5: 95.8333 (71.6433)  time: 0.1265  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1778 s / it)\n",
            "* Acc@1 20.127 Acc@5 71.643 loss 3.939\n",
            "Accuracy of the model EMA on 3925 test images: 20.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [54]  [  0/295]  eta: 0:07:22  lr: 0.002467  min_lr: 0.002467  loss: 3.3671 (3.3671)  weight_decay: 0.0500 (0.0500)  time: 1.4990  data: 1.1306  max mem: 3500\n",
            "Epoch: [54]  [ 10/295]  eta: 0:01:54  lr: 0.002465  min_lr: 0.002465  loss: 3.3400 (3.2395)  weight_decay: 0.0500 (0.0500)  time: 0.4021  data: 0.1038  max mem: 3500\n",
            "Epoch: [54]  [ 20/295]  eta: 0:01:32  lr: 0.002462  min_lr: 0.002462  loss: 3.3154 (3.2343)  weight_decay: 0.0500 (0.0500)  time: 0.2781  data: 0.0017  max mem: 3500\n",
            "Epoch: [54]  [ 30/295]  eta: 0:01:23  lr: 0.002460  min_lr: 0.002460  loss: 3.1767 (3.1936)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0016  max mem: 3500\n",
            "Epoch: [54]  [ 40/295]  eta: 0:01:17  lr: 0.002457  min_lr: 0.002457  loss: 3.1167 (3.1704)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0010  max mem: 3500\n",
            "Epoch: [54]  [ 50/295]  eta: 0:01:13  lr: 0.002455  min_lr: 0.002455  loss: 3.2122 (3.1985)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0019  max mem: 3500\n",
            "Epoch: [54]  [ 60/295]  eta: 0:01:08  lr: 0.002452  min_lr: 0.002452  loss: 3.3333 (3.2135)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0025  max mem: 3500\n",
            "Epoch: [54]  [ 70/295]  eta: 0:01:05  lr: 0.002449  min_lr: 0.002449  loss: 3.2817 (3.2091)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0012  max mem: 3500\n",
            "Epoch: [54]  [ 80/295]  eta: 0:01:01  lr: 0.002446  min_lr: 0.002446  loss: 3.1683 (3.2051)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0014  max mem: 3500\n",
            "Epoch: [54]  [ 90/295]  eta: 0:00:58  lr: 0.002444  min_lr: 0.002444  loss: 3.1683 (3.2006)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0018  max mem: 3500\n",
            "Epoch: [54]  [100/295]  eta: 0:00:55  lr: 0.002441  min_lr: 0.002441  loss: 3.0940 (3.1965)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0014  max mem: 3500\n",
            "Epoch: [54]  [110/295]  eta: 0:00:51  lr: 0.002439  min_lr: 0.002439  loss: 3.0940 (3.2024)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0033  max mem: 3500\n",
            "Epoch: [54]  [120/295]  eta: 0:00:49  lr: 0.002436  min_lr: 0.002436  loss: 3.3267 (3.2069)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0051  max mem: 3500\n",
            "Epoch: [54]  [130/295]  eta: 0:00:45  lr: 0.002434  min_lr: 0.002434  loss: 3.3614 (3.2153)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0028  max mem: 3500\n",
            "Epoch: [54]  [140/295]  eta: 0:00:43  lr: 0.002431  min_lr: 0.002431  loss: 3.3547 (3.2123)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0003  max mem: 3500\n",
            "Epoch: [54]  [150/295]  eta: 0:00:40  lr: 0.002428  min_lr: 0.002428  loss: 3.1859 (3.2179)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0005  max mem: 3500\n",
            "Epoch: [54]  [160/295]  eta: 0:00:37  lr: 0.002425  min_lr: 0.002425  loss: 3.2110 (3.2202)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0024  max mem: 3500\n",
            "Epoch: [54]  [170/295]  eta: 0:00:34  lr: 0.002423  min_lr: 0.002423  loss: 3.2241 (3.2179)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0043  max mem: 3500\n",
            "Epoch: [54]  [180/295]  eta: 0:00:31  lr: 0.002420  min_lr: 0.002420  loss: 3.2207 (3.2206)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0040  max mem: 3500\n",
            "Epoch: [54]  [190/295]  eta: 0:00:28  lr: 0.002418  min_lr: 0.002418  loss: 3.2207 (3.2175)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0022  max mem: 3500\n",
            "Epoch: [54]  [200/295]  eta: 0:00:25  lr: 0.002415  min_lr: 0.002415  loss: 3.1970 (3.2167)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0018  max mem: 3500\n",
            "Epoch: [54]  [210/295]  eta: 0:00:23  lr: 0.002413  min_lr: 0.002413  loss: 3.2914 (3.2176)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0019  max mem: 3500\n",
            "Epoch: [54]  [220/295]  eta: 0:00:20  lr: 0.002410  min_lr: 0.002410  loss: 3.3167 (3.2190)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0009  max mem: 3500\n",
            "Epoch: [54]  [230/295]  eta: 0:00:17  lr: 0.002407  min_lr: 0.002407  loss: 3.2136 (3.2198)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0022  max mem: 3500\n",
            "Epoch: [54]  [240/295]  eta: 0:00:14  lr: 0.002404  min_lr: 0.002404  loss: 3.2825 (3.2219)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0039  max mem: 3500\n",
            "Epoch: [54]  [250/295]  eta: 0:00:12  lr: 0.002402  min_lr: 0.002402  loss: 3.2273 (3.2187)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0031  max mem: 3500\n",
            "Epoch: [54]  [260/295]  eta: 0:00:09  lr: 0.002399  min_lr: 0.002399  loss: 3.1074 (3.2156)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0019  max mem: 3500\n",
            "Epoch: [54]  [270/295]  eta: 0:00:06  lr: 0.002397  min_lr: 0.002397  loss: 3.2101 (3.2149)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0016  max mem: 3500\n",
            "Epoch: [54]  [280/295]  eta: 0:00:04  lr: 0.002394  min_lr: 0.002394  loss: 3.2702 (3.2170)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0011  max mem: 3500\n",
            "Epoch: [54]  [290/295]  eta: 0:00:01  lr: 0.002392  min_lr: 0.002392  loss: 3.2702 (3.2175)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0004  max mem: 3500\n",
            "Epoch: [54]  [294/295]  eta: 0:00:00  lr: 0.002392  min_lr: 0.002392  loss: 3.2702 (3.2168)  weight_decay: 0.0500 (0.0500)  time: 0.2221  data: 0.0002  max mem: 3500\n",
            "Epoch: [54] Total time: 0:01:19 (0.2698 s / it)\n",
            "Averaged stats: lr: 0.002392  min_lr: 0.002392  loss: 3.2702 (3.2168)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:41  loss: 0.8959 (0.8959)  acc1: 83.3333 (83.3333)  acc5: 93.7500 (93.7500)  time: 3.4309  data: 3.2287  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:35  loss: 0.8959 (0.9353)  acc1: 83.3333 (82.5758)  acc5: 95.8333 (95.4545)  time: 0.4891  data: 0.3142  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:21  loss: 0.8599 (0.9025)  acc1: 83.3333 (82.5397)  acc5: 97.9167 (96.7262)  time: 0.1886  data: 0.0285  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 0.9492 (1.0302)  acc1: 79.1667 (76.4113)  acc5: 97.9167 (97.2446)  time: 0.1582  data: 0.0194  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 0.8720 (0.9685)  acc1: 81.2500 (78.9126)  acc5: 100.0000 (97.6626)  time: 0.1288  data: 0.0045  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8808 (0.9951)  acc1: 83.3333 (77.9003)  acc5: 97.9167 (97.5082)  time: 0.1232  data: 0.0042  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 1.0087 (0.9972)  acc1: 75.0000 (77.8005)  acc5: 97.9167 (97.6434)  time: 0.1223  data: 0.0037  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.1287 (1.0273)  acc1: 70.8333 (76.5552)  acc5: 97.9167 (97.3298)  time: 0.1205  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0885 (1.0076)  acc1: 72.9167 (77.0319)  acc5: 95.8333 (97.4023)  time: 0.1182  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0885 (1.0089)  acc1: 72.9167 (77.0446)  acc5: 95.8333 (97.3503)  time: 0.1172  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1852 s / it)\n",
            "* Acc@1 77.045 Acc@5 97.350 loss 1.009\n",
            "Accuracy of the model on the 3925 test images: 77.0%\n",
            "Max accuracy: 77.04%\n",
            "Test:  [ 0/82]  eta: 0:03:04  loss: 3.2047 (3.2047)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 2.2490  data: 2.0318  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 3.2047 (3.3103)  acc1: 8.3333 (9.2803)  acc5: 89.5833 (90.3409)  time: 0.3766  data: 0.2165  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.2568 (3.4191)  acc1: 12.5000 (12.5992)  acc5: 89.5833 (90.0794)  time: 0.1709  data: 0.0213  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 3.9646 (3.9480)  acc1: 12.5000 (10.2823)  acc5: 83.3333 (78.0242)  time: 0.1887  data: 0.0450  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.8308 (4.1279)  acc1: 2.0833 (9.6545)  acc5: 54.1667 (73.8821)  time: 0.1824  data: 0.0417  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.6418 (4.2866)  acc1: 8.3333 (10.7026)  acc5: 60.4167 (70.5882)  time: 0.1413  data: 0.0039  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.9443 (4.4135)  acc1: 4.1667 (9.2555)  acc5: 52.0833 (68.2377)  time: 0.1338  data: 0.0064  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5409 (4.2993)  acc1: 2.0833 (12.0599)  acc5: 75.0000 (67.9871)  time: 0.1226  data: 0.0033  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.7668 (3.9375)  acc1: 54.1667 (19.7531)  acc5: 95.8333 (71.5535)  time: 0.1200  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.6600 (3.9081)  acc1: 60.4167 (20.3057)  acc5: 95.8333 (71.7452)  time: 0.1190  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1821 s / it)\n",
            "* Acc@1 20.306 Acc@5 71.745 loss 3.908\n",
            "Accuracy of the model EMA on 3925 test images: 20.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [55]  [  0/295]  eta: 0:09:06  lr: 0.002391  min_lr: 0.002391  loss: 2.8693 (2.8693)  weight_decay: 0.0500 (0.0500)  time: 1.8511  data: 1.4219  max mem: 3500\n",
            "Epoch: [55]  [ 10/295]  eta: 0:01:58  lr: 0.002388  min_lr: 0.002388  loss: 3.2087 (3.1507)  weight_decay: 0.0500 (0.0500)  time: 0.4171  data: 0.1306  max mem: 3500\n",
            "Epoch: [55]  [ 20/295]  eta: 0:01:36  lr: 0.002385  min_lr: 0.002385  loss: 3.2758 (3.2226)  weight_decay: 0.0500 (0.0500)  time: 0.2758  data: 0.0028  max mem: 3500\n",
            "Epoch: [55]  [ 30/295]  eta: 0:01:26  lr: 0.002383  min_lr: 0.002383  loss: 3.2720 (3.2062)  weight_decay: 0.0500 (0.0500)  time: 0.2750  data: 0.0030  max mem: 3500\n",
            "Epoch: [55]  [ 40/295]  eta: 0:01:19  lr: 0.002380  min_lr: 0.002380  loss: 3.1105 (3.1736)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0018  max mem: 3500\n",
            "Epoch: [55]  [ 50/295]  eta: 0:01:14  lr: 0.002378  min_lr: 0.002378  loss: 3.1105 (3.1718)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0013  max mem: 3500\n",
            "Epoch: [55]  [ 60/295]  eta: 0:01:09  lr: 0.002375  min_lr: 0.002375  loss: 3.2633 (3.1878)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0013  max mem: 3500\n",
            "Epoch: [55]  [ 70/295]  eta: 0:01:05  lr: 0.002373  min_lr: 0.002373  loss: 3.2633 (3.1898)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0016  max mem: 3500\n",
            "Epoch: [55]  [ 80/295]  eta: 0:01:01  lr: 0.002369  min_lr: 0.002369  loss: 3.2399 (3.1921)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0028  max mem: 3500\n",
            "Epoch: [55]  [ 90/295]  eta: 0:00:58  lr: 0.002367  min_lr: 0.002367  loss: 3.1833 (3.1927)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0039  max mem: 3500\n",
            "Epoch: [55]  [100/295]  eta: 0:00:55  lr: 0.002364  min_lr: 0.002364  loss: 3.1622 (3.1891)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0034  max mem: 3500\n",
            "Epoch: [55]  [110/295]  eta: 0:00:52  lr: 0.002362  min_lr: 0.002362  loss: 3.1622 (3.1887)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0033  max mem: 3500\n",
            "Epoch: [55]  [120/295]  eta: 0:00:49  lr: 0.002359  min_lr: 0.002359  loss: 3.2349 (3.1916)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0025  max mem: 3500\n",
            "Epoch: [55]  [130/295]  eta: 0:00:46  lr: 0.002357  min_lr: 0.002357  loss: 3.2349 (3.1897)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0014  max mem: 3500\n",
            "Epoch: [55]  [140/295]  eta: 0:00:43  lr: 0.002354  min_lr: 0.002354  loss: 3.2047 (3.1920)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0009  max mem: 3500\n",
            "Epoch: [55]  [150/295]  eta: 0:00:40  lr: 0.002351  min_lr: 0.002351  loss: 3.1994 (3.1925)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0009  max mem: 3500\n",
            "Epoch: [55]  [160/295]  eta: 0:00:37  lr: 0.002348  min_lr: 0.002348  loss: 3.1675 (3.1910)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0020  max mem: 3500\n",
            "Epoch: [55]  [170/295]  eta: 0:00:34  lr: 0.002346  min_lr: 0.002346  loss: 3.2104 (3.1967)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0027  max mem: 3500\n",
            "Epoch: [55]  [180/295]  eta: 0:00:31  lr: 0.002343  min_lr: 0.002343  loss: 3.2679 (3.1981)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0022  max mem: 3500\n",
            "Epoch: [55]  [190/295]  eta: 0:00:28  lr: 0.002341  min_lr: 0.002341  loss: 3.2794 (3.2036)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0017  max mem: 3500\n",
            "Epoch: [55]  [200/295]  eta: 0:00:26  lr: 0.002338  min_lr: 0.002338  loss: 3.2120 (3.1993)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0023  max mem: 3500\n",
            "Epoch: [55]  [210/295]  eta: 0:00:23  lr: 0.002336  min_lr: 0.002336  loss: 3.1664 (3.1976)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0023  max mem: 3500\n",
            "Epoch: [55]  [220/295]  eta: 0:00:20  lr: 0.002332  min_lr: 0.002332  loss: 3.1813 (3.1957)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0029  max mem: 3500\n",
            "Epoch: [55]  [230/295]  eta: 0:00:17  lr: 0.002330  min_lr: 0.002330  loss: 3.1942 (3.1946)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0044  max mem: 3500\n",
            "Epoch: [55]  [240/295]  eta: 0:00:14  lr: 0.002327  min_lr: 0.002327  loss: 3.1511 (3.1949)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0034  max mem: 3500\n",
            "Epoch: [55]  [250/295]  eta: 0:00:12  lr: 0.002325  min_lr: 0.002325  loss: 3.1511 (3.1937)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0010  max mem: 3500\n",
            "Epoch: [55]  [260/295]  eta: 0:00:09  lr: 0.002322  min_lr: 0.002322  loss: 3.0839 (3.1922)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0009  max mem: 3500\n",
            "Epoch: [55]  [270/295]  eta: 0:00:06  lr: 0.002320  min_lr: 0.002320  loss: 3.1548 (3.1923)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0009  max mem: 3500\n",
            "Epoch: [55]  [280/295]  eta: 0:00:04  lr: 0.002316  min_lr: 0.002316  loss: 3.1548 (3.1897)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0006  max mem: 3500\n",
            "Epoch: [55]  [290/295]  eta: 0:00:01  lr: 0.002314  min_lr: 0.002314  loss: 3.1572 (3.1917)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0004  max mem: 3500\n",
            "Epoch: [55]  [294/295]  eta: 0:00:00  lr: 0.002314  min_lr: 0.002314  loss: 3.1860 (3.1917)  weight_decay: 0.0500 (0.0500)  time: 0.2217  data: 0.0002  max mem: 3500\n",
            "Epoch: [55] Total time: 0:01:19 (0.2697 s / it)\n",
            "Averaged stats: lr: 0.002314  min_lr: 0.002314  loss: 3.1860 (3.1917)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:35  loss: 0.8800 (0.8800)  acc1: 83.3333 (83.3333)  acc5: 95.8333 (95.8333)  time: 2.6237  data: 2.4539  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.9369 (0.9570)  acc1: 83.3333 (82.1970)  acc5: 95.8333 (95.8333)  time: 0.3626  data: 0.2324  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.9803 (0.9579)  acc1: 83.3333 (82.4405)  acc5: 97.9167 (97.0238)  time: 0.1300  data: 0.0063  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.9987 (1.1329)  acc1: 79.1667 (74.5968)  acc5: 95.8333 (95.9677)  time: 0.1247  data: 0.0045  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.9585 (1.0802)  acc1: 79.1667 (76.7276)  acc5: 95.8333 (96.5955)  time: 0.1252  data: 0.0072  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.9039 (1.0762)  acc1: 81.2500 (76.6340)  acc5: 97.9167 (96.5278)  time: 0.1242  data: 0.0060  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9667 (1.0662)  acc1: 77.0833 (76.6052)  acc5: 95.8333 (96.6189)  time: 0.1241  data: 0.0040  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9612 (1.0634)  acc1: 77.0833 (76.6725)  acc5: 97.9167 (96.6256)  time: 0.1211  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9016 (1.0293)  acc1: 81.2500 (77.8549)  acc5: 97.9167 (96.9136)  time: 0.1178  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9016 (1.0292)  acc1: 81.2500 (77.8344)  acc5: 97.9167 (96.8662)  time: 0.1161  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1613 s / it)\n",
            "* Acc@1 77.834 Acc@5 96.866 loss 1.029\n",
            "Accuracy of the model on the 3925 test images: 77.8%\n",
            "Max accuracy: 77.83%\n",
            "Test:  [ 0/82]  eta: 0:04:11  loss: 3.1657 (3.1657)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 3.0708  data: 2.9085  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 3.1657 (3.2833)  acc1: 8.3333 (9.2803)  acc5: 89.5833 (90.3409)  time: 0.4335  data: 0.2795  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 3.2453 (3.3979)  acc1: 14.5833 (12.8968)  acc5: 89.5833 (90.2778)  time: 0.1458  data: 0.0093  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.9437 (3.9263)  acc1: 14.5833 (10.3495)  acc5: 83.3333 (77.9570)  time: 0.1212  data: 0.0025  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.7555 (4.0968)  acc1: 2.0833 (9.6545)  acc5: 54.1667 (73.9329)  time: 0.1231  data: 0.0055  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.5705 (4.2642)  acc1: 8.3333 (10.6618)  acc5: 58.3333 (70.3431)  time: 0.1247  data: 0.0067  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.9157 (4.3905)  acc1: 4.1667 (9.2213)  acc5: 47.9167 (67.9986)  time: 0.1226  data: 0.0042  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.5251 (4.2722)  acc1: 2.0833 (12.1772)  acc5: 75.0000 (67.7817)  time: 0.1200  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.7125 (3.9100)  acc1: 56.2500 (19.8560)  acc5: 95.8333 (71.3735)  time: 0.1186  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.6088 (3.8807)  acc1: 60.4167 (20.4076)  acc5: 95.8333 (71.5669)  time: 0.1174  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1677 s / it)\n",
            "* Acc@1 20.408 Acc@5 71.567 loss 3.881\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [56]  [  0/295]  eta: 0:12:43  lr: 0.002313  min_lr: 0.002313  loss: 3.3602 (3.3602)  weight_decay: 0.0500 (0.0500)  time: 2.5895  data: 2.0170  max mem: 3500\n",
            "Epoch: [56]  [ 10/295]  eta: 0:02:33  lr: 0.002311  min_lr: 0.002311  loss: 3.2669 (3.2049)  weight_decay: 0.0500 (0.0500)  time: 0.5372  data: 0.1873  max mem: 3500\n",
            "Epoch: [56]  [ 20/295]  eta: 0:01:53  lr: 0.002308  min_lr: 0.002308  loss: 3.2566 (3.2139)  weight_decay: 0.0500 (0.0500)  time: 0.3028  data: 0.0030  max mem: 3500\n",
            "Epoch: [56]  [ 30/295]  eta: 0:01:36  lr: 0.002306  min_lr: 0.002306  loss: 3.2405 (3.2237)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0017  max mem: 3500\n",
            "Epoch: [56]  [ 40/295]  eta: 0:01:26  lr: 0.002303  min_lr: 0.002303  loss: 3.1818 (3.1986)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0015  max mem: 3500\n",
            "Epoch: [56]  [ 50/295]  eta: 0:01:19  lr: 0.002301  min_lr: 0.002301  loss: 3.1688 (3.1925)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0011  max mem: 3500\n",
            "Epoch: [56]  [ 60/295]  eta: 0:01:14  lr: 0.002297  min_lr: 0.002297  loss: 3.1813 (3.1927)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0019  max mem: 3500\n",
            "Epoch: [56]  [ 70/295]  eta: 0:01:09  lr: 0.002295  min_lr: 0.002295  loss: 3.2160 (3.2029)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0033  max mem: 3500\n",
            "Epoch: [56]  [ 80/295]  eta: 0:01:06  lr: 0.002292  min_lr: 0.002292  loss: 3.3360 (3.2142)  weight_decay: 0.0500 (0.0500)  time: 0.2831  data: 0.0037  max mem: 3500\n",
            "Epoch: [56]  [ 90/295]  eta: 0:01:02  lr: 0.002290  min_lr: 0.002290  loss: 3.3321 (3.2126)  weight_decay: 0.0500 (0.0500)  time: 0.2826  data: 0.0050  max mem: 3500\n",
            "Epoch: [56]  [100/295]  eta: 0:00:58  lr: 0.002287  min_lr: 0.002287  loss: 3.1579 (3.2090)  weight_decay: 0.0500 (0.0500)  time: 0.2795  data: 0.0054  max mem: 3500\n",
            "Epoch: [56]  [110/295]  eta: 0:00:55  lr: 0.002285  min_lr: 0.002285  loss: 3.1646 (3.2086)  weight_decay: 0.0500 (0.0500)  time: 0.2755  data: 0.0045  max mem: 3500\n",
            "Epoch: [56]  [120/295]  eta: 0:00:51  lr: 0.002281  min_lr: 0.002281  loss: 3.2756 (3.2065)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0027  max mem: 3500\n",
            "Epoch: [56]  [130/295]  eta: 0:00:48  lr: 0.002279  min_lr: 0.002279  loss: 3.2815 (3.2127)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0010  max mem: 3500\n",
            "Epoch: [56]  [140/295]  eta: 0:00:45  lr: 0.002276  min_lr: 0.002276  loss: 3.2066 (3.2055)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0006  max mem: 3500\n",
            "Epoch: [56]  [150/295]  eta: 0:00:41  lr: 0.002274  min_lr: 0.002274  loss: 3.1905 (3.2103)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0023  max mem: 3500\n",
            "Epoch: [56]  [160/295]  eta: 0:00:38  lr: 0.002271  min_lr: 0.002271  loss: 3.2907 (3.2149)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0053  max mem: 3500\n",
            "Epoch: [56]  [170/295]  eta: 0:00:35  lr: 0.002269  min_lr: 0.002269  loss: 3.3466 (3.2173)  weight_decay: 0.0500 (0.0500)  time: 0.2741  data: 0.0047  max mem: 3500\n",
            "Epoch: [56]  [180/295]  eta: 0:00:32  lr: 0.002265  min_lr: 0.002265  loss: 3.1411 (3.2107)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0022  max mem: 3500\n",
            "Epoch: [56]  [190/295]  eta: 0:00:29  lr: 0.002263  min_lr: 0.002263  loss: 3.1411 (3.2061)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0009  max mem: 3500\n",
            "Epoch: [56]  [200/295]  eta: 0:00:26  lr: 0.002260  min_lr: 0.002260  loss: 3.2135 (3.2098)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0017  max mem: 3500\n",
            "Epoch: [56]  [210/295]  eta: 0:00:24  lr: 0.002258  min_lr: 0.002258  loss: 3.1480 (3.2062)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0024  max mem: 3500\n",
            "Epoch: [56]  [220/295]  eta: 0:00:21  lr: 0.002255  min_lr: 0.002255  loss: 3.1359 (3.2058)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0032  max mem: 3500\n",
            "Epoch: [56]  [230/295]  eta: 0:00:18  lr: 0.002253  min_lr: 0.002253  loss: 3.2985 (3.2088)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0039  max mem: 3500\n",
            "Epoch: [56]  [240/295]  eta: 0:00:15  lr: 0.002249  min_lr: 0.002249  loss: 3.2985 (3.2089)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0033  max mem: 3500\n",
            "Epoch: [56]  [250/295]  eta: 0:00:12  lr: 0.002247  min_lr: 0.002247  loss: 3.2740 (3.2090)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0030  max mem: 3500\n",
            "Epoch: [56]  [260/295]  eta: 0:00:09  lr: 0.002244  min_lr: 0.002244  loss: 3.2340 (3.2086)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0022  max mem: 3500\n",
            "Epoch: [56]  [270/295]  eta: 0:00:06  lr: 0.002242  min_lr: 0.002242  loss: 3.1645 (3.2073)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0013  max mem: 3500\n",
            "Epoch: [56]  [280/295]  eta: 0:00:04  lr: 0.002239  min_lr: 0.002239  loss: 3.1645 (3.2067)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0011  max mem: 3500\n",
            "Epoch: [56]  [290/295]  eta: 0:00:01  lr: 0.002237  min_lr: 0.002237  loss: 3.2136 (3.2070)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0006  max mem: 3500\n",
            "Epoch: [56]  [294/295]  eta: 0:00:00  lr: 0.002237  min_lr: 0.002237  loss: 3.2207 (3.2078)  weight_decay: 0.0500 (0.0500)  time: 0.2231  data: 0.0002  max mem: 3500\n",
            "Epoch: [56] Total time: 0:01:21 (0.2764 s / it)\n",
            "Averaged stats: lr: 0.002237  min_lr: 0.002237  loss: 3.2207 (3.2078)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:50  loss: 0.6297 (0.6297)  acc1: 87.5000 (87.5000)  acc5: 97.9167 (97.9167)  time: 2.0778  data: 1.9128  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.6888 (0.7401)  acc1: 87.5000 (86.1742)  acc5: 97.9167 (98.1061)  time: 0.3039  data: 0.1751  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.8475 (0.8418)  acc1: 85.4167 (83.4325)  acc5: 97.9167 (98.1151)  time: 0.1247  data: 0.0018  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 1.0367 (0.9477)  acc1: 75.0000 (79.4355)  acc5: 97.9167 (98.3871)  time: 0.1233  data: 0.0020  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 1.0318 (0.9391)  acc1: 79.1667 (79.9289)  acc5: 97.9167 (98.0691)  time: 0.1237  data: 0.0020  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.9360 (0.9523)  acc1: 79.1667 (79.0441)  acc5: 97.9167 (98.1209)  time: 0.1250  data: 0.0034  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9498 (0.9593)  acc1: 81.2500 (79.5082)  acc5: 97.9167 (98.1557)  time: 0.1266  data: 0.0054  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9983 (0.9701)  acc1: 81.2500 (79.2254)  acc5: 97.9167 (97.8873)  time: 0.1227  data: 0.0032  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9032 (0.9545)  acc1: 79.1667 (79.6296)  acc5: 97.9167 (97.8395)  time: 0.1181  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9032 (0.9569)  acc1: 79.1667 (79.5669)  acc5: 97.9167 (97.7834)  time: 0.1161  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1535 s / it)\n",
            "* Acc@1 79.567 Acc@5 97.783 loss 0.957\n",
            "Accuracy of the model on the 3925 test images: 79.6%\n",
            "Max accuracy: 79.57%\n",
            "Test:  [ 0/82]  eta: 0:04:08  loss: 3.1254 (3.1254)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 3.0332  data: 2.8197  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 3.1254 (3.2525)  acc1: 10.4167 (9.4697)  acc5: 89.5833 (90.7197)  time: 0.4011  data: 0.2617  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.2302 (3.3720)  acc1: 12.5000 (12.5992)  acc5: 91.6667 (90.6746)  time: 0.1331  data: 0.0061  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.9233 (3.9027)  acc1: 12.5000 (10.0806)  acc5: 85.4167 (78.2930)  time: 0.1257  data: 0.0048  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.6905 (4.0665)  acc1: 4.1667 (9.5020)  acc5: 56.2500 (74.3394)  time: 0.1232  data: 0.0036  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.5566 (4.2417)  acc1: 8.3333 (10.4167)  acc5: 58.3333 (70.7108)  time: 0.1251  data: 0.0047  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.8881 (4.3676)  acc1: 4.1667 (9.0164)  acc5: 47.9167 (68.3402)  time: 0.1245  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.5070 (4.2460)  acc1: 2.0833 (12.1772)  acc5: 75.0000 (68.0458)  time: 0.1202  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.6629 (3.8835)  acc1: 56.2500 (19.8817)  acc5: 95.8333 (71.6049)  time: 0.1184  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.5628 (3.8541)  acc1: 60.4167 (20.4331)  acc5: 95.8333 (71.7962)  time: 0.1173  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1652 s / it)\n",
            "* Acc@1 20.433 Acc@5 71.796 loss 3.854\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [57]  [  0/295]  eta: 0:13:42  lr: 0.002236  min_lr: 0.002236  loss: 3.1122 (3.1122)  weight_decay: 0.0500 (0.0500)  time: 2.7893  data: 2.2033  max mem: 3500\n",
            "Epoch: [57]  [ 10/295]  eta: 0:02:38  lr: 0.002233  min_lr: 0.002233  loss: 3.1333 (3.1192)  weight_decay: 0.0500 (0.0500)  time: 0.5576  data: 0.2058  max mem: 3500\n",
            "Epoch: [57]  [ 20/295]  eta: 0:01:55  lr: 0.002230  min_lr: 0.002230  loss: 3.1696 (3.1439)  weight_decay: 0.0500 (0.0500)  time: 0.2999  data: 0.0038  max mem: 3500\n",
            "Epoch: [57]  [ 30/295]  eta: 0:01:37  lr: 0.002228  min_lr: 0.002228  loss: 3.1140 (3.1468)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0010  max mem: 3500\n",
            "Epoch: [57]  [ 40/295]  eta: 0:01:27  lr: 0.002225  min_lr: 0.002225  loss: 3.0936 (3.1565)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0007  max mem: 3500\n",
            "Epoch: [57]  [ 50/295]  eta: 0:01:20  lr: 0.002223  min_lr: 0.002223  loss: 3.1107 (3.1596)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0009  max mem: 3500\n",
            "Epoch: [57]  [ 60/295]  eta: 0:01:14  lr: 0.002219  min_lr: 0.002219  loss: 3.2090 (3.1766)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0014  max mem: 3500\n",
            "Epoch: [57]  [ 70/295]  eta: 0:01:10  lr: 0.002217  min_lr: 0.002217  loss: 3.3212 (3.1944)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0025  max mem: 3500\n",
            "Epoch: [57]  [ 80/295]  eta: 0:01:05  lr: 0.002214  min_lr: 0.002214  loss: 3.3325 (3.2020)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0035  max mem: 3500\n",
            "Epoch: [57]  [ 90/295]  eta: 0:01:01  lr: 0.002212  min_lr: 0.002212  loss: 3.2649 (3.2062)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0021  max mem: 3500\n",
            "Epoch: [57]  [100/295]  eta: 0:00:58  lr: 0.002209  min_lr: 0.002209  loss: 3.1918 (3.1983)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0011  max mem: 3500\n",
            "Epoch: [57]  [110/295]  eta: 0:00:54  lr: 0.002207  min_lr: 0.002207  loss: 3.2382 (3.2048)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0018  max mem: 3500\n",
            "Epoch: [57]  [120/295]  eta: 0:00:51  lr: 0.002203  min_lr: 0.002203  loss: 3.1846 (3.2010)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0019  max mem: 3500\n",
            "Epoch: [57]  [130/295]  eta: 0:00:47  lr: 0.002201  min_lr: 0.002201  loss: 3.1519 (3.2040)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0035  max mem: 3500\n",
            "Epoch: [57]  [140/295]  eta: 0:00:44  lr: 0.002198  min_lr: 0.002198  loss: 3.2527 (3.2045)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0044  max mem: 3500\n",
            "Epoch: [57]  [150/295]  eta: 0:00:41  lr: 0.002196  min_lr: 0.002196  loss: 3.1823 (3.2029)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0027  max mem: 3500\n",
            "Epoch: [57]  [160/295]  eta: 0:00:38  lr: 0.002193  min_lr: 0.002193  loss: 3.1962 (3.2027)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0020  max mem: 3500\n",
            "Epoch: [57]  [170/295]  eta: 0:00:35  lr: 0.002191  min_lr: 0.002191  loss: 3.2232 (3.2050)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0021  max mem: 3500\n",
            "Epoch: [57]  [180/295]  eta: 0:00:32  lr: 0.002187  min_lr: 0.002187  loss: 3.2270 (3.2049)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0014  max mem: 3500\n",
            "Epoch: [57]  [190/295]  eta: 0:00:29  lr: 0.002185  min_lr: 0.002185  loss: 3.2433 (3.2090)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0022  max mem: 3500\n",
            "Epoch: [57]  [200/295]  eta: 0:00:26  lr: 0.002182  min_lr: 0.002182  loss: 3.2433 (3.2002)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0046  max mem: 3500\n",
            "Epoch: [57]  [210/295]  eta: 0:00:23  lr: 0.002180  min_lr: 0.002180  loss: 3.0215 (3.1940)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0038  max mem: 3500\n",
            "Epoch: [57]  [220/295]  eta: 0:00:21  lr: 0.002177  min_lr: 0.002177  loss: 3.2322 (3.1968)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0013  max mem: 3500\n",
            "Epoch: [57]  [230/295]  eta: 0:00:18  lr: 0.002175  min_lr: 0.002175  loss: 3.3081 (3.1942)  weight_decay: 0.0500 (0.0500)  time: 0.2578  data: 0.0015  max mem: 3500\n",
            "Epoch: [57]  [240/295]  eta: 0:00:15  lr: 0.002171  min_lr: 0.002171  loss: 3.1738 (3.1915)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0021  max mem: 3500\n",
            "Epoch: [57]  [250/295]  eta: 0:00:12  lr: 0.002169  min_lr: 0.002169  loss: 3.1889 (3.1940)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0024  max mem: 3500\n",
            "Epoch: [57]  [260/295]  eta: 0:00:09  lr: 0.002166  min_lr: 0.002166  loss: 3.2004 (3.1902)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0026  max mem: 3500\n",
            "Epoch: [57]  [270/295]  eta: 0:00:06  lr: 0.002164  min_lr: 0.002164  loss: 2.9724 (3.1861)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0029  max mem: 3500\n",
            "Epoch: [57]  [280/295]  eta: 0:00:04  lr: 0.002161  min_lr: 0.002161  loss: 3.0474 (3.1838)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0036  max mem: 3500\n",
            "Epoch: [57]  [290/295]  eta: 0:00:01  lr: 0.002158  min_lr: 0.002158  loss: 3.0591 (3.1805)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0019  max mem: 3500\n",
            "Epoch: [57]  [294/295]  eta: 0:00:00  lr: 0.002158  min_lr: 0.002158  loss: 3.0735 (3.1817)  weight_decay: 0.0500 (0.0500)  time: 0.2242  data: 0.0002  max mem: 3500\n",
            "Epoch: [57] Total time: 0:01:21 (0.2757 s / it)\n",
            "Averaged stats: lr: 0.002158  min_lr: 0.002158  loss: 3.0735 (3.1817)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:36  loss: 0.6715 (0.6715)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 1.9092  data: 1.7421  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.7044 (0.7273)  acc1: 87.5000 (85.9849)  acc5: 97.9167 (98.1061)  time: 0.2840  data: 0.1596  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.7271 (0.7337)  acc1: 85.4167 (85.5159)  acc5: 100.0000 (98.7103)  time: 0.1216  data: 0.0019  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.8371 (0.9703)  acc1: 79.1667 (75.7393)  acc5: 97.9167 (97.9167)  time: 0.1246  data: 0.0021  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8198 (0.9193)  acc1: 79.1667 (77.3882)  acc5: 95.8333 (97.8659)  time: 0.1446  data: 0.0018  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7961 (0.9144)  acc1: 81.2500 (77.6144)  acc5: 97.9167 (97.7941)  time: 0.1619  data: 0.0020  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8186 (0.9067)  acc1: 81.2500 (78.1421)  acc5: 97.9167 (97.6776)  time: 0.1603  data: 0.0023  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9111 (0.9159)  acc1: 81.2500 (77.9343)  acc5: 97.9167 (97.6819)  time: 0.1484  data: 0.0014  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9111 (0.9013)  acc1: 79.1667 (78.7809)  acc5: 97.9167 (97.6852)  time: 0.1284  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9111 (0.9038)  acc1: 79.1667 (78.7516)  acc5: 97.9167 (97.6561)  time: 0.1270  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1655 s / it)\n",
            "* Acc@1 78.752 Acc@5 97.656 loss 0.904\n",
            "Accuracy of the model on the 3925 test images: 78.8%\n",
            "Max accuracy: 79.57%\n",
            "Test:  [ 0/82]  eta: 0:02:38  loss: 3.0825 (3.0825)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 1.9374  data: 1.7604  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.0871 (3.2225)  acc1: 10.4167 (9.6591)  acc5: 89.5833 (90.7197)  time: 0.2902  data: 0.1619  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.2058 (3.3491)  acc1: 14.5833 (12.8968)  acc5: 91.6667 (90.7738)  time: 0.1244  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.9038 (3.8813)  acc1: 14.5833 (10.2151)  acc5: 85.4167 (78.4946)  time: 0.1224  data: 0.0043  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.6241 (4.0375)  acc1: 4.1667 (9.6545)  acc5: 56.2500 (74.6443)  time: 0.1229  data: 0.0055  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.5403 (4.2191)  acc1: 8.3333 (10.5392)  acc5: 58.3333 (70.7925)  time: 0.1249  data: 0.0058  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.8550 (4.3438)  acc1: 2.0833 (9.0505)  acc5: 47.9167 (68.4768)  time: 0.1233  data: 0.0046  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.4817 (4.2188)  acc1: 2.0833 (12.2653)  acc5: 75.0000 (68.1925)  time: 0.1199  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.6134 (3.8564)  acc1: 56.2500 (19.9588)  acc5: 95.8333 (71.7335)  time: 0.1186  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.5159 (3.8271)  acc1: 60.4167 (20.5096)  acc5: 95.8333 (71.9236)  time: 0.1175  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1507 s / it)\n",
            "* Acc@1 20.510 Acc@5 71.924 loss 3.827\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [58]  [  0/295]  eta: 0:14:00  lr: 0.002157  min_lr: 0.002157  loss: 2.7876 (2.7876)  weight_decay: 0.0500 (0.0500)  time: 2.8489  data: 2.2353  max mem: 3500\n",
            "Epoch: [58]  [ 10/295]  eta: 0:02:29  lr: 0.002155  min_lr: 0.002155  loss: 3.2186 (3.2070)  weight_decay: 0.0500 (0.0500)  time: 0.5258  data: 0.2071  max mem: 3500\n",
            "Epoch: [58]  [ 20/295]  eta: 0:01:50  lr: 0.002152  min_lr: 0.002152  loss: 3.2156 (3.1783)  weight_decay: 0.0500 (0.0500)  time: 0.2779  data: 0.0030  max mem: 3500\n",
            "Epoch: [58]  [ 30/295]  eta: 0:01:34  lr: 0.002150  min_lr: 0.002150  loss: 3.1990 (3.1785)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0014  max mem: 3500\n",
            "Epoch: [58]  [ 40/295]  eta: 0:01:24  lr: 0.002147  min_lr: 0.002147  loss: 3.2530 (3.1985)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0014  max mem: 3500\n",
            "Epoch: [58]  [ 50/295]  eta: 0:01:18  lr: 0.002145  min_lr: 0.002145  loss: 3.0908 (3.1818)  weight_decay: 0.0500 (0.0500)  time: 0.2668  data: 0.0024  max mem: 3500\n",
            "Epoch: [58]  [ 60/295]  eta: 0:01:13  lr: 0.002141  min_lr: 0.002141  loss: 3.2322 (3.1924)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0023  max mem: 3500\n",
            "Epoch: [58]  [ 70/295]  eta: 0:01:09  lr: 0.002139  min_lr: 0.002139  loss: 3.2588 (3.1915)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0019  max mem: 3500\n",
            "Epoch: [58]  [ 80/295]  eta: 0:01:04  lr: 0.002136  min_lr: 0.002136  loss: 3.2321 (3.1874)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0022  max mem: 3500\n",
            "Epoch: [58]  [ 90/295]  eta: 0:01:00  lr: 0.002134  min_lr: 0.002134  loss: 3.2404 (3.1960)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0013  max mem: 3500\n",
            "Epoch: [58]  [100/295]  eta: 0:00:57  lr: 0.002131  min_lr: 0.002131  loss: 3.2554 (3.1938)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0009  max mem: 3500\n",
            "Epoch: [58]  [110/295]  eta: 0:00:53  lr: 0.002128  min_lr: 0.002128  loss: 3.1954 (3.1964)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0017  max mem: 3500\n",
            "Epoch: [58]  [120/295]  eta: 0:00:50  lr: 0.002125  min_lr: 0.002125  loss: 3.2096 (3.1964)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0030  max mem: 3500\n",
            "Epoch: [58]  [130/295]  eta: 0:00:47  lr: 0.002123  min_lr: 0.002123  loss: 3.2954 (3.2054)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0057  max mem: 3500\n",
            "Epoch: [58]  [140/295]  eta: 0:00:44  lr: 0.002120  min_lr: 0.002120  loss: 3.2620 (3.2018)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0065  max mem: 3500\n",
            "Epoch: [58]  [150/295]  eta: 0:00:41  lr: 0.002118  min_lr: 0.002118  loss: 3.2097 (3.2046)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0034  max mem: 3500\n",
            "Epoch: [58]  [160/295]  eta: 0:00:38  lr: 0.002114  min_lr: 0.002114  loss: 3.2407 (3.2018)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0011  max mem: 3500\n",
            "Epoch: [58]  [170/295]  eta: 0:00:35  lr: 0.002112  min_lr: 0.002112  loss: 3.2132 (3.1994)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0015  max mem: 3500\n",
            "Epoch: [58]  [180/295]  eta: 0:00:32  lr: 0.002109  min_lr: 0.002109  loss: 3.2132 (3.2025)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0019  max mem: 3500\n",
            "Epoch: [58]  [190/295]  eta: 0:00:29  lr: 0.002107  min_lr: 0.002107  loss: 3.2311 (3.2035)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0036  max mem: 3500\n",
            "Epoch: [58]  [200/295]  eta: 0:00:26  lr: 0.002104  min_lr: 0.002104  loss: 3.3134 (3.2115)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0049  max mem: 3500\n",
            "Epoch: [58]  [210/295]  eta: 0:00:23  lr: 0.002102  min_lr: 0.002102  loss: 3.3134 (3.2079)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0038  max mem: 3500\n",
            "Epoch: [58]  [220/295]  eta: 0:00:20  lr: 0.002098  min_lr: 0.002098  loss: 3.2603 (3.2136)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0028  max mem: 3500\n",
            "Epoch: [58]  [230/295]  eta: 0:00:18  lr: 0.002096  min_lr: 0.002096  loss: 3.2678 (3.2140)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0023  max mem: 3500\n",
            "Epoch: [58]  [240/295]  eta: 0:00:15  lr: 0.002093  min_lr: 0.002093  loss: 3.2280 (3.2129)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0017  max mem: 3500\n",
            "Epoch: [58]  [250/295]  eta: 0:00:12  lr: 0.002091  min_lr: 0.002091  loss: 3.2455 (3.2139)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0020  max mem: 3500\n",
            "Epoch: [58]  [260/295]  eta: 0:00:09  lr: 0.002088  min_lr: 0.002088  loss: 3.1094 (3.2078)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0026  max mem: 3500\n",
            "Epoch: [58]  [270/295]  eta: 0:00:06  lr: 0.002085  min_lr: 0.002085  loss: 3.0747 (3.2048)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0023  max mem: 3500\n",
            "Epoch: [58]  [280/295]  eta: 0:00:04  lr: 0.002082  min_lr: 0.002082  loss: 3.2431 (3.2074)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0011  max mem: 3500\n",
            "Epoch: [58]  [290/295]  eta: 0:00:01  lr: 0.002080  min_lr: 0.002080  loss: 3.3015 (3.2100)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0003  max mem: 3500\n",
            "Epoch: [58]  [294/295]  eta: 0:00:00  lr: 0.002080  min_lr: 0.002080  loss: 3.3086 (3.2105)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0002  max mem: 3500\n",
            "Epoch: [58] Total time: 0:01:20 (0.2736 s / it)\n",
            "Averaged stats: lr: 0.002080  min_lr: 0.002080  loss: 3.3086 (3.2105)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:01:58  loss: 0.6358 (0.6358)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 1.4395  data: 1.2857  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.6709 (0.7456)  acc1: 87.5000 (86.7424)  acc5: 97.9167 (97.5379)  time: 0.3110  data: 0.1646  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.7660 (0.7799)  acc1: 85.4167 (85.2183)  acc5: 97.9167 (98.1151)  time: 0.1870  data: 0.0384  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8860 (0.9449)  acc1: 79.1667 (77.6882)  acc5: 97.9167 (97.9839)  time: 0.1672  data: 0.0154  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 1.0024 (0.9420)  acc1: 77.0833 (78.8110)  acc5: 97.9167 (97.8150)  time: 0.1609  data: 0.0144  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 1.0010 (0.9658)  acc1: 81.2500 (78.5539)  acc5: 97.9167 (97.9575)  time: 0.1732  data: 0.0298  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9539 (0.9610)  acc1: 81.2500 (78.7910)  acc5: 97.9167 (98.0191)  time: 0.1614  data: 0.0195  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9539 (0.9706)  acc1: 81.2500 (78.6972)  acc5: 97.9167 (97.7406)  time: 0.1367  data: 0.0078  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8720 (0.9446)  acc1: 81.2500 (79.6039)  acc5: 97.9167 (97.8395)  time: 0.1258  data: 0.0070  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8720 (0.9455)  acc1: 81.2500 (79.6178)  acc5: 97.9167 (97.8089)  time: 0.1245  data: 0.0069  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1779 s / it)\n",
            "* Acc@1 79.618 Acc@5 97.809 loss 0.945\n",
            "Accuracy of the model on the 3925 test images: 79.6%\n",
            "Max accuracy: 79.62%\n",
            "Test:  [ 0/82]  eta: 0:02:46  loss: 3.0395 (3.0395)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 2.0262  data: 1.8483  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 3.0505 (3.1895)  acc1: 10.4167 (10.2273)  acc5: 89.5833 (90.7197)  time: 0.2977  data: 0.1704  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.1654 (3.3241)  acc1: 14.5833 (13.1944)  acc5: 91.6667 (90.9722)  time: 0.1231  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.8881 (3.8580)  acc1: 14.5833 (10.4167)  acc5: 85.4167 (78.6962)  time: 0.1235  data: 0.0023  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.5570 (4.0071)  acc1: 6.2500 (9.8577)  acc5: 56.2500 (74.8984)  time: 0.1427  data: 0.0038  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.5486 (4.1965)  acc1: 8.3333 (10.5392)  acc5: 56.2500 (70.9150)  time: 0.1528  data: 0.0035  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.8240 (4.3204)  acc1: 2.0833 (9.0164)  acc5: 47.9167 (68.4426)  time: 0.1524  data: 0.0015  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.4569 (4.1923)  acc1: 2.0833 (12.3533)  acc5: 72.9167 (68.1338)  time: 0.1511  data: 0.0009  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.5652 (3.8300)  acc1: 58.3333 (20.0617)  acc5: 95.8333 (71.6821)  time: 0.1317  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4716 (3.8008)  acc1: 62.5000 (20.6369)  acc5: 95.8333 (71.8726)  time: 0.1289  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1659 s / it)\n",
            "* Acc@1 20.637 Acc@5 71.873 loss 3.801\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [59]  [  0/295]  eta: 0:07:25  lr: 0.002079  min_lr: 0.002079  loss: 3.2001 (3.2001)  weight_decay: 0.0500 (0.0500)  time: 1.5115  data: 1.1753  max mem: 3500\n",
            "Epoch: [59]  [ 10/295]  eta: 0:01:51  lr: 0.002077  min_lr: 0.002077  loss: 3.1861 (3.1464)  weight_decay: 0.0500 (0.0500)  time: 0.3913  data: 0.1090  max mem: 3500\n",
            "Epoch: [59]  [ 20/295]  eta: 0:01:30  lr: 0.002074  min_lr: 0.002074  loss: 3.1861 (3.1527)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0021  max mem: 3500\n",
            "Epoch: [59]  [ 30/295]  eta: 0:01:21  lr: 0.002071  min_lr: 0.002071  loss: 3.1909 (3.1508)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0021  max mem: 3500\n",
            "Epoch: [59]  [ 40/295]  eta: 0:01:16  lr: 0.002068  min_lr: 0.002068  loss: 3.1239 (3.1380)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0029  max mem: 3500\n",
            "Epoch: [59]  [ 50/295]  eta: 0:01:11  lr: 0.002066  min_lr: 0.002066  loss: 3.1239 (3.1294)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0038  max mem: 3500\n",
            "Epoch: [59]  [ 60/295]  eta: 0:01:08  lr: 0.002063  min_lr: 0.002063  loss: 3.1289 (3.1319)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0030  max mem: 3500\n",
            "Epoch: [59]  [ 70/295]  eta: 0:01:04  lr: 0.002061  min_lr: 0.002061  loss: 3.2156 (3.1399)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0012  max mem: 3500\n",
            "Epoch: [59]  [ 80/295]  eta: 0:01:01  lr: 0.002058  min_lr: 0.002058  loss: 3.3014 (3.1455)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0012  max mem: 3500\n",
            "Epoch: [59]  [ 90/295]  eta: 0:00:58  lr: 0.002055  min_lr: 0.002055  loss: 3.1129 (3.1398)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0021  max mem: 3500\n",
            "Epoch: [59]  [100/295]  eta: 0:00:54  lr: 0.002052  min_lr: 0.002052  loss: 3.1131 (3.1458)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0028  max mem: 3500\n",
            "Epoch: [59]  [110/295]  eta: 0:00:51  lr: 0.002050  min_lr: 0.002050  loss: 3.1388 (3.1435)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0052  max mem: 3500\n",
            "Epoch: [59]  [120/295]  eta: 0:00:49  lr: 0.002047  min_lr: 0.002047  loss: 3.0455 (3.1357)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0071  max mem: 3500\n",
            "Epoch: [59]  [130/295]  eta: 0:00:46  lr: 0.002045  min_lr: 0.002045  loss: 3.0718 (3.1400)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0053  max mem: 3500\n",
            "Epoch: [59]  [140/295]  eta: 0:00:43  lr: 0.002041  min_lr: 0.002041  loss: 3.2576 (3.1427)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0028  max mem: 3500\n",
            "Epoch: [59]  [150/295]  eta: 0:00:40  lr: 0.002039  min_lr: 0.002039  loss: 3.1193 (3.1344)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0019  max mem: 3500\n",
            "Epoch: [59]  [160/295]  eta: 0:00:37  lr: 0.002036  min_lr: 0.002036  loss: 3.1193 (3.1363)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0013  max mem: 3500\n",
            "Epoch: [59]  [170/295]  eta: 0:00:34  lr: 0.002034  min_lr: 0.002034  loss: 3.1349 (3.1333)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0017  max mem: 3500\n",
            "Epoch: [59]  [180/295]  eta: 0:00:31  lr: 0.002031  min_lr: 0.002031  loss: 3.1413 (3.1394)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0032  max mem: 3500\n",
            "Epoch: [59]  [190/295]  eta: 0:00:28  lr: 0.002028  min_lr: 0.002028  loss: 3.2862 (3.1429)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0035  max mem: 3500\n",
            "Epoch: [59]  [200/295]  eta: 0:00:26  lr: 0.002025  min_lr: 0.002025  loss: 3.1446 (3.1420)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0025  max mem: 3500\n",
            "Epoch: [59]  [210/295]  eta: 0:00:23  lr: 0.002023  min_lr: 0.002023  loss: 3.2273 (3.1490)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0021  max mem: 3500\n",
            "Epoch: [59]  [220/295]  eta: 0:00:20  lr: 0.002020  min_lr: 0.002020  loss: 3.2294 (3.1477)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0026  max mem: 3500\n",
            "Epoch: [59]  [230/295]  eta: 0:00:17  lr: 0.002018  min_lr: 0.002018  loss: 3.1379 (3.1508)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0021  max mem: 3500\n",
            "Epoch: [59]  [240/295]  eta: 0:00:14  lr: 0.002014  min_lr: 0.002014  loss: 3.2398 (3.1541)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0032  max mem: 3500\n",
            "Epoch: [59]  [250/295]  eta: 0:00:12  lr: 0.002012  min_lr: 0.002012  loss: 3.2195 (3.1548)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0045  max mem: 3500\n",
            "Epoch: [59]  [260/295]  eta: 0:00:09  lr: 0.002009  min_lr: 0.002009  loss: 3.1305 (3.1529)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0036  max mem: 3500\n",
            "Epoch: [59]  [270/295]  eta: 0:00:06  lr: 0.002007  min_lr: 0.002007  loss: 3.1305 (3.1569)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0022  max mem: 3500\n",
            "Epoch: [59]  [280/295]  eta: 0:00:04  lr: 0.002004  min_lr: 0.002004  loss: 3.1663 (3.1553)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0005  max mem: 3500\n",
            "Epoch: [59]  [290/295]  eta: 0:00:01  lr: 0.002002  min_lr: 0.002002  loss: 3.1397 (3.1541)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0003  max mem: 3500\n",
            "Epoch: [59]  [294/295]  eta: 0:00:00  lr: 0.002002  min_lr: 0.002002  loss: 3.1515 (3.1545)  weight_decay: 0.0500 (0.0500)  time: 0.2191  data: 0.0002  max mem: 3500\n",
            "Epoch: [59] Total time: 0:01:19 (0.2691 s / it)\n",
            "Averaged stats: lr: 0.002002  min_lr: 0.002002  loss: 3.1515 (3.1545)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:56  loss: 0.7074 (0.7074)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 2.8827  data: 2.7077  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.7074 (0.7440)  acc1: 87.5000 (86.3636)  acc5: 97.9167 (97.7273)  time: 0.4391  data: 0.2878  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.7230 (0.7328)  acc1: 87.5000 (87.1032)  acc5: 97.9167 (98.2143)  time: 0.1883  data: 0.0419  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.7927 (0.9496)  acc1: 85.4167 (78.3602)  acc5: 97.9167 (97.6479)  time: 0.1532  data: 0.0204  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.8396 (0.9135)  acc1: 83.3333 (79.9289)  acc5: 97.9167 (97.8150)  time: 0.1235  data: 0.0028  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7928 (0.9165)  acc1: 83.3333 (79.7794)  acc5: 97.9167 (97.8758)  time: 0.1236  data: 0.0039  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9169 (0.9275)  acc1: 79.1667 (79.5082)  acc5: 97.9167 (97.6776)  time: 0.1246  data: 0.0046  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0824 (0.9576)  acc1: 72.9167 (78.2277)  acc5: 97.9167 (97.4472)  time: 0.1220  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8432 (0.9282)  acc1: 81.2500 (79.3982)  acc5: 97.9167 (97.5566)  time: 0.1188  data: 0.0006  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8432 (0.9285)  acc1: 81.2500 (79.4395)  acc5: 97.9167 (97.5287)  time: 0.1167  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1762 s / it)\n",
            "* Acc@1 79.439 Acc@5 97.529 loss 0.928\n",
            "Accuracy of the model on the 3925 test images: 79.4%\n",
            "Max accuracy: 79.62%\n",
            "Test:  [ 0/82]  eta: 0:02:16  loss: 2.9956 (2.9956)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 1.6600  data: 1.4985  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 3.0129 (3.1548)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (91.0985)  time: 0.2855  data: 0.1464  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 3.1414 (3.2973)  acc1: 12.5000 (12.8968)  acc5: 91.6667 (91.5675)  time: 0.1698  data: 0.0320  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.8741 (3.8350)  acc1: 10.4167 (10.0134)  acc5: 87.5000 (78.9651)  time: 0.1842  data: 0.0512  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.4882 (3.9768)  acc1: 6.2500 (9.6545)  acc5: 56.2500 (75.1524)  time: 0.1749  data: 0.0462  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.5154 (4.1734)  acc1: 8.3333 (10.3350)  acc5: 56.2500 (71.0376)  time: 0.1803  data: 0.0413  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.7956 (4.2969)  acc1: 2.0833 (8.8456)  acc5: 47.9167 (68.5792)  time: 0.1622  data: 0.0268  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.4379 (4.1659)  acc1: 2.0833 (12.2359)  acc5: 72.9167 (68.2218)  time: 0.1283  data: 0.0073  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.5169 (3.8037)  acc1: 58.3333 (19.9588)  acc5: 95.8333 (71.7593)  time: 0.1195  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4264 (3.7747)  acc1: 64.5833 (20.5350)  acc5: 95.8333 (71.9490)  time: 0.1177  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1793 s / it)\n",
            "* Acc@1 20.535 Acc@5 71.949 loss 3.775\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [60]  [  0/295]  eta: 0:08:54  lr: 0.002000  min_lr: 0.002000  loss: 3.0555 (3.0555)  weight_decay: 0.0500 (0.0500)  time: 1.8119  data: 1.4459  max mem: 3500\n",
            "Epoch: [60]  [ 10/295]  eta: 0:01:57  lr: 0.001998  min_lr: 0.001998  loss: 3.2171 (3.1605)  weight_decay: 0.0500 (0.0500)  time: 0.4120  data: 0.1332  max mem: 3500\n",
            "Epoch: [60]  [ 20/295]  eta: 0:01:33  lr: 0.001995  min_lr: 0.001995  loss: 3.2215 (3.1698)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0014  max mem: 3500\n",
            "Epoch: [60]  [ 30/295]  eta: 0:01:24  lr: 0.001993  min_lr: 0.001993  loss: 3.2215 (3.1546)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0027  max mem: 3500\n",
            "Epoch: [60]  [ 40/295]  eta: 0:01:18  lr: 0.001990  min_lr: 0.001990  loss: 3.1043 (3.1450)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0038  max mem: 3500\n",
            "Epoch: [60]  [ 50/295]  eta: 0:01:13  lr: 0.001988  min_lr: 0.001988  loss: 3.0673 (3.1205)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0031  max mem: 3500\n",
            "Epoch: [60]  [ 60/295]  eta: 0:01:09  lr: 0.001984  min_lr: 0.001984  loss: 2.9970 (3.1185)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0020  max mem: 3500\n",
            "Epoch: [60]  [ 70/295]  eta: 0:01:05  lr: 0.001982  min_lr: 0.001982  loss: 3.2915 (3.1425)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0017  max mem: 3500\n",
            "Epoch: [60]  [ 80/295]  eta: 0:01:01  lr: 0.001979  min_lr: 0.001979  loss: 3.3345 (3.1524)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0021  max mem: 3500\n",
            "Epoch: [60]  [ 90/295]  eta: 0:00:58  lr: 0.001977  min_lr: 0.001977  loss: 3.2783 (3.1623)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0038  max mem: 3500\n",
            "Epoch: [60]  [100/295]  eta: 0:00:55  lr: 0.001974  min_lr: 0.001974  loss: 3.2505 (3.1614)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0044  max mem: 3500\n",
            "Epoch: [60]  [110/295]  eta: 0:00:52  lr: 0.001971  min_lr: 0.001971  loss: 3.0517 (3.1464)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0025  max mem: 3500\n",
            "Epoch: [60]  [120/295]  eta: 0:00:48  lr: 0.001968  min_lr: 0.001968  loss: 3.0517 (3.1520)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0017  max mem: 3500\n",
            "Epoch: [60]  [130/295]  eta: 0:00:45  lr: 0.001966  min_lr: 0.001966  loss: 3.1815 (3.1541)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0012  max mem: 3500\n",
            "Epoch: [60]  [140/295]  eta: 0:00:42  lr: 0.001963  min_lr: 0.001963  loss: 3.1671 (3.1524)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0010  max mem: 3500\n",
            "Epoch: [60]  [150/295]  eta: 0:00:40  lr: 0.001961  min_lr: 0.001961  loss: 3.0696 (3.1439)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0023  max mem: 3500\n",
            "Epoch: [60]  [160/295]  eta: 0:00:37  lr: 0.001957  min_lr: 0.001957  loss: 3.0714 (3.1464)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0034  max mem: 3500\n",
            "Epoch: [60]  [170/295]  eta: 0:00:34  lr: 0.001955  min_lr: 0.001955  loss: 3.2188 (3.1524)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0033  max mem: 3500\n",
            "Epoch: [60]  [180/295]  eta: 0:00:31  lr: 0.001952  min_lr: 0.001952  loss: 3.2294 (3.1539)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0036  max mem: 3500\n",
            "Epoch: [60]  [190/295]  eta: 0:00:28  lr: 0.001950  min_lr: 0.001950  loss: 3.1634 (3.1526)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0032  max mem: 3500\n",
            "Epoch: [60]  [200/295]  eta: 0:00:25  lr: 0.001947  min_lr: 0.001947  loss: 3.1826 (3.1575)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0019  max mem: 3500\n",
            "Epoch: [60]  [210/295]  eta: 0:00:23  lr: 0.001945  min_lr: 0.001945  loss: 3.2392 (3.1557)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0019  max mem: 3500\n",
            "Epoch: [60]  [220/295]  eta: 0:00:20  lr: 0.001941  min_lr: 0.001941  loss: 3.1450 (3.1535)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0029  max mem: 3500\n",
            "Epoch: [60]  [230/295]  eta: 0:00:17  lr: 0.001939  min_lr: 0.001939  loss: 3.1450 (3.1546)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0031  max mem: 3500\n",
            "Epoch: [60]  [240/295]  eta: 0:00:14  lr: 0.001936  min_lr: 0.001936  loss: 3.1255 (3.1521)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0030  max mem: 3500\n",
            "Epoch: [60]  [250/295]  eta: 0:00:12  lr: 0.001934  min_lr: 0.001934  loss: 3.0509 (3.1495)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0023  max mem: 3500\n",
            "Epoch: [60]  [260/295]  eta: 0:00:09  lr: 0.001931  min_lr: 0.001931  loss: 3.0665 (3.1470)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0013  max mem: 3500\n",
            "Epoch: [60]  [270/295]  eta: 0:00:06  lr: 0.001928  min_lr: 0.001928  loss: 3.0939 (3.1489)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0013  max mem: 3500\n",
            "Epoch: [60]  [280/295]  eta: 0:00:04  lr: 0.001925  min_lr: 0.001925  loss: 3.2826 (3.1560)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0014  max mem: 3500\n",
            "Epoch: [60]  [290/295]  eta: 0:00:01  lr: 0.001923  min_lr: 0.001923  loss: 3.3170 (3.1598)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0006  max mem: 3500\n",
            "Epoch: [60]  [294/295]  eta: 0:00:00  lr: 0.001923  min_lr: 0.001923  loss: 3.2832 (3.1597)  weight_decay: 0.0500 (0.0500)  time: 0.2217  data: 0.0002  max mem: 3500\n",
            "Epoch: [60] Total time: 0:01:19 (0.2700 s / it)\n",
            "Averaged stats: lr: 0.001923  min_lr: 0.001923  loss: 3.2832 (3.1597)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:39  loss: 0.7369 (0.7369)  acc1: 85.4167 (85.4167)  acc5: 93.7500 (93.7500)  time: 3.4049  data: 3.2143  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:33  loss: 0.7064 (0.7373)  acc1: 89.5833 (87.6894)  acc5: 97.9167 (97.9167)  time: 0.4645  data: 0.2991  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:21  loss: 0.6817 (0.7156)  acc1: 89.5833 (88.9881)  acc5: 100.0000 (98.4127)  time: 0.1856  data: 0.0225  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 0.8140 (0.9784)  acc1: 81.2500 (77.2849)  acc5: 97.9167 (97.2446)  time: 0.1633  data: 0.0199  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.8686 (0.9403)  acc1: 81.2500 (79.0142)  acc5: 95.8333 (97.5102)  time: 0.1245  data: 0.0018  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8233 (0.9495)  acc1: 83.3333 (79.2892)  acc5: 97.9167 (97.5490)  time: 0.1235  data: 0.0030  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9171 (0.9449)  acc1: 79.1667 (79.7131)  acc5: 97.9167 (97.7118)  time: 0.1235  data: 0.0053  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0018 (0.9762)  acc1: 72.9167 (78.1397)  acc5: 97.9167 (97.4178)  time: 0.1216  data: 0.0037  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0002 (0.9624)  acc1: 75.0000 (78.9095)  acc5: 97.9167 (97.5051)  time: 0.1189  data: 0.0008  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0002 (0.9645)  acc1: 75.0000 (78.8790)  acc5: 97.9167 (97.4522)  time: 0.1172  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1825 s / it)\n",
            "* Acc@1 78.879 Acc@5 97.452 loss 0.964\n",
            "Accuracy of the model on the 3925 test images: 78.9%\n",
            "Max accuracy: 79.62%\n",
            "Test:  [ 0/82]  eta: 0:03:55  loss: 2.9512 (2.9512)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 2.8707  data: 2.6833  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 2.9734 (3.1214)  acc1: 10.4167 (10.7955)  acc5: 89.5833 (91.4773)  time: 0.4465  data: 0.3079  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 3.1280 (3.2714)  acc1: 12.5000 (12.7976)  acc5: 91.6667 (91.9643)  time: 0.1743  data: 0.0361  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 3.8540 (3.8125)  acc1: 10.4167 (9.8790)  acc5: 87.5000 (78.9651)  time: 0.1619  data: 0.0169  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.4133 (3.9456)  acc1: 6.2500 (9.6037)  acc5: 58.3333 (75.4573)  time: 0.1601  data: 0.0172  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.4849 (4.1492)  acc1: 8.3333 (10.1716)  acc5: 58.3333 (71.2418)  time: 0.1330  data: 0.0036  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.7550 (4.2706)  acc1: 2.0833 (8.7090)  acc5: 47.9167 (68.7500)  time: 0.1238  data: 0.0036  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.4056 (4.1368)  acc1: 2.0833 (12.1772)  acc5: 70.8333 (68.3685)  time: 0.1211  data: 0.0014  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4729 (3.7754)  acc1: 60.4167 (20.0103)  acc5: 95.8333 (71.8879)  time: 0.1194  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.4005 (3.7464)  acc1: 64.5833 (20.5860)  acc5: 95.8333 (72.0764)  time: 0.1183  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1824 s / it)\n",
            "* Acc@1 20.586 Acc@5 72.076 loss 3.746\n",
            "Accuracy of the model EMA on 3925 test images: 20.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [61]  [  0/295]  eta: 0:08:38  lr: 0.001922  min_lr: 0.001922  loss: 3.4913 (3.4913)  weight_decay: 0.0500 (0.0500)  time: 1.7587  data: 1.4133  max mem: 3500\n",
            "Epoch: [61]  [ 10/295]  eta: 0:01:57  lr: 0.001920  min_lr: 0.001920  loss: 2.9867 (3.0969)  weight_decay: 0.0500 (0.0500)  time: 0.4123  data: 0.1306  max mem: 3500\n",
            "Epoch: [61]  [ 20/295]  eta: 0:01:35  lr: 0.001917  min_lr: 0.001917  loss: 3.1990 (3.1896)  weight_decay: 0.0500 (0.0500)  time: 0.2769  data: 0.0032  max mem: 3500\n",
            "Epoch: [61]  [ 30/295]  eta: 0:01:26  lr: 0.001914  min_lr: 0.001914  loss: 3.2477 (3.1975)  weight_decay: 0.0500 (0.0500)  time: 0.2773  data: 0.0055  max mem: 3500\n",
            "Epoch: [61]  [ 40/295]  eta: 0:01:19  lr: 0.001911  min_lr: 0.001911  loss: 3.1524 (3.1915)  weight_decay: 0.0500 (0.0500)  time: 0.2774  data: 0.0054  max mem: 3500\n",
            "Epoch: [61]  [ 50/295]  eta: 0:01:14  lr: 0.001909  min_lr: 0.001909  loss: 3.1267 (3.1844)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0025  max mem: 3500\n",
            "Epoch: [61]  [ 60/295]  eta: 0:01:09  lr: 0.001906  min_lr: 0.001906  loss: 3.0915 (3.1773)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0018  max mem: 3500\n",
            "Epoch: [61]  [ 70/295]  eta: 0:01:05  lr: 0.001904  min_lr: 0.001904  loss: 3.1720 (3.1794)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0024  max mem: 3500\n",
            "Epoch: [61]  [ 80/295]  eta: 0:01:02  lr: 0.001901  min_lr: 0.001901  loss: 3.1720 (3.1687)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0024  max mem: 3500\n",
            "Epoch: [61]  [ 90/295]  eta: 0:00:59  lr: 0.001898  min_lr: 0.001898  loss: 3.1377 (3.1625)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0035  max mem: 3500\n",
            "Epoch: [61]  [100/295]  eta: 0:00:55  lr: 0.001895  min_lr: 0.001895  loss: 3.1402 (3.1690)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0039  max mem: 3500\n",
            "Epoch: [61]  [110/295]  eta: 0:00:52  lr: 0.001893  min_lr: 0.001893  loss: 3.1711 (3.1669)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0028  max mem: 3500\n",
            "Epoch: [61]  [120/295]  eta: 0:00:49  lr: 0.001890  min_lr: 0.001890  loss: 3.1545 (3.1687)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0019  max mem: 3500\n",
            "Epoch: [61]  [130/295]  eta: 0:00:46  lr: 0.001888  min_lr: 0.001888  loss: 3.1198 (3.1654)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0020  max mem: 3500\n",
            "Epoch: [61]  [140/295]  eta: 0:00:43  lr: 0.001884  min_lr: 0.001884  loss: 3.2093 (3.1684)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0019  max mem: 3500\n",
            "Epoch: [61]  [150/295]  eta: 0:00:40  lr: 0.001882  min_lr: 0.001882  loss: 3.2410 (3.1650)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0019  max mem: 3500\n",
            "Epoch: [61]  [160/295]  eta: 0:00:37  lr: 0.001879  min_lr: 0.001879  loss: 3.1994 (3.1668)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0028  max mem: 3500\n",
            "Epoch: [61]  [170/295]  eta: 0:00:34  lr: 0.001877  min_lr: 0.001877  loss: 3.2712 (3.1718)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0033  max mem: 3500\n",
            "Epoch: [61]  [180/295]  eta: 0:00:31  lr: 0.001874  min_lr: 0.001874  loss: 3.2932 (3.1752)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0024  max mem: 3500\n",
            "Epoch: [61]  [190/295]  eta: 0:00:28  lr: 0.001872  min_lr: 0.001872  loss: 3.2088 (3.1759)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0017  max mem: 3500\n",
            "Epoch: [61]  [200/295]  eta: 0:00:26  lr: 0.001868  min_lr: 0.001868  loss: 3.0982 (3.1714)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0019  max mem: 3500\n",
            "Epoch: [61]  [210/295]  eta: 0:00:23  lr: 0.001866  min_lr: 0.001866  loss: 3.0982 (3.1658)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0029  max mem: 3500\n",
            "Epoch: [61]  [220/295]  eta: 0:00:20  lr: 0.001863  min_lr: 0.001863  loss: 3.0088 (3.1630)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0040  max mem: 3500\n",
            "Epoch: [61]  [230/295]  eta: 0:00:17  lr: 0.001861  min_lr: 0.001861  loss: 3.1440 (3.1673)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0036  max mem: 3500\n",
            "Epoch: [61]  [240/295]  eta: 0:00:15  lr: 0.001858  min_lr: 0.001858  loss: 3.2488 (3.1706)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0026  max mem: 3500\n",
            "Epoch: [61]  [250/295]  eta: 0:00:12  lr: 0.001855  min_lr: 0.001855  loss: 3.1833 (3.1650)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0015  max mem: 3500\n",
            "Epoch: [61]  [260/295]  eta: 0:00:09  lr: 0.001852  min_lr: 0.001852  loss: 3.0792 (3.1670)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0015  max mem: 3500\n",
            "Epoch: [61]  [270/295]  eta: 0:00:06  lr: 0.001850  min_lr: 0.001850  loss: 3.2749 (3.1700)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0020  max mem: 3500\n",
            "Epoch: [61]  [280/295]  eta: 0:00:04  lr: 0.001847  min_lr: 0.001847  loss: 3.2345 (3.1701)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0015  max mem: 3500\n",
            "Epoch: [61]  [290/295]  eta: 0:00:01  lr: 0.001845  min_lr: 0.001845  loss: 3.1978 (3.1715)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0005  max mem: 3500\n",
            "Epoch: [61]  [294/295]  eta: 0:00:00  lr: 0.001845  min_lr: 0.001845  loss: 3.1978 (3.1726)  weight_decay: 0.0500 (0.0500)  time: 0.2219  data: 0.0002  max mem: 3500\n",
            "Epoch: [61] Total time: 0:01:19 (0.2703 s / it)\n",
            "Averaged stats: lr: 0.001845  min_lr: 0.001845  loss: 3.1978 (3.1726)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:59  loss: 0.7166 (0.7166)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.1871  data: 2.0218  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.7166 (0.7611)  acc1: 87.5000 (86.7424)  acc5: 97.9167 (97.5379)  time: 0.3080  data: 0.1853  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.7300 (0.7573)  acc1: 87.5000 (86.7064)  acc5: 97.9167 (98.0159)  time: 0.1220  data: 0.0038  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.8012 (0.9341)  acc1: 83.3333 (78.9651)  acc5: 97.9167 (97.9839)  time: 0.1247  data: 0.0047  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.9211 (0.9219)  acc1: 81.2500 (80.1321)  acc5: 100.0000 (98.2215)  time: 0.1238  data: 0.0039  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8957 (0.9150)  acc1: 83.3333 (80.5147)  acc5: 100.0000 (98.2026)  time: 0.1224  data: 0.0054  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9213 (0.9129)  acc1: 81.2500 (80.7036)  acc5: 97.9167 (98.0533)  time: 0.1226  data: 0.0051  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9888 (0.9343)  acc1: 81.2500 (79.9589)  acc5: 95.8333 (97.6526)  time: 0.1208  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9888 (0.9316)  acc1: 81.2500 (79.9640)  acc5: 95.8333 (97.4794)  time: 0.1184  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9888 (0.9358)  acc1: 81.2500 (79.8217)  acc5: 95.8333 (97.4522)  time: 0.1161  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1534 s / it)\n",
            "* Acc@1 79.822 Acc@5 97.452 loss 0.936\n",
            "Accuracy of the model on the 3925 test images: 79.8%\n",
            "Max accuracy: 79.82%\n",
            "Test:  [ 0/82]  eta: 0:04:14  loss: 2.9020 (2.9020)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 3.1044  data: 2.9313  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 2.9295 (3.0856)  acc1: 10.4167 (10.6061)  acc5: 91.6667 (92.0455)  time: 0.3966  data: 0.2690  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.1166 (3.2457)  acc1: 12.5000 (12.4008)  acc5: 91.6667 (92.4603)  time: 0.1267  data: 0.0047  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.8322 (3.7887)  acc1: 10.4167 (9.5430)  acc5: 87.5000 (79.2339)  time: 0.1261  data: 0.0066  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.3535 (3.9164)  acc1: 8.3333 (9.5020)  acc5: 58.3333 (75.8638)  time: 0.1246  data: 0.0054  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.4223 (4.1261)  acc1: 8.3333 (9.9265)  acc5: 58.3333 (71.4869)  time: 0.1239  data: 0.0053  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.7228 (4.2466)  acc1: 2.0833 (8.5041)  acc5: 47.9167 (69.0574)  time: 0.1227  data: 0.0056  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.3856 (4.1099)  acc1: 2.0833 (12.0599)  acc5: 72.9167 (68.6913)  time: 0.1200  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.4278 (3.7489)  acc1: 62.5000 (19.9331)  acc5: 95.8333 (72.1708)  time: 0.1180  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3816 (3.7201)  acc1: 64.5833 (20.5096)  acc5: 95.8333 (72.3567)  time: 0.1167  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1656 s / it)\n",
            "* Acc@1 20.510 Acc@5 72.357 loss 3.720\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [62]  [  0/295]  eta: 0:14:08  lr: 0.001844  min_lr: 0.001844  loss: 3.3036 (3.3036)  weight_decay: 0.0500 (0.0500)  time: 2.8767  data: 2.3190  max mem: 3500\n",
            "Epoch: [62]  [ 10/295]  eta: 0:02:40  lr: 0.001841  min_lr: 0.001841  loss: 3.2308 (3.1560)  weight_decay: 0.0500 (0.0500)  time: 0.5622  data: 0.2133  max mem: 3500\n",
            "Epoch: [62]  [ 20/295]  eta: 0:01:55  lr: 0.001838  min_lr: 0.001838  loss: 3.1676 (3.1500)  weight_decay: 0.0500 (0.0500)  time: 0.2968  data: 0.0016  max mem: 3500\n",
            "Epoch: [62]  [ 30/295]  eta: 0:01:37  lr: 0.001836  min_lr: 0.001836  loss: 3.1563 (3.1535)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0010  max mem: 3500\n",
            "Epoch: [62]  [ 40/295]  eta: 0:01:27  lr: 0.001833  min_lr: 0.001833  loss: 3.2141 (3.1871)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0013  max mem: 3500\n",
            "Epoch: [62]  [ 50/295]  eta: 0:01:20  lr: 0.001831  min_lr: 0.001831  loss: 3.1156 (3.1633)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0019  max mem: 3500\n",
            "Epoch: [62]  [ 60/295]  eta: 0:01:15  lr: 0.001828  min_lr: 0.001828  loss: 3.0600 (3.1539)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0041  max mem: 3500\n",
            "Epoch: [62]  [ 70/295]  eta: 0:01:10  lr: 0.001825  min_lr: 0.001825  loss: 3.1440 (3.1470)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0047  max mem: 3500\n",
            "Epoch: [62]  [ 80/295]  eta: 0:01:06  lr: 0.001822  min_lr: 0.001822  loss: 3.1448 (3.1532)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0042  max mem: 3500\n",
            "Epoch: [62]  [ 90/295]  eta: 0:01:02  lr: 0.001820  min_lr: 0.001820  loss: 3.0784 (3.1466)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0039  max mem: 3500\n",
            "Epoch: [62]  [100/295]  eta: 0:00:58  lr: 0.001817  min_lr: 0.001817  loss: 3.1042 (3.1456)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0038  max mem: 3500\n",
            "Epoch: [62]  [110/295]  eta: 0:00:55  lr: 0.001815  min_lr: 0.001815  loss: 3.1317 (3.1446)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0030  max mem: 3500\n",
            "Epoch: [62]  [120/295]  eta: 0:00:51  lr: 0.001811  min_lr: 0.001811  loss: 3.0776 (3.1383)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0019  max mem: 3500\n",
            "Epoch: [62]  [130/295]  eta: 0:00:48  lr: 0.001809  min_lr: 0.001809  loss: 3.1161 (3.1380)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0025  max mem: 3500\n",
            "Epoch: [62]  [140/295]  eta: 0:00:45  lr: 0.001806  min_lr: 0.001806  loss: 3.1544 (3.1442)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0027  max mem: 3500\n",
            "Epoch: [62]  [150/295]  eta: 0:00:42  lr: 0.001804  min_lr: 0.001804  loss: 3.2411 (3.1527)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0026  max mem: 3500\n",
            "Epoch: [62]  [160/295]  eta: 0:00:38  lr: 0.001801  min_lr: 0.001801  loss: 3.2411 (3.1544)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0015  max mem: 3500\n",
            "Epoch: [62]  [170/295]  eta: 0:00:35  lr: 0.001799  min_lr: 0.001799  loss: 3.2070 (3.1586)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0005  max mem: 3500\n",
            "Epoch: [62]  [180/295]  eta: 0:00:32  lr: 0.001795  min_lr: 0.001795  loss: 3.2544 (3.1613)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0010  max mem: 3500\n",
            "Epoch: [62]  [190/295]  eta: 0:00:29  lr: 0.001793  min_lr: 0.001793  loss: 3.3045 (3.1636)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0021  max mem: 3500\n",
            "Epoch: [62]  [200/295]  eta: 0:00:26  lr: 0.001790  min_lr: 0.001790  loss: 3.2494 (3.1611)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0027  max mem: 3500\n",
            "Epoch: [62]  [210/295]  eta: 0:00:24  lr: 0.001788  min_lr: 0.001788  loss: 3.0232 (3.1546)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0032  max mem: 3500\n",
            "Epoch: [62]  [220/295]  eta: 0:00:21  lr: 0.001785  min_lr: 0.001785  loss: 3.0285 (3.1547)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0030  max mem: 3500\n",
            "Epoch: [62]  [230/295]  eta: 0:00:18  lr: 0.001783  min_lr: 0.001783  loss: 3.2060 (3.1573)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0020  max mem: 3500\n",
            "Epoch: [62]  [240/295]  eta: 0:00:15  lr: 0.001779  min_lr: 0.001779  loss: 3.1957 (3.1592)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0013  max mem: 3500\n",
            "Epoch: [62]  [250/295]  eta: 0:00:12  lr: 0.001777  min_lr: 0.001777  loss: 3.1160 (3.1549)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0021  max mem: 3500\n",
            "Epoch: [62]  [260/295]  eta: 0:00:09  lr: 0.001774  min_lr: 0.001774  loss: 3.0749 (3.1546)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0044  max mem: 3500\n",
            "Epoch: [62]  [270/295]  eta: 0:00:06  lr: 0.001772  min_lr: 0.001772  loss: 3.0345 (3.1489)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0047  max mem: 3500\n",
            "Epoch: [62]  [280/295]  eta: 0:00:04  lr: 0.001769  min_lr: 0.001769  loss: 2.9859 (3.1472)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0021  max mem: 3500\n",
            "Epoch: [62]  [290/295]  eta: 0:00:01  lr: 0.001767  min_lr: 0.001767  loss: 3.1779 (3.1480)  weight_decay: 0.0500 (0.0500)  time: 0.2574  data: 0.0004  max mem: 3500\n",
            "Epoch: [62]  [294/295]  eta: 0:00:00  lr: 0.001767  min_lr: 0.001767  loss: 3.1779 (3.1483)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0003  max mem: 3500\n",
            "Epoch: [62] Total time: 0:01:21 (0.2759 s / it)\n",
            "Averaged stats: lr: 0.001767  min_lr: 0.001767  loss: 3.1779 (3.1483)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:47  loss: 0.6230 (0.6230)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 2.0376  data: 1.8726  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.6942 (0.7537)  acc1: 89.5833 (85.7955)  acc5: 97.9167 (97.9167)  time: 0.3097  data: 0.1717  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.7130 (0.7610)  acc1: 89.5833 (86.1111)  acc5: 97.9167 (98.5119)  time: 0.1504  data: 0.0078  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8119 (0.9404)  acc1: 81.2500 (78.2930)  acc5: 97.9167 (97.6479)  time: 0.1806  data: 0.0279  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.9558 (0.9327)  acc1: 81.2500 (79.1667)  acc5: 95.8333 (97.7642)  time: 0.1895  data: 0.0358  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.9314 (0.9592)  acc1: 81.2500 (78.4314)  acc5: 97.9167 (97.7941)  time: 0.1704  data: 0.0186  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9314 (0.9573)  acc1: 77.0833 (78.3811)  acc5: 97.9167 (97.7801)  time: 0.1484  data: 0.0078  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8556 (0.9373)  acc1: 79.1667 (78.9906)  acc5: 97.9167 (97.7700)  time: 0.1293  data: 0.0040  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7787 (0.9210)  acc1: 83.3333 (79.6296)  acc5: 97.9167 (97.7623)  time: 0.1195  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7787 (0.9250)  acc1: 83.3333 (79.4395)  acc5: 97.9167 (97.6815)  time: 0.1180  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1795 s / it)\n",
            "* Acc@1 79.439 Acc@5 97.682 loss 0.925\n",
            "Accuracy of the model on the 3925 test images: 79.4%\n",
            "Max accuracy: 79.82%\n",
            "Test:  [ 0/82]  eta: 0:02:26  loss: 2.8450 (2.8450)  acc1: 12.5000 (12.5000)  acc5: 89.5833 (89.5833)  time: 1.7902  data: 1.6302  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.8790 (3.0430)  acc1: 10.4167 (11.3636)  acc5: 93.7500 (92.9924)  time: 0.2792  data: 0.1514  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 3.0929 (3.2153)  acc1: 10.4167 (12.4008)  acc5: 93.7500 (92.9564)  time: 0.1258  data: 0.0028  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.8104 (3.7609)  acc1: 10.4167 (9.5430)  acc5: 87.5000 (79.2339)  time: 0.1227  data: 0.0018  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 4.2878 (3.8827)  acc1: 8.3333 (9.5020)  acc5: 58.3333 (76.0671)  time: 0.1243  data: 0.0042  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.3553 (4.0992)  acc1: 8.3333 (9.7631)  acc5: 58.3333 (71.4461)  time: 0.1376  data: 0.0047  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6866 (4.2186)  acc1: 2.0833 (8.3675)  acc5: 43.7500 (68.9208)  time: 0.1581  data: 0.0041  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.3608 (4.0801)  acc1: 2.0833 (11.9718)  acc5: 72.9167 (68.5739)  time: 0.1498  data: 0.0030  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3886 (3.7201)  acc1: 62.5000 (19.8560)  acc5: 95.8333 (72.0936)  time: 0.1257  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3614 (3.6913)  acc1: 64.5833 (20.4331)  acc5: 95.8333 (72.2803)  time: 0.1240  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1607 s / it)\n",
            "* Acc@1 20.433 Acc@5 72.280 loss 3.691\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [63]  [  0/295]  eta: 0:11:51  lr: 0.001765  min_lr: 0.001765  loss: 3.5731 (3.5731)  weight_decay: 0.0500 (0.0500)  time: 2.4121  data: 1.9727  max mem: 3500\n",
            "Epoch: [63]  [ 10/295]  eta: 0:02:12  lr: 0.001763  min_lr: 0.001763  loss: 3.3128 (3.2687)  weight_decay: 0.0500 (0.0500)  time: 0.4635  data: 0.1804  max mem: 3500\n",
            "Epoch: [63]  [ 20/295]  eta: 0:01:41  lr: 0.001760  min_lr: 0.001760  loss: 3.1627 (3.1855)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0009  max mem: 3500\n",
            "Epoch: [63]  [ 30/295]  eta: 0:01:28  lr: 0.001758  min_lr: 0.001758  loss: 3.1431 (3.1809)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0006  max mem: 3500\n",
            "Epoch: [63]  [ 40/295]  eta: 0:01:21  lr: 0.001755  min_lr: 0.001755  loss: 3.1327 (3.1325)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0020  max mem: 3500\n",
            "Epoch: [63]  [ 50/295]  eta: 0:01:15  lr: 0.001753  min_lr: 0.001753  loss: 3.0894 (3.1336)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0021  max mem: 3500\n",
            "Epoch: [63]  [ 60/295]  eta: 0:01:10  lr: 0.001749  min_lr: 0.001749  loss: 3.1601 (3.1348)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0016  max mem: 3500\n",
            "Epoch: [63]  [ 70/295]  eta: 0:01:06  lr: 0.001747  min_lr: 0.001747  loss: 3.0393 (3.1153)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0022  max mem: 3500\n",
            "Epoch: [63]  [ 80/295]  eta: 0:01:02  lr: 0.001744  min_lr: 0.001744  loss: 3.0323 (3.1137)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0014  max mem: 3500\n",
            "Epoch: [63]  [ 90/295]  eta: 0:00:59  lr: 0.001742  min_lr: 0.001742  loss: 3.1671 (3.1160)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0018  max mem: 3500\n",
            "Epoch: [63]  [100/295]  eta: 0:00:55  lr: 0.001739  min_lr: 0.001739  loss: 3.1671 (3.1147)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0029  max mem: 3500\n",
            "Epoch: [63]  [110/295]  eta: 0:00:52  lr: 0.001737  min_lr: 0.001737  loss: 3.1627 (3.1128)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0029  max mem: 3500\n",
            "Epoch: [63]  [120/295]  eta: 0:00:49  lr: 0.001733  min_lr: 0.001733  loss: 3.0514 (3.1067)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0033  max mem: 3500\n",
            "Epoch: [63]  [130/295]  eta: 0:00:46  lr: 0.001731  min_lr: 0.001731  loss: 3.0514 (3.1137)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0037  max mem: 3500\n",
            "Epoch: [63]  [140/295]  eta: 0:00:43  lr: 0.001728  min_lr: 0.001728  loss: 3.0729 (3.1134)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0021  max mem: 3500\n",
            "Epoch: [63]  [150/295]  eta: 0:00:40  lr: 0.001726  min_lr: 0.001726  loss: 3.0729 (3.1167)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0018  max mem: 3500\n",
            "Epoch: [63]  [160/295]  eta: 0:00:37  lr: 0.001723  min_lr: 0.001723  loss: 3.1645 (3.1149)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0024  max mem: 3500\n",
            "Epoch: [63]  [170/295]  eta: 0:00:34  lr: 0.001721  min_lr: 0.001721  loss: 3.1619 (3.1169)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0025  max mem: 3500\n",
            "Epoch: [63]  [180/295]  eta: 0:00:31  lr: 0.001717  min_lr: 0.001717  loss: 3.2438 (3.1250)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0022  max mem: 3500\n",
            "Epoch: [63]  [190/295]  eta: 0:00:29  lr: 0.001715  min_lr: 0.001715  loss: 3.3216 (3.1352)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0038  max mem: 3500\n",
            "Epoch: [63]  [200/295]  eta: 0:00:26  lr: 0.001712  min_lr: 0.001712  loss: 3.2984 (3.1380)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0055  max mem: 3500\n",
            "Epoch: [63]  [210/295]  eta: 0:00:23  lr: 0.001710  min_lr: 0.001710  loss: 3.2984 (3.1464)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0030  max mem: 3500\n",
            "Epoch: [63]  [220/295]  eta: 0:00:20  lr: 0.001707  min_lr: 0.001707  loss: 3.3094 (3.1489)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0012  max mem: 3500\n",
            "Epoch: [63]  [230/295]  eta: 0:00:17  lr: 0.001705  min_lr: 0.001705  loss: 3.1191 (3.1480)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0017  max mem: 3500\n",
            "Epoch: [63]  [240/295]  eta: 0:00:15  lr: 0.001702  min_lr: 0.001702  loss: 3.2062 (3.1521)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0019  max mem: 3500\n",
            "Epoch: [63]  [250/295]  eta: 0:00:12  lr: 0.001699  min_lr: 0.001699  loss: 3.2826 (3.1601)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0039  max mem: 3500\n",
            "Epoch: [63]  [260/295]  eta: 0:00:09  lr: 0.001696  min_lr: 0.001696  loss: 3.2492 (3.1573)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0049  max mem: 3500\n",
            "Epoch: [63]  [270/295]  eta: 0:00:06  lr: 0.001694  min_lr: 0.001694  loss: 3.1208 (3.1557)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0029  max mem: 3500\n",
            "Epoch: [63]  [280/295]  eta: 0:00:04  lr: 0.001691  min_lr: 0.001691  loss: 3.1453 (3.1563)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0018  max mem: 3500\n",
            "Epoch: [63]  [290/295]  eta: 0:00:01  lr: 0.001689  min_lr: 0.001689  loss: 3.1114 (3.1539)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0007  max mem: 3500\n",
            "Epoch: [63]  [294/295]  eta: 0:00:00  lr: 0.001689  min_lr: 0.001689  loss: 3.1114 (3.1547)  weight_decay: 0.0500 (0.0500)  time: 0.2191  data: 0.0002  max mem: 3500\n",
            "Epoch: [63] Total time: 0:01:19 (0.2710 s / it)\n",
            "Averaged stats: lr: 0.001689  min_lr: 0.001689  loss: 3.1114 (3.1547)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:05:27  loss: 0.6241 (0.6241)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 3.9915  data: 3.7809  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:38  loss: 0.6701 (0.6961)  acc1: 87.5000 (86.9318)  acc5: 97.9167 (97.7273)  time: 0.5336  data: 0.3463  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:22  loss: 0.6922 (0.6936)  acc1: 87.5000 (87.7976)  acc5: 97.9167 (98.1151)  time: 0.1865  data: 0.0075  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:16  loss: 0.7484 (0.8337)  acc1: 83.3333 (81.3844)  acc5: 97.9167 (97.9167)  time: 0.1850  data: 0.0302  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:11  loss: 0.8391 (0.8221)  acc1: 81.2500 (82.3171)  acc5: 97.9167 (97.9675)  time: 0.1740  data: 0.0376  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:08  loss: 0.8391 (0.8527)  acc1: 81.2500 (81.0049)  acc5: 97.9167 (97.9575)  time: 0.1608  data: 0.0148  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:05  loss: 0.8699 (0.8510)  acc1: 79.1667 (80.6352)  acc5: 97.9167 (98.0533)  time: 0.1396  data: 0.0023  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9288 (0.8798)  acc1: 75.0000 (79.6948)  acc5: 97.9167 (97.7993)  time: 0.1200  data: 0.0011  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8891 (0.8622)  acc1: 81.2500 (80.4270)  acc5: 97.9167 (97.8909)  time: 0.1183  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8891 (0.8637)  acc1: 81.2500 (80.3567)  acc5: 97.9167 (97.8599)  time: 0.1167  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:16 (0.2056 s / it)\n",
            "* Acc@1 80.357 Acc@5 97.860 loss 0.864\n",
            "Accuracy of the model on the 3925 test images: 80.4%\n",
            "Max accuracy: 80.36%\n",
            "Test:  [ 0/82]  eta: 0:02:45  loss: 2.7913 (2.7913)  acc1: 12.5000 (12.5000)  acc5: 91.6667 (91.6667)  time: 2.0200  data: 1.8510  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.8423 (3.0013)  acc1: 10.4167 (11.7424)  acc5: 93.7500 (93.7500)  time: 0.3001  data: 0.1713  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.0451 (3.1841)  acc1: 10.4167 (12.2024)  acc5: 93.7500 (93.4524)  time: 0.1276  data: 0.0027  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 3.7898 (3.7333)  acc1: 8.3333 (9.4086)  acc5: 87.5000 (79.4355)  time: 0.1387  data: 0.0011  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 4.2219 (3.8491)  acc1: 8.3333 (9.4004)  acc5: 60.4167 (76.4228)  time: 0.1506  data: 0.0014  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.3222 (4.0722)  acc1: 8.3333 (9.5588)  acc5: 60.4167 (71.6912)  time: 0.1520  data: 0.0024  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6548 (4.1913)  acc1: 2.0833 (8.1626)  acc5: 43.7500 (69.1257)  time: 0.1656  data: 0.0148  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.3413 (4.0512)  acc1: 2.0833 (11.9425)  acc5: 70.8333 (68.7207)  time: 0.1789  data: 0.0170  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3516 (3.6923)  acc1: 62.5000 (19.8302)  acc5: 95.8333 (72.2479)  time: 0.1513  data: 0.0042  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3437 (3.6636)  acc1: 64.5833 (20.4076)  acc5: 95.8333 (72.4331)  time: 0.1472  data: 0.0035  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1766 s / it)\n",
            "* Acc@1 20.408 Acc@5 72.433 loss 3.664\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [64]  [  0/295]  eta: 0:08:17  lr: 0.001688  min_lr: 0.001688  loss: 3.1427 (3.1427)  weight_decay: 0.0500 (0.0500)  time: 1.6860  data: 1.3059  max mem: 3500\n",
            "Epoch: [64]  [ 10/295]  eta: 0:01:57  lr: 0.001686  min_lr: 0.001686  loss: 3.1427 (3.1712)  weight_decay: 0.0500 (0.0500)  time: 0.4140  data: 0.1209  max mem: 3500\n",
            "Epoch: [64]  [ 20/295]  eta: 0:01:34  lr: 0.001682  min_lr: 0.001682  loss: 3.1567 (3.2046)  weight_decay: 0.0500 (0.0500)  time: 0.2752  data: 0.0019  max mem: 3500\n",
            "Epoch: [64]  [ 30/295]  eta: 0:01:24  lr: 0.001680  min_lr: 0.001680  loss: 3.1845 (3.1730)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0018  max mem: 3500\n",
            "Epoch: [64]  [ 40/295]  eta: 0:01:18  lr: 0.001677  min_lr: 0.001677  loss: 3.2098 (3.2049)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0045  max mem: 3500\n",
            "Epoch: [64]  [ 50/295]  eta: 0:01:13  lr: 0.001675  min_lr: 0.001675  loss: 3.1299 (3.1597)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0055  max mem: 3500\n",
            "Epoch: [64]  [ 60/295]  eta: 0:01:09  lr: 0.001672  min_lr: 0.001672  loss: 3.0920 (3.1515)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0026  max mem: 3500\n",
            "Epoch: [64]  [ 70/295]  eta: 0:01:05  lr: 0.001670  min_lr: 0.001670  loss: 3.1509 (3.1613)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0015  max mem: 3500\n",
            "Epoch: [64]  [ 80/295]  eta: 0:01:01  lr: 0.001666  min_lr: 0.001666  loss: 3.2448 (3.1638)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0013  max mem: 3500\n",
            "Epoch: [64]  [ 90/295]  eta: 0:00:58  lr: 0.001664  min_lr: 0.001664  loss: 3.0818 (3.1520)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0007  max mem: 3500\n",
            "Epoch: [64]  [100/295]  eta: 0:00:55  lr: 0.001661  min_lr: 0.001661  loss: 3.0875 (3.1495)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0018  max mem: 3500\n",
            "Epoch: [64]  [110/295]  eta: 0:00:52  lr: 0.001659  min_lr: 0.001659  loss: 3.1818 (3.1551)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0025  max mem: 3500\n",
            "Epoch: [64]  [120/295]  eta: 0:00:49  lr: 0.001656  min_lr: 0.001656  loss: 3.1781 (3.1503)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0016  max mem: 3500\n",
            "Epoch: [64]  [130/295]  eta: 0:00:46  lr: 0.001654  min_lr: 0.001654  loss: 3.1498 (3.1489)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0021  max mem: 3500\n",
            "Epoch: [64]  [140/295]  eta: 0:00:43  lr: 0.001651  min_lr: 0.001651  loss: 3.1220 (3.1483)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0020  max mem: 3500\n",
            "Epoch: [64]  [150/295]  eta: 0:00:40  lr: 0.001648  min_lr: 0.001648  loss: 3.1989 (3.1535)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0010  max mem: 3500\n",
            "Epoch: [64]  [160/295]  eta: 0:00:37  lr: 0.001645  min_lr: 0.001645  loss: 3.1989 (3.1480)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0017  max mem: 3500\n",
            "Epoch: [64]  [170/295]  eta: 0:00:34  lr: 0.001643  min_lr: 0.001643  loss: 3.1456 (3.1460)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0047  max mem: 3500\n",
            "Epoch: [64]  [180/295]  eta: 0:00:31  lr: 0.001640  min_lr: 0.001640  loss: 3.1410 (3.1491)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0062  max mem: 3500\n",
            "Epoch: [64]  [190/295]  eta: 0:00:28  lr: 0.001638  min_lr: 0.001638  loss: 3.1410 (3.1487)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0043  max mem: 3500\n",
            "Epoch: [64]  [200/295]  eta: 0:00:26  lr: 0.001635  min_lr: 0.001635  loss: 3.1542 (3.1508)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0022  max mem: 3500\n",
            "Epoch: [64]  [210/295]  eta: 0:00:23  lr: 0.001633  min_lr: 0.001633  loss: 3.1329 (3.1488)  weight_decay: 0.0500 (0.0500)  time: 0.2577  data: 0.0008  max mem: 3500\n",
            "Epoch: [64]  [220/295]  eta: 0:00:20  lr: 0.001629  min_lr: 0.001629  loss: 3.1555 (3.1509)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0013  max mem: 3500\n",
            "Epoch: [64]  [230/295]  eta: 0:00:17  lr: 0.001627  min_lr: 0.001627  loss: 3.0994 (3.1470)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0018  max mem: 3500\n",
            "Epoch: [64]  [240/295]  eta: 0:00:14  lr: 0.001624  min_lr: 0.001624  loss: 3.0922 (3.1485)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0019  max mem: 3500\n",
            "Epoch: [64]  [250/295]  eta: 0:00:12  lr: 0.001622  min_lr: 0.001622  loss: 3.2783 (3.1547)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0032  max mem: 3500\n",
            "Epoch: [64]  [260/295]  eta: 0:00:09  lr: 0.001619  min_lr: 0.001619  loss: 3.2011 (3.1505)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0034  max mem: 3500\n",
            "Epoch: [64]  [270/295]  eta: 0:00:06  lr: 0.001617  min_lr: 0.001617  loss: 3.1514 (3.1486)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0018  max mem: 3500\n",
            "Epoch: [64]  [280/295]  eta: 0:00:04  lr: 0.001614  min_lr: 0.001614  loss: 3.1221 (3.1467)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0010  max mem: 3500\n",
            "Epoch: [64]  [290/295]  eta: 0:00:01  lr: 0.001611  min_lr: 0.001611  loss: 3.1597 (3.1489)  weight_decay: 0.0500 (0.0500)  time: 0.2572  data: 0.0005  max mem: 3500\n",
            "Epoch: [64]  [294/295]  eta: 0:00:00  lr: 0.001611  min_lr: 0.001611  loss: 3.1597 (3.1492)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0002  max mem: 3500\n",
            "Epoch: [64] Total time: 0:01:19 (0.2695 s / it)\n",
            "Averaged stats: lr: 0.001611  min_lr: 0.001611  loss: 3.1597 (3.1492)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:20  loss: 0.6500 (0.6500)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 3.1789  data: 2.9936  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:34  loss: 0.6253 (0.6527)  acc1: 89.5833 (88.4470)  acc5: 97.9167 (98.1061)  time: 0.4781  data: 0.3149  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.6578 (0.6868)  acc1: 89.5833 (88.0952)  acc5: 100.0000 (98.5119)  time: 0.1673  data: 0.0268  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.8168 (0.9188)  acc1: 83.3333 (78.1586)  acc5: 97.9167 (97.9167)  time: 0.1248  data: 0.0052  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.9380 (0.9084)  acc1: 79.1667 (79.3191)  acc5: 97.9167 (97.8659)  time: 0.1233  data: 0.0031  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8541 (0.8928)  acc1: 83.3333 (80.4330)  acc5: 97.9167 (98.0801)  time: 0.1232  data: 0.0031  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8646 (0.8940)  acc1: 83.3333 (80.2596)  acc5: 100.0000 (97.9850)  time: 0.1222  data: 0.0033  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9218 (0.9048)  acc1: 79.1667 (79.8122)  acc5: 97.9167 (97.8286)  time: 0.1194  data: 0.0015  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8202 (0.8817)  acc1: 81.2500 (80.5813)  acc5: 97.9167 (97.9424)  time: 0.1177  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8202 (0.8833)  acc1: 81.2500 (80.5350)  acc5: 97.9167 (97.9108)  time: 0.1164  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1739 s / it)\n",
            "* Acc@1 80.535 Acc@5 97.911 loss 0.883\n",
            "Accuracy of the model on the 3925 test images: 80.5%\n",
            "Max accuracy: 80.54%\n",
            "Test:  [ 0/82]  eta: 0:04:31  loss: 2.7426 (2.7426)  acc1: 12.5000 (12.5000)  acc5: 91.6667 (91.6667)  time: 3.3122  data: 3.1316  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:33  loss: 2.8100 (2.9629)  acc1: 12.5000 (12.5000)  acc5: 93.7500 (93.9394)  time: 0.4595  data: 0.3024  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 3.0367 (3.1537)  acc1: 12.5000 (12.1032)  acc5: 93.7500 (93.5516)  time: 0.1720  data: 0.0253  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 3.7621 (3.7032)  acc1: 8.3333 (9.3414)  acc5: 87.5000 (79.5699)  time: 0.1477  data: 0.0173  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.1619 (3.8145)  acc1: 8.3333 (9.4512)  acc5: 64.5833 (76.6260)  time: 0.1248  data: 0.0047  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.3095 (4.0430)  acc1: 8.3333 (9.5997)  acc5: 64.5833 (71.6095)  time: 0.1259  data: 0.0051  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6600 (4.1602)  acc1: 2.0833 (8.1967)  acc5: 43.7500 (69.0232)  time: 0.1258  data: 0.0054  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.3056 (4.0189)  acc1: 2.0833 (12.0305)  acc5: 70.8333 (68.7207)  time: 0.1216  data: 0.0034  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.3176 (3.6615)  acc1: 64.5833 (19.9588)  acc5: 95.8333 (72.2479)  time: 0.1194  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.3176 (3.6330)  acc1: 64.5833 (20.5350)  acc5: 95.8333 (72.4331)  time: 0.1184  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1784 s / it)\n",
            "* Acc@1 20.535 Acc@5 72.433 loss 3.633\n",
            "Accuracy of the model EMA on 3925 test images: 20.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [65]  [  0/295]  eta: 0:09:35  lr: 0.001610  min_lr: 0.001610  loss: 3.3298 (3.3298)  weight_decay: 0.0500 (0.0500)  time: 1.9514  data: 1.5456  max mem: 3500\n",
            "Epoch: [65]  [ 10/295]  eta: 0:02:07  lr: 0.001608  min_lr: 0.001608  loss: 3.3298 (3.3052)  weight_decay: 0.0500 (0.0500)  time: 0.4484  data: 0.1427  max mem: 3500\n",
            "Epoch: [65]  [ 20/295]  eta: 0:01:41  lr: 0.001605  min_lr: 0.001605  loss: 3.3184 (3.2654)  weight_decay: 0.0500 (0.0500)  time: 0.2901  data: 0.0042  max mem: 3500\n",
            "Epoch: [65]  [ 30/295]  eta: 0:01:29  lr: 0.001603  min_lr: 0.001603  loss: 3.3136 (3.2799)  weight_decay: 0.0500 (0.0500)  time: 0.2762  data: 0.0041  max mem: 3500\n",
            "Epoch: [65]  [ 40/295]  eta: 0:01:21  lr: 0.001600  min_lr: 0.001600  loss: 3.1952 (3.2662)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0019  max mem: 3500\n",
            "Epoch: [65]  [ 50/295]  eta: 0:01:15  lr: 0.001598  min_lr: 0.001598  loss: 3.1809 (3.2509)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0014  max mem: 3500\n",
            "Epoch: [65]  [ 60/295]  eta: 0:01:10  lr: 0.001595  min_lr: 0.001595  loss: 3.1809 (3.2394)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0011  max mem: 3500\n",
            "Epoch: [65]  [ 70/295]  eta: 0:01:06  lr: 0.001592  min_lr: 0.001592  loss: 3.1001 (3.2040)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0013  max mem: 3500\n",
            "Epoch: [65]  [ 80/295]  eta: 0:01:03  lr: 0.001589  min_lr: 0.001589  loss: 3.1010 (3.1975)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0032  max mem: 3500\n",
            "Epoch: [65]  [ 90/295]  eta: 0:01:00  lr: 0.001587  min_lr: 0.001587  loss: 3.1518 (3.2010)  weight_decay: 0.0500 (0.0500)  time: 0.2825  data: 0.0061  max mem: 3500\n",
            "Epoch: [65]  [100/295]  eta: 0:00:56  lr: 0.001584  min_lr: 0.001584  loss: 3.1649 (3.1938)  weight_decay: 0.0500 (0.0500)  time: 0.2817  data: 0.0060  max mem: 3500\n",
            "Epoch: [65]  [110/295]  eta: 0:00:53  lr: 0.001582  min_lr: 0.001582  loss: 3.1446 (3.1950)  weight_decay: 0.0500 (0.0500)  time: 0.2768  data: 0.0035  max mem: 3500\n",
            "Epoch: [65]  [120/295]  eta: 0:00:50  lr: 0.001579  min_lr: 0.001579  loss: 3.2354 (3.1960)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0024  max mem: 3500\n",
            "Epoch: [65]  [130/295]  eta: 0:00:47  lr: 0.001577  min_lr: 0.001577  loss: 3.2354 (3.1929)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0014  max mem: 3500\n",
            "Epoch: [65]  [140/295]  eta: 0:00:44  lr: 0.001574  min_lr: 0.001574  loss: 3.1629 (3.1914)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0015  max mem: 3500\n",
            "Epoch: [65]  [150/295]  eta: 0:00:41  lr: 0.001571  min_lr: 0.001571  loss: 3.1156 (3.1824)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0018  max mem: 3500\n",
            "Epoch: [65]  [160/295]  eta: 0:00:38  lr: 0.001568  min_lr: 0.001568  loss: 3.1133 (3.1857)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0022  max mem: 3500\n",
            "Epoch: [65]  [170/295]  eta: 0:00:35  lr: 0.001566  min_lr: 0.001566  loss: 3.1022 (3.1791)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0027  max mem: 3500\n",
            "Epoch: [65]  [180/295]  eta: 0:00:32  lr: 0.001563  min_lr: 0.001563  loss: 3.1092 (3.1796)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0017  max mem: 3500\n",
            "Epoch: [65]  [190/295]  eta: 0:00:29  lr: 0.001561  min_lr: 0.001561  loss: 3.2111 (3.1794)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0012  max mem: 3500\n",
            "Epoch: [65]  [200/295]  eta: 0:00:26  lr: 0.001558  min_lr: 0.001558  loss: 3.0979 (3.1688)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0020  max mem: 3500\n",
            "Epoch: [65]  [210/295]  eta: 0:00:23  lr: 0.001556  min_lr: 0.001556  loss: 3.0416 (3.1709)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0019  max mem: 3500\n",
            "Epoch: [65]  [220/295]  eta: 0:00:20  lr: 0.001553  min_lr: 0.001553  loss: 3.2451 (3.1726)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0022  max mem: 3500\n",
            "Epoch: [65]  [230/295]  eta: 0:00:17  lr: 0.001550  min_lr: 0.001550  loss: 3.2280 (3.1736)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0028  max mem: 3500\n",
            "Epoch: [65]  [240/295]  eta: 0:00:15  lr: 0.001547  min_lr: 0.001547  loss: 3.2280 (3.1719)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0022  max mem: 3500\n",
            "Epoch: [65]  [250/295]  eta: 0:00:12  lr: 0.001545  min_lr: 0.001545  loss: 3.2126 (3.1747)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0025  max mem: 3500\n",
            "Epoch: [65]  [260/295]  eta: 0:00:09  lr: 0.001542  min_lr: 0.001542  loss: 3.2060 (3.1682)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0019  max mem: 3500\n",
            "Epoch: [65]  [270/295]  eta: 0:00:06  lr: 0.001540  min_lr: 0.001540  loss: 3.1645 (3.1659)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0010  max mem: 3500\n",
            "Epoch: [65]  [280/295]  eta: 0:00:04  lr: 0.001537  min_lr: 0.001537  loss: 3.2419 (3.1719)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0008  max mem: 3500\n",
            "Epoch: [65]  [290/295]  eta: 0:00:01  lr: 0.001535  min_lr: 0.001535  loss: 3.3056 (3.1732)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0002  max mem: 3500\n",
            "Epoch: [65]  [294/295]  eta: 0:00:00  lr: 0.001535  min_lr: 0.001535  loss: 3.2930 (3.1716)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0002  max mem: 3500\n",
            "Epoch: [65] Total time: 0:01:20 (0.2729 s / it)\n",
            "Averaged stats: lr: 0.001535  min_lr: 0.001535  loss: 3.2930 (3.1716)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:18  loss: 0.7552 (0.7552)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.4180  data: 2.1912  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.7249 (0.7442)  acc1: 89.5833 (88.4470)  acc5: 97.9167 (97.5379)  time: 0.3732  data: 0.2418  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.7249 (0.7402)  acc1: 89.5833 (87.5000)  acc5: 97.9167 (98.0159)  time: 0.1479  data: 0.0265  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8192 (0.9492)  acc1: 81.2500 (78.8979)  acc5: 97.9167 (97.3118)  time: 0.1251  data: 0.0053  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8962 (0.9209)  acc1: 81.2500 (80.4370)  acc5: 95.8333 (97.6118)  time: 0.1226  data: 0.0036  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8157 (0.8909)  acc1: 85.4167 (81.2092)  acc5: 100.0000 (97.8758)  time: 0.1231  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8097 (0.8874)  acc1: 85.4167 (81.7281)  acc5: 97.9167 (97.8825)  time: 0.1230  data: 0.0051  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9650 (0.9112)  acc1: 79.1667 (80.8685)  acc5: 97.9167 (97.6526)  time: 0.1202  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8672 (0.8897)  acc1: 79.1667 (81.6101)  acc5: 97.9167 (97.7881)  time: 0.1184  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8672 (0.8918)  acc1: 79.1667 (81.5032)  acc5: 97.9167 (97.7325)  time: 0.1163  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1617 s / it)\n",
            "* Acc@1 81.503 Acc@5 97.732 loss 0.892\n",
            "Accuracy of the model on the 3925 test images: 81.5%\n",
            "Max accuracy: 81.50%\n",
            "Test:  [ 0/82]  eta: 0:04:27  loss: 2.6995 (2.6995)  acc1: 12.5000 (12.5000)  acc5: 91.6667 (91.6667)  time: 3.2631  data: 3.0560  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 2.7822 (2.9290)  acc1: 12.5000 (12.8788)  acc5: 93.7500 (94.3182)  time: 0.4272  data: 0.2792  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 3.0332 (3.1274)  acc1: 12.5000 (12.2024)  acc5: 93.7500 (94.0476)  time: 0.1591  data: 0.0249  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.7410 (3.6785)  acc1: 8.3333 (9.4758)  acc5: 91.6667 (80.1075)  time: 0.1524  data: 0.0284  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 4.0985 (3.7833)  acc1: 8.3333 (9.7053)  acc5: 68.7500 (77.2358)  time: 0.1269  data: 0.0054  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.3032 (4.0171)  acc1: 8.3333 (9.7631)  acc5: 68.7500 (71.9363)  time: 0.1231  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6715 (4.1333)  acc1: 2.0833 (8.3333)  acc5: 43.7500 (69.3989)  time: 0.1240  data: 0.0046  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.2831 (3.9908)  acc1: 2.0833 (12.2946)  acc5: 70.8333 (69.1021)  time: 0.1230  data: 0.0029  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2971 (3.6343)  acc1: 64.5833 (20.1903)  acc5: 95.8333 (72.6080)  time: 0.1198  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2971 (3.6059)  acc1: 64.5833 (20.7643)  acc5: 95.8333 (72.7898)  time: 0.1175  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1748 s / it)\n",
            "* Acc@1 20.764 Acc@5 72.790 loss 3.606\n",
            "Accuracy of the model EMA on 3925 test images: 20.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [66]  [  0/295]  eta: 0:07:48  lr: 0.001534  min_lr: 0.001534  loss: 2.8703 (2.8703)  weight_decay: 0.0500 (0.0500)  time: 1.5866  data: 1.1240  max mem: 3500\n",
            "Epoch: [66]  [ 10/295]  eta: 0:02:11  lr: 0.001532  min_lr: 0.001532  loss: 3.1796 (3.2039)  weight_decay: 0.0500 (0.0500)  time: 0.4627  data: 0.1144  max mem: 3500\n",
            "Epoch: [66]  [ 20/295]  eta: 0:01:42  lr: 0.001528  min_lr: 0.001528  loss: 3.1785 (3.1437)  weight_decay: 0.0500 (0.0500)  time: 0.3138  data: 0.0077  max mem: 3500\n",
            "Epoch: [66]  [ 30/295]  eta: 0:01:30  lr: 0.001526  min_lr: 0.001526  loss: 3.1895 (3.1513)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0016  max mem: 3500\n",
            "Epoch: [66]  [ 40/295]  eta: 0:01:21  lr: 0.001523  min_lr: 0.001523  loss: 3.1313 (3.1047)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0009  max mem: 3500\n",
            "Epoch: [66]  [ 50/295]  eta: 0:01:15  lr: 0.001521  min_lr: 0.001521  loss: 3.1186 (3.1268)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0010  max mem: 3500\n",
            "Epoch: [66]  [ 60/295]  eta: 0:01:11  lr: 0.001518  min_lr: 0.001518  loss: 3.2008 (3.1314)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0017  max mem: 3500\n",
            "Epoch: [66]  [ 70/295]  eta: 0:01:06  lr: 0.001516  min_lr: 0.001516  loss: 3.0820 (3.1348)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0034  max mem: 3500\n",
            "Epoch: [66]  [ 80/295]  eta: 0:01:03  lr: 0.001513  min_lr: 0.001513  loss: 3.2408 (3.1506)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0042  max mem: 3500\n",
            "Epoch: [66]  [ 90/295]  eta: 0:00:59  lr: 0.001511  min_lr: 0.001511  loss: 3.2226 (3.1510)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0028  max mem: 3500\n",
            "Epoch: [66]  [100/295]  eta: 0:00:56  lr: 0.001508  min_lr: 0.001508  loss: 3.1308 (3.1448)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0014  max mem: 3500\n",
            "Epoch: [66]  [110/295]  eta: 0:00:53  lr: 0.001506  min_lr: 0.001506  loss: 3.0517 (3.1308)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0008  max mem: 3500\n",
            "Epoch: [66]  [120/295]  eta: 0:00:49  lr: 0.001502  min_lr: 0.001502  loss: 3.0761 (3.1326)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0014  max mem: 3500\n",
            "Epoch: [66]  [130/295]  eta: 0:00:46  lr: 0.001500  min_lr: 0.001500  loss: 3.1817 (3.1364)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0015  max mem: 3500\n",
            "Epoch: [66]  [140/295]  eta: 0:00:43  lr: 0.001497  min_lr: 0.001497  loss: 3.1821 (3.1377)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0031  max mem: 3500\n",
            "Epoch: [66]  [150/295]  eta: 0:00:40  lr: 0.001495  min_lr: 0.001495  loss: 3.1380 (3.1334)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0042  max mem: 3500\n",
            "Epoch: [66]  [160/295]  eta: 0:00:37  lr: 0.001492  min_lr: 0.001492  loss: 3.1754 (3.1361)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0032  max mem: 3500\n",
            "Epoch: [66]  [170/295]  eta: 0:00:34  lr: 0.001490  min_lr: 0.001490  loss: 3.2288 (3.1389)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0021  max mem: 3500\n",
            "Epoch: [66]  [180/295]  eta: 0:00:32  lr: 0.001487  min_lr: 0.001487  loss: 3.1440 (3.1383)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0011  max mem: 3500\n",
            "Epoch: [66]  [190/295]  eta: 0:00:29  lr: 0.001485  min_lr: 0.001485  loss: 3.0832 (3.1337)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0009  max mem: 3500\n",
            "Epoch: [66]  [200/295]  eta: 0:00:26  lr: 0.001482  min_lr: 0.001482  loss: 3.0343 (3.1285)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0005  max mem: 3500\n",
            "Epoch: [66]  [210/295]  eta: 0:00:23  lr: 0.001480  min_lr: 0.001480  loss: 3.1228 (3.1332)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0008  max mem: 3500\n",
            "Epoch: [66]  [220/295]  eta: 0:00:20  lr: 0.001476  min_lr: 0.001476  loss: 3.0784 (3.1276)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0025  max mem: 3500\n",
            "Epoch: [66]  [230/295]  eta: 0:00:17  lr: 0.001474  min_lr: 0.001474  loss: 3.0622 (3.1282)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0023  max mem: 3500\n",
            "Epoch: [66]  [240/295]  eta: 0:00:15  lr: 0.001471  min_lr: 0.001471  loss: 3.0986 (3.1272)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0015  max mem: 3500\n",
            "Epoch: [66]  [250/295]  eta: 0:00:12  lr: 0.001469  min_lr: 0.001469  loss: 3.1093 (3.1304)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0017  max mem: 3500\n",
            "Epoch: [66]  [260/295]  eta: 0:00:09  lr: 0.001466  min_lr: 0.001466  loss: 3.2030 (3.1327)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0013  max mem: 3500\n",
            "Epoch: [66]  [270/295]  eta: 0:00:06  lr: 0.001464  min_lr: 0.001464  loss: 3.1933 (3.1343)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0015  max mem: 3500\n",
            "Epoch: [66]  [280/295]  eta: 0:00:04  lr: 0.001461  min_lr: 0.001461  loss: 3.1410 (3.1327)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0013  max mem: 3500\n",
            "Epoch: [66]  [290/295]  eta: 0:00:01  lr: 0.001459  min_lr: 0.001459  loss: 3.1511 (3.1336)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0006  max mem: 3500\n",
            "Epoch: [66]  [294/295]  eta: 0:00:00  lr: 0.001459  min_lr: 0.001459  loss: 3.1322 (3.1334)  weight_decay: 0.0500 (0.0500)  time: 0.2232  data: 0.0002  max mem: 3500\n",
            "Epoch: [66] Total time: 0:01:20 (0.2725 s / it)\n",
            "Averaged stats: lr: 0.001459  min_lr: 0.001459  loss: 3.1322 (3.1334)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:17  loss: 0.7306 (0.7306)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 3.1448  data: 2.9147  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 0.6377 (0.6729)  acc1: 89.5833 (89.0152)  acc5: 97.9167 (97.3485)  time: 0.3998  data: 0.2665  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.6689 (0.6936)  acc1: 89.5833 (88.4921)  acc5: 97.9167 (97.7183)  time: 0.1268  data: 0.0044  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7751 (0.8679)  acc1: 83.3333 (81.1156)  acc5: 97.9167 (97.9167)  time: 0.1258  data: 0.0064  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.9861 (0.8744)  acc1: 77.0833 (81.1484)  acc5: 97.9167 (97.9167)  time: 0.1232  data: 0.0049  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7602 (0.8450)  acc1: 83.3333 (82.0670)  acc5: 100.0000 (98.0801)  time: 0.1238  data: 0.0057  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7602 (0.8569)  acc1: 83.3333 (81.6598)  acc5: 97.9167 (98.0533)  time: 0.1228  data: 0.0046  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9628 (0.8791)  acc1: 77.0833 (80.6338)  acc5: 97.9167 (97.9167)  time: 0.1214  data: 0.0016  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8824 (0.8694)  acc1: 79.1667 (81.2243)  acc5: 97.9167 (97.8909)  time: 0.1196  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8824 (0.8721)  acc1: 79.1667 (81.1720)  acc5: 97.9167 (97.8599)  time: 0.1180  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1664 s / it)\n",
            "* Acc@1 81.172 Acc@5 97.860 loss 0.872\n",
            "Accuracy of the model on the 3925 test images: 81.2%\n",
            "Max accuracy: 81.50%\n",
            "Test:  [ 0/82]  eta: 0:03:11  loss: 2.6561 (2.6561)  acc1: 14.5833 (14.5833)  acc5: 91.6667 (91.6667)  time: 2.3325  data: 2.1654  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 2.7549 (2.8935)  acc1: 12.5000 (12.8788)  acc5: 93.7500 (94.6970)  time: 0.3813  data: 0.2482  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 3.0306 (3.0983)  acc1: 12.5000 (11.8056)  acc5: 93.7500 (94.3452)  time: 0.1553  data: 0.0298  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.7161 (3.6503)  acc1: 8.3333 (9.2070)  acc5: 91.6667 (80.4436)  time: 0.1252  data: 0.0022  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 4.0306 (3.7484)  acc1: 8.3333 (9.6545)  acc5: 68.7500 (77.6931)  time: 0.1250  data: 0.0025  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.2907 (3.9871)  acc1: 8.3333 (9.6814)  acc5: 68.7500 (72.1814)  time: 0.1251  data: 0.0055  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6810 (4.1014)  acc1: 2.0833 (8.2650)  acc5: 43.7500 (69.7063)  time: 0.1256  data: 0.0057  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.2495 (3.9579)  acc1: 2.0833 (12.2359)  acc5: 70.8333 (69.3955)  time: 0.1224  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2803 (3.6034)  acc1: 64.5833 (20.1389)  acc5: 97.9167 (72.9167)  time: 0.1196  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2803 (3.5752)  acc1: 64.5833 (20.7134)  acc5: 97.9167 (73.0955)  time: 0.1183  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1628 s / it)\n",
            "* Acc@1 20.713 Acc@5 73.096 loss 3.575\n",
            "Accuracy of the model EMA on 3925 test images: 20.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [67]  [  0/295]  eta: 0:14:58  lr: 0.001458  min_lr: 0.001458  loss: 3.3954 (3.3954)  weight_decay: 0.0500 (0.0500)  time: 3.0442  data: 2.5078  max mem: 3500\n",
            "Epoch: [67]  [ 10/295]  eta: 0:02:36  lr: 0.001456  min_lr: 0.001456  loss: 3.2523 (3.1192)  weight_decay: 0.0500 (0.0500)  time: 0.5487  data: 0.2316  max mem: 3500\n",
            "Epoch: [67]  [ 20/295]  eta: 0:01:54  lr: 0.001453  min_lr: 0.001453  loss: 3.2429 (3.1619)  weight_decay: 0.0500 (0.0500)  time: 0.2858  data: 0.0033  max mem: 3500\n",
            "Epoch: [67]  [ 30/295]  eta: 0:01:37  lr: 0.001451  min_lr: 0.001451  loss: 3.2429 (3.1821)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0027  max mem: 3500\n",
            "Epoch: [67]  [ 40/295]  eta: 0:01:27  lr: 0.001447  min_lr: 0.001447  loss: 3.2420 (3.1883)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0017  max mem: 3500\n",
            "Epoch: [67]  [ 50/295]  eta: 0:01:19  lr: 0.001445  min_lr: 0.001445  loss: 3.1064 (3.1592)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0009  max mem: 3500\n",
            "Epoch: [67]  [ 60/295]  eta: 0:01:14  lr: 0.001442  min_lr: 0.001442  loss: 3.0798 (3.1606)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0030  max mem: 3500\n",
            "Epoch: [67]  [ 70/295]  eta: 0:01:09  lr: 0.001440  min_lr: 0.001440  loss: 3.1591 (3.1570)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0040  max mem: 3500\n",
            "Epoch: [67]  [ 80/295]  eta: 0:01:05  lr: 0.001437  min_lr: 0.001437  loss: 3.0903 (3.1437)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0031  max mem: 3500\n",
            "Epoch: [67]  [ 90/295]  eta: 0:01:01  lr: 0.001435  min_lr: 0.001435  loss: 3.0903 (3.1501)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0017  max mem: 3500\n",
            "Epoch: [67]  [100/295]  eta: 0:00:58  lr: 0.001432  min_lr: 0.001432  loss: 3.1002 (3.1375)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0004  max mem: 3500\n",
            "Epoch: [67]  [110/295]  eta: 0:00:54  lr: 0.001430  min_lr: 0.001430  loss: 3.1002 (3.1418)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0023  max mem: 3500\n",
            "Epoch: [67]  [120/295]  eta: 0:00:51  lr: 0.001427  min_lr: 0.001427  loss: 3.2323 (3.1484)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0029  max mem: 3500\n",
            "Epoch: [67]  [130/295]  eta: 0:00:47  lr: 0.001425  min_lr: 0.001425  loss: 3.2323 (3.1531)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0023  max mem: 3500\n",
            "Epoch: [67]  [140/295]  eta: 0:00:44  lr: 0.001422  min_lr: 0.001422  loss: 3.0892 (3.1424)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0057  max mem: 3500\n",
            "Epoch: [67]  [150/295]  eta: 0:00:41  lr: 0.001420  min_lr: 0.001420  loss: 3.0432 (3.1402)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0054  max mem: 3500\n",
            "Epoch: [67]  [160/295]  eta: 0:00:38  lr: 0.001416  min_lr: 0.001416  loss: 3.1249 (3.1368)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0023  max mem: 3500\n",
            "Epoch: [67]  [170/295]  eta: 0:00:35  lr: 0.001414  min_lr: 0.001414  loss: 3.2030 (3.1413)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0020  max mem: 3500\n",
            "Epoch: [67]  [180/295]  eta: 0:00:32  lr: 0.001411  min_lr: 0.001411  loss: 3.1639 (3.1340)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0015  max mem: 3500\n",
            "Epoch: [67]  [190/295]  eta: 0:00:29  lr: 0.001409  min_lr: 0.001409  loss: 3.0974 (3.1365)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0012  max mem: 3500\n",
            "Epoch: [67]  [200/295]  eta: 0:00:26  lr: 0.001406  min_lr: 0.001406  loss: 3.1810 (3.1390)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0022  max mem: 3500\n",
            "Epoch: [67]  [210/295]  eta: 0:00:23  lr: 0.001404  min_lr: 0.001404  loss: 3.1910 (3.1395)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0035  max mem: 3500\n",
            "Epoch: [67]  [220/295]  eta: 0:00:20  lr: 0.001401  min_lr: 0.001401  loss: 2.9908 (3.1349)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0038  max mem: 3500\n",
            "Epoch: [67]  [230/295]  eta: 0:00:18  lr: 0.001399  min_lr: 0.001399  loss: 2.9366 (3.1269)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0029  max mem: 3500\n",
            "Epoch: [67]  [240/295]  eta: 0:00:15  lr: 0.001396  min_lr: 0.001396  loss: 3.0272 (3.1239)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0028  max mem: 3500\n",
            "Epoch: [67]  [250/295]  eta: 0:00:12  lr: 0.001394  min_lr: 0.001394  loss: 3.2282 (3.1275)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0027  max mem: 3500\n",
            "Epoch: [67]  [260/295]  eta: 0:00:09  lr: 0.001391  min_lr: 0.001391  loss: 3.3055 (3.1334)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0018  max mem: 3500\n",
            "Epoch: [67]  [270/295]  eta: 0:00:06  lr: 0.001389  min_lr: 0.001389  loss: 3.2471 (3.1342)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0028  max mem: 3500\n",
            "Epoch: [67]  [280/295]  eta: 0:00:04  lr: 0.001386  min_lr: 0.001386  loss: 3.1917 (3.1361)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0022  max mem: 3500\n",
            "Epoch: [67]  [290/295]  eta: 0:00:01  lr: 0.001384  min_lr: 0.001384  loss: 3.0585 (3.1297)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0003  max mem: 3500\n",
            "Epoch: [67]  [294/295]  eta: 0:00:00  lr: 0.001384  min_lr: 0.001384  loss: 3.0720 (3.1298)  weight_decay: 0.0500 (0.0500)  time: 0.2198  data: 0.0002  max mem: 3500\n",
            "Epoch: [67] Total time: 0:01:20 (0.2741 s / it)\n",
            "Averaged stats: lr: 0.001384  min_lr: 0.001384  loss: 3.0720 (3.1298)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:40  loss: 0.7364 (0.7364)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 1.9611  data: 1.7859  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.6180 (0.6631)  acc1: 91.6667 (89.5833)  acc5: 97.9167 (97.5379)  time: 0.2933  data: 0.1653  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.6178 (0.6629)  acc1: 91.6667 (90.4762)  acc5: 97.9167 (98.0159)  time: 0.1268  data: 0.0020  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.8365 (0.8784)  acc1: 83.3333 (80.3091)  acc5: 97.9167 (98.0511)  time: 0.1285  data: 0.0031  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8231 (0.8429)  acc1: 81.2500 (81.6565)  acc5: 97.9167 (98.1199)  time: 0.1439  data: 0.0115  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7861 (0.8794)  acc1: 83.3333 (80.5147)  acc5: 97.9167 (97.9575)  time: 0.1809  data: 0.0279  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 1.0023 (0.8936)  acc1: 75.0000 (80.1571)  acc5: 97.9167 (97.7459)  time: 0.1841  data: 0.0314  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 1.0958 (0.9314)  acc1: 70.8333 (78.7852)  acc5: 97.9167 (97.3885)  time: 0.1482  data: 0.0128  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8220 (0.9071)  acc1: 79.1667 (79.7582)  acc5: 97.9167 (97.6080)  time: 0.1251  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8220 (0.9073)  acc1: 81.0811 (79.7707)  acc5: 97.9167 (97.5796)  time: 0.1234  data: 0.0005  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1715 s / it)\n",
            "* Acc@1 79.771 Acc@5 97.580 loss 0.907\n",
            "Accuracy of the model on the 3925 test images: 79.8%\n",
            "Max accuracy: 81.50%\n",
            "Test:  [ 0/82]  eta: 0:02:52  loss: 2.6108 (2.6108)  acc1: 14.5833 (14.5833)  acc5: 89.5833 (89.5833)  time: 2.1009  data: 1.9385  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.7244 (2.8584)  acc1: 14.5833 (13.2576)  acc5: 93.7500 (95.0758)  time: 0.3042  data: 0.1780  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.0285 (3.0729)  acc1: 12.5000 (12.0040)  acc5: 93.7500 (94.6429)  time: 0.1233  data: 0.0022  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.6993 (3.6255)  acc1: 8.3333 (9.3414)  acc5: 91.6667 (80.5780)  time: 0.1243  data: 0.0038  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.9672 (3.7170)  acc1: 8.3333 (9.9085)  acc5: 68.7500 (77.8455)  time: 0.1263  data: 0.0050  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.2809 (3.9604)  acc1: 8.3333 (9.8448)  acc5: 68.7500 (72.1814)  time: 0.1252  data: 0.0043  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6887 (4.0727)  acc1: 2.0833 (8.4016)  acc5: 43.7500 (69.7746)  time: 0.1249  data: 0.0058  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.2246 (3.9272)  acc1: 2.0833 (12.3826)  acc5: 72.9167 (69.6303)  time: 0.1226  data: 0.0040  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2642 (3.5743)  acc1: 64.5833 (20.3189)  acc5: 97.9167 (73.1224)  time: 0.1196  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2642 (3.5462)  acc1: 66.6667 (20.8917)  acc5: 97.9167 (73.2994)  time: 0.1187  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1542 s / it)\n",
            "* Acc@1 20.892 Acc@5 73.299 loss 3.546\n",
            "Accuracy of the model EMA on 3925 test images: 20.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [68]  [  0/295]  eta: 0:14:42  lr: 0.001383  min_lr: 0.001383  loss: 3.4799 (3.4799)  weight_decay: 0.0500 (0.0500)  time: 2.9926  data: 2.3895  max mem: 3500\n",
            "Epoch: [68]  [ 10/295]  eta: 0:02:32  lr: 0.001381  min_lr: 0.001381  loss: 3.2556 (3.1753)  weight_decay: 0.0500 (0.0500)  time: 0.5352  data: 0.2212  max mem: 3500\n",
            "Epoch: [68]  [ 20/295]  eta: 0:01:51  lr: 0.001378  min_lr: 0.001378  loss: 3.1929 (3.1739)  weight_decay: 0.0500 (0.0500)  time: 0.2772  data: 0.0041  max mem: 3500\n",
            "Epoch: [68]  [ 30/295]  eta: 0:01:35  lr: 0.001375  min_lr: 0.001375  loss: 3.1141 (3.1602)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0026  max mem: 3500\n",
            "Epoch: [68]  [ 40/295]  eta: 0:01:25  lr: 0.001372  min_lr: 0.001372  loss: 3.1289 (3.1524)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0014  max mem: 3500\n",
            "Epoch: [68]  [ 50/295]  eta: 0:01:19  lr: 0.001370  min_lr: 0.001370  loss: 3.1402 (3.1457)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0015  max mem: 3500\n",
            "Epoch: [68]  [ 60/295]  eta: 0:01:14  lr: 0.001367  min_lr: 0.001367  loss: 3.1150 (3.1451)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0020  max mem: 3500\n",
            "Epoch: [68]  [ 70/295]  eta: 0:01:09  lr: 0.001365  min_lr: 0.001365  loss: 3.2922 (3.1568)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0027  max mem: 3500\n",
            "Epoch: [68]  [ 80/295]  eta: 0:01:05  lr: 0.001362  min_lr: 0.001362  loss: 3.2121 (3.1550)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0018  max mem: 3500\n",
            "Epoch: [68]  [ 90/295]  eta: 0:01:01  lr: 0.001360  min_lr: 0.001360  loss: 3.0670 (3.1415)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0008  max mem: 3500\n",
            "Epoch: [68]  [100/295]  eta: 0:00:57  lr: 0.001357  min_lr: 0.001357  loss: 3.1091 (3.1497)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0039  max mem: 3500\n",
            "Epoch: [68]  [110/295]  eta: 0:00:54  lr: 0.001355  min_lr: 0.001355  loss: 3.2219 (3.1484)  weight_decay: 0.0500 (0.0500)  time: 0.2743  data: 0.0056  max mem: 3500\n",
            "Epoch: [68]  [120/295]  eta: 0:00:51  lr: 0.001352  min_lr: 0.001352  loss: 3.0937 (3.1419)  weight_decay: 0.0500 (0.0500)  time: 0.2746  data: 0.0053  max mem: 3500\n",
            "Epoch: [68]  [130/295]  eta: 0:00:48  lr: 0.001350  min_lr: 0.001350  loss: 3.0937 (3.1385)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0050  max mem: 3500\n",
            "Epoch: [68]  [140/295]  eta: 0:00:44  lr: 0.001347  min_lr: 0.001347  loss: 3.1053 (3.1344)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0030  max mem: 3500\n",
            "Epoch: [68]  [150/295]  eta: 0:00:41  lr: 0.001345  min_lr: 0.001345  loss: 3.1389 (3.1385)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0019  max mem: 3500\n",
            "Epoch: [68]  [160/295]  eta: 0:00:38  lr: 0.001342  min_lr: 0.001342  loss: 3.1893 (3.1394)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0016  max mem: 3500\n",
            "Epoch: [68]  [170/295]  eta: 0:00:35  lr: 0.001340  min_lr: 0.001340  loss: 3.1893 (3.1373)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0029  max mem: 3500\n",
            "Epoch: [68]  [180/295]  eta: 0:00:32  lr: 0.001337  min_lr: 0.001337  loss: 3.1838 (3.1363)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0040  max mem: 3500\n",
            "Epoch: [68]  [190/295]  eta: 0:00:29  lr: 0.001335  min_lr: 0.001335  loss: 3.2013 (3.1368)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0045  max mem: 3500\n",
            "Epoch: [68]  [200/295]  eta: 0:00:26  lr: 0.001332  min_lr: 0.001332  loss: 3.1445 (3.1345)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0039  max mem: 3500\n",
            "Epoch: [68]  [210/295]  eta: 0:00:23  lr: 0.001330  min_lr: 0.001330  loss: 3.1503 (3.1408)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0031  max mem: 3500\n",
            "Epoch: [68]  [220/295]  eta: 0:00:21  lr: 0.001327  min_lr: 0.001327  loss: 3.2513 (3.1402)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0037  max mem: 3500\n",
            "Epoch: [68]  [230/295]  eta: 0:00:18  lr: 0.001325  min_lr: 0.001325  loss: 3.0509 (3.1365)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0026  max mem: 3500\n",
            "Epoch: [68]  [240/295]  eta: 0:00:15  lr: 0.001322  min_lr: 0.001322  loss: 3.0509 (3.1351)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0014  max mem: 3500\n",
            "Epoch: [68]  [250/295]  eta: 0:00:12  lr: 0.001320  min_lr: 0.001320  loss: 3.1989 (3.1349)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0021  max mem: 3500\n",
            "Epoch: [68]  [260/295]  eta: 0:00:09  lr: 0.001317  min_lr: 0.001317  loss: 3.1989 (3.1362)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0035  max mem: 3500\n",
            "Epoch: [68]  [270/295]  eta: 0:00:06  lr: 0.001314  min_lr: 0.001314  loss: 3.2297 (3.1371)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0054  max mem: 3500\n",
            "Epoch: [68]  [280/295]  eta: 0:00:04  lr: 0.001311  min_lr: 0.001311  loss: 3.0586 (3.1334)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0042  max mem: 3500\n",
            "Epoch: [68]  [290/295]  eta: 0:00:01  lr: 0.001309  min_lr: 0.001309  loss: 3.0611 (3.1320)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0008  max mem: 3500\n",
            "Epoch: [68]  [294/295]  eta: 0:00:00  lr: 0.001309  min_lr: 0.001309  loss: 3.0859 (3.1324)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0002  max mem: 3500\n",
            "Epoch: [68] Total time: 0:01:21 (0.2746 s / it)\n",
            "Averaged stats: lr: 0.001309  min_lr: 0.001309  loss: 3.0859 (3.1324)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:48  loss: 0.6857 (0.6857)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.0604  data: 1.8944  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.6729 (0.6974)  acc1: 91.6667 (88.6364)  acc5: 97.9167 (98.1061)  time: 0.3032  data: 0.1773  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.7031 (0.7465)  acc1: 87.5000 (86.6071)  acc5: 100.0000 (98.6111)  time: 0.1359  data: 0.0031  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.9039 (0.9720)  acc1: 81.2500 (76.6801)  acc5: 97.9167 (97.7151)  time: 0.1464  data: 0.0032  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8059 (0.9263)  acc1: 81.2500 (78.3537)  acc5: 97.9167 (98.0691)  time: 0.1666  data: 0.0295  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7983 (0.9272)  acc1: 83.3333 (78.6765)  acc5: 97.9167 (97.9984)  time: 0.1779  data: 0.0434  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9076 (0.9174)  acc1: 81.2500 (79.0642)  acc5: 97.9167 (97.8142)  time: 0.1693  data: 0.0304  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8447 (0.9166)  acc1: 81.2500 (79.2840)  acc5: 97.9167 (97.5939)  time: 0.1492  data: 0.0142  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6679 (0.8755)  acc1: 87.5000 (80.7613)  acc5: 97.9167 (97.7881)  time: 0.1241  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6679 (0.8757)  acc1: 87.5000 (80.7389)  acc5: 97.9167 (97.7325)  time: 0.1191  data: 0.0005  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1768 s / it)\n",
            "* Acc@1 80.739 Acc@5 97.732 loss 0.876\n",
            "Accuracy of the model on the 3925 test images: 80.7%\n",
            "Max accuracy: 81.50%\n",
            "Test:  [ 0/82]  eta: 0:02:22  loss: 2.5667 (2.5667)  acc1: 16.6667 (16.6667)  acc5: 89.5833 (89.5833)  time: 1.7438  data: 1.5777  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.6935 (2.8242)  acc1: 14.5833 (13.8258)  acc5: 95.8333 (95.6439)  time: 0.2845  data: 0.1583  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 3.0165 (3.0477)  acc1: 10.4167 (12.3016)  acc5: 95.8333 (95.1389)  time: 0.1330  data: 0.0101  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.6792 (3.6004)  acc1: 8.3333 (9.4758)  acc5: 91.6667 (80.9140)  time: 0.1259  data: 0.0036  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.9032 (3.6854)  acc1: 8.3333 (10.4675)  acc5: 68.7500 (78.2520)  time: 0.1260  data: 0.0047  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.2721 (3.9334)  acc1: 12.5000 (10.2124)  acc5: 68.7500 (72.5490)  time: 0.1325  data: 0.0089  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6974 (4.0444)  acc1: 2.0833 (8.7090)  acc5: 43.7500 (70.0137)  time: 0.1450  data: 0.0068  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 4.1990 (3.8977)  acc1: 2.0833 (12.6174)  acc5: 70.8333 (69.8650)  time: 0.1468  data: 0.0011  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2472 (3.5463)  acc1: 64.5833 (20.5247)  acc5: 97.9167 (73.3539)  time: 0.1298  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2472 (3.5184)  acc1: 68.7500 (21.0955)  acc5: 97.9167 (73.5287)  time: 0.1271  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1584 s / it)\n",
            "* Acc@1 21.096 Acc@5 73.529 loss 3.518\n",
            "Accuracy of the model EMA on 3925 test images: 21.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [69]  [  0/295]  eta: 0:12:58  lr: 0.001308  min_lr: 0.001308  loss: 3.1303 (3.1303)  weight_decay: 0.0500 (0.0500)  time: 2.6398  data: 2.0674  max mem: 3500\n",
            "Epoch: [69]  [ 10/295]  eta: 0:02:18  lr: 0.001306  min_lr: 0.001306  loss: 3.1303 (3.1124)  weight_decay: 0.0500 (0.0500)  time: 0.4864  data: 0.1896  max mem: 3500\n",
            "Epoch: [69]  [ 20/295]  eta: 0:01:44  lr: 0.001303  min_lr: 0.001303  loss: 3.1523 (3.1485)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0024  max mem: 3500\n",
            "Epoch: [69]  [ 30/295]  eta: 0:01:30  lr: 0.001301  min_lr: 0.001301  loss: 3.1936 (3.1377)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0019  max mem: 3500\n",
            "Epoch: [69]  [ 40/295]  eta: 0:01:22  lr: 0.001298  min_lr: 0.001298  loss: 3.0158 (3.1129)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0026  max mem: 3500\n",
            "Epoch: [69]  [ 50/295]  eta: 0:01:16  lr: 0.001296  min_lr: 0.001296  loss: 2.9754 (3.0936)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0040  max mem: 3500\n",
            "Epoch: [69]  [ 60/295]  eta: 0:01:12  lr: 0.001293  min_lr: 0.001293  loss: 3.0575 (3.0772)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0039  max mem: 3500\n",
            "Epoch: [69]  [ 70/295]  eta: 0:01:07  lr: 0.001291  min_lr: 0.001291  loss: 3.0606 (3.0856)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0039  max mem: 3500\n",
            "Epoch: [69]  [ 80/295]  eta: 0:01:03  lr: 0.001288  min_lr: 0.001288  loss: 3.2350 (3.0918)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0024  max mem: 3500\n",
            "Epoch: [69]  [ 90/295]  eta: 0:01:00  lr: 0.001286  min_lr: 0.001286  loss: 3.1897 (3.0796)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0021  max mem: 3500\n",
            "Epoch: [69]  [100/295]  eta: 0:00:56  lr: 0.001283  min_lr: 0.001283  loss: 3.0367 (3.0764)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0032  max mem: 3500\n",
            "Epoch: [69]  [110/295]  eta: 0:00:53  lr: 0.001281  min_lr: 0.001281  loss: 3.1078 (3.0813)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0038  max mem: 3500\n",
            "Epoch: [69]  [120/295]  eta: 0:00:50  lr: 0.001278  min_lr: 0.001278  loss: 3.1227 (3.0828)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0042  max mem: 3500\n",
            "Epoch: [69]  [130/295]  eta: 0:00:47  lr: 0.001276  min_lr: 0.001276  loss: 3.1222 (3.0907)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0039  max mem: 3500\n",
            "Epoch: [69]  [140/295]  eta: 0:00:44  lr: 0.001273  min_lr: 0.001273  loss: 3.1885 (3.0981)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0024  max mem: 3500\n",
            "Epoch: [69]  [150/295]  eta: 0:00:40  lr: 0.001271  min_lr: 0.001271  loss: 3.1460 (3.0943)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0013  max mem: 3500\n",
            "Epoch: [69]  [160/295]  eta: 0:00:37  lr: 0.001268  min_lr: 0.001268  loss: 3.0433 (3.0953)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0018  max mem: 3500\n",
            "Epoch: [69]  [170/295]  eta: 0:00:35  lr: 0.001266  min_lr: 0.001266  loss: 3.2161 (3.1017)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0030  max mem: 3500\n",
            "Epoch: [69]  [180/295]  eta: 0:00:32  lr: 0.001263  min_lr: 0.001263  loss: 3.2018 (3.1041)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0046  max mem: 3500\n",
            "Epoch: [69]  [190/295]  eta: 0:00:29  lr: 0.001261  min_lr: 0.001261  loss: 3.1847 (3.1085)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0037  max mem: 3500\n",
            "Epoch: [69]  [200/295]  eta: 0:00:26  lr: 0.001258  min_lr: 0.001258  loss: 3.1500 (3.1087)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0020  max mem: 3500\n",
            "Epoch: [69]  [210/295]  eta: 0:00:23  lr: 0.001256  min_lr: 0.001256  loss: 3.1113 (3.1059)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0021  max mem: 3500\n",
            "Epoch: [69]  [220/295]  eta: 0:00:20  lr: 0.001253  min_lr: 0.001253  loss: 3.1659 (3.1081)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0017  max mem: 3500\n",
            "Epoch: [69]  [230/295]  eta: 0:00:17  lr: 0.001251  min_lr: 0.001251  loss: 3.1749 (3.1075)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0027  max mem: 3500\n",
            "Epoch: [69]  [240/295]  eta: 0:00:15  lr: 0.001248  min_lr: 0.001248  loss: 3.1001 (3.1065)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0033  max mem: 3500\n",
            "Epoch: [69]  [250/295]  eta: 0:00:12  lr: 0.001246  min_lr: 0.001246  loss: 3.0784 (3.1037)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0038  max mem: 3500\n",
            "Epoch: [69]  [260/295]  eta: 0:00:09  lr: 0.001243  min_lr: 0.001243  loss: 3.0185 (3.1006)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0038  max mem: 3500\n",
            "Epoch: [69]  [270/295]  eta: 0:00:06  lr: 0.001241  min_lr: 0.001241  loss: 2.9856 (3.0947)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0029  max mem: 3500\n",
            "Epoch: [69]  [280/295]  eta: 0:00:04  lr: 0.001238  min_lr: 0.001238  loss: 2.9241 (3.0927)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0018  max mem: 3500\n",
            "Epoch: [69]  [290/295]  eta: 0:00:01  lr: 0.001236  min_lr: 0.001236  loss: 2.9616 (3.0891)  weight_decay: 0.0500 (0.0500)  time: 0.2568  data: 0.0004  max mem: 3500\n",
            "Epoch: [69]  [294/295]  eta: 0:00:00  lr: 0.001236  min_lr: 0.001236  loss: 2.9616 (3.0876)  weight_decay: 0.0500 (0.0500)  time: 0.2194  data: 0.0002  max mem: 3500\n",
            "Epoch: [69] Total time: 0:01:20 (0.2720 s / it)\n",
            "Averaged stats: lr: 0.001236  min_lr: 0.001236  loss: 2.9616 (3.0876)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:38  loss: 0.6032 (0.6032)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 3.4015  data: 3.2050  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:36  loss: 0.5828 (0.6245)  acc1: 91.6667 (88.6364)  acc5: 97.9167 (98.2955)  time: 0.5006  data: 0.3299  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:21  loss: 0.6015 (0.6460)  acc1: 89.5833 (87.8968)  acc5: 100.0000 (98.6111)  time: 0.1988  data: 0.0332  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:16  loss: 0.6982 (0.7658)  acc1: 83.3333 (83.6022)  acc5: 100.0000 (98.3871)  time: 0.2209  data: 0.0513  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:12  loss: 0.6764 (0.7364)  acc1: 83.3333 (84.6545)  acc5: 97.9167 (98.4248)  time: 0.2186  data: 0.0491  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:08  loss: 0.6820 (0.7617)  acc1: 85.4167 (83.6601)  acc5: 97.9167 (98.4069)  time: 0.1775  data: 0.0242  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:05  loss: 0.9205 (0.7865)  acc1: 79.1667 (82.7186)  acc5: 97.9167 (98.3948)  time: 0.1550  data: 0.0200  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8901 (0.8148)  acc1: 77.0833 (81.8662)  acc5: 97.9167 (98.1808)  time: 0.1293  data: 0.0065  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8147 (0.8021)  acc1: 81.2500 (82.3045)  acc5: 97.9167 (98.2510)  time: 0.1195  data: 0.0009  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8147 (0.8054)  acc1: 81.2500 (82.2166)  acc5: 97.9167 (98.2166)  time: 0.1175  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:17 (0.2166 s / it)\n",
            "* Acc@1 82.217 Acc@5 98.217 loss 0.805\n",
            "Accuracy of the model on the 3925 test images: 82.2%\n",
            "Max accuracy: 82.22%\n",
            "Test:  [ 0/82]  eta: 0:02:23  loss: 2.5129 (2.5129)  acc1: 16.6667 (16.6667)  acc5: 91.6667 (91.6667)  time: 1.7503  data: 1.5751  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.6460 (2.7801)  acc1: 14.5833 (14.2045)  acc5: 95.8333 (95.8333)  time: 0.2894  data: 0.1503  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 3.0067 (3.0165)  acc1: 12.5000 (12.3016)  acc5: 95.8333 (95.3373)  time: 0.1612  data: 0.0140  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.6639 (3.5703)  acc1: 6.2500 (9.4758)  acc5: 91.6667 (80.9812)  time: 0.1799  data: 0.0329  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.8394 (3.6496)  acc1: 8.3333 (10.5183)  acc5: 70.8333 (78.4045)  time: 0.1797  data: 0.0440  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.2600 (3.9019)  acc1: 12.5000 (10.1716)  acc5: 70.8333 (72.7124)  time: 0.1711  data: 0.0356  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6965 (4.0131)  acc1: 2.0833 (8.6749)  acc5: 43.7500 (70.1503)  time: 0.1645  data: 0.0302  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.1742 (3.8667)  acc1: 2.0833 (12.6174)  acc5: 70.8333 (69.8944)  time: 0.1453  data: 0.0158  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2295 (3.5171)  acc1: 64.5833 (20.6019)  acc5: 97.9167 (73.3796)  time: 0.1231  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2295 (3.4893)  acc1: 68.7500 (21.1720)  acc5: 97.9167 (73.5541)  time: 0.1200  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1815 s / it)\n",
            "* Acc@1 21.172 Acc@5 73.554 loss 3.489\n",
            "Accuracy of the model EMA on 3925 test images: 21.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [70]  [  0/295]  eta: 0:07:21  lr: 0.001235  min_lr: 0.001235  loss: 3.5245 (3.5245)  weight_decay: 0.0500 (0.0500)  time: 1.4972  data: 1.1407  max mem: 3500\n",
            "Epoch: [70]  [ 10/295]  eta: 0:01:54  lr: 0.001233  min_lr: 0.001233  loss: 3.2857 (3.2580)  weight_decay: 0.0500 (0.0500)  time: 0.4025  data: 0.1052  max mem: 3500\n",
            "Epoch: [70]  [ 20/295]  eta: 0:01:33  lr: 0.001230  min_lr: 0.001230  loss: 3.1411 (3.1984)  weight_decay: 0.0500 (0.0500)  time: 0.2819  data: 0.0023  max mem: 3500\n",
            "Epoch: [70]  [ 30/295]  eta: 0:01:24  lr: 0.001228  min_lr: 0.001228  loss: 3.1975 (3.2115)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0029  max mem: 3500\n",
            "Epoch: [70]  [ 40/295]  eta: 0:01:18  lr: 0.001225  min_lr: 0.001225  loss: 3.2570 (3.2103)  weight_decay: 0.0500 (0.0500)  time: 0.2746  data: 0.0031  max mem: 3500\n",
            "Epoch: [70]  [ 50/295]  eta: 0:01:13  lr: 0.001223  min_lr: 0.001223  loss: 3.2046 (3.1944)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0026  max mem: 3500\n",
            "Epoch: [70]  [ 60/295]  eta: 0:01:09  lr: 0.001220  min_lr: 0.001220  loss: 3.1529 (3.1752)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0013  max mem: 3500\n",
            "Epoch: [70]  [ 70/295]  eta: 0:01:05  lr: 0.001218  min_lr: 0.001218  loss: 3.1850 (3.1698)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0011  max mem: 3500\n",
            "Epoch: [70]  [ 80/295]  eta: 0:01:01  lr: 0.001215  min_lr: 0.001215  loss: 3.0623 (3.1523)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0014  max mem: 3500\n",
            "Epoch: [70]  [ 90/295]  eta: 0:00:58  lr: 0.001214  min_lr: 0.001214  loss: 3.0353 (3.1501)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0021  max mem: 3500\n",
            "Epoch: [70]  [100/295]  eta: 0:00:55  lr: 0.001211  min_lr: 0.001211  loss: 3.1136 (3.1544)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0029  max mem: 3500\n",
            "Epoch: [70]  [110/295]  eta: 0:00:52  lr: 0.001209  min_lr: 0.001209  loss: 3.1576 (3.1549)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0041  max mem: 3500\n",
            "Epoch: [70]  [120/295]  eta: 0:00:49  lr: 0.001206  min_lr: 0.001206  loss: 3.1576 (3.1508)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0039  max mem: 3500\n",
            "Epoch: [70]  [130/295]  eta: 0:00:45  lr: 0.001204  min_lr: 0.001204  loss: 3.1234 (3.1485)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0017  max mem: 3500\n",
            "Epoch: [70]  [140/295]  eta: 0:00:43  lr: 0.001201  min_lr: 0.001201  loss: 3.1234 (3.1475)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0014  max mem: 3500\n",
            "Epoch: [70]  [150/295]  eta: 0:00:40  lr: 0.001199  min_lr: 0.001199  loss: 3.2159 (3.1505)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0020  max mem: 3500\n",
            "Epoch: [70]  [160/295]  eta: 0:00:37  lr: 0.001196  min_lr: 0.001196  loss: 3.0917 (3.1421)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0030  max mem: 3500\n",
            "Epoch: [70]  [170/295]  eta: 0:00:34  lr: 0.001194  min_lr: 0.001194  loss: 3.1049 (3.1497)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0030  max mem: 3500\n",
            "Epoch: [70]  [180/295]  eta: 0:00:31  lr: 0.001191  min_lr: 0.001191  loss: 3.1707 (3.1446)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0031  max mem: 3500\n",
            "Epoch: [70]  [190/295]  eta: 0:00:28  lr: 0.001189  min_lr: 0.001189  loss: 3.1113 (3.1430)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0030  max mem: 3500\n",
            "Epoch: [70]  [200/295]  eta: 0:00:26  lr: 0.001186  min_lr: 0.001186  loss: 2.9926 (3.1365)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0015  max mem: 3500\n",
            "Epoch: [70]  [210/295]  eta: 0:00:23  lr: 0.001184  min_lr: 0.001184  loss: 2.8951 (3.1292)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0010  max mem: 3500\n",
            "Epoch: [70]  [220/295]  eta: 0:00:20  lr: 0.001181  min_lr: 0.001181  loss: 3.0560 (3.1283)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0010  max mem: 3500\n",
            "Epoch: [70]  [230/295]  eta: 0:00:17  lr: 0.001179  min_lr: 0.001179  loss: 3.2165 (3.1352)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0029  max mem: 3500\n",
            "Epoch: [70]  [240/295]  eta: 0:00:14  lr: 0.001176  min_lr: 0.001176  loss: 3.2444 (3.1399)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0035  max mem: 3500\n",
            "Epoch: [70]  [250/295]  eta: 0:00:12  lr: 0.001174  min_lr: 0.001174  loss: 3.1643 (3.1386)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0024  max mem: 3500\n",
            "Epoch: [70]  [260/295]  eta: 0:00:09  lr: 0.001171  min_lr: 0.001171  loss: 3.1009 (3.1356)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0016  max mem: 3500\n",
            "Epoch: [70]  [270/295]  eta: 0:00:06  lr: 0.001169  min_lr: 0.001169  loss: 2.9623 (3.1327)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0006  max mem: 3500\n",
            "Epoch: [70]  [280/295]  eta: 0:00:04  lr: 0.001166  min_lr: 0.001166  loss: 3.1961 (3.1349)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0004  max mem: 3500\n",
            "Epoch: [70]  [290/295]  eta: 0:00:01  lr: 0.001164  min_lr: 0.001164  loss: 3.2033 (3.1347)  weight_decay: 0.0500 (0.0500)  time: 0.2580  data: 0.0003  max mem: 3500\n",
            "Epoch: [70]  [294/295]  eta: 0:00:00  lr: 0.001164  min_lr: 0.001164  loss: 3.2033 (3.1347)  weight_decay: 0.0500 (0.0500)  time: 0.2207  data: 0.0002  max mem: 3500\n",
            "Epoch: [70] Total time: 0:01:19 (0.2697 s / it)\n",
            "Averaged stats: lr: 0.001164  min_lr: 0.001164  loss: 3.2033 (3.1347)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:15  loss: 0.5810 (0.5810)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.3889  data: 2.2178  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 0.5810 (0.6795)  acc1: 91.6667 (88.6364)  acc5: 97.9167 (97.7273)  time: 0.3942  data: 0.2474  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.7487 (0.7420)  acc1: 85.4167 (86.1111)  acc5: 97.9167 (98.2143)  time: 0.1608  data: 0.0271  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.8465 (0.9050)  acc1: 77.0833 (79.1667)  acc5: 97.9167 (98.0511)  time: 0.1255  data: 0.0042  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8566 (0.8858)  acc1: 79.1667 (80.2337)  acc5: 97.9167 (98.2215)  time: 0.1243  data: 0.0057  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8566 (0.9157)  acc1: 83.3333 (79.4526)  acc5: 97.9167 (98.0392)  time: 0.1243  data: 0.0069  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8346 (0.8966)  acc1: 79.1667 (80.0888)  acc5: 97.9167 (98.0533)  time: 0.1219  data: 0.0052  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8346 (0.9014)  acc1: 79.1667 (79.9883)  acc5: 97.9167 (97.8286)  time: 0.1185  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7975 (0.8737)  acc1: 83.3333 (81.0185)  acc5: 97.9167 (97.9424)  time: 0.1177  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7975 (0.8751)  acc1: 83.3333 (80.9682)  acc5: 97.9167 (97.9108)  time: 0.1163  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1655 s / it)\n",
            "* Acc@1 80.968 Acc@5 97.911 loss 0.875\n",
            "Accuracy of the model on the 3925 test images: 81.0%\n",
            "Max accuracy: 82.22%\n",
            "Test:  [ 0/82]  eta: 0:04:08  loss: 2.4597 (2.4597)  acc1: 16.6667 (16.6667)  acc5: 91.6667 (91.6667)  time: 3.0349  data: 2.8485  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 2.5924 (2.7372)  acc1: 16.6667 (15.3409)  acc5: 95.8333 (95.6439)  time: 0.4199  data: 0.2774  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 2.9957 (2.9858)  acc1: 12.5000 (12.7976)  acc5: 95.8333 (95.2381)  time: 0.1640  data: 0.0179  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.6478 (3.5413)  acc1: 6.2500 (9.7446)  acc5: 91.6667 (80.9812)  time: 0.1477  data: 0.0107  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 3.7706 (3.6138)  acc1: 8.3333 (10.9248)  acc5: 72.9167 (78.5569)  time: 0.1247  data: 0.0044  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.2456 (3.8698)  acc1: 12.5000 (10.4575)  acc5: 72.9167 (72.7533)  time: 0.1244  data: 0.0032  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6932 (3.9804)  acc1: 2.0833 (8.9481)  acc5: 43.7500 (70.1844)  time: 0.1246  data: 0.0033  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.1456 (3.8341)  acc1: 2.0833 (12.8815)  acc5: 70.8333 (69.9531)  time: 0.1218  data: 0.0021  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.2139 (3.4866)  acc1: 66.6667 (20.8848)  acc5: 97.9167 (73.4311)  time: 0.1195  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.2139 (3.4591)  acc1: 68.7500 (21.4522)  acc5: 97.9167 (73.6051)  time: 0.1181  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1727 s / it)\n",
            "* Acc@1 21.452 Acc@5 73.605 loss 3.459\n",
            "Accuracy of the model EMA on 3925 test images: 21.5%\n",
            "Max EMA accuracy: 21.45%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [71]  [  0/295]  eta: 0:10:34  lr: 0.001163  min_lr: 0.001163  loss: 3.2887 (3.2887)  weight_decay: 0.0500 (0.0500)  time: 2.1496  data: 1.6421  max mem: 3500\n",
            "Epoch: [71]  [ 10/295]  eta: 0:02:29  lr: 0.001161  min_lr: 0.001161  loss: 3.1001 (3.1196)  weight_decay: 0.0500 (0.0500)  time: 0.5229  data: 0.1601  max mem: 3500\n",
            "Epoch: [71]  [ 20/295]  eta: 0:01:51  lr: 0.001159  min_lr: 0.001159  loss: 3.1351 (3.1321)  weight_decay: 0.0500 (0.0500)  time: 0.3189  data: 0.0067  max mem: 3500\n",
            "Epoch: [71]  [ 30/295]  eta: 0:01:35  lr: 0.001157  min_lr: 0.001157  loss: 3.1893 (3.1515)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0009  max mem: 3500\n",
            "Epoch: [71]  [ 40/295]  eta: 0:01:25  lr: 0.001154  min_lr: 0.001154  loss: 3.2027 (3.1504)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0009  max mem: 3500\n",
            "Epoch: [71]  [ 50/295]  eta: 0:01:18  lr: 0.001152  min_lr: 0.001152  loss: 3.1873 (3.1549)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0008  max mem: 3500\n",
            "Epoch: [71]  [ 60/295]  eta: 0:01:13  lr: 0.001149  min_lr: 0.001149  loss: 3.1338 (3.1409)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0016  max mem: 3500\n",
            "Epoch: [71]  [ 70/295]  eta: 0:01:08  lr: 0.001147  min_lr: 0.001147  loss: 3.0642 (3.1404)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0036  max mem: 3500\n",
            "Epoch: [71]  [ 80/295]  eta: 0:01:05  lr: 0.001144  min_lr: 0.001144  loss: 3.1110 (3.1342)  weight_decay: 0.0500 (0.0500)  time: 0.2748  data: 0.0039  max mem: 3500\n",
            "Epoch: [71]  [ 90/295]  eta: 0:01:01  lr: 0.001142  min_lr: 0.001142  loss: 3.1110 (3.1310)  weight_decay: 0.0500 (0.0500)  time: 0.2789  data: 0.0049  max mem: 3500\n",
            "Epoch: [71]  [100/295]  eta: 0:00:58  lr: 0.001139  min_lr: 0.001139  loss: 3.0842 (3.1172)  weight_decay: 0.0500 (0.0500)  time: 0.2805  data: 0.0036  max mem: 3500\n",
            "Epoch: [71]  [110/295]  eta: 0:00:54  lr: 0.001137  min_lr: 0.001137  loss: 3.0585 (3.1128)  weight_decay: 0.0500 (0.0500)  time: 0.2757  data: 0.0017  max mem: 3500\n",
            "Epoch: [71]  [120/295]  eta: 0:00:51  lr: 0.001134  min_lr: 0.001134  loss: 3.1135 (3.1121)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0015  max mem: 3500\n",
            "Epoch: [71]  [130/295]  eta: 0:00:47  lr: 0.001132  min_lr: 0.001132  loss: 3.1385 (3.1144)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0010  max mem: 3500\n",
            "Epoch: [71]  [140/295]  eta: 0:00:44  lr: 0.001129  min_lr: 0.001129  loss: 3.1627 (3.1222)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0014  max mem: 3500\n",
            "Epoch: [71]  [150/295]  eta: 0:00:41  lr: 0.001127  min_lr: 0.001127  loss: 3.2937 (3.1342)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0022  max mem: 3500\n",
            "Epoch: [71]  [160/295]  eta: 0:00:38  lr: 0.001125  min_lr: 0.001125  loss: 3.2753 (3.1378)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0034  max mem: 3500\n",
            "Epoch: [71]  [170/295]  eta: 0:00:35  lr: 0.001123  min_lr: 0.001123  loss: 3.2033 (3.1371)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0040  max mem: 3500\n",
            "Epoch: [71]  [180/295]  eta: 0:00:32  lr: 0.001120  min_lr: 0.001120  loss: 3.0836 (3.1375)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0024  max mem: 3500\n",
            "Epoch: [71]  [190/295]  eta: 0:00:29  lr: 0.001118  min_lr: 0.001118  loss: 3.2148 (3.1418)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0010  max mem: 3500\n",
            "Epoch: [71]  [200/295]  eta: 0:00:26  lr: 0.001115  min_lr: 0.001115  loss: 3.2032 (3.1367)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0012  max mem: 3500\n",
            "Epoch: [71]  [210/295]  eta: 0:00:23  lr: 0.001113  min_lr: 0.001113  loss: 3.0541 (3.1347)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0021  max mem: 3500\n",
            "Epoch: [71]  [220/295]  eta: 0:00:21  lr: 0.001110  min_lr: 0.001110  loss: 3.0541 (3.1318)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0042  max mem: 3500\n",
            "Epoch: [71]  [230/295]  eta: 0:00:18  lr: 0.001108  min_lr: 0.001108  loss: 3.2257 (3.1375)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0051  max mem: 3500\n",
            "Epoch: [71]  [240/295]  eta: 0:00:15  lr: 0.001105  min_lr: 0.001105  loss: 3.0526 (3.1312)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0031  max mem: 3500\n",
            "Epoch: [71]  [250/295]  eta: 0:00:12  lr: 0.001103  min_lr: 0.001103  loss: 2.8954 (3.1270)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0010  max mem: 3500\n",
            "Epoch: [71]  [260/295]  eta: 0:00:09  lr: 0.001100  min_lr: 0.001100  loss: 3.0742 (3.1268)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0013  max mem: 3500\n",
            "Epoch: [71]  [270/295]  eta: 0:00:06  lr: 0.001099  min_lr: 0.001099  loss: 3.2035 (3.1299)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0018  max mem: 3500\n",
            "Epoch: [71]  [280/295]  eta: 0:00:04  lr: 0.001096  min_lr: 0.001096  loss: 3.2448 (3.1287)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0008  max mem: 3500\n",
            "Epoch: [71]  [290/295]  eta: 0:00:01  lr: 0.001094  min_lr: 0.001094  loss: 3.1126 (3.1302)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0002  max mem: 3500\n",
            "Epoch: [71]  [294/295]  eta: 0:00:00  lr: 0.001094  min_lr: 0.001094  loss: 3.1126 (3.1314)  weight_decay: 0.0500 (0.0500)  time: 0.2221  data: 0.0002  max mem: 3500\n",
            "Epoch: [71] Total time: 0:01:21 (0.2750 s / it)\n",
            "Averaged stats: lr: 0.001094  min_lr: 0.001094  loss: 3.1126 (3.1314)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:23  loss: 0.7617 (0.7617)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (97.9167)  time: 1.7549  data: 1.6014  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.7385 (0.7915)  acc1: 87.5000 (86.7424)  acc5: 97.9167 (98.1061)  time: 0.2804  data: 0.1522  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 0.7344 (0.7668)  acc1: 87.5000 (87.5000)  acc5: 97.9167 (98.4127)  time: 0.1267  data: 0.0050  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.7390 (0.9173)  acc1: 85.4167 (80.7796)  acc5: 97.9167 (98.0511)  time: 0.1209  data: 0.0027  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 0.7390 (0.8637)  acc1: 83.3333 (82.2154)  acc5: 97.9167 (98.0691)  time: 0.1226  data: 0.0031  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7506 (0.8734)  acc1: 83.3333 (81.7810)  acc5: 100.0000 (98.2026)  time: 0.1236  data: 0.0046  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9565 (0.9092)  acc1: 79.1667 (80.6694)  acc5: 97.9167 (97.9850)  time: 0.1237  data: 0.0056  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9843 (0.9169)  acc1: 75.0000 (80.1056)  acc5: 97.9167 (97.8580)  time: 0.1214  data: 0.0029  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6649 (0.8821)  acc1: 87.5000 (81.1471)  acc5: 97.9167 (97.8652)  time: 0.1181  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6649 (0.8842)  acc1: 87.5000 (81.1210)  acc5: 97.9167 (97.8344)  time: 0.1163  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1491 s / it)\n",
            "* Acc@1 81.121 Acc@5 97.834 loss 0.884\n",
            "Accuracy of the model on the 3925 test images: 81.1%\n",
            "Max accuracy: 82.22%\n",
            "Test:  [ 0/82]  eta: 0:03:57  loss: 2.4114 (2.4114)  acc1: 22.9167 (22.9167)  acc5: 93.7500 (93.7500)  time: 2.8962  data: 2.7142  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 2.5446 (2.6990)  acc1: 16.6667 (16.2879)  acc5: 97.9167 (96.4015)  time: 0.4053  data: 0.2590  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 2.9954 (2.9582)  acc1: 10.4167 (13.1944)  acc5: 95.8333 (95.6349)  time: 0.1418  data: 0.0082  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.6286 (3.5156)  acc1: 6.2500 (9.8790)  acc5: 91.6667 (81.3172)  time: 0.1261  data: 0.0052  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.7075 (3.5817)  acc1: 8.3333 (11.1280)  acc5: 72.9167 (79.1159)  time: 0.1240  data: 0.0056  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.2320 (3.8410)  acc1: 12.5000 (10.6209)  acc5: 72.9167 (73.2026)  time: 0.1236  data: 0.0046  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6922 (3.9508)  acc1: 2.0833 (9.0847)  acc5: 43.7500 (70.5260)  time: 0.1246  data: 0.0063  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.1209 (3.8040)  acc1: 2.0833 (13.0282)  acc5: 70.8333 (70.2171)  time: 0.1218  data: 0.0039  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1991 (3.4585)  acc1: 66.6667 (21.0391)  acc5: 97.9167 (73.6626)  time: 0.1185  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1991 (3.4311)  acc1: 68.7500 (21.6051)  acc5: 97.9167 (73.8344)  time: 0.1170  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1654 s / it)\n",
            "* Acc@1 21.605 Acc@5 73.834 loss 3.431\n",
            "Accuracy of the model EMA on 3925 test images: 21.6%\n",
            "Max EMA accuracy: 21.61%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [72]  [  0/295]  eta: 0:18:15  lr: 0.001093  min_lr: 0.001093  loss: 3.4570 (3.4570)  weight_decay: 0.0500 (0.0500)  time: 3.7132  data: 3.0152  max mem: 3500\n",
            "Epoch: [72]  [ 10/295]  eta: 0:02:54  lr: 0.001091  min_lr: 0.001091  loss: 3.1845 (3.1325)  weight_decay: 0.0500 (0.0500)  time: 0.6127  data: 0.2770  max mem: 3500\n",
            "Epoch: [72]  [ 20/295]  eta: 0:02:02  lr: 0.001088  min_lr: 0.001088  loss: 3.1845 (3.1747)  weight_decay: 0.0500 (0.0500)  time: 0.2828  data: 0.0018  max mem: 3500\n",
            "Epoch: [72]  [ 30/295]  eta: 0:01:42  lr: 0.001086  min_lr: 0.001086  loss: 3.0907 (3.1252)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0011  max mem: 3500\n",
            "Epoch: [72]  [ 40/295]  eta: 0:01:31  lr: 0.001083  min_lr: 0.001083  loss: 3.0632 (3.1436)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0017  max mem: 3500\n",
            "Epoch: [72]  [ 50/295]  eta: 0:01:22  lr: 0.001081  min_lr: 0.001081  loss: 3.1303 (3.1176)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0013  max mem: 3500\n",
            "Epoch: [72]  [ 60/295]  eta: 0:01:17  lr: 0.001078  min_lr: 0.001078  loss: 3.0938 (3.1199)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0016  max mem: 3500\n",
            "Epoch: [72]  [ 70/295]  eta: 0:01:12  lr: 0.001076  min_lr: 0.001076  loss: 3.2284 (3.1394)  weight_decay: 0.0500 (0.0500)  time: 0.2744  data: 0.0025  max mem: 3500\n",
            "Epoch: [72]  [ 80/295]  eta: 0:01:07  lr: 0.001074  min_lr: 0.001074  loss: 3.1914 (3.1256)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0017  max mem: 3500\n",
            "Epoch: [72]  [ 90/295]  eta: 0:01:03  lr: 0.001072  min_lr: 0.001072  loss: 3.1073 (3.1227)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0011  max mem: 3500\n",
            "Epoch: [72]  [100/295]  eta: 0:00:59  lr: 0.001069  min_lr: 0.001069  loss: 3.0141 (3.1017)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0016  max mem: 3500\n",
            "Epoch: [72]  [110/295]  eta: 0:00:55  lr: 0.001067  min_lr: 0.001067  loss: 3.0141 (3.1004)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0014  max mem: 3500\n",
            "Epoch: [72]  [120/295]  eta: 0:00:52  lr: 0.001064  min_lr: 0.001064  loss: 3.2046 (3.1087)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0013  max mem: 3500\n",
            "Epoch: [72]  [130/295]  eta: 0:00:48  lr: 0.001062  min_lr: 0.001062  loss: 3.1845 (3.1071)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0014  max mem: 3500\n",
            "Epoch: [72]  [140/295]  eta: 0:00:45  lr: 0.001059  min_lr: 0.001059  loss: 3.1161 (3.1087)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0015  max mem: 3500\n",
            "Epoch: [72]  [150/295]  eta: 0:00:42  lr: 0.001057  min_lr: 0.001057  loss: 3.1921 (3.1122)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0016  max mem: 3500\n",
            "Epoch: [72]  [160/295]  eta: 0:00:39  lr: 0.001055  min_lr: 0.001055  loss: 3.2069 (3.1108)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0010  max mem: 3500\n",
            "Epoch: [72]  [170/295]  eta: 0:00:36  lr: 0.001053  min_lr: 0.001053  loss: 3.1666 (3.1105)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0014  max mem: 3500\n",
            "Epoch: [72]  [180/295]  eta: 0:00:32  lr: 0.001050  min_lr: 0.001050  loss: 3.1647 (3.1083)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0022  max mem: 3500\n",
            "Epoch: [72]  [190/295]  eta: 0:00:30  lr: 0.001048  min_lr: 0.001048  loss: 3.0813 (3.1068)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0029  max mem: 3500\n",
            "Epoch: [72]  [200/295]  eta: 0:00:27  lr: 0.001045  min_lr: 0.001045  loss: 3.1169 (3.1091)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0037  max mem: 3500\n",
            "Epoch: [72]  [210/295]  eta: 0:00:24  lr: 0.001043  min_lr: 0.001043  loss: 3.2190 (3.1056)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0039  max mem: 3500\n",
            "Epoch: [72]  [220/295]  eta: 0:00:21  lr: 0.001040  min_lr: 0.001040  loss: 3.0210 (3.1053)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0028  max mem: 3500\n",
            "Epoch: [72]  [230/295]  eta: 0:00:18  lr: 0.001039  min_lr: 0.001039  loss: 2.9881 (3.1026)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0014  max mem: 3500\n",
            "Epoch: [72]  [240/295]  eta: 0:00:15  lr: 0.001036  min_lr: 0.001036  loss: 3.1873 (3.1052)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0012  max mem: 3500\n",
            "Epoch: [72]  [250/295]  eta: 0:00:12  lr: 0.001034  min_lr: 0.001034  loss: 3.1080 (3.1023)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0014  max mem: 3500\n",
            "Epoch: [72]  [260/295]  eta: 0:00:09  lr: 0.001031  min_lr: 0.001031  loss: 3.0939 (3.1015)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0020  max mem: 3500\n",
            "Epoch: [72]  [270/295]  eta: 0:00:06  lr: 0.001029  min_lr: 0.001029  loss: 3.0618 (3.0975)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0023  max mem: 3500\n",
            "Epoch: [72]  [280/295]  eta: 0:00:04  lr: 0.001026  min_lr: 0.001026  loss: 3.0284 (3.0961)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0014  max mem: 3500\n",
            "Epoch: [72]  [290/295]  eta: 0:00:01  lr: 0.001024  min_lr: 0.001024  loss: 3.1013 (3.0986)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0004  max mem: 3500\n",
            "Epoch: [72]  [294/295]  eta: 0:00:00  lr: 0.001024  min_lr: 0.001024  loss: 3.0398 (3.0973)  weight_decay: 0.0500 (0.0500)  time: 0.2219  data: 0.0002  max mem: 3500\n",
            "Epoch: [72] Total time: 0:01:21 (0.2775 s / it)\n",
            "Averaged stats: lr: 0.001024  min_lr: 0.001024  loss: 3.0398 (3.0973)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:13  loss: 0.6700 (0.6700)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 2.3560  data: 2.1791  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.6520 (0.6914)  acc1: 89.5833 (88.4470)  acc5: 97.9167 (97.3485)  time: 0.3309  data: 0.2005  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.6789 (0.7009)  acc1: 87.5000 (87.8968)  acc5: 97.9167 (98.0159)  time: 0.1334  data: 0.0021  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7614 (0.8783)  acc1: 81.2500 (80.7796)  acc5: 97.9167 (97.7151)  time: 0.1615  data: 0.0253  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7580 (0.8416)  acc1: 81.2500 (82.2663)  acc5: 97.9167 (97.8659)  time: 0.1842  data: 0.0446  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7536 (0.8473)  acc1: 83.3333 (82.0670)  acc5: 100.0000 (97.9984)  time: 0.1761  data: 0.0346  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7713 (0.8308)  acc1: 83.3333 (82.3087)  acc5: 100.0000 (98.0874)  time: 0.1957  data: 0.0453  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8119 (0.8399)  acc1: 83.3333 (82.1009)  acc5: 97.9167 (97.9167)  time: 0.1751  data: 0.0309  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8104 (0.8269)  acc1: 85.4167 (82.6903)  acc5: 97.9167 (97.9424)  time: 0.1221  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8104 (0.8301)  acc1: 85.4167 (82.6242)  acc5: 97.9167 (97.8854)  time: 0.1206  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1904 s / it)\n",
            "* Acc@1 82.624 Acc@5 97.885 loss 0.830\n",
            "Accuracy of the model on the 3925 test images: 82.6%\n",
            "Max accuracy: 82.62%\n",
            "Test:  [ 0/82]  eta: 0:02:28  loss: 2.3648 (2.3648)  acc1: 22.9167 (22.9167)  acc5: 93.7500 (93.7500)  time: 1.8147  data: 1.6414  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 2.4970 (2.6600)  acc1: 16.6667 (16.2879)  acc5: 97.9167 (96.4015)  time: 0.3069  data: 0.1514  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.9950 (2.9294)  acc1: 10.4167 (13.0952)  acc5: 95.8333 (95.6349)  time: 0.1393  data: 0.0027  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.5964 (3.4884)  acc1: 6.2500 (9.6774)  acc5: 91.6667 (81.2500)  time: 0.1246  data: 0.0029  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.6466 (3.5485)  acc1: 8.3333 (10.9756)  acc5: 72.9167 (79.1667)  time: 0.1424  data: 0.0051  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.2129 (3.8099)  acc1: 12.5000 (10.4575)  acc5: 72.9167 (73.2026)  time: 0.1501  data: 0.0038  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6817 (3.9194)  acc1: 2.0833 (8.9481)  acc5: 43.7500 (70.5601)  time: 0.1454  data: 0.0007  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.0935 (3.7727)  acc1: 2.0833 (12.9108)  acc5: 70.8333 (70.2171)  time: 0.1502  data: 0.0007  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1851 (3.4293)  acc1: 66.6667 (20.9619)  acc5: 97.9167 (73.6883)  time: 0.1389  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1851 (3.4021)  acc1: 68.7500 (21.5032)  acc5: 97.9167 (73.8599)  time: 0.1316  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1683 s / it)\n",
            "* Acc@1 21.503 Acc@5 73.860 loss 3.402\n",
            "Accuracy of the model EMA on 3925 test images: 21.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [73]  [  0/295]  eta: 0:10:48  lr: 0.001024  min_lr: 0.001024  loss: 3.2318 (3.2318)  weight_decay: 0.0500 (0.0500)  time: 2.1972  data: 1.8124  max mem: 3500\n",
            "Epoch: [73]  [ 10/295]  eta: 0:02:05  lr: 0.001022  min_lr: 0.001022  loss: 3.2611 (3.1987)  weight_decay: 0.0500 (0.0500)  time: 0.4407  data: 0.1654  max mem: 3500\n",
            "Epoch: [73]  [ 20/295]  eta: 0:01:38  lr: 0.001019  min_lr: 0.001019  loss: 3.1914 (3.1619)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0006  max mem: 3500\n",
            "Epoch: [73]  [ 30/295]  eta: 0:01:26  lr: 0.001017  min_lr: 0.001017  loss: 3.1683 (3.1740)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0011  max mem: 3500\n",
            "Epoch: [73]  [ 40/295]  eta: 0:01:19  lr: 0.001014  min_lr: 0.001014  loss: 3.2114 (3.1967)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0020  max mem: 3500\n",
            "Epoch: [73]  [ 50/295]  eta: 0:01:14  lr: 0.001012  min_lr: 0.001012  loss: 3.0458 (3.1499)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0040  max mem: 3500\n",
            "Epoch: [73]  [ 60/295]  eta: 0:01:10  lr: 0.001009  min_lr: 0.001009  loss: 2.9391 (3.1351)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0035  max mem: 3500\n",
            "Epoch: [73]  [ 70/295]  eta: 0:01:06  lr: 0.001008  min_lr: 0.001008  loss: 3.1185 (3.1361)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0024  max mem: 3500\n",
            "Epoch: [73]  [ 80/295]  eta: 0:01:02  lr: 0.001005  min_lr: 0.001005  loss: 3.1217 (3.1317)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0022  max mem: 3500\n",
            "Epoch: [73]  [ 90/295]  eta: 0:00:59  lr: 0.001003  min_lr: 0.001003  loss: 3.1911 (3.1427)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0015  max mem: 3500\n",
            "Epoch: [73]  [100/295]  eta: 0:00:55  lr: 0.001000  min_lr: 0.001000  loss: 3.2026 (3.1480)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0019  max mem: 3500\n",
            "Epoch: [73]  [110/295]  eta: 0:00:52  lr: 0.000998  min_lr: 0.000998  loss: 3.0852 (3.1410)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0015  max mem: 3500\n",
            "Epoch: [73]  [120/295]  eta: 0:00:49  lr: 0.000995  min_lr: 0.000995  loss: 3.0285 (3.1369)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0019  max mem: 3500\n",
            "Epoch: [73]  [130/295]  eta: 0:00:46  lr: 0.000994  min_lr: 0.000994  loss: 3.1866 (3.1347)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0035  max mem: 3500\n",
            "Epoch: [73]  [140/295]  eta: 0:00:43  lr: 0.000991  min_lr: 0.000991  loss: 3.2407 (3.1404)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0032  max mem: 3500\n",
            "Epoch: [73]  [150/295]  eta: 0:00:40  lr: 0.000989  min_lr: 0.000989  loss: 3.2492 (3.1432)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0018  max mem: 3500\n",
            "Epoch: [73]  [160/295]  eta: 0:00:37  lr: 0.000986  min_lr: 0.000986  loss: 3.1185 (3.1400)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0016  max mem: 3500\n",
            "Epoch: [73]  [170/295]  eta: 0:00:34  lr: 0.000984  min_lr: 0.000984  loss: 3.1913 (3.1416)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0018  max mem: 3500\n",
            "Epoch: [73]  [180/295]  eta: 0:00:31  lr: 0.000982  min_lr: 0.000982  loss: 3.1343 (3.1337)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0014  max mem: 3500\n",
            "Epoch: [73]  [190/295]  eta: 0:00:29  lr: 0.000980  min_lr: 0.000980  loss: 3.1343 (3.1363)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0034  max mem: 3500\n",
            "Epoch: [73]  [200/295]  eta: 0:00:26  lr: 0.000977  min_lr: 0.000977  loss: 3.2008 (3.1354)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0035  max mem: 3500\n",
            "Epoch: [73]  [210/295]  eta: 0:00:23  lr: 0.000975  min_lr: 0.000975  loss: 3.1224 (3.1328)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0014  max mem: 3500\n",
            "Epoch: [73]  [220/295]  eta: 0:00:20  lr: 0.000972  min_lr: 0.000972  loss: 3.1123 (3.1312)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0015  max mem: 3500\n",
            "Epoch: [73]  [230/295]  eta: 0:00:17  lr: 0.000970  min_lr: 0.000970  loss: 2.9827 (3.1237)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0012  max mem: 3500\n",
            "Epoch: [73]  [240/295]  eta: 0:00:15  lr: 0.000968  min_lr: 0.000968  loss: 3.1615 (3.1316)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0024  max mem: 3500\n",
            "Epoch: [73]  [250/295]  eta: 0:00:12  lr: 0.000966  min_lr: 0.000966  loss: 3.2654 (3.1328)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0045  max mem: 3500\n",
            "Epoch: [73]  [260/295]  eta: 0:00:09  lr: 0.000963  min_lr: 0.000963  loss: 3.2251 (3.1330)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0045  max mem: 3500\n",
            "Epoch: [73]  [270/295]  eta: 0:00:06  lr: 0.000961  min_lr: 0.000961  loss: 3.2209 (3.1335)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0020  max mem: 3500\n",
            "Epoch: [73]  [280/295]  eta: 0:00:04  lr: 0.000959  min_lr: 0.000959  loss: 3.2209 (3.1331)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0008  max mem: 3500\n",
            "Epoch: [73]  [290/295]  eta: 0:00:01  lr: 0.000957  min_lr: 0.000957  loss: 3.2347 (3.1338)  weight_decay: 0.0500 (0.0500)  time: 0.2569  data: 0.0007  max mem: 3500\n",
            "Epoch: [73]  [294/295]  eta: 0:00:00  lr: 0.000957  min_lr: 0.000957  loss: 3.2347 (3.1343)  weight_decay: 0.0500 (0.0500)  time: 0.2189  data: 0.0002  max mem: 3500\n",
            "Epoch: [73] Total time: 0:01:19 (0.2704 s / it)\n",
            "Averaged stats: lr: 0.000957  min_lr: 0.000957  loss: 3.2347 (3.1343)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:11  loss: 0.6586 (0.6586)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 3.0616  data: 2.8652  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:32  loss: 0.6586 (0.6782)  acc1: 89.5833 (89.7727)  acc5: 100.0000 (98.2955)  time: 0.4529  data: 0.2938  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.6782 (0.6896)  acc1: 89.5833 (89.0873)  acc5: 100.0000 (98.6111)  time: 0.1799  data: 0.0233  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.7633 (0.8714)  acc1: 85.4167 (82.3925)  acc5: 97.9167 (98.1183)  time: 0.1646  data: 0.0061  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7415 (0.8259)  acc1: 85.4167 (83.9431)  acc5: 97.9167 (98.2724)  time: 0.1426  data: 0.0019  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6983 (0.8422)  acc1: 85.4167 (83.3333)  acc5: 100.0000 (98.3660)  time: 0.1248  data: 0.0035  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.9441 (0.8624)  acc1: 79.1667 (82.3771)  acc5: 97.9167 (98.2924)  time: 0.1247  data: 0.0049  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9495 (0.8761)  acc1: 79.1667 (81.8662)  acc5: 97.9167 (98.0340)  time: 0.1213  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7921 (0.8567)  acc1: 85.4167 (82.6132)  acc5: 97.9167 (98.0710)  time: 0.1184  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7921 (0.8584)  acc1: 85.4167 (82.6242)  acc5: 97.9167 (98.0382)  time: 0.1173  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1814 s / it)\n",
            "* Acc@1 82.624 Acc@5 98.038 loss 0.858\n",
            "Accuracy of the model on the 3925 test images: 82.6%\n",
            "Max accuracy: 82.62%\n",
            "Test:  [ 0/82]  eta: 0:02:16  loss: 2.3202 (2.3202)  acc1: 25.0000 (25.0000)  acc5: 93.7500 (93.7500)  time: 1.6593  data: 1.4894  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:18  loss: 2.4525 (2.6221)  acc1: 18.7500 (17.2348)  acc5: 97.9167 (96.4015)  time: 0.2633  data: 0.1374  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.9900 (2.8992)  acc1: 12.5000 (13.5913)  acc5: 95.8333 (95.8333)  time: 0.1335  data: 0.0015  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.5607 (3.4608)  acc1: 6.2500 (10.0134)  acc5: 93.7500 (81.2500)  time: 0.1529  data: 0.0085  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.5986 (3.5158)  acc1: 8.3333 (11.2805)  acc5: 72.9167 (79.2683)  time: 0.1750  data: 0.0309  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.1890 (3.7790)  acc1: 10.4167 (10.6209)  acc5: 72.9167 (73.2435)  time: 0.1802  data: 0.0396  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6698 (3.8875)  acc1: 2.0833 (9.0847)  acc5: 43.7500 (70.6626)  time: 0.1710  data: 0.0289  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.0610 (3.7409)  acc1: 2.0833 (13.0575)  acc5: 70.8333 (70.3345)  time: 0.1631  data: 0.0300  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1621 (3.3999)  acc1: 66.6667 (21.0905)  acc5: 97.9167 (73.7912)  time: 0.1378  data: 0.0179  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1621 (3.3729)  acc1: 68.7500 (21.6306)  acc5: 97.9167 (73.9618)  time: 0.1352  data: 0.0178  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1773 s / it)\n",
            "* Acc@1 21.631 Acc@5 73.962 loss 3.373\n",
            "Accuracy of the model EMA on 3925 test images: 21.6%\n",
            "Max EMA accuracy: 21.63%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [74]  [  0/295]  eta: 0:10:30  lr: 0.000956  min_lr: 0.000956  loss: 3.1560 (3.1560)  weight_decay: 0.0500 (0.0500)  time: 2.1382  data: 1.7874  max mem: 3500\n",
            "Epoch: [74]  [ 10/295]  eta: 0:02:04  lr: 0.000954  min_lr: 0.000954  loss: 3.1237 (3.0946)  weight_decay: 0.0500 (0.0500)  time: 0.4371  data: 0.1647  max mem: 3500\n",
            "Epoch: [74]  [ 20/295]  eta: 0:01:38  lr: 0.000951  min_lr: 0.000951  loss: 3.0743 (3.0534)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0024  max mem: 3500\n",
            "Epoch: [74]  [ 30/295]  eta: 0:01:27  lr: 0.000949  min_lr: 0.000949  loss: 3.0743 (3.0840)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0029  max mem: 3500\n",
            "Epoch: [74]  [ 40/295]  eta: 0:01:20  lr: 0.000947  min_lr: 0.000947  loss: 3.1285 (3.0978)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0024  max mem: 3500\n",
            "Epoch: [74]  [ 50/295]  eta: 0:01:14  lr: 0.000945  min_lr: 0.000945  loss: 3.1167 (3.0928)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0013  max mem: 3500\n",
            "Epoch: [74]  [ 60/295]  eta: 0:01:10  lr: 0.000942  min_lr: 0.000942  loss: 3.1859 (3.1202)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0027  max mem: 3500\n",
            "Epoch: [74]  [ 70/295]  eta: 0:01:06  lr: 0.000940  min_lr: 0.000940  loss: 3.1859 (3.1174)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0043  max mem: 3500\n",
            "Epoch: [74]  [ 80/295]  eta: 0:01:03  lr: 0.000937  min_lr: 0.000937  loss: 3.1316 (3.1231)  weight_decay: 0.0500 (0.0500)  time: 0.2738  data: 0.0024  max mem: 3500\n",
            "Epoch: [74]  [ 90/295]  eta: 0:00:59  lr: 0.000936  min_lr: 0.000936  loss: 3.1931 (3.1347)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0012  max mem: 3500\n",
            "Epoch: [74]  [100/295]  eta: 0:00:56  lr: 0.000933  min_lr: 0.000933  loss: 3.1441 (3.1313)  weight_decay: 0.0500 (0.0500)  time: 0.2745  data: 0.0017  max mem: 3500\n",
            "Epoch: [74]  [110/295]  eta: 0:00:53  lr: 0.000931  min_lr: 0.000931  loss: 3.0946 (3.1271)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0018  max mem: 3500\n",
            "Epoch: [74]  [120/295]  eta: 0:00:50  lr: 0.000928  min_lr: 0.000928  loss: 3.1124 (3.1234)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0020  max mem: 3500\n",
            "Epoch: [74]  [130/295]  eta: 0:00:46  lr: 0.000927  min_lr: 0.000927  loss: 3.1725 (3.1301)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0025  max mem: 3500\n",
            "Epoch: [74]  [140/295]  eta: 0:00:43  lr: 0.000924  min_lr: 0.000924  loss: 3.1301 (3.1240)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0030  max mem: 3500\n",
            "Epoch: [74]  [150/295]  eta: 0:00:40  lr: 0.000922  min_lr: 0.000922  loss: 3.1301 (3.1271)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0026  max mem: 3500\n",
            "Epoch: [74]  [160/295]  eta: 0:00:37  lr: 0.000919  min_lr: 0.000919  loss: 3.1768 (3.1276)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0023  max mem: 3500\n",
            "Epoch: [74]  [170/295]  eta: 0:00:34  lr: 0.000918  min_lr: 0.000918  loss: 3.1374 (3.1234)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0038  max mem: 3500\n",
            "Epoch: [74]  [180/295]  eta: 0:00:32  lr: 0.000915  min_lr: 0.000915  loss: 3.1375 (3.1216)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0043  max mem: 3500\n",
            "Epoch: [74]  [190/295]  eta: 0:00:29  lr: 0.000913  min_lr: 0.000913  loss: 3.1944 (3.1287)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0028  max mem: 3500\n",
            "Epoch: [74]  [200/295]  eta: 0:00:26  lr: 0.000910  min_lr: 0.000910  loss: 3.0013 (3.1174)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0022  max mem: 3500\n",
            "Epoch: [74]  [210/295]  eta: 0:00:23  lr: 0.000908  min_lr: 0.000908  loss: 2.9174 (3.1186)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0015  max mem: 3500\n",
            "Epoch: [74]  [220/295]  eta: 0:00:20  lr: 0.000906  min_lr: 0.000906  loss: 3.1509 (3.1152)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0012  max mem: 3500\n",
            "Epoch: [74]  [230/295]  eta: 0:00:17  lr: 0.000904  min_lr: 0.000904  loss: 3.1718 (3.1170)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0023  max mem: 3500\n",
            "Epoch: [74]  [240/295]  eta: 0:00:15  lr: 0.000901  min_lr: 0.000901  loss: 3.2323 (3.1195)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0045  max mem: 3500\n",
            "Epoch: [74]  [250/295]  eta: 0:00:12  lr: 0.000899  min_lr: 0.000899  loss: 3.1879 (3.1185)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0035  max mem: 3500\n",
            "Epoch: [74]  [260/295]  eta: 0:00:09  lr: 0.000897  min_lr: 0.000897  loss: 3.1697 (3.1193)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0019  max mem: 3500\n",
            "Epoch: [74]  [270/295]  eta: 0:00:06  lr: 0.000895  min_lr: 0.000895  loss: 3.1284 (3.1190)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0019  max mem: 3500\n",
            "Epoch: [74]  [280/295]  eta: 0:00:04  lr: 0.000892  min_lr: 0.000892  loss: 3.0566 (3.1179)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0009  max mem: 3500\n",
            "Epoch: [74]  [290/295]  eta: 0:00:01  lr: 0.000891  min_lr: 0.000891  loss: 2.9223 (3.1132)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0003  max mem: 3500\n",
            "Epoch: [74]  [294/295]  eta: 0:00:00  lr: 0.000891  min_lr: 0.000891  loss: 2.8846 (3.1119)  weight_decay: 0.0500 (0.0500)  time: 0.2201  data: 0.0002  max mem: 3500\n",
            "Epoch: [74] Total time: 0:01:20 (0.2721 s / it)\n",
            "Averaged stats: lr: 0.000891  min_lr: 0.000891  loss: 2.8846 (3.1119)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:32  loss: 0.5361 (0.5361)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.5904  data: 2.3929  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 0.5361 (0.5502)  acc1: 91.6667 (90.9091)  acc5: 97.9167 (97.9167)  time: 0.3993  data: 0.2438  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.5726 (0.5974)  acc1: 91.6667 (89.6825)  acc5: 97.9167 (98.5119)  time: 0.1574  data: 0.0198  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7864 (0.7468)  acc1: 81.2500 (84.1398)  acc5: 97.9167 (98.4543)  time: 0.1303  data: 0.0067  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8602 (0.7618)  acc1: 81.2500 (84.3496)  acc5: 97.9167 (98.3740)  time: 0.1248  data: 0.0036  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8519 (0.7752)  acc1: 83.3333 (83.9461)  acc5: 97.9167 (98.3660)  time: 0.1224  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8594 (0.7891)  acc1: 83.3333 (83.6749)  acc5: 97.9167 (98.3948)  time: 0.1220  data: 0.0059  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8768 (0.8055)  acc1: 81.2500 (83.3333)  acc5: 97.9167 (98.0927)  time: 0.1206  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7276 (0.7936)  acc1: 83.3333 (83.7191)  acc5: 97.9167 (98.0453)  time: 0.1184  data: 0.0006  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7276 (0.7973)  acc1: 83.3333 (83.6688)  acc5: 97.9167 (97.9873)  time: 0.1164  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1653 s / it)\n",
            "* Acc@1 83.669 Acc@5 97.987 loss 0.797\n",
            "Accuracy of the model on the 3925 test images: 83.7%\n",
            "Max accuracy: 83.67%\n",
            "Test:  [ 0/82]  eta: 0:03:26  loss: 2.2692 (2.2692)  acc1: 25.0000 (25.0000)  acc5: 93.7500 (93.7500)  time: 2.5225  data: 2.3590  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 2.4010 (2.5797)  acc1: 18.7500 (17.9924)  acc5: 97.9167 (97.1591)  time: 0.4187  data: 0.2720  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.9941 (2.8691)  acc1: 12.5000 (13.9881)  acc5: 95.8333 (96.4286)  time: 0.1780  data: 0.0368  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.5278 (3.4330)  acc1: 6.2500 (10.2823)  acc5: 93.7500 (81.5188)  time: 0.1425  data: 0.0100  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.5684 (3.4826)  acc1: 8.3333 (11.6870)  acc5: 72.9167 (79.5732)  time: 0.1322  data: 0.0071  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.1707 (3.7489)  acc1: 10.4167 (10.8660)  acc5: 72.9167 (73.3660)  time: 0.1274  data: 0.0028  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6638 (3.8570)  acc1: 2.0833 (9.2896)  acc5: 43.7500 (70.7650)  time: 0.1274  data: 0.0026  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.0343 (3.7108)  acc1: 2.0833 (13.3509)  acc5: 70.8333 (70.4225)  time: 0.1235  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1408 (3.3718)  acc1: 66.6667 (21.3477)  acc5: 97.9167 (73.8683)  time: 0.1198  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1408 (3.3449)  acc1: 70.8333 (21.8854)  acc5: 97.9167 (74.0382)  time: 0.1182  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1732 s / it)\n",
            "* Acc@1 21.885 Acc@5 74.038 loss 3.345\n",
            "Accuracy of the model EMA on 3925 test images: 21.9%\n",
            "Max EMA accuracy: 21.89%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [75]  [  0/295]  eta: 0:11:22  lr: 0.000890  min_lr: 0.000890  loss: 3.2265 (3.2265)  weight_decay: 0.0500 (0.0500)  time: 2.3151  data: 1.7540  max mem: 3500\n",
            "Epoch: [75]  [ 10/295]  eta: 0:02:27  lr: 0.000888  min_lr: 0.000888  loss: 2.9961 (3.0785)  weight_decay: 0.0500 (0.0500)  time: 0.5180  data: 0.1637  max mem: 3500\n",
            "Epoch: [75]  [ 20/295]  eta: 0:01:50  lr: 0.000885  min_lr: 0.000885  loss: 2.9961 (3.1150)  weight_decay: 0.0500 (0.0500)  time: 0.3072  data: 0.0046  max mem: 3500\n",
            "Epoch: [75]  [ 30/295]  eta: 0:01:34  lr: 0.000883  min_lr: 0.000883  loss: 3.0006 (3.0785)  weight_decay: 0.0500 (0.0500)  time: 0.2691  data: 0.0025  max mem: 3500\n",
            "Epoch: [75]  [ 40/295]  eta: 0:01:25  lr: 0.000881  min_lr: 0.000881  loss: 3.0036 (3.0480)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0004  max mem: 3500\n",
            "Epoch: [75]  [ 50/295]  eta: 0:01:18  lr: 0.000879  min_lr: 0.000879  loss: 3.0647 (3.0506)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0005  max mem: 3500\n",
            "Epoch: [75]  [ 60/295]  eta: 0:01:13  lr: 0.000876  min_lr: 0.000876  loss: 3.0940 (3.0565)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0013  max mem: 3500\n",
            "Epoch: [75]  [ 70/295]  eta: 0:01:08  lr: 0.000874  min_lr: 0.000874  loss: 3.1351 (3.0692)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0017  max mem: 3500\n",
            "Epoch: [75]  [ 80/295]  eta: 0:01:04  lr: 0.000872  min_lr: 0.000872  loss: 3.2379 (3.0856)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0026  max mem: 3500\n",
            "Epoch: [75]  [ 90/295]  eta: 0:01:01  lr: 0.000870  min_lr: 0.000870  loss: 3.2727 (3.1052)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0027  max mem: 3500\n",
            "Epoch: [75]  [100/295]  eta: 0:00:57  lr: 0.000867  min_lr: 0.000867  loss: 3.2291 (3.1021)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0028  max mem: 3500\n",
            "Epoch: [75]  [110/295]  eta: 0:00:53  lr: 0.000866  min_lr: 0.000866  loss: 3.0772 (3.0973)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0027  max mem: 3500\n",
            "Epoch: [75]  [120/295]  eta: 0:00:50  lr: 0.000863  min_lr: 0.000863  loss: 3.0626 (3.0978)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0021  max mem: 3500\n",
            "Epoch: [75]  [130/295]  eta: 0:00:47  lr: 0.000861  min_lr: 0.000861  loss: 3.0626 (3.0895)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0026  max mem: 3500\n",
            "Epoch: [75]  [140/295]  eta: 0:00:44  lr: 0.000859  min_lr: 0.000859  loss: 3.0590 (3.0900)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0031  max mem: 3500\n",
            "Epoch: [75]  [150/295]  eta: 0:00:41  lr: 0.000857  min_lr: 0.000857  loss: 3.0811 (3.0856)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0031  max mem: 3500\n",
            "Epoch: [75]  [160/295]  eta: 0:00:38  lr: 0.000854  min_lr: 0.000854  loss: 3.0772 (3.0854)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0028  max mem: 3500\n",
            "Epoch: [75]  [170/295]  eta: 0:00:35  lr: 0.000852  min_lr: 0.000852  loss: 3.0469 (3.0832)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0020  max mem: 3500\n",
            "Epoch: [75]  [180/295]  eta: 0:00:32  lr: 0.000850  min_lr: 0.000850  loss: 2.9788 (3.0820)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0019  max mem: 3500\n",
            "Epoch: [75]  [190/295]  eta: 0:00:29  lr: 0.000848  min_lr: 0.000848  loss: 3.1866 (3.0850)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0022  max mem: 3500\n",
            "Epoch: [75]  [200/295]  eta: 0:00:26  lr: 0.000845  min_lr: 0.000845  loss: 3.1036 (3.0798)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0022  max mem: 3500\n",
            "Epoch: [75]  [210/295]  eta: 0:00:23  lr: 0.000844  min_lr: 0.000844  loss: 2.9798 (3.0750)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0030  max mem: 3500\n",
            "Epoch: [75]  [220/295]  eta: 0:00:20  lr: 0.000841  min_lr: 0.000841  loss: 3.1173 (3.0787)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0050  max mem: 3500\n",
            "Epoch: [75]  [230/295]  eta: 0:00:18  lr: 0.000839  min_lr: 0.000839  loss: 3.2021 (3.0834)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0040  max mem: 3500\n",
            "Epoch: [75]  [240/295]  eta: 0:00:15  lr: 0.000837  min_lr: 0.000837  loss: 3.1031 (3.0823)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0016  max mem: 3500\n",
            "Epoch: [75]  [250/295]  eta: 0:00:12  lr: 0.000835  min_lr: 0.000835  loss: 3.0351 (3.0812)  weight_decay: 0.0500 (0.0500)  time: 0.2587  data: 0.0018  max mem: 3500\n",
            "Epoch: [75]  [260/295]  eta: 0:00:09  lr: 0.000832  min_lr: 0.000832  loss: 3.1593 (3.0854)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0018  max mem: 3500\n",
            "Epoch: [75]  [270/295]  eta: 0:00:06  lr: 0.000830  min_lr: 0.000830  loss: 3.1695 (3.0884)  weight_decay: 0.0500 (0.0500)  time: 0.2680  data: 0.0036  max mem: 3500\n",
            "Epoch: [75]  [280/295]  eta: 0:00:04  lr: 0.000828  min_lr: 0.000828  loss: 3.1759 (3.0906)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0027  max mem: 3500\n",
            "Epoch: [75]  [290/295]  eta: 0:00:01  lr: 0.000826  min_lr: 0.000826  loss: 3.1707 (3.0906)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0002  max mem: 3500\n",
            "Epoch: [75]  [294/295]  eta: 0:00:00  lr: 0.000826  min_lr: 0.000826  loss: 3.1707 (3.0913)  weight_decay: 0.0500 (0.0500)  time: 0.2246  data: 0.0002  max mem: 3500\n",
            "Epoch: [75] Total time: 0:01:21 (0.2746 s / it)\n",
            "Averaged stats: lr: 0.000826  min_lr: 0.000826  loss: 3.1707 (3.0913)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:41  loss: 0.6435 (0.6435)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.6963  data: 2.5264  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.6333 (0.6370)  acc1: 91.6667 (90.9091)  acc5: 97.9167 (97.9167)  time: 0.3642  data: 0.2348  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.6254 (0.6350)  acc1: 91.6667 (90.9722)  acc5: 97.9167 (98.2143)  time: 0.1295  data: 0.0049  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.7279 (0.8146)  acc1: 87.5000 (83.8710)  acc5: 97.9167 (98.1855)  time: 0.1256  data: 0.0042  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.8592 (0.8124)  acc1: 83.3333 (84.4004)  acc5: 97.9167 (98.1707)  time: 0.1230  data: 0.0035  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8586 (0.8242)  acc1: 83.3333 (83.8235)  acc5: 97.9167 (98.1209)  time: 0.1244  data: 0.0036  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.9272 (0.8364)  acc1: 81.2500 (83.4016)  acc5: 97.9167 (98.0874)  time: 0.1252  data: 0.0061  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.9401 (0.8521)  acc1: 79.1667 (82.8052)  acc5: 97.9167 (97.7993)  time: 0.1216  data: 0.0044  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7936 (0.8322)  acc1: 83.3333 (83.5391)  acc5: 97.9167 (97.8909)  time: 0.1180  data: 0.0006  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7936 (0.8336)  acc1: 83.3333 (83.5159)  acc5: 97.9167 (97.8344)  time: 0.1167  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1626 s / it)\n",
            "* Acc@1 83.516 Acc@5 97.834 loss 0.834\n",
            "Accuracy of the model on the 3925 test images: 83.5%\n",
            "Max accuracy: 83.67%\n",
            "Test:  [ 0/82]  eta: 0:04:16  loss: 2.2194 (2.2194)  acc1: 29.1667 (29.1667)  acc5: 93.7500 (93.7500)  time: 3.1251  data: 2.9573  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 2.3506 (2.5373)  acc1: 18.7500 (18.5606)  acc5: 97.9167 (97.1591)  time: 0.4272  data: 0.2711  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.9918 (2.8372)  acc1: 10.4167 (13.9881)  acc5: 95.8333 (96.5278)  time: 0.1412  data: 0.0017  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.4930 (3.4035)  acc1: 6.2500 (10.2823)  acc5: 93.7500 (81.8548)  time: 0.1247  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.5104 (3.4490)  acc1: 8.3333 (11.7886)  acc5: 72.9167 (79.9289)  time: 0.1235  data: 0.0046  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.1511 (3.7183)  acc1: 10.4167 (10.8660)  acc5: 72.9167 (73.6520)  time: 0.1236  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6592 (3.8255)  acc1: 2.0833 (9.2896)  acc5: 43.7500 (71.1066)  time: 0.1249  data: 0.0058  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 4.0048 (3.6797)  acc1: 2.0833 (13.3803)  acc5: 70.8333 (70.8040)  time: 0.1229  data: 0.0036  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1204 (3.3429)  acc1: 66.6667 (21.3992)  acc5: 97.9167 (74.2027)  time: 0.1201  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1204 (3.3163)  acc1: 70.8333 (21.9363)  acc5: 97.9167 (74.3694)  time: 0.1184  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1684 s / it)\n",
            "* Acc@1 21.936 Acc@5 74.369 loss 3.316\n",
            "Accuracy of the model EMA on 3925 test images: 21.9%\n",
            "Max EMA accuracy: 21.94%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [76]  [  0/295]  eta: 0:15:33  lr: 0.000825  min_lr: 0.000825  loss: 3.1440 (3.1440)  weight_decay: 0.0500 (0.0500)  time: 3.1635  data: 2.4682  max mem: 3500\n",
            "Epoch: [76]  [ 10/295]  eta: 0:02:47  lr: 0.000823  min_lr: 0.000823  loss: 3.0949 (3.0819)  weight_decay: 0.0500 (0.0500)  time: 0.5892  data: 0.2262  max mem: 3500\n",
            "Epoch: [76]  [ 20/295]  eta: 0:01:59  lr: 0.000821  min_lr: 0.000821  loss: 3.0910 (3.0572)  weight_decay: 0.0500 (0.0500)  time: 0.2977  data: 0.0020  max mem: 3500\n",
            "Epoch: [76]  [ 30/295]  eta: 0:01:40  lr: 0.000819  min_lr: 0.000819  loss: 3.1435 (3.0971)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0017  max mem: 3500\n",
            "Epoch: [76]  [ 40/295]  eta: 0:01:29  lr: 0.000817  min_lr: 0.000817  loss: 3.1807 (3.1038)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0016  max mem: 3500\n",
            "Epoch: [76]  [ 50/295]  eta: 0:01:21  lr: 0.000815  min_lr: 0.000815  loss: 3.0733 (3.0862)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0018  max mem: 3500\n",
            "Epoch: [76]  [ 60/295]  eta: 0:01:16  lr: 0.000812  min_lr: 0.000812  loss: 3.1240 (3.0960)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0029  max mem: 3500\n",
            "Epoch: [76]  [ 70/295]  eta: 0:01:11  lr: 0.000810  min_lr: 0.000810  loss: 3.1867 (3.0994)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0031  max mem: 3500\n",
            "Epoch: [76]  [ 80/295]  eta: 0:01:06  lr: 0.000808  min_lr: 0.000808  loss: 3.1540 (3.0994)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0022  max mem: 3500\n",
            "Epoch: [76]  [ 90/295]  eta: 0:01:02  lr: 0.000806  min_lr: 0.000806  loss: 3.0833 (3.1002)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0018  max mem: 3500\n",
            "Epoch: [76]  [100/295]  eta: 0:00:58  lr: 0.000804  min_lr: 0.000804  loss: 3.0343 (3.0978)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0016  max mem: 3500\n",
            "Epoch: [76]  [110/295]  eta: 0:00:54  lr: 0.000802  min_lr: 0.000802  loss: 3.1480 (3.1022)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0019  max mem: 3500\n",
            "Epoch: [76]  [120/295]  eta: 0:00:51  lr: 0.000799  min_lr: 0.000799  loss: 3.1925 (3.1015)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0019  max mem: 3500\n",
            "Epoch: [76]  [130/295]  eta: 0:00:48  lr: 0.000798  min_lr: 0.000798  loss: 3.1303 (3.0997)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0027  max mem: 3500\n",
            "Epoch: [76]  [140/295]  eta: 0:00:45  lr: 0.000795  min_lr: 0.000795  loss: 3.1303 (3.0982)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0034  max mem: 3500\n",
            "Epoch: [76]  [150/295]  eta: 0:00:41  lr: 0.000793  min_lr: 0.000793  loss: 3.0321 (3.0973)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0028  max mem: 3500\n",
            "Epoch: [76]  [160/295]  eta: 0:00:38  lr: 0.000791  min_lr: 0.000791  loss: 3.0193 (3.0963)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0019  max mem: 3500\n",
            "Epoch: [76]  [170/295]  eta: 0:00:35  lr: 0.000789  min_lr: 0.000789  loss: 3.0384 (3.0936)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0021  max mem: 3500\n",
            "Epoch: [76]  [180/295]  eta: 0:00:32  lr: 0.000786  min_lr: 0.000786  loss: 3.1308 (3.0975)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0021  max mem: 3500\n",
            "Epoch: [76]  [190/295]  eta: 0:00:29  lr: 0.000785  min_lr: 0.000785  loss: 3.1308 (3.0970)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0024  max mem: 3500\n",
            "Epoch: [76]  [200/295]  eta: 0:00:26  lr: 0.000782  min_lr: 0.000782  loss: 3.1235 (3.0993)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0037  max mem: 3500\n",
            "Epoch: [76]  [210/295]  eta: 0:00:23  lr: 0.000780  min_lr: 0.000780  loss: 3.1038 (3.0971)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0036  max mem: 3500\n",
            "Epoch: [76]  [220/295]  eta: 0:00:21  lr: 0.000778  min_lr: 0.000778  loss: 3.1038 (3.0980)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0033  max mem: 3500\n",
            "Epoch: [76]  [230/295]  eta: 0:00:18  lr: 0.000776  min_lr: 0.000776  loss: 3.0986 (3.0964)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0030  max mem: 3500\n",
            "Epoch: [76]  [240/295]  eta: 0:00:15  lr: 0.000774  min_lr: 0.000774  loss: 3.0986 (3.0958)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0018  max mem: 3500\n",
            "Epoch: [76]  [250/295]  eta: 0:00:12  lr: 0.000772  min_lr: 0.000772  loss: 2.9658 (3.0902)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0011  max mem: 3500\n",
            "Epoch: [76]  [260/295]  eta: 0:00:09  lr: 0.000769  min_lr: 0.000769  loss: 3.0975 (3.0934)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0023  max mem: 3500\n",
            "Epoch: [76]  [270/295]  eta: 0:00:06  lr: 0.000768  min_lr: 0.000768  loss: 3.1398 (3.0916)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0031  max mem: 3500\n",
            "Epoch: [76]  [280/295]  eta: 0:00:04  lr: 0.000765  min_lr: 0.000765  loss: 3.0875 (3.0904)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0029  max mem: 3500\n",
            "Epoch: [76]  [290/295]  eta: 0:00:01  lr: 0.000763  min_lr: 0.000763  loss: 3.0961 (3.0897)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0014  max mem: 3500\n",
            "Epoch: [76]  [294/295]  eta: 0:00:00  lr: 0.000763  min_lr: 0.000763  loss: 3.0961 (3.0908)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0002  max mem: 3500\n",
            "Epoch: [76] Total time: 0:01:21 (0.2755 s / it)\n",
            "Averaged stats: lr: 0.000763  min_lr: 0.000763  loss: 3.0961 (3.0908)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:30  loss: 0.6217 (0.6217)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 1.8318  data: 1.6475  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5999 (0.5962)  acc1: 89.5833 (90.1515)  acc5: 97.9167 (98.4849)  time: 0.2939  data: 0.1544  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5999 (0.6122)  acc1: 89.5833 (90.2778)  acc5: 100.0000 (98.9087)  time: 0.1342  data: 0.0053  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.7302 (0.7759)  acc1: 85.4167 (83.9382)  acc5: 100.0000 (98.7231)  time: 0.1535  data: 0.0090  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8965 (0.7849)  acc1: 79.1667 (83.9939)  acc5: 97.9167 (98.5772)  time: 0.1679  data: 0.0079  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.8068 (0.7769)  acc1: 83.3333 (83.9869)  acc5: 100.0000 (98.6520)  time: 0.1582  data: 0.0085  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7545 (0.7875)  acc1: 85.4167 (83.8115)  acc5: 100.0000 (98.4973)  time: 0.1771  data: 0.0316  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8949 (0.8059)  acc1: 81.2500 (83.4507)  acc5: 97.9167 (98.1808)  time: 0.1890  data: 0.0336  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7913 (0.8012)  acc1: 81.2500 (83.6677)  acc5: 97.9167 (98.0967)  time: 0.1504  data: 0.0088  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7913 (0.8050)  acc1: 81.2500 (83.5924)  acc5: 97.9167 (98.0127)  time: 0.1377  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1818 s / it)\n",
            "* Acc@1 83.592 Acc@5 98.013 loss 0.805\n",
            "Accuracy of the model on the 3925 test images: 83.6%\n",
            "Max accuracy: 83.67%\n",
            "Test:  [ 0/82]  eta: 0:02:31  loss: 2.1686 (2.1686)  acc1: 29.1667 (29.1667)  acc5: 93.7500 (93.7500)  time: 1.8421  data: 1.6698  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.2994 (2.4933)  acc1: 18.7500 (19.3182)  acc5: 97.9167 (97.1591)  time: 0.2853  data: 0.1553  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.9849 (2.8026)  acc1: 10.4167 (14.4841)  acc5: 95.8333 (96.7262)  time: 0.1251  data: 0.0032  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.4542 (3.3714)  acc1: 6.2500 (10.6855)  acc5: 93.7500 (82.1909)  time: 0.1220  data: 0.0030  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.4517 (3.4128)  acc1: 8.3333 (12.2459)  acc5: 72.9167 (80.2846)  time: 0.1247  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.1258 (3.6845)  acc1: 10.4167 (11.0703)  acc5: 70.8333 (73.8562)  time: 0.1265  data: 0.0045  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6487 (3.7909)  acc1: 2.0833 (9.4945)  acc5: 43.7500 (71.3115)  time: 0.1272  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.9699 (3.6459)  acc1: 2.0833 (13.6444)  acc5: 70.8333 (70.9507)  time: 0.1274  data: 0.0034  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.1065 (3.3119)  acc1: 70.8333 (21.6307)  acc5: 97.9167 (74.3313)  time: 0.1232  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.1065 (3.2855)  acc1: 70.8333 (22.1656)  acc5: 97.9167 (74.4968)  time: 0.1199  data: 0.0004  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1522 s / it)\n",
            "* Acc@1 22.166 Acc@5 74.497 loss 3.285\n",
            "Accuracy of the model EMA on 3925 test images: 22.2%\n",
            "Max EMA accuracy: 22.17%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [77]  [  0/295]  eta: 0:13:17  lr: 0.000763  min_lr: 0.000763  loss: 3.2985 (3.2985)  weight_decay: 0.0500 (0.0500)  time: 2.7043  data: 2.2249  max mem: 3500\n",
            "Epoch: [77]  [ 10/295]  eta: 0:02:18  lr: 0.000761  min_lr: 0.000761  loss: 3.0996 (3.1209)  weight_decay: 0.0500 (0.0500)  time: 0.4876  data: 0.2028  max mem: 3500\n",
            "Epoch: [77]  [ 20/295]  eta: 0:01:44  lr: 0.000758  min_lr: 0.000758  loss: 3.0996 (3.1084)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0004  max mem: 3500\n",
            "Epoch: [77]  [ 30/295]  eta: 0:01:30  lr: 0.000757  min_lr: 0.000757  loss: 3.1332 (3.1098)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0005  max mem: 3500\n",
            "Epoch: [77]  [ 40/295]  eta: 0:01:22  lr: 0.000754  min_lr: 0.000754  loss: 3.0403 (3.0898)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0009  max mem: 3500\n",
            "Epoch: [77]  [ 50/295]  eta: 0:01:17  lr: 0.000753  min_lr: 0.000753  loss: 3.1075 (3.0926)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0015  max mem: 3500\n",
            "Epoch: [77]  [ 60/295]  eta: 0:01:12  lr: 0.000750  min_lr: 0.000750  loss: 3.1667 (3.0985)  weight_decay: 0.0500 (0.0500)  time: 0.2786  data: 0.0024  max mem: 3500\n",
            "Epoch: [77]  [ 70/295]  eta: 0:01:08  lr: 0.000748  min_lr: 0.000748  loss: 3.1542 (3.0940)  weight_decay: 0.0500 (0.0500)  time: 0.2790  data: 0.0017  max mem: 3500\n",
            "Epoch: [77]  [ 80/295]  eta: 0:01:04  lr: 0.000746  min_lr: 0.000746  loss: 3.0657 (3.0892)  weight_decay: 0.0500 (0.0500)  time: 0.2758  data: 0.0016  max mem: 3500\n",
            "Epoch: [77]  [ 90/295]  eta: 0:01:00  lr: 0.000744  min_lr: 0.000744  loss: 3.0963 (3.0872)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0026  max mem: 3500\n",
            "Epoch: [77]  [100/295]  eta: 0:00:57  lr: 0.000742  min_lr: 0.000742  loss: 3.0064 (3.0824)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0022  max mem: 3500\n",
            "Epoch: [77]  [110/295]  eta: 0:00:53  lr: 0.000740  min_lr: 0.000740  loss: 3.0507 (3.0860)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0013  max mem: 3500\n",
            "Epoch: [77]  [120/295]  eta: 0:00:50  lr: 0.000737  min_lr: 0.000737  loss: 3.1413 (3.0909)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0022  max mem: 3500\n",
            "Epoch: [77]  [130/295]  eta: 0:00:47  lr: 0.000736  min_lr: 0.000736  loss: 3.1433 (3.0968)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0032  max mem: 3500\n",
            "Epoch: [77]  [140/295]  eta: 0:00:44  lr: 0.000733  min_lr: 0.000733  loss: 3.1169 (3.0939)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0023  max mem: 3500\n",
            "Epoch: [77]  [150/295]  eta: 0:00:41  lr: 0.000732  min_lr: 0.000732  loss: 3.0508 (3.0877)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0010  max mem: 3500\n",
            "Epoch: [77]  [160/295]  eta: 0:00:38  lr: 0.000729  min_lr: 0.000729  loss: 3.0508 (3.0870)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0011  max mem: 3500\n",
            "Epoch: [77]  [170/295]  eta: 0:00:35  lr: 0.000727  min_lr: 0.000727  loss: 3.1127 (3.0867)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0009  max mem: 3500\n",
            "Epoch: [77]  [180/295]  eta: 0:00:32  lr: 0.000725  min_lr: 0.000725  loss: 3.0897 (3.0913)  weight_decay: 0.0500 (0.0500)  time: 0.2615  data: 0.0010  max mem: 3500\n",
            "Epoch: [77]  [190/295]  eta: 0:00:29  lr: 0.000723  min_lr: 0.000723  loss: 3.1306 (3.0933)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0017  max mem: 3500\n",
            "Epoch: [77]  [200/295]  eta: 0:00:26  lr: 0.000721  min_lr: 0.000721  loss: 3.1536 (3.0960)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0023  max mem: 3500\n",
            "Epoch: [77]  [210/295]  eta: 0:00:23  lr: 0.000719  min_lr: 0.000719  loss: 3.1634 (3.0930)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0020  max mem: 3500\n",
            "Epoch: [77]  [220/295]  eta: 0:00:20  lr: 0.000717  min_lr: 0.000717  loss: 3.0361 (3.0932)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0010  max mem: 3500\n",
            "Epoch: [77]  [230/295]  eta: 0:00:18  lr: 0.000715  min_lr: 0.000715  loss: 3.0597 (3.0934)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0018  max mem: 3500\n",
            "Epoch: [77]  [240/295]  eta: 0:00:15  lr: 0.000713  min_lr: 0.000713  loss: 3.1594 (3.0932)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0024  max mem: 3500\n",
            "Epoch: [77]  [250/295]  eta: 0:00:12  lr: 0.000711  min_lr: 0.000711  loss: 3.1611 (3.0928)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0030  max mem: 3500\n",
            "Epoch: [77]  [260/295]  eta: 0:00:09  lr: 0.000708  min_lr: 0.000708  loss: 3.0770 (3.0925)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0028  max mem: 3500\n",
            "Epoch: [77]  [270/295]  eta: 0:00:06  lr: 0.000707  min_lr: 0.000707  loss: 3.1428 (3.0941)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0029  max mem: 3500\n",
            "Epoch: [77]  [280/295]  eta: 0:00:04  lr: 0.000704  min_lr: 0.000704  loss: 3.1897 (3.0966)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0028  max mem: 3500\n",
            "Epoch: [77]  [290/295]  eta: 0:00:01  lr: 0.000703  min_lr: 0.000703  loss: 3.2052 (3.0975)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0008  max mem: 3500\n",
            "Epoch: [77]  [294/295]  eta: 0:00:00  lr: 0.000703  min_lr: 0.000703  loss: 3.1897 (3.0967)  weight_decay: 0.0500 (0.0500)  time: 0.2193  data: 0.0004  max mem: 3500\n",
            "Epoch: [77] Total time: 0:01:20 (0.2733 s / it)\n",
            "Averaged stats: lr: 0.000703  min_lr: 0.000703  loss: 3.1897 (3.0967)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:23  loss: 0.5773 (0.5773)  acc1: 93.7500 (93.7500)  acc5: 97.9167 (97.9167)  time: 1.7464  data: 1.5790  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 0.5773 (0.6020)  acc1: 93.7500 (91.8561)  acc5: 97.9167 (98.4849)  time: 0.2829  data: 0.1501  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.6342 (0.6696)  acc1: 89.5833 (89.6825)  acc5: 97.9167 (98.6111)  time: 0.1469  data: 0.0045  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.8068 (0.8640)  acc1: 81.2500 (81.7876)  acc5: 97.9167 (98.3871)  time: 0.1677  data: 0.0190  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.8310 (0.8388)  acc1: 81.2500 (82.7744)  acc5: 97.9167 (98.3740)  time: 0.1846  data: 0.0364  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.8181 (0.8674)  acc1: 85.4167 (81.8219)  acc5: 97.9167 (98.1618)  time: 0.1781  data: 0.0288  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8783 (0.8504)  acc1: 85.4167 (82.4795)  acc5: 97.9167 (98.2582)  time: 0.1699  data: 0.0298  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8725 (0.8601)  acc1: 83.3333 (82.2183)  acc5: 97.9167 (98.0340)  time: 0.1477  data: 0.0196  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7729 (0.8368)  acc1: 85.4167 (83.0504)  acc5: 97.9167 (98.1739)  time: 0.1192  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7729 (0.8378)  acc1: 85.4167 (83.0318)  acc5: 97.9167 (98.1401)  time: 0.1180  data: 0.0003  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1780 s / it)\n",
            "* Acc@1 83.032 Acc@5 98.140 loss 0.838\n",
            "Accuracy of the model on the 3925 test images: 83.0%\n",
            "Max accuracy: 83.67%\n",
            "Test:  [ 0/82]  eta: 0:02:45  loss: 2.1246 (2.1246)  acc1: 29.1667 (29.1667)  acc5: 93.7500 (93.7500)  time: 2.0145  data: 1.8414  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.2552 (2.4546)  acc1: 18.7500 (19.8864)  acc5: 97.9167 (97.1591)  time: 0.2951  data: 0.1700  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.9753 (2.7706)  acc1: 10.4167 (14.8810)  acc5: 95.8333 (96.8254)  time: 0.1238  data: 0.0030  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.4170 (3.3400)  acc1: 6.2500 (10.9543)  acc5: 93.7500 (82.1909)  time: 0.1242  data: 0.0041  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.3926 (3.3770)  acc1: 8.3333 (12.5508)  acc5: 75.0000 (80.5386)  time: 0.1234  data: 0.0042  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.0980 (3.6500)  acc1: 10.4167 (11.1928)  acc5: 68.7500 (73.9788)  time: 0.1265  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.6295 (3.7556)  acc1: 2.0833 (9.5970)  acc5: 41.6667 (71.4139)  time: 0.1387  data: 0.0045  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.9357 (3.6114)  acc1: 2.0833 (13.7617)  acc5: 70.8333 (71.0681)  time: 0.1469  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0949 (3.2803)  acc1: 70.8333 (21.7593)  acc5: 97.9167 (74.4342)  time: 0.1324  data: 0.0006  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0949 (3.2542)  acc1: 72.9167 (22.2930)  acc5: 97.9167 (74.5987)  time: 0.1291  data: 0.0006  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1597 s / it)\n",
            "* Acc@1 22.293 Acc@5 74.599 loss 3.254\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "Max EMA accuracy: 22.29%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [78]  [  0/295]  eta: 0:11:08  lr: 0.000702  min_lr: 0.000702  loss: 3.0886 (3.0886)  weight_decay: 0.0500 (0.0500)  time: 2.2659  data: 1.8753  max mem: 3500\n",
            "Epoch: [78]  [ 10/295]  eta: 0:02:06  lr: 0.000700  min_lr: 0.000700  loss: 3.1711 (3.0578)  weight_decay: 0.0500 (0.0500)  time: 0.4446  data: 0.1728  max mem: 3500\n",
            "Epoch: [78]  [ 20/295]  eta: 0:01:38  lr: 0.000698  min_lr: 0.000698  loss: 3.1711 (3.0815)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0016  max mem: 3500\n",
            "Epoch: [78]  [ 30/295]  eta: 0:01:26  lr: 0.000696  min_lr: 0.000696  loss: 3.0582 (3.0205)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0016  max mem: 3500\n",
            "Epoch: [78]  [ 40/295]  eta: 0:01:20  lr: 0.000694  min_lr: 0.000694  loss: 3.0475 (3.0493)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0022  max mem: 3500\n",
            "Epoch: [78]  [ 50/295]  eta: 0:01:14  lr: 0.000692  min_lr: 0.000692  loss: 3.0475 (3.0361)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0025  max mem: 3500\n",
            "Epoch: [78]  [ 60/295]  eta: 0:01:10  lr: 0.000690  min_lr: 0.000690  loss: 2.9103 (3.0291)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0020  max mem: 3500\n",
            "Epoch: [78]  [ 70/295]  eta: 0:01:06  lr: 0.000688  min_lr: 0.000688  loss: 3.1039 (3.0399)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0021  max mem: 3500\n",
            "Epoch: [78]  [ 80/295]  eta: 0:01:02  lr: 0.000686  min_lr: 0.000686  loss: 3.0405 (3.0384)  weight_decay: 0.0500 (0.0500)  time: 0.2655  data: 0.0029  max mem: 3500\n",
            "Epoch: [78]  [ 90/295]  eta: 0:00:59  lr: 0.000684  min_lr: 0.000684  loss: 2.9764 (3.0361)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0021  max mem: 3500\n",
            "Epoch: [78]  [100/295]  eta: 0:00:55  lr: 0.000682  min_lr: 0.000682  loss: 3.0248 (3.0344)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0013  max mem: 3500\n",
            "Epoch: [78]  [110/295]  eta: 0:00:52  lr: 0.000680  min_lr: 0.000680  loss: 3.0452 (3.0330)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0032  max mem: 3500\n",
            "Epoch: [78]  [120/295]  eta: 0:00:49  lr: 0.000678  min_lr: 0.000678  loss: 3.0452 (3.0359)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0046  max mem: 3500\n",
            "Epoch: [78]  [130/295]  eta: 0:00:46  lr: 0.000676  min_lr: 0.000676  loss: 3.1130 (3.0455)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0029  max mem: 3500\n",
            "Epoch: [78]  [140/295]  eta: 0:00:43  lr: 0.000674  min_lr: 0.000674  loss: 3.0802 (3.0445)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0023  max mem: 3500\n",
            "Epoch: [78]  [150/295]  eta: 0:00:40  lr: 0.000672  min_lr: 0.000672  loss: 2.9878 (3.0379)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0019  max mem: 3500\n",
            "Epoch: [78]  [160/295]  eta: 0:00:37  lr: 0.000670  min_lr: 0.000670  loss: 2.9993 (3.0396)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0011  max mem: 3500\n",
            "Epoch: [78]  [170/295]  eta: 0:00:34  lr: 0.000668  min_lr: 0.000668  loss: 2.9993 (3.0383)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0016  max mem: 3500\n",
            "Epoch: [78]  [180/295]  eta: 0:00:31  lr: 0.000666  min_lr: 0.000666  loss: 3.0374 (3.0411)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0030  max mem: 3500\n",
            "Epoch: [78]  [190/295]  eta: 0:00:29  lr: 0.000664  min_lr: 0.000664  loss: 2.9627 (3.0375)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0027  max mem: 3500\n",
            "Epoch: [78]  [200/295]  eta: 0:00:26  lr: 0.000662  min_lr: 0.000662  loss: 2.9627 (3.0368)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0009  max mem: 3500\n",
            "Epoch: [78]  [210/295]  eta: 0:00:23  lr: 0.000660  min_lr: 0.000660  loss: 3.0481 (3.0374)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0005  max mem: 3500\n",
            "Epoch: [78]  [220/295]  eta: 0:00:20  lr: 0.000658  min_lr: 0.000658  loss: 3.0793 (3.0413)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0015  max mem: 3500\n",
            "Epoch: [78]  [230/295]  eta: 0:00:17  lr: 0.000656  min_lr: 0.000656  loss: 3.1062 (3.0435)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0018  max mem: 3500\n",
            "Epoch: [78]  [240/295]  eta: 0:00:15  lr: 0.000654  min_lr: 0.000654  loss: 3.0774 (3.0446)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0012  max mem: 3500\n",
            "Epoch: [78]  [250/295]  eta: 0:00:12  lr: 0.000652  min_lr: 0.000652  loss: 3.0613 (3.0457)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0032  max mem: 3500\n",
            "Epoch: [78]  [260/295]  eta: 0:00:09  lr: 0.000650  min_lr: 0.000650  loss: 3.0445 (3.0458)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0032  max mem: 3500\n",
            "Epoch: [78]  [270/295]  eta: 0:00:06  lr: 0.000648  min_lr: 0.000648  loss: 3.0793 (3.0482)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0027  max mem: 3500\n",
            "Epoch: [78]  [280/295]  eta: 0:00:04  lr: 0.000646  min_lr: 0.000646  loss: 3.0793 (3.0471)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0022  max mem: 3500\n",
            "Epoch: [78]  [290/295]  eta: 0:00:01  lr: 0.000644  min_lr: 0.000644  loss: 3.1941 (3.0509)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0002  max mem: 3500\n",
            "Epoch: [78]  [294/295]  eta: 0:00:00  lr: 0.000644  min_lr: 0.000644  loss: 3.1941 (3.0520)  weight_decay: 0.0500 (0.0500)  time: 0.2214  data: 0.0002  max mem: 3500\n",
            "Epoch: [78] Total time: 0:01:20 (0.2717 s / it)\n",
            "Averaged stats: lr: 0.000644  min_lr: 0.000644  loss: 3.1941 (3.0520)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:59  loss: 0.5481 (0.5481)  acc1: 93.7500 (93.7500)  acc5: 97.9167 (97.9167)  time: 2.9217  data: 2.7001  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 0.5481 (0.5780)  acc1: 93.7500 (91.2879)  acc5: 97.9167 (97.9167)  time: 0.4183  data: 0.2802  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.6206 (0.6493)  acc1: 87.5000 (88.5913)  acc5: 97.9167 (98.4127)  time: 0.1710  data: 0.0310  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.8099 (0.7950)  acc1: 81.2500 (83.2661)  acc5: 97.9167 (98.2527)  time: 0.1619  data: 0.0198  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.8148 (0.7774)  acc1: 81.2500 (84.4004)  acc5: 100.0000 (98.4248)  time: 0.1370  data: 0.0094  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7468 (0.7808)  acc1: 85.4167 (83.9869)  acc5: 100.0000 (98.4886)  time: 0.1262  data: 0.0032  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7447 (0.7768)  acc1: 83.3333 (84.0164)  acc5: 100.0000 (98.5997)  time: 0.1266  data: 0.0033  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8620 (0.8001)  acc1: 79.1667 (82.9519)  acc5: 97.9167 (98.2688)  time: 0.1219  data: 0.0022  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8184 (0.7868)  acc1: 81.2500 (83.5134)  acc5: 97.9167 (98.2768)  time: 0.1186  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8184 (0.7888)  acc1: 81.2500 (83.4904)  acc5: 97.9167 (98.2420)  time: 0.1165  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1768 s / it)\n",
            "* Acc@1 83.490 Acc@5 98.242 loss 0.789\n",
            "Accuracy of the model on the 3925 test images: 83.5%\n",
            "Max accuracy: 83.67%\n",
            "Test:  [ 0/82]  eta: 0:02:30  loss: 2.0756 (2.0756)  acc1: 29.1667 (29.1667)  acc5: 95.8333 (95.8333)  time: 1.8304  data: 1.6658  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 2.2056 (2.4127)  acc1: 20.8333 (20.6439)  acc5: 97.9167 (97.5379)  time: 0.2867  data: 0.1566  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.9506 (2.7383)  acc1: 12.5000 (15.4762)  acc5: 97.9167 (97.0238)  time: 0.1384  data: 0.0061  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 3.3824 (3.3096)  acc1: 6.2500 (11.3575)  acc5: 91.6667 (82.3253)  time: 0.1662  data: 0.0300  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.3339 (3.3421)  acc1: 8.3333 (13.1606)  acc5: 77.0833 (80.6911)  time: 0.1754  data: 0.0397  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 4.0700 (3.6163)  acc1: 10.4167 (11.5605)  acc5: 68.7500 (74.0605)  time: 0.1602  data: 0.0285  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.6132 (3.7209)  acc1: 2.0833 (9.9044)  acc5: 41.6667 (71.4822)  time: 0.1648  data: 0.0282  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.9004 (3.5777)  acc1: 2.0833 (14.0258)  acc5: 70.8333 (71.2148)  time: 0.1526  data: 0.0174  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0796 (3.2495)  acc1: 70.8333 (22.0422)  acc5: 97.9167 (74.5628)  time: 0.1257  data: 0.0048  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0796 (3.2236)  acc1: 72.9167 (22.5478)  acc5: 97.9167 (74.7261)  time: 0.1207  data: 0.0020  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1759 s / it)\n",
            "* Acc@1 22.548 Acc@5 74.726 loss 3.224\n",
            "Accuracy of the model EMA on 3925 test images: 22.5%\n",
            "Max EMA accuracy: 22.55%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [79]  [  0/295]  eta: 0:11:08  lr: 0.000643  min_lr: 0.000643  loss: 2.8649 (2.8649)  weight_decay: 0.0500 (0.0500)  time: 2.2667  data: 1.8526  max mem: 3500\n",
            "Epoch: [79]  [ 10/295]  eta: 0:02:08  lr: 0.000642  min_lr: 0.000642  loss: 3.0795 (3.0390)  weight_decay: 0.0500 (0.0500)  time: 0.4506  data: 0.1695  max mem: 3500\n",
            "Epoch: [79]  [ 20/295]  eta: 0:01:40  lr: 0.000639  min_lr: 0.000639  loss: 3.0795 (3.0605)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0009  max mem: 3500\n",
            "Epoch: [79]  [ 30/295]  eta: 0:01:28  lr: 0.000638  min_lr: 0.000638  loss: 3.0650 (3.0493)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0021  max mem: 3500\n",
            "Epoch: [79]  [ 40/295]  eta: 0:01:21  lr: 0.000635  min_lr: 0.000635  loss: 3.1146 (3.0786)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0019  max mem: 3500\n",
            "Epoch: [79]  [ 50/295]  eta: 0:01:15  lr: 0.000634  min_lr: 0.000634  loss: 3.0190 (3.0665)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0007  max mem: 3500\n",
            "Epoch: [79]  [ 60/295]  eta: 0:01:10  lr: 0.000631  min_lr: 0.000631  loss: 2.8962 (3.0436)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0010  max mem: 3500\n",
            "Epoch: [79]  [ 70/295]  eta: 0:01:06  lr: 0.000630  min_lr: 0.000630  loss: 2.9232 (3.0383)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0017  max mem: 3500\n",
            "Epoch: [79]  [ 80/295]  eta: 0:01:02  lr: 0.000628  min_lr: 0.000628  loss: 3.0731 (3.0347)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0017  max mem: 3500\n",
            "Epoch: [79]  [ 90/295]  eta: 0:00:59  lr: 0.000626  min_lr: 0.000626  loss: 3.0491 (3.0287)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0015  max mem: 3500\n",
            "Epoch: [79]  [100/295]  eta: 0:00:56  lr: 0.000624  min_lr: 0.000624  loss: 3.0491 (3.0355)  weight_decay: 0.0500 (0.0500)  time: 0.2718  data: 0.0020  max mem: 3500\n",
            "Epoch: [79]  [110/295]  eta: 0:00:52  lr: 0.000622  min_lr: 0.000622  loss: 3.1098 (3.0418)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0022  max mem: 3500\n",
            "Epoch: [79]  [120/295]  eta: 0:00:49  lr: 0.000620  min_lr: 0.000620  loss: 3.0989 (3.0474)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0021  max mem: 3500\n",
            "Epoch: [79]  [130/295]  eta: 0:00:46  lr: 0.000618  min_lr: 0.000618  loss: 3.1094 (3.0481)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0011  max mem: 3500\n",
            "Epoch: [79]  [140/295]  eta: 0:00:43  lr: 0.000616  min_lr: 0.000616  loss: 3.0510 (3.0483)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0005  max mem: 3500\n",
            "Epoch: [79]  [150/295]  eta: 0:00:40  lr: 0.000614  min_lr: 0.000614  loss: 3.0493 (3.0472)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0013  max mem: 3500\n",
            "Epoch: [79]  [160/295]  eta: 0:00:37  lr: 0.000612  min_lr: 0.000612  loss: 3.1049 (3.0515)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0022  max mem: 3500\n",
            "Epoch: [79]  [170/295]  eta: 0:00:34  lr: 0.000610  min_lr: 0.000610  loss: 3.1736 (3.0568)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0023  max mem: 3500\n",
            "Epoch: [79]  [180/295]  eta: 0:00:31  lr: 0.000608  min_lr: 0.000608  loss: 3.1690 (3.0602)  weight_decay: 0.0500 (0.0500)  time: 0.2662  data: 0.0017  max mem: 3500\n",
            "Epoch: [79]  [190/295]  eta: 0:00:29  lr: 0.000607  min_lr: 0.000607  loss: 2.9996 (3.0607)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0007  max mem: 3500\n",
            "Epoch: [79]  [200/295]  eta: 0:00:26  lr: 0.000604  min_lr: 0.000604  loss: 2.9885 (3.0566)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0003  max mem: 3500\n",
            "Epoch: [79]  [210/295]  eta: 0:00:23  lr: 0.000603  min_lr: 0.000603  loss: 2.9736 (3.0584)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0010  max mem: 3500\n",
            "Epoch: [79]  [220/295]  eta: 0:00:20  lr: 0.000600  min_lr: 0.000600  loss: 3.1928 (3.0637)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0024  max mem: 3500\n",
            "Epoch: [79]  [230/295]  eta: 0:00:17  lr: 0.000599  min_lr: 0.000599  loss: 3.0852 (3.0638)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0028  max mem: 3500\n",
            "Epoch: [79]  [240/295]  eta: 0:00:15  lr: 0.000597  min_lr: 0.000597  loss: 3.0746 (3.0656)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0020  max mem: 3500\n",
            "Epoch: [79]  [250/295]  eta: 0:00:12  lr: 0.000595  min_lr: 0.000595  loss: 3.1100 (3.0675)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0012  max mem: 3500\n",
            "Epoch: [79]  [260/295]  eta: 0:00:09  lr: 0.000593  min_lr: 0.000593  loss: 3.1496 (3.0683)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0010  max mem: 3500\n",
            "Epoch: [79]  [270/295]  eta: 0:00:06  lr: 0.000591  min_lr: 0.000591  loss: 3.0459 (3.0654)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0011  max mem: 3500\n",
            "Epoch: [79]  [280/295]  eta: 0:00:04  lr: 0.000589  min_lr: 0.000589  loss: 3.0459 (3.0654)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0009  max mem: 3500\n",
            "Epoch: [79]  [290/295]  eta: 0:00:01  lr: 0.000587  min_lr: 0.000587  loss: 3.0611 (3.0652)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0004  max mem: 3500\n",
            "Epoch: [79]  [294/295]  eta: 0:00:00  lr: 0.000587  min_lr: 0.000587  loss: 3.0712 (3.0657)  weight_decay: 0.0500 (0.0500)  time: 0.2213  data: 0.0002  max mem: 3500\n",
            "Epoch: [79] Total time: 0:01:20 (0.2712 s / it)\n",
            "Averaged stats: lr: 0.000587  min_lr: 0.000587  loss: 3.0712 (3.0657)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:26  loss: 0.5994 (0.5994)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 2.5129  data: 2.3375  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 0.5806 (0.6040)  acc1: 91.6667 (90.7197)  acc5: 97.9167 (98.2955)  time: 0.3548  data: 0.2209  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.6635 (0.6764)  acc1: 87.5000 (88.0952)  acc5: 97.9167 (98.4127)  time: 0.1336  data: 0.0051  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.8514 (0.8260)  acc1: 81.2500 (82.5269)  acc5: 97.9167 (98.4543)  time: 0.1295  data: 0.0012  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7470 (0.7894)  acc1: 83.3333 (84.2988)  acc5: 100.0000 (98.5772)  time: 0.1277  data: 0.0022  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7206 (0.7928)  acc1: 85.4167 (83.9869)  acc5: 100.0000 (98.5294)  time: 0.1239  data: 0.0033  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7734 (0.7830)  acc1: 83.3333 (84.1530)  acc5: 100.0000 (98.5314)  time: 0.1224  data: 0.0034  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.7756 (0.7972)  acc1: 81.2500 (83.4800)  acc5: 97.9167 (98.3568)  time: 0.1222  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7500 (0.7803)  acc1: 83.3333 (84.1049)  acc5: 97.9167 (98.3282)  time: 0.1203  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7500 (0.7821)  acc1: 83.3333 (84.0510)  acc5: 97.9167 (98.2930)  time: 0.1181  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1617 s / it)\n",
            "* Acc@1 84.051 Acc@5 98.293 loss 0.782\n",
            "Accuracy of the model on the 3925 test images: 84.1%\n",
            "Max accuracy: 84.05%\n",
            "Test:  [ 0/82]  eta: 0:03:53  loss: 2.0276 (2.0276)  acc1: 31.2500 (31.2500)  acc5: 95.8333 (95.8333)  time: 2.8521  data: 2.6482  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:29  loss: 2.1570 (2.3707)  acc1: 25.0000 (21.5909)  acc5: 97.9167 (97.7273)  time: 0.4145  data: 0.2823  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.9229 (2.7046)  acc1: 12.5000 (15.9722)  acc5: 97.9167 (97.1230)  time: 0.1467  data: 0.0235  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.3454 (3.2779)  acc1: 6.2500 (11.6935)  acc5: 91.6667 (82.3253)  time: 0.1239  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.2766 (3.3066)  acc1: 8.3333 (13.6179)  acc5: 77.0833 (80.7927)  time: 0.1253  data: 0.0035  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.0380 (3.5824)  acc1: 8.3333 (11.8873)  acc5: 68.7500 (74.1422)  time: 0.1244  data: 0.0027  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5987 (3.6858)  acc1: 2.0833 (10.1776)  acc5: 41.6667 (71.6189)  time: 0.1251  data: 0.0046  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.8618 (3.5440)  acc1: 2.0833 (14.3192)  acc5: 70.8333 (71.3322)  time: 0.1227  data: 0.0036  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0655 (3.2186)  acc1: 70.8333 (22.2994)  acc5: 97.9167 (74.6656)  time: 0.1187  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0655 (3.1929)  acc1: 72.9167 (22.8025)  acc5: 97.9167 (74.8280)  time: 0.1173  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1667 s / it)\n",
            "* Acc@1 22.803 Acc@5 74.828 loss 3.193\n",
            "Accuracy of the model EMA on 3925 test images: 22.8%\n",
            "Max EMA accuracy: 22.80%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [80]  [  0/295]  eta: 0:14:13  lr: 0.000587  min_lr: 0.000587  loss: 2.8087 (2.8087)  weight_decay: 0.0500 (0.0500)  time: 2.8916  data: 2.2035  max mem: 3500\n",
            "Epoch: [80]  [ 10/295]  eta: 0:02:41  lr: 0.000585  min_lr: 0.000585  loss: 3.2118 (3.1673)  weight_decay: 0.0500 (0.0500)  time: 0.5664  data: 0.2018  max mem: 3500\n",
            "Epoch: [80]  [ 20/295]  eta: 0:01:56  lr: 0.000583  min_lr: 0.000583  loss: 3.1602 (3.1137)  weight_decay: 0.0500 (0.0500)  time: 0.2989  data: 0.0015  max mem: 3500\n",
            "Epoch: [80]  [ 30/295]  eta: 0:01:38  lr: 0.000581  min_lr: 0.000581  loss: 3.1093 (3.1175)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0017  max mem: 3500\n",
            "Epoch: [80]  [ 40/295]  eta: 0:01:28  lr: 0.000579  min_lr: 0.000579  loss: 2.9988 (3.0709)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0019  max mem: 3500\n",
            "Epoch: [80]  [ 50/295]  eta: 0:01:21  lr: 0.000578  min_lr: 0.000578  loss: 2.8501 (3.0454)  weight_decay: 0.0500 (0.0500)  time: 0.2774  data: 0.0023  max mem: 3500\n",
            "Epoch: [80]  [ 60/295]  eta: 0:01:16  lr: 0.000575  min_lr: 0.000575  loss: 2.9809 (3.0385)  weight_decay: 0.0500 (0.0500)  time: 0.2837  data: 0.0032  max mem: 3500\n",
            "Epoch: [80]  [ 70/295]  eta: 0:01:11  lr: 0.000574  min_lr: 0.000574  loss: 3.0391 (3.0418)  weight_decay: 0.0500 (0.0500)  time: 0.2797  data: 0.0028  max mem: 3500\n",
            "Epoch: [80]  [ 80/295]  eta: 0:01:07  lr: 0.000572  min_lr: 0.000572  loss: 3.0522 (3.0400)  weight_decay: 0.0500 (0.0500)  time: 0.2750  data: 0.0017  max mem: 3500\n",
            "Epoch: [80]  [ 90/295]  eta: 0:01:03  lr: 0.000570  min_lr: 0.000570  loss: 3.1128 (3.0568)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0019  max mem: 3500\n",
            "Epoch: [80]  [100/295]  eta: 0:00:59  lr: 0.000568  min_lr: 0.000568  loss: 2.9875 (3.0492)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0019  max mem: 3500\n",
            "Epoch: [80]  [110/295]  eta: 0:00:55  lr: 0.000566  min_lr: 0.000566  loss: 2.9271 (3.0327)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0017  max mem: 3500\n",
            "Epoch: [80]  [120/295]  eta: 0:00:52  lr: 0.000564  min_lr: 0.000564  loss: 3.0559 (3.0469)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0018  max mem: 3500\n",
            "Epoch: [80]  [130/295]  eta: 0:00:48  lr: 0.000563  min_lr: 0.000563  loss: 3.1159 (3.0449)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0012  max mem: 3500\n",
            "Epoch: [80]  [140/295]  eta: 0:00:45  lr: 0.000560  min_lr: 0.000560  loss: 3.0925 (3.0471)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0014  max mem: 3500\n",
            "Epoch: [80]  [150/295]  eta: 0:00:42  lr: 0.000559  min_lr: 0.000559  loss: 3.0419 (3.0500)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0017  max mem: 3500\n",
            "Epoch: [80]  [160/295]  eta: 0:00:39  lr: 0.000557  min_lr: 0.000557  loss: 3.1107 (3.0495)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0014  max mem: 3500\n",
            "Epoch: [80]  [170/295]  eta: 0:00:36  lr: 0.000555  min_lr: 0.000555  loss: 3.0783 (3.0476)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0009  max mem: 3500\n",
            "Epoch: [80]  [180/295]  eta: 0:00:32  lr: 0.000553  min_lr: 0.000553  loss: 3.1300 (3.0545)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0003  max mem: 3500\n",
            "Epoch: [80]  [190/295]  eta: 0:00:29  lr: 0.000551  min_lr: 0.000551  loss: 3.2102 (3.0621)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0007  max mem: 3500\n",
            "Epoch: [80]  [200/295]  eta: 0:00:27  lr: 0.000549  min_lr: 0.000549  loss: 3.1811 (3.0640)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0024  max mem: 3500\n",
            "Epoch: [80]  [210/295]  eta: 0:00:24  lr: 0.000548  min_lr: 0.000548  loss: 3.1736 (3.0627)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0023  max mem: 3500\n",
            "Epoch: [80]  [220/295]  eta: 0:00:21  lr: 0.000545  min_lr: 0.000545  loss: 3.1673 (3.0670)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0008  max mem: 3500\n",
            "Epoch: [80]  [230/295]  eta: 0:00:18  lr: 0.000544  min_lr: 0.000544  loss: 3.1751 (3.0630)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0009  max mem: 3500\n",
            "Epoch: [80]  [240/295]  eta: 0:00:15  lr: 0.000542  min_lr: 0.000542  loss: 3.1956 (3.0702)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0012  max mem: 3500\n",
            "Epoch: [80]  [250/295]  eta: 0:00:12  lr: 0.000540  min_lr: 0.000540  loss: 3.2389 (3.0702)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0012  max mem: 3500\n",
            "Epoch: [80]  [260/295]  eta: 0:00:09  lr: 0.000538  min_lr: 0.000538  loss: 3.0430 (3.0710)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0025  max mem: 3500\n",
            "Epoch: [80]  [270/295]  eta: 0:00:06  lr: 0.000537  min_lr: 0.000537  loss: 3.1448 (3.0706)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0040  max mem: 3500\n",
            "Epoch: [80]  [280/295]  eta: 0:00:04  lr: 0.000534  min_lr: 0.000534  loss: 3.1638 (3.0756)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0041  max mem: 3500\n",
            "Epoch: [80]  [290/295]  eta: 0:00:01  lr: 0.000533  min_lr: 0.000533  loss: 3.1986 (3.0772)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0020  max mem: 3500\n",
            "Epoch: [80]  [294/295]  eta: 0:00:00  lr: 0.000533  min_lr: 0.000533  loss: 3.1986 (3.0779)  weight_decay: 0.0500 (0.0500)  time: 0.2195  data: 0.0003  max mem: 3500\n",
            "Epoch: [80] Total time: 0:01:21 (0.2767 s / it)\n",
            "Averaged stats: lr: 0.000533  min_lr: 0.000533  loss: 3.1986 (3.0779)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:57  loss: 0.6357 (0.6357)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.1694  data: 2.0002  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.6299 (0.6223)  acc1: 91.6667 (90.9091)  acc5: 100.0000 (98.4849)  time: 0.3122  data: 0.1852  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.6355 (0.6402)  acc1: 91.6667 (90.1786)  acc5: 100.0000 (98.7103)  time: 0.1287  data: 0.0047  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.7401 (0.8241)  acc1: 83.3333 (83.0645)  acc5: 97.9167 (98.1855)  time: 0.1439  data: 0.0044  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7787 (0.7972)  acc1: 83.3333 (84.2480)  acc5: 97.9167 (98.2724)  time: 0.1465  data: 0.0021  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7689 (0.8005)  acc1: 85.4167 (84.1912)  acc5: 100.0000 (98.4069)  time: 0.1448  data: 0.0022  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8406 (0.8187)  acc1: 83.3333 (83.8456)  acc5: 100.0000 (98.3948)  time: 0.1548  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8827 (0.8287)  acc1: 81.2500 (83.3040)  acc5: 97.9167 (98.1221)  time: 0.1556  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.6529 (0.7984)  acc1: 87.5000 (84.2593)  acc5: 97.9167 (98.1482)  time: 0.1363  data: 0.0027  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.6529 (0.7983)  acc1: 87.5000 (84.2548)  acc5: 97.9167 (98.1147)  time: 0.1327  data: 0.0027  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1711 s / it)\n",
            "* Acc@1 84.255 Acc@5 98.115 loss 0.798\n",
            "Accuracy of the model on the 3925 test images: 84.3%\n",
            "Max accuracy: 84.25%\n",
            "Test:  [ 0/82]  eta: 0:02:46  loss: 1.9800 (1.9800)  acc1: 31.2500 (31.2500)  acc5: 95.8333 (95.8333)  time: 2.0267  data: 1.8685  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.1094 (2.3300)  acc1: 25.0000 (22.9167)  acc5: 97.9167 (97.9167)  time: 0.2963  data: 0.1712  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.8895 (2.6735)  acc1: 12.5000 (16.5675)  acc5: 97.9167 (97.2222)  time: 0.1232  data: 0.0027  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.3116 (3.2486)  acc1: 6.2500 (12.0968)  acc5: 91.6667 (82.3925)  time: 0.1252  data: 0.0036  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.2201 (3.2732)  acc1: 8.3333 (13.9736)  acc5: 77.0833 (80.8943)  time: 0.1273  data: 0.0034  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 4.0048 (3.5503)  acc1: 8.3333 (12.1732)  acc5: 68.7500 (74.2647)  time: 0.1264  data: 0.0037  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5829 (3.6522)  acc1: 2.0833 (10.4508)  acc5: 43.7500 (71.8238)  time: 0.1430  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.8243 (3.5113)  acc1: 2.0833 (14.5833)  acc5: 70.8333 (71.5082)  time: 0.1482  data: 0.0013  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0503 (3.1887)  acc1: 70.8333 (22.5051)  acc5: 97.9167 (74.8200)  time: 0.1271  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0503 (3.1633)  acc1: 72.9167 (22.9809)  acc5: 97.9167 (74.9809)  time: 0.1254  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1600 s / it)\n",
            "* Acc@1 22.981 Acc@5 74.981 loss 3.163\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "Max EMA accuracy: 22.98%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [81]  [  0/295]  eta: 0:09:56  lr: 0.000532  min_lr: 0.000532  loss: 3.2225 (3.2225)  weight_decay: 0.0500 (0.0500)  time: 2.0222  data: 1.5746  max mem: 3500\n",
            "Epoch: [81]  [ 10/295]  eta: 0:02:08  lr: 0.000531  min_lr: 0.000531  loss: 3.0515 (3.0474)  weight_decay: 0.0500 (0.0500)  time: 0.4493  data: 0.1518  max mem: 3500\n",
            "Epoch: [81]  [ 20/295]  eta: 0:01:39  lr: 0.000529  min_lr: 0.000529  loss: 3.0694 (3.1075)  weight_decay: 0.0500 (0.0500)  time: 0.2772  data: 0.0051  max mem: 3500\n",
            "Epoch: [81]  [ 30/295]  eta: 0:01:27  lr: 0.000527  min_lr: 0.000527  loss: 3.1329 (3.0938)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0006  max mem: 3500\n",
            "Epoch: [81]  [ 40/295]  eta: 0:01:20  lr: 0.000525  min_lr: 0.000525  loss: 3.1329 (3.0906)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0013  max mem: 3500\n",
            "Epoch: [81]  [ 50/295]  eta: 0:01:15  lr: 0.000523  min_lr: 0.000523  loss: 3.1316 (3.0931)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0025  max mem: 3500\n",
            "Epoch: [81]  [ 60/295]  eta: 0:01:10  lr: 0.000521  min_lr: 0.000521  loss: 3.0861 (3.0720)  weight_decay: 0.0500 (0.0500)  time: 0.2760  data: 0.0044  max mem: 3500\n",
            "Epoch: [81]  [ 70/295]  eta: 0:01:06  lr: 0.000520  min_lr: 0.000520  loss: 2.8105 (3.0429)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0033  max mem: 3500\n",
            "Epoch: [81]  [ 80/295]  eta: 0:01:02  lr: 0.000518  min_lr: 0.000518  loss: 2.9969 (3.0484)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0011  max mem: 3500\n",
            "Epoch: [81]  [ 90/295]  eta: 0:00:59  lr: 0.000516  min_lr: 0.000516  loss: 3.1986 (3.0520)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0016  max mem: 3500\n",
            "Epoch: [81]  [100/295]  eta: 0:00:55  lr: 0.000514  min_lr: 0.000514  loss: 3.1039 (3.0588)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0014  max mem: 3500\n",
            "Epoch: [81]  [110/295]  eta: 0:00:52  lr: 0.000513  min_lr: 0.000513  loss: 3.1189 (3.0648)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0019  max mem: 3500\n",
            "Epoch: [81]  [120/295]  eta: 0:00:49  lr: 0.000511  min_lr: 0.000511  loss: 3.0348 (3.0582)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0032  max mem: 3500\n",
            "Epoch: [81]  [130/295]  eta: 0:00:46  lr: 0.000509  min_lr: 0.000509  loss: 3.1313 (3.0671)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0027  max mem: 3500\n",
            "Epoch: [81]  [140/295]  eta: 0:00:43  lr: 0.000507  min_lr: 0.000507  loss: 3.1369 (3.0643)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0010  max mem: 3500\n",
            "Epoch: [81]  [150/295]  eta: 0:00:40  lr: 0.000505  min_lr: 0.000505  loss: 2.9106 (3.0566)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0008  max mem: 3500\n",
            "Epoch: [81]  [160/295]  eta: 0:00:37  lr: 0.000503  min_lr: 0.000503  loss: 2.9147 (3.0539)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0010  max mem: 3500\n",
            "Epoch: [81]  [170/295]  eta: 0:00:34  lr: 0.000502  min_lr: 0.000502  loss: 3.0985 (3.0565)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0011  max mem: 3500\n",
            "Epoch: [81]  [180/295]  eta: 0:00:31  lr: 0.000500  min_lr: 0.000500  loss: 3.0985 (3.0601)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0022  max mem: 3500\n",
            "Epoch: [81]  [190/295]  eta: 0:00:29  lr: 0.000498  min_lr: 0.000498  loss: 3.0793 (3.0600)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0030  max mem: 3500\n",
            "Epoch: [81]  [200/295]  eta: 0:00:26  lr: 0.000496  min_lr: 0.000496  loss: 3.1361 (3.0659)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0024  max mem: 3500\n",
            "Epoch: [81]  [210/295]  eta: 0:00:23  lr: 0.000495  min_lr: 0.000495  loss: 3.1016 (3.0605)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0016  max mem: 3500\n",
            "Epoch: [81]  [220/295]  eta: 0:00:20  lr: 0.000493  min_lr: 0.000493  loss: 3.0479 (3.0647)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0009  max mem: 3500\n",
            "Epoch: [81]  [230/295]  eta: 0:00:17  lr: 0.000491  min_lr: 0.000491  loss: 3.0479 (3.0619)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0013  max mem: 3500\n",
            "Epoch: [81]  [240/295]  eta: 0:00:15  lr: 0.000489  min_lr: 0.000489  loss: 3.1022 (3.0654)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0028  max mem: 3500\n",
            "Epoch: [81]  [250/295]  eta: 0:00:12  lr: 0.000488  min_lr: 0.000488  loss: 3.0874 (3.0603)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0036  max mem: 3500\n",
            "Epoch: [81]  [260/295]  eta: 0:00:09  lr: 0.000486  min_lr: 0.000486  loss: 3.0496 (3.0608)  weight_decay: 0.0500 (0.0500)  time: 0.2769  data: 0.0031  max mem: 3500\n",
            "Epoch: [81]  [270/295]  eta: 0:00:06  lr: 0.000484  min_lr: 0.000484  loss: 3.1316 (3.0639)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0022  max mem: 3500\n",
            "Epoch: [81]  [280/295]  eta: 0:00:04  lr: 0.000482  min_lr: 0.000482  loss: 3.1761 (3.0631)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0016  max mem: 3500\n",
            "Epoch: [81]  [290/295]  eta: 0:00:01  lr: 0.000481  min_lr: 0.000481  loss: 3.0146 (3.0615)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0007  max mem: 3500\n",
            "Epoch: [81]  [294/295]  eta: 0:00:00  lr: 0.000481  min_lr: 0.000481  loss: 3.1562 (3.0618)  weight_decay: 0.0500 (0.0500)  time: 0.2210  data: 0.0002  max mem: 3500\n",
            "Epoch: [81] Total time: 0:01:20 (0.2717 s / it)\n",
            "Averaged stats: lr: 0.000481  min_lr: 0.000481  loss: 3.1562 (3.0618)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:28  loss: 0.6872 (0.6872)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.5414  data: 2.3597  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:25  loss: 0.6083 (0.6149)  acc1: 91.6667 (90.3409)  acc5: 97.9167 (98.2955)  time: 0.3506  data: 0.2184  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.6083 (0.6151)  acc1: 89.5833 (89.8810)  acc5: 100.0000 (98.6111)  time: 0.1306  data: 0.0037  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6767 (0.7579)  acc1: 81.2500 (84.6774)  acc5: 100.0000 (98.7231)  time: 0.1293  data: 0.0031  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7460 (0.7398)  acc1: 83.3333 (85.7215)  acc5: 100.0000 (98.7805)  time: 0.1476  data: 0.0059  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7381 (0.7533)  acc1: 87.5000 (85.2124)  acc5: 100.0000 (98.7337)  time: 0.1682  data: 0.0056  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7809 (0.7566)  acc1: 85.4167 (85.1093)  acc5: 100.0000 (98.8046)  time: 0.1670  data: 0.0034  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8191 (0.7734)  acc1: 85.4167 (84.6831)  acc5: 100.0000 (98.6209)  time: 0.1467  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7855 (0.7702)  acc1: 85.4167 (84.9023)  acc5: 97.9167 (98.4568)  time: 0.1239  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7855 (0.7736)  acc1: 85.4167 (84.8662)  acc5: 97.9167 (98.4204)  time: 0.1215  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1758 s / it)\n",
            "* Acc@1 84.866 Acc@5 98.420 loss 0.774\n",
            "Accuracy of the model on the 3925 test images: 84.9%\n",
            "Max accuracy: 84.87%\n",
            "Test:  [ 0/82]  eta: 0:02:39  loss: 1.9361 (1.9361)  acc1: 31.2500 (31.2500)  acc5: 95.8333 (95.8333)  time: 1.9479  data: 1.7889  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 2.0655 (2.2920)  acc1: 27.0833 (23.6742)  acc5: 97.9167 (97.9167)  time: 0.2926  data: 0.1648  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.8565 (2.6432)  acc1: 12.5000 (17.1627)  acc5: 97.9167 (97.2222)  time: 0.1259  data: 0.0025  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.2782 (3.2203)  acc1: 6.2500 (12.5000)  acc5: 91.6667 (82.2581)  time: 0.1227  data: 0.0031  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.1650 (3.2407)  acc1: 8.3333 (14.3801)  acc5: 77.0833 (80.7927)  time: 0.1241  data: 0.0034  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.9737 (3.5185)  acc1: 8.3333 (12.5000)  acc5: 68.7500 (74.1013)  time: 0.1277  data: 0.0047  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5645 (3.6192)  acc1: 2.0833 (10.7240)  acc5: 41.6667 (71.8579)  time: 0.1396  data: 0.0048  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.7892 (3.4793)  acc1: 2.0833 (14.8474)  acc5: 72.9167 (71.5669)  time: 0.1425  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0360 (3.1594)  acc1: 70.8333 (22.7623)  acc5: 97.9167 (74.8714)  time: 0.1265  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0360 (3.1342)  acc1: 72.9167 (23.2357)  acc5: 97.9167 (75.0318)  time: 0.1244  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1585 s / it)\n",
            "* Acc@1 23.236 Acc@5 75.032 loss 3.134\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "Max EMA accuracy: 23.24%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [82]  [  0/295]  eta: 0:09:04  lr: 0.000480  min_lr: 0.000480  loss: 2.8143 (2.8143)  weight_decay: 0.0500 (0.0500)  time: 1.8473  data: 1.4007  max mem: 3500\n",
            "Epoch: [82]  [ 10/295]  eta: 0:02:01  lr: 0.000479  min_lr: 0.000479  loss: 3.0906 (3.0342)  weight_decay: 0.0500 (0.0500)  time: 0.4246  data: 0.1279  max mem: 3500\n",
            "Epoch: [82]  [ 20/295]  eta: 0:01:35  lr: 0.000477  min_lr: 0.000477  loss: 3.0345 (3.0150)  weight_decay: 0.0500 (0.0500)  time: 0.2726  data: 0.0008  max mem: 3500\n",
            "Epoch: [82]  [ 30/295]  eta: 0:01:24  lr: 0.000475  min_lr: 0.000475  loss: 2.9999 (3.0123)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0016  max mem: 3500\n",
            "Epoch: [82]  [ 40/295]  eta: 0:01:18  lr: 0.000473  min_lr: 0.000473  loss: 3.0228 (3.0155)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0029  max mem: 3500\n",
            "Epoch: [82]  [ 50/295]  eta: 0:01:13  lr: 0.000472  min_lr: 0.000472  loss: 2.9669 (2.9986)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0025  max mem: 3500\n",
            "Epoch: [82]  [ 60/295]  eta: 0:01:09  lr: 0.000470  min_lr: 0.000470  loss: 2.9522 (2.9957)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0013  max mem: 3500\n",
            "Epoch: [82]  [ 70/295]  eta: 0:01:05  lr: 0.000468  min_lr: 0.000468  loss: 3.1320 (3.0113)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0023  max mem: 3500\n",
            "Epoch: [82]  [ 80/295]  eta: 0:01:01  lr: 0.000466  min_lr: 0.000466  loss: 3.1320 (3.0067)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0022  max mem: 3500\n",
            "Epoch: [82]  [ 90/295]  eta: 0:00:58  lr: 0.000465  min_lr: 0.000465  loss: 3.0627 (3.0141)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0016  max mem: 3500\n",
            "Epoch: [82]  [100/295]  eta: 0:00:55  lr: 0.000463  min_lr: 0.000463  loss: 3.1630 (3.0218)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0018  max mem: 3500\n",
            "Epoch: [82]  [110/295]  eta: 0:00:52  lr: 0.000461  min_lr: 0.000461  loss: 3.0987 (3.0280)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0023  max mem: 3500\n",
            "Epoch: [82]  [120/295]  eta: 0:00:49  lr: 0.000459  min_lr: 0.000459  loss: 3.1260 (3.0366)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0032  max mem: 3500\n",
            "Epoch: [82]  [130/295]  eta: 0:00:46  lr: 0.000458  min_lr: 0.000458  loss: 2.9554 (3.0209)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0022  max mem: 3500\n",
            "Epoch: [82]  [140/295]  eta: 0:00:43  lr: 0.000456  min_lr: 0.000456  loss: 2.8482 (3.0201)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0015  max mem: 3500\n",
            "Epoch: [82]  [150/295]  eta: 0:00:40  lr: 0.000455  min_lr: 0.000455  loss: 3.1317 (3.0246)  weight_decay: 0.0500 (0.0500)  time: 0.2605  data: 0.0014  max mem: 3500\n",
            "Epoch: [82]  [160/295]  eta: 0:00:37  lr: 0.000452  min_lr: 0.000452  loss: 3.1941 (3.0334)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0012  max mem: 3500\n",
            "Epoch: [82]  [170/295]  eta: 0:00:34  lr: 0.000451  min_lr: 0.000451  loss: 3.1314 (3.0344)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0021  max mem: 3500\n",
            "Epoch: [82]  [180/295]  eta: 0:00:31  lr: 0.000449  min_lr: 0.000449  loss: 3.0188 (3.0366)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0024  max mem: 3500\n",
            "Epoch: [82]  [190/295]  eta: 0:00:28  lr: 0.000448  min_lr: 0.000448  loss: 3.0554 (3.0409)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0021  max mem: 3500\n",
            "Epoch: [82]  [200/295]  eta: 0:00:26  lr: 0.000446  min_lr: 0.000446  loss: 3.0858 (3.0461)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0020  max mem: 3500\n",
            "Epoch: [82]  [210/295]  eta: 0:00:23  lr: 0.000444  min_lr: 0.000444  loss: 3.1525 (3.0495)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0017  max mem: 3500\n",
            "Epoch: [82]  [220/295]  eta: 0:00:20  lr: 0.000442  min_lr: 0.000442  loss: 3.1347 (3.0479)  weight_decay: 0.0500 (0.0500)  time: 0.2596  data: 0.0013  max mem: 3500\n",
            "Epoch: [82]  [230/295]  eta: 0:00:17  lr: 0.000441  min_lr: 0.000441  loss: 2.9431 (3.0419)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0020  max mem: 3500\n",
            "Epoch: [82]  [240/295]  eta: 0:00:14  lr: 0.000439  min_lr: 0.000439  loss: 2.8732 (3.0380)  weight_decay: 0.0500 (0.0500)  time: 0.2654  data: 0.0022  max mem: 3500\n",
            "Epoch: [82]  [250/295]  eta: 0:00:12  lr: 0.000438  min_lr: 0.000438  loss: 3.1582 (3.0431)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0019  max mem: 3500\n",
            "Epoch: [82]  [260/295]  eta: 0:00:09  lr: 0.000436  min_lr: 0.000436  loss: 3.2740 (3.0504)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0019  max mem: 3500\n",
            "Epoch: [82]  [270/295]  eta: 0:00:06  lr: 0.000434  min_lr: 0.000434  loss: 3.2807 (3.0561)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0017  max mem: 3500\n",
            "Epoch: [82]  [280/295]  eta: 0:00:04  lr: 0.000432  min_lr: 0.000432  loss: 3.2058 (3.0600)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0014  max mem: 3500\n",
            "Epoch: [82]  [290/295]  eta: 0:00:01  lr: 0.000431  min_lr: 0.000431  loss: 3.1784 (3.0625)  weight_decay: 0.0500 (0.0500)  time: 0.2583  data: 0.0005  max mem: 3500\n",
            "Epoch: [82]  [294/295]  eta: 0:00:00  lr: 0.000431  min_lr: 0.000431  loss: 3.1784 (3.0613)  weight_decay: 0.0500 (0.0500)  time: 0.2195  data: 0.0002  max mem: 3500\n",
            "Epoch: [82] Total time: 0:01:19 (0.2699 s / it)\n",
            "Averaged stats: lr: 0.000431  min_lr: 0.000431  loss: 3.1784 (3.0613)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:30  loss: 0.6779 (0.6779)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 3.3022  data: 3.1405  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.6298 (0.6293)  acc1: 91.6667 (90.9091)  acc5: 97.9167 (97.5379)  time: 0.4357  data: 0.2967  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.6298 (0.6465)  acc1: 91.6667 (90.5754)  acc5: 97.9167 (98.3135)  time: 0.1668  data: 0.0107  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 0.7391 (0.8426)  acc1: 83.3333 (83.1317)  acc5: 97.9167 (98.0511)  time: 0.1868  data: 0.0081  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 0.7108 (0.8000)  acc1: 85.4167 (84.5528)  acc5: 97.9167 (98.3232)  time: 0.1660  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.6992 (0.8062)  acc1: 87.5000 (84.4363)  acc5: 100.0000 (98.4886)  time: 0.1426  data: 0.0106  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8312 (0.8130)  acc1: 85.4167 (84.2213)  acc5: 100.0000 (98.5314)  time: 0.1358  data: 0.0109  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8422 (0.8216)  acc1: 85.4167 (84.0082)  acc5: 97.9167 (98.3568)  time: 0.1245  data: 0.0008  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7582 (0.8049)  acc1: 85.4167 (84.5422)  acc5: 97.9167 (98.2768)  time: 0.1191  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7582 (0.8072)  acc1: 85.4167 (84.5096)  acc5: 97.9167 (98.2420)  time: 0.1171  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1893 s / it)\n",
            "* Acc@1 84.510 Acc@5 98.242 loss 0.807\n",
            "Accuracy of the model on the 3925 test images: 84.5%\n",
            "Max accuracy: 84.87%\n",
            "Test:  [ 0/82]  eta: 0:03:14  loss: 1.8928 (1.8928)  acc1: 33.3333 (33.3333)  acc5: 95.8333 (95.8333)  time: 2.3665  data: 2.1919  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 2.0224 (2.2536)  acc1: 27.0833 (24.8106)  acc5: 97.9167 (97.9167)  time: 0.3299  data: 0.2020  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 2.8232 (2.6125)  acc1: 12.5000 (17.9563)  acc5: 97.9167 (97.2222)  time: 0.1344  data: 0.0071  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 3.2406 (3.1905)  acc1: 6.2500 (13.0376)  acc5: 93.7500 (82.1909)  time: 0.1514  data: 0.0066  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 3.1080 (3.2066)  acc1: 8.3333 (14.8882)  acc5: 79.1667 (81.2500)  time: 0.1553  data: 0.0011  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.9441 (3.4853)  acc1: 8.3333 (12.9493)  acc5: 68.7500 (74.4690)  time: 0.1543  data: 0.0007  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.5431 (3.5852)  acc1: 2.0833 (11.1339)  acc5: 41.6667 (72.3019)  time: 0.1548  data: 0.0024  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.7560 (3.4465)  acc1: 2.0833 (15.1995)  acc5: 72.9167 (71.9777)  time: 0.1553  data: 0.0024  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0207 (3.1296)  acc1: 70.8333 (23.0710)  acc5: 97.9167 (75.2315)  time: 0.1400  data: 0.0006  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0207 (3.1046)  acc1: 72.9167 (23.5414)  acc5: 97.9167 (75.3885)  time: 0.1378  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1782 s / it)\n",
            "* Acc@1 23.541 Acc@5 75.389 loss 3.105\n",
            "Accuracy of the model EMA on 3925 test images: 23.5%\n",
            "Max EMA accuracy: 23.54%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [83]  [  0/295]  eta: 0:10:30  lr: 0.000430  min_lr: 0.000430  loss: 3.1523 (3.1523)  weight_decay: 0.0500 (0.0500)  time: 2.1381  data: 1.8109  max mem: 3500\n",
            "Epoch: [83]  [ 10/295]  eta: 0:02:03  lr: 0.000429  min_lr: 0.000429  loss: 3.1867 (3.1090)  weight_decay: 0.0500 (0.0500)  time: 0.4324  data: 0.1655  max mem: 3500\n",
            "Epoch: [83]  [ 20/295]  eta: 0:01:37  lr: 0.000427  min_lr: 0.000427  loss: 3.0586 (3.0808)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0020  max mem: 3500\n",
            "Epoch: [83]  [ 30/295]  eta: 0:01:27  lr: 0.000426  min_lr: 0.000426  loss: 3.0029 (3.0519)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0031  max mem: 3500\n",
            "Epoch: [83]  [ 40/295]  eta: 0:01:21  lr: 0.000424  min_lr: 0.000424  loss: 3.0934 (3.0428)  weight_decay: 0.0500 (0.0500)  time: 0.2862  data: 0.0027  max mem: 3500\n",
            "Epoch: [83]  [ 50/295]  eta: 0:01:16  lr: 0.000422  min_lr: 0.000422  loss: 3.0934 (3.0403)  weight_decay: 0.0500 (0.0500)  time: 0.2876  data: 0.0027  max mem: 3500\n",
            "Epoch: [83]  [ 60/295]  eta: 0:01:12  lr: 0.000420  min_lr: 0.000420  loss: 3.1022 (3.0281)  weight_decay: 0.0500 (0.0500)  time: 0.2805  data: 0.0029  max mem: 3500\n",
            "Epoch: [83]  [ 70/295]  eta: 0:01:07  lr: 0.000419  min_lr: 0.000419  loss: 3.1200 (3.0384)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0016  max mem: 3500\n",
            "Epoch: [83]  [ 80/295]  eta: 0:01:03  lr: 0.000417  min_lr: 0.000417  loss: 3.1762 (3.0500)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0007  max mem: 3500\n",
            "Epoch: [83]  [ 90/295]  eta: 0:01:00  lr: 0.000416  min_lr: 0.000416  loss: 3.1796 (3.0595)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0018  max mem: 3500\n",
            "Epoch: [83]  [100/295]  eta: 0:00:56  lr: 0.000414  min_lr: 0.000414  loss: 3.1284 (3.0533)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0016  max mem: 3500\n",
            "Epoch: [83]  [110/295]  eta: 0:00:53  lr: 0.000412  min_lr: 0.000412  loss: 3.0422 (3.0520)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0010  max mem: 3500\n",
            "Epoch: [83]  [120/295]  eta: 0:00:50  lr: 0.000410  min_lr: 0.000410  loss: 3.1956 (3.0571)  weight_decay: 0.0500 (0.0500)  time: 0.2734  data: 0.0018  max mem: 3500\n",
            "Epoch: [83]  [130/295]  eta: 0:00:47  lr: 0.000409  min_lr: 0.000409  loss: 3.1969 (3.0642)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0026  max mem: 3500\n",
            "Epoch: [83]  [140/295]  eta: 0:00:44  lr: 0.000407  min_lr: 0.000407  loss: 3.1884 (3.0641)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0022  max mem: 3500\n",
            "Epoch: [83]  [150/295]  eta: 0:00:40  lr: 0.000406  min_lr: 0.000406  loss: 3.0364 (3.0569)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0009  max mem: 3500\n",
            "Epoch: [83]  [160/295]  eta: 0:00:37  lr: 0.000404  min_lr: 0.000404  loss: 2.9200 (3.0523)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0007  max mem: 3500\n",
            "Epoch: [83]  [170/295]  eta: 0:00:35  lr: 0.000403  min_lr: 0.000403  loss: 2.9956 (3.0508)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0010  max mem: 3500\n",
            "Epoch: [83]  [180/295]  eta: 0:00:32  lr: 0.000401  min_lr: 0.000401  loss: 3.0425 (3.0525)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0022  max mem: 3500\n",
            "Epoch: [83]  [190/295]  eta: 0:00:29  lr: 0.000399  min_lr: 0.000399  loss: 3.0425 (3.0542)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0037  max mem: 3500\n",
            "Epoch: [83]  [200/295]  eta: 0:00:26  lr: 0.000398  min_lr: 0.000398  loss: 2.9864 (3.0547)  weight_decay: 0.0500 (0.0500)  time: 0.2685  data: 0.0034  max mem: 3500\n",
            "Epoch: [83]  [210/295]  eta: 0:00:23  lr: 0.000396  min_lr: 0.000396  loss: 2.9604 (3.0492)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0020  max mem: 3500\n",
            "Epoch: [83]  [220/295]  eta: 0:00:20  lr: 0.000394  min_lr: 0.000394  loss: 2.9053 (3.0457)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0012  max mem: 3500\n",
            "Epoch: [83]  [230/295]  eta: 0:00:17  lr: 0.000393  min_lr: 0.000393  loss: 2.8528 (3.0403)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0011  max mem: 3500\n",
            "Epoch: [83]  [240/295]  eta: 0:00:15  lr: 0.000391  min_lr: 0.000391  loss: 3.1054 (3.0433)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0018  max mem: 3500\n",
            "Epoch: [83]  [250/295]  eta: 0:00:12  lr: 0.000390  min_lr: 0.000390  loss: 3.1395 (3.0429)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0023  max mem: 3500\n",
            "Epoch: [83]  [260/295]  eta: 0:00:09  lr: 0.000388  min_lr: 0.000388  loss: 3.1830 (3.0496)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0018  max mem: 3500\n",
            "Epoch: [83]  [270/295]  eta: 0:00:06  lr: 0.000387  min_lr: 0.000387  loss: 3.2172 (3.0555)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0020  max mem: 3500\n",
            "Epoch: [83]  [280/295]  eta: 0:00:04  lr: 0.000385  min_lr: 0.000385  loss: 3.1600 (3.0588)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0016  max mem: 3500\n",
            "Epoch: [83]  [290/295]  eta: 0:00:01  lr: 0.000384  min_lr: 0.000384  loss: 3.1217 (3.0555)  weight_decay: 0.0500 (0.0500)  time: 0.2581  data: 0.0003  max mem: 3500\n",
            "Epoch: [83]  [294/295]  eta: 0:00:00  lr: 0.000384  min_lr: 0.000384  loss: 3.0504 (3.0541)  weight_decay: 0.0500 (0.0500)  time: 0.2198  data: 0.0003  max mem: 3500\n",
            "Epoch: [83] Total time: 0:01:20 (0.2722 s / it)\n",
            "Averaged stats: lr: 0.000384  min_lr: 0.000384  loss: 3.0504 (3.0541)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:03  loss: 0.6110 (0.6110)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.9649  data: 2.8066  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.6036 (0.6165)  acc1: 91.6667 (91.0985)  acc5: 97.9167 (97.9167)  time: 0.4337  data: 0.2940  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.6036 (0.6297)  acc1: 89.5833 (89.9802)  acc5: 100.0000 (98.4127)  time: 0.1744  data: 0.0236  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.6721 (0.8230)  acc1: 85.4167 (82.7957)  acc5: 97.9167 (97.7151)  time: 0.1638  data: 0.0044  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 0.7494 (0.7939)  acc1: 83.3333 (83.8923)  acc5: 97.9167 (97.9675)  time: 0.1738  data: 0.0108  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.7169 (0.7915)  acc1: 87.5000 (83.9461)  acc5: 100.0000 (97.9984)  time: 0.1645  data: 0.0121  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7809 (0.7905)  acc1: 83.3333 (83.9481)  acc5: 100.0000 (98.0874)  time: 0.1354  data: 0.0081  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8547 (0.8044)  acc1: 83.3333 (83.4507)  acc5: 97.9167 (97.9167)  time: 0.1241  data: 0.0049  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7801 (0.7845)  acc1: 85.4167 (84.3107)  acc5: 97.9167 (97.9681)  time: 0.1183  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7801 (0.7859)  acc1: 85.4167 (84.3057)  acc5: 97.9167 (97.9363)  time: 0.1166  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1899 s / it)\n",
            "* Acc@1 84.306 Acc@5 97.936 loss 0.786\n",
            "Accuracy of the model on the 3925 test images: 84.3%\n",
            "Max accuracy: 84.87%\n",
            "Test:  [ 0/82]  eta: 0:02:35  loss: 1.8495 (1.8495)  acc1: 35.4167 (35.4167)  acc5: 95.8333 (95.8333)  time: 1.8975  data: 1.7205  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.9791 (2.2151)  acc1: 29.1667 (25.5682)  acc5: 97.9167 (97.9167)  time: 0.2843  data: 0.1579  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.8003 (2.5804)  acc1: 12.5000 (18.3532)  acc5: 97.9167 (97.2222)  time: 0.1225  data: 0.0011  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.2043 (3.1583)  acc1: 6.2500 (13.4409)  acc5: 93.7500 (82.2581)  time: 0.1264  data: 0.0029  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 3.0542 (3.1710)  acc1: 8.3333 (15.4980)  acc5: 79.1667 (81.5041)  time: 0.1412  data: 0.0032  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.9102 (3.4504)  acc1: 8.3333 (13.3987)  acc5: 68.7500 (74.7141)  time: 0.1534  data: 0.0007  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.5192 (3.5493)  acc1: 2.0833 (11.5779)  acc5: 39.5833 (72.5068)  time: 0.1627  data: 0.0016  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.7187 (3.4118)  acc1: 2.0833 (15.5810)  acc5: 72.9167 (72.2124)  time: 0.1683  data: 0.0015  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 1.0069 (3.0982)  acc1: 70.8333 (23.4054)  acc5: 97.9167 (75.4372)  time: 0.1433  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 1.0069 (3.0735)  acc1: 72.9167 (23.8726)  acc5: 97.9167 (75.5924)  time: 0.1410  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1705 s / it)\n",
            "* Acc@1 23.873 Acc@5 75.592 loss 3.074\n",
            "Accuracy of the model EMA on 3925 test images: 23.9%\n",
            "Max EMA accuracy: 23.87%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [84]  [  0/295]  eta: 0:10:49  lr: 0.000383  min_lr: 0.000383  loss: 3.1743 (3.1743)  weight_decay: 0.0500 (0.0500)  time: 2.2033  data: 1.7149  max mem: 3500\n",
            "Epoch: [84]  [ 10/295]  eta: 0:02:05  lr: 0.000382  min_lr: 0.000382  loss: 3.1743 (3.0796)  weight_decay: 0.0500 (0.0500)  time: 0.4397  data: 0.1567  max mem: 3500\n",
            "Epoch: [84]  [ 20/295]  eta: 0:01:37  lr: 0.000380  min_lr: 0.000380  loss: 3.0881 (3.0744)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0008  max mem: 3500\n",
            "Epoch: [84]  [ 30/295]  eta: 0:01:27  lr: 0.000378  min_lr: 0.000378  loss: 3.0759 (3.0629)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0015  max mem: 3500\n",
            "Epoch: [84]  [ 40/295]  eta: 0:01:20  lr: 0.000377  min_lr: 0.000377  loss: 3.0589 (3.0685)  weight_decay: 0.0500 (0.0500)  time: 0.2750  data: 0.0025  max mem: 3500\n",
            "Epoch: [84]  [ 50/295]  eta: 0:01:15  lr: 0.000375  min_lr: 0.000375  loss: 3.0650 (3.0678)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0032  max mem: 3500\n",
            "Epoch: [84]  [ 60/295]  eta: 0:01:10  lr: 0.000373  min_lr: 0.000373  loss: 2.9958 (3.0486)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0025  max mem: 3500\n",
            "Epoch: [84]  [ 70/295]  eta: 0:01:06  lr: 0.000372  min_lr: 0.000372  loss: 3.0473 (3.0433)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0018  max mem: 3500\n",
            "Epoch: [84]  [ 80/295]  eta: 0:01:02  lr: 0.000370  min_lr: 0.000370  loss: 3.0476 (3.0418)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0016  max mem: 3500\n",
            "Epoch: [84]  [ 90/295]  eta: 0:00:59  lr: 0.000369  min_lr: 0.000369  loss: 3.0407 (3.0418)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0018  max mem: 3500\n",
            "Epoch: [84]  [100/295]  eta: 0:00:55  lr: 0.000367  min_lr: 0.000367  loss: 3.0737 (3.0478)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0019  max mem: 3500\n",
            "Epoch: [84]  [110/295]  eta: 0:00:52  lr: 0.000366  min_lr: 0.000366  loss: 3.0709 (3.0324)  weight_decay: 0.0500 (0.0500)  time: 0.2732  data: 0.0021  max mem: 3500\n",
            "Epoch: [84]  [120/295]  eta: 0:00:49  lr: 0.000364  min_lr: 0.000364  loss: 3.0709 (3.0393)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0032  max mem: 3500\n",
            "Epoch: [84]  [130/295]  eta: 0:00:46  lr: 0.000363  min_lr: 0.000363  loss: 3.1542 (3.0403)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0020  max mem: 3500\n",
            "Epoch: [84]  [140/295]  eta: 0:00:43  lr: 0.000361  min_lr: 0.000361  loss: 3.1500 (3.0480)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0005  max mem: 3500\n",
            "Epoch: [84]  [150/295]  eta: 0:00:40  lr: 0.000360  min_lr: 0.000360  loss: 3.0606 (3.0380)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0008  max mem: 3500\n",
            "Epoch: [84]  [160/295]  eta: 0:00:37  lr: 0.000358  min_lr: 0.000358  loss: 3.1376 (3.0509)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0024  max mem: 3500\n",
            "Epoch: [84]  [170/295]  eta: 0:00:34  lr: 0.000357  min_lr: 0.000357  loss: 3.1805 (3.0524)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0034  max mem: 3500\n",
            "Epoch: [84]  [180/295]  eta: 0:00:31  lr: 0.000355  min_lr: 0.000355  loss: 3.0665 (3.0516)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0037  max mem: 3500\n",
            "Epoch: [84]  [190/295]  eta: 0:00:29  lr: 0.000354  min_lr: 0.000354  loss: 3.1421 (3.0552)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0032  max mem: 3500\n",
            "Epoch: [84]  [200/295]  eta: 0:00:26  lr: 0.000352  min_lr: 0.000352  loss: 3.0594 (3.0521)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0020  max mem: 3500\n",
            "Epoch: [84]  [210/295]  eta: 0:00:23  lr: 0.000351  min_lr: 0.000351  loss: 3.0594 (3.0568)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0027  max mem: 3500\n",
            "Epoch: [84]  [220/295]  eta: 0:00:20  lr: 0.000349  min_lr: 0.000349  loss: 3.1421 (3.0579)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0021  max mem: 3500\n",
            "Epoch: [84]  [230/295]  eta: 0:00:17  lr: 0.000348  min_lr: 0.000348  loss: 3.0494 (3.0587)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0012  max mem: 3500\n",
            "Epoch: [84]  [240/295]  eta: 0:00:15  lr: 0.000346  min_lr: 0.000346  loss: 3.0069 (3.0587)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0029  max mem: 3500\n",
            "Epoch: [84]  [250/295]  eta: 0:00:12  lr: 0.000345  min_lr: 0.000345  loss: 2.9464 (3.0546)  weight_decay: 0.0500 (0.0500)  time: 0.2781  data: 0.0042  max mem: 3500\n",
            "Epoch: [84]  [260/295]  eta: 0:00:09  lr: 0.000343  min_lr: 0.000343  loss: 2.8365 (3.0456)  weight_decay: 0.0500 (0.0500)  time: 0.2783  data: 0.0034  max mem: 3500\n",
            "Epoch: [84]  [270/295]  eta: 0:00:06  lr: 0.000342  min_lr: 0.000342  loss: 2.9926 (3.0493)  weight_decay: 0.0500 (0.0500)  time: 0.2724  data: 0.0026  max mem: 3500\n",
            "Epoch: [84]  [280/295]  eta: 0:00:04  lr: 0.000340  min_lr: 0.000340  loss: 3.1904 (3.0474)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0021  max mem: 3500\n",
            "Epoch: [84]  [290/295]  eta: 0:00:01  lr: 0.000339  min_lr: 0.000339  loss: 3.0859 (3.0491)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0009  max mem: 3500\n",
            "Epoch: [84]  [294/295]  eta: 0:00:00  lr: 0.000339  min_lr: 0.000339  loss: 3.0859 (3.0498)  weight_decay: 0.0500 (0.0500)  time: 0.2190  data: 0.0002  max mem: 3500\n",
            "Epoch: [84] Total time: 0:01:20 (0.2722 s / it)\n",
            "Averaged stats: lr: 0.000339  min_lr: 0.000339  loss: 3.0859 (3.0498)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:09  loss: 0.6083 (0.6083)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 1.5775  data: 1.4233  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5816 (0.5808)  acc1: 91.6667 (91.0985)  acc5: 97.9167 (97.7273)  time: 0.2984  data: 0.1702  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5816 (0.5923)  acc1: 91.6667 (90.5754)  acc5: 97.9167 (98.1151)  time: 0.1628  data: 0.0246  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6968 (0.7327)  acc1: 87.5000 (85.3495)  acc5: 97.9167 (98.3871)  time: 0.1546  data: 0.0080  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7042 (0.7103)  acc1: 87.5000 (86.2805)  acc5: 100.0000 (98.5264)  time: 0.1832  data: 0.0435  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6944 (0.7202)  acc1: 87.5000 (85.7843)  acc5: 100.0000 (98.6111)  time: 0.1735  data: 0.0392  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7865 (0.7328)  acc1: 83.3333 (85.1776)  acc5: 100.0000 (98.7022)  time: 0.1594  data: 0.0031  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.9110 (0.7628)  acc1: 81.2500 (84.2430)  acc5: 97.9167 (98.2981)  time: 0.1593  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7468 (0.7458)  acc1: 85.4167 (84.8508)  acc5: 97.9167 (98.3282)  time: 0.1261  data: 0.0009  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7468 (0.7473)  acc1: 85.4167 (84.8408)  acc5: 97.9167 (98.2930)  time: 0.1198  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1793 s / it)\n",
            "* Acc@1 84.841 Acc@5 98.293 loss 0.747\n",
            "Accuracy of the model on the 3925 test images: 84.8%\n",
            "Max accuracy: 84.87%\n",
            "Test:  [ 0/82]  eta: 0:02:26  loss: 1.8076 (1.8076)  acc1: 35.4167 (35.4167)  acc5: 95.8333 (95.8333)  time: 1.7872  data: 1.6155  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.9393 (2.1781)  acc1: 29.1667 (26.1364)  acc5: 97.9167 (97.9167)  time: 0.2821  data: 0.1551  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.7700 (2.5495)  acc1: 12.5000 (18.6508)  acc5: 97.9167 (97.1230)  time: 0.1270  data: 0.0058  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.1693 (3.1281)  acc1: 6.2500 (13.6425)  acc5: 91.6667 (82.3925)  time: 0.1233  data: 0.0026  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:06  loss: 3.0142 (3.1373)  acc1: 8.3333 (15.8028)  acc5: 79.1667 (81.8598)  time: 0.1243  data: 0.0048  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.8749 (3.4177)  acc1: 8.3333 (13.5621)  acc5: 68.7500 (75.0000)  time: 0.1251  data: 0.0061  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.4998 (3.5151)  acc1: 2.0833 (11.7486)  acc5: 39.5833 (72.8484)  time: 0.1270  data: 0.0075  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.6805 (3.3788)  acc1: 2.0833 (15.9038)  acc5: 75.0000 (72.5059)  time: 0.1251  data: 0.0050  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9930 (3.0683)  acc1: 70.8333 (23.6883)  acc5: 97.9167 (75.6944)  time: 0.1201  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9930 (3.0439)  acc1: 72.9167 (24.1529)  acc5: 97.9167 (75.8471)  time: 0.1190  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1524 s / it)\n",
            "* Acc@1 24.153 Acc@5 75.847 loss 3.044\n",
            "Accuracy of the model EMA on 3925 test images: 24.2%\n",
            "Max EMA accuracy: 24.15%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [85]  [  0/295]  eta: 0:12:41  lr: 0.000338  min_lr: 0.000338  loss: 3.2498 (3.2498)  weight_decay: 0.0500 (0.0500)  time: 2.5813  data: 2.1578  max mem: 3500\n",
            "Epoch: [85]  [ 10/295]  eta: 0:02:16  lr: 0.000337  min_lr: 0.000337  loss: 2.9362 (3.0244)  weight_decay: 0.0500 (0.0500)  time: 0.4773  data: 0.1979  max mem: 3500\n",
            "Epoch: [85]  [ 20/295]  eta: 0:01:42  lr: 0.000335  min_lr: 0.000335  loss: 2.9130 (2.9660)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0012  max mem: 3500\n",
            "Epoch: [85]  [ 30/295]  eta: 0:01:29  lr: 0.000334  min_lr: 0.000334  loss: 3.0326 (3.0241)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0009  max mem: 3500\n",
            "Epoch: [85]  [ 40/295]  eta: 0:01:21  lr: 0.000332  min_lr: 0.000332  loss: 3.0657 (3.0159)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0014  max mem: 3500\n",
            "Epoch: [85]  [ 50/295]  eta: 0:01:16  lr: 0.000331  min_lr: 0.000331  loss: 2.9290 (3.0080)  weight_decay: 0.0500 (0.0500)  time: 0.2733  data: 0.0021  max mem: 3500\n",
            "Epoch: [85]  [ 60/295]  eta: 0:01:11  lr: 0.000329  min_lr: 0.000329  loss: 3.0695 (3.0290)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0019  max mem: 3500\n",
            "Epoch: [85]  [ 70/295]  eta: 0:01:07  lr: 0.000328  min_lr: 0.000328  loss: 3.1579 (3.0414)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0013  max mem: 3500\n",
            "Epoch: [85]  [ 80/295]  eta: 0:01:03  lr: 0.000326  min_lr: 0.000326  loss: 3.0866 (3.0404)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0013  max mem: 3500\n",
            "Epoch: [85]  [ 90/295]  eta: 0:00:59  lr: 0.000325  min_lr: 0.000325  loss: 2.9703 (3.0349)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0011  max mem: 3500\n",
            "Epoch: [85]  [100/295]  eta: 0:00:56  lr: 0.000323  min_lr: 0.000323  loss: 3.0044 (3.0382)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0008  max mem: 3500\n",
            "Epoch: [85]  [110/295]  eta: 0:00:53  lr: 0.000322  min_lr: 0.000322  loss: 3.0044 (3.0316)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0015  max mem: 3500\n",
            "Epoch: [85]  [120/295]  eta: 0:00:50  lr: 0.000320  min_lr: 0.000320  loss: 2.9213 (3.0323)  weight_decay: 0.0500 (0.0500)  time: 0.2757  data: 0.0041  max mem: 3500\n",
            "Epoch: [85]  [130/295]  eta: 0:00:47  lr: 0.000319  min_lr: 0.000319  loss: 3.0229 (3.0276)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0048  max mem: 3500\n",
            "Epoch: [85]  [140/295]  eta: 0:00:43  lr: 0.000317  min_lr: 0.000317  loss: 2.9638 (3.0216)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0026  max mem: 3500\n",
            "Epoch: [85]  [150/295]  eta: 0:00:40  lr: 0.000316  min_lr: 0.000316  loss: 2.9991 (3.0274)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0009  max mem: 3500\n",
            "Epoch: [85]  [160/295]  eta: 0:00:37  lr: 0.000314  min_lr: 0.000314  loss: 3.0224 (3.0282)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0006  max mem: 3500\n",
            "Epoch: [85]  [170/295]  eta: 0:00:34  lr: 0.000313  min_lr: 0.000313  loss: 3.0421 (3.0320)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0016  max mem: 3500\n",
            "Epoch: [85]  [180/295]  eta: 0:00:32  lr: 0.000312  min_lr: 0.000312  loss: 3.0421 (3.0308)  weight_decay: 0.0500 (0.0500)  time: 0.2704  data: 0.0024  max mem: 3500\n",
            "Epoch: [85]  [190/295]  eta: 0:00:29  lr: 0.000310  min_lr: 0.000310  loss: 3.0412 (3.0342)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0034  max mem: 3500\n",
            "Epoch: [85]  [200/295]  eta: 0:00:26  lr: 0.000309  min_lr: 0.000309  loss: 3.0541 (3.0323)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0031  max mem: 3500\n",
            "Epoch: [85]  [210/295]  eta: 0:00:23  lr: 0.000308  min_lr: 0.000308  loss: 2.9062 (3.0309)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0010  max mem: 3500\n",
            "Epoch: [85]  [220/295]  eta: 0:00:20  lr: 0.000306  min_lr: 0.000306  loss: 2.9062 (3.0271)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0010  max mem: 3500\n",
            "Epoch: [85]  [230/295]  eta: 0:00:17  lr: 0.000305  min_lr: 0.000305  loss: 3.0492 (3.0317)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0021  max mem: 3500\n",
            "Epoch: [85]  [240/295]  eta: 0:00:15  lr: 0.000303  min_lr: 0.000303  loss: 3.0313 (3.0249)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0029  max mem: 3500\n",
            "Epoch: [85]  [250/295]  eta: 0:00:12  lr: 0.000302  min_lr: 0.000302  loss: 2.9439 (3.0253)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0022  max mem: 3500\n",
            "Epoch: [85]  [260/295]  eta: 0:00:09  lr: 0.000300  min_lr: 0.000300  loss: 2.9972 (3.0241)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0018  max mem: 3500\n",
            "Epoch: [85]  [270/295]  eta: 0:00:06  lr: 0.000299  min_lr: 0.000299  loss: 3.0177 (3.0214)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0020  max mem: 3500\n",
            "Epoch: [85]  [280/295]  eta: 0:00:04  lr: 0.000297  min_lr: 0.000297  loss: 2.9711 (3.0204)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0009  max mem: 3500\n",
            "Epoch: [85]  [290/295]  eta: 0:00:01  lr: 0.000296  min_lr: 0.000296  loss: 2.9547 (3.0198)  weight_decay: 0.0500 (0.0500)  time: 0.2571  data: 0.0002  max mem: 3500\n",
            "Epoch: [85]  [294/295]  eta: 0:00:00  lr: 0.000296  min_lr: 0.000296  loss: 2.9547 (3.0214)  weight_decay: 0.0500 (0.0500)  time: 0.2194  data: 0.0002  max mem: 3500\n",
            "Epoch: [85] Total time: 0:01:20 (0.2720 s / it)\n",
            "Averaged stats: lr: 0.000296  min_lr: 0.000296  loss: 2.9547 (3.0214)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:20  loss: 0.5416 (0.5416)  acc1: 93.7500 (93.7500)  acc5: 97.9167 (97.9167)  time: 3.1781  data: 3.0016  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 0.5333 (0.5472)  acc1: 93.7500 (92.0455)  acc5: 97.9167 (97.9167)  time: 0.4400  data: 0.2911  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.5371 (0.5825)  acc1: 89.5833 (90.3770)  acc5: 100.0000 (98.4127)  time: 0.1747  data: 0.0243  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.6746 (0.7229)  acc1: 85.4167 (85.1479)  acc5: 97.9167 (98.5215)  time: 0.1533  data: 0.0156  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7135 (0.7033)  acc1: 83.3333 (85.9248)  acc5: 97.9167 (98.5772)  time: 0.1234  data: 0.0042  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.6966 (0.7094)  acc1: 85.4167 (85.6618)  acc5: 100.0000 (98.6520)  time: 0.1239  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7522 (0.7170)  acc1: 83.3333 (85.3825)  acc5: 100.0000 (98.6339)  time: 0.1258  data: 0.0045  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8026 (0.7389)  acc1: 83.3333 (84.7418)  acc5: 97.9167 (98.4448)  time: 0.1226  data: 0.0028  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7004 (0.7301)  acc1: 85.4167 (85.1852)  acc5: 97.9167 (98.4568)  time: 0.1179  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7004 (0.7326)  acc1: 85.4167 (85.1465)  acc5: 97.9167 (98.4204)  time: 0.1166  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1773 s / it)\n",
            "* Acc@1 85.146 Acc@5 98.420 loss 0.733\n",
            "Accuracy of the model on the 3925 test images: 85.1%\n",
            "Max accuracy: 85.15%\n",
            "Test:  [ 0/82]  eta: 0:04:10  loss: 1.7653 (1.7653)  acc1: 35.4167 (35.4167)  acc5: 95.8333 (95.8333)  time: 3.0518  data: 2.8509  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:34  loss: 1.8997 (2.1409)  acc1: 31.2500 (26.8939)  acc5: 97.9167 (98.2955)  time: 0.4741  data: 0.3288  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 2.7404 (2.5201)  acc1: 12.5000 (19.1468)  acc5: 97.9167 (97.3214)  time: 0.1853  data: 0.0425  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 3.1349 (3.0997)  acc1: 6.2500 (13.9785)  acc5: 91.6667 (82.4597)  time: 0.1621  data: 0.0192  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 3.0058 (3.1048)  acc1: 8.3333 (16.1585)  acc5: 79.1667 (82.0122)  time: 0.1585  data: 0.0157  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.8403 (3.3861)  acc1: 8.3333 (13.8889)  acc5: 68.7500 (75.1634)  time: 0.1346  data: 0.0025  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.4672 (3.4821)  acc1: 2.0833 (12.0560)  acc5: 39.5833 (73.0533)  time: 0.1246  data: 0.0040  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.6425 (3.3471)  acc1: 2.0833 (16.1972)  acc5: 75.0000 (72.7406)  time: 0.1240  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9798 (3.0395)  acc1: 70.8333 (23.9455)  acc5: 97.9167 (75.9002)  time: 0.1202  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9798 (3.0153)  acc1: 72.9167 (24.4076)  acc5: 97.9167 (76.0510)  time: 0.1185  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1867 s / it)\n",
            "* Acc@1 24.408 Acc@5 76.051 loss 3.015\n",
            "Accuracy of the model EMA on 3925 test images: 24.4%\n",
            "Max EMA accuracy: 24.41%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [86]  [  0/295]  eta: 0:09:45  lr: 0.000296  min_lr: 0.000296  loss: 3.0837 (3.0837)  weight_decay: 0.0500 (0.0500)  time: 1.9838  data: 1.6082  max mem: 3500\n",
            "Epoch: [86]  [ 10/295]  eta: 0:02:08  lr: 0.000295  min_lr: 0.000295  loss: 3.0308 (3.0427)  weight_decay: 0.0500 (0.0500)  time: 0.4504  data: 0.1488  max mem: 3500\n",
            "Epoch: [86]  [ 20/295]  eta: 0:01:41  lr: 0.000293  min_lr: 0.000293  loss: 3.0239 (3.0242)  weight_decay: 0.0500 (0.0500)  time: 0.2893  data: 0.0025  max mem: 3500\n",
            "Epoch: [86]  [ 30/295]  eta: 0:01:29  lr: 0.000292  min_lr: 0.000292  loss: 3.1533 (3.0636)  weight_decay: 0.0500 (0.0500)  time: 0.2785  data: 0.0021  max mem: 3500\n",
            "Epoch: [86]  [ 40/295]  eta: 0:01:23  lr: 0.000290  min_lr: 0.000290  loss: 3.1775 (3.0520)  weight_decay: 0.0500 (0.0500)  time: 0.2814  data: 0.0019  max mem: 3500\n",
            "Epoch: [86]  [ 50/295]  eta: 0:01:17  lr: 0.000289  min_lr: 0.000289  loss: 3.0391 (3.0283)  weight_decay: 0.0500 (0.0500)  time: 0.2807  data: 0.0026  max mem: 3500\n",
            "Epoch: [86]  [ 60/295]  eta: 0:01:12  lr: 0.000287  min_lr: 0.000287  loss: 3.0391 (3.0335)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0019  max mem: 3500\n",
            "Epoch: [86]  [ 70/295]  eta: 0:01:07  lr: 0.000286  min_lr: 0.000286  loss: 3.1493 (3.0492)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0006  max mem: 3500\n",
            "Epoch: [86]  [ 80/295]  eta: 0:01:03  lr: 0.000285  min_lr: 0.000285  loss: 3.0972 (3.0484)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0016  max mem: 3500\n",
            "Epoch: [86]  [ 90/295]  eta: 0:01:00  lr: 0.000283  min_lr: 0.000283  loss: 3.0640 (3.0483)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0014  max mem: 3500\n",
            "Epoch: [86]  [100/295]  eta: 0:00:56  lr: 0.000282  min_lr: 0.000282  loss: 3.1095 (3.0512)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0016  max mem: 3500\n",
            "Epoch: [86]  [110/295]  eta: 0:00:53  lr: 0.000281  min_lr: 0.000281  loss: 3.0976 (3.0407)  weight_decay: 0.0500 (0.0500)  time: 0.2770  data: 0.0018  max mem: 3500\n",
            "Epoch: [86]  [120/295]  eta: 0:00:50  lr: 0.000279  min_lr: 0.000279  loss: 3.0976 (3.0548)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0016  max mem: 3500\n",
            "Epoch: [86]  [130/295]  eta: 0:00:47  lr: 0.000278  min_lr: 0.000278  loss: 3.1778 (3.0586)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0021  max mem: 3500\n",
            "Epoch: [86]  [140/295]  eta: 0:00:44  lr: 0.000276  min_lr: 0.000276  loss: 3.2006 (3.0683)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0019  max mem: 3500\n",
            "Epoch: [86]  [150/295]  eta: 0:00:40  lr: 0.000275  min_lr: 0.000275  loss: 3.2292 (3.0696)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0019  max mem: 3500\n",
            "Epoch: [86]  [160/295]  eta: 0:00:38  lr: 0.000274  min_lr: 0.000274  loss: 3.0694 (3.0689)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0019  max mem: 3500\n",
            "Epoch: [86]  [170/295]  eta: 0:00:35  lr: 0.000272  min_lr: 0.000272  loss: 3.0159 (3.0579)  weight_decay: 0.0500 (0.0500)  time: 0.2706  data: 0.0033  max mem: 3500\n",
            "Epoch: [86]  [180/295]  eta: 0:00:32  lr: 0.000271  min_lr: 0.000271  loss: 2.8774 (3.0543)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0040  max mem: 3500\n",
            "Epoch: [86]  [190/295]  eta: 0:00:29  lr: 0.000270  min_lr: 0.000270  loss: 3.0275 (3.0564)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0021  max mem: 3500\n",
            "Epoch: [86]  [200/295]  eta: 0:00:26  lr: 0.000268  min_lr: 0.000268  loss: 3.1115 (3.0609)  weight_decay: 0.0500 (0.0500)  time: 0.2588  data: 0.0011  max mem: 3500\n",
            "Epoch: [86]  [210/295]  eta: 0:00:23  lr: 0.000267  min_lr: 0.000267  loss: 3.0467 (3.0570)  weight_decay: 0.0500 (0.0500)  time: 0.2600  data: 0.0014  max mem: 3500\n",
            "Epoch: [86]  [220/295]  eta: 0:00:20  lr: 0.000265  min_lr: 0.000265  loss: 2.9050 (3.0509)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0021  max mem: 3500\n",
            "Epoch: [86]  [230/295]  eta: 0:00:17  lr: 0.000264  min_lr: 0.000264  loss: 3.0645 (3.0567)  weight_decay: 0.0500 (0.0500)  time: 0.2667  data: 0.0036  max mem: 3500\n",
            "Epoch: [86]  [240/295]  eta: 0:00:15  lr: 0.000263  min_lr: 0.000263  loss: 3.1261 (3.0546)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0040  max mem: 3500\n",
            "Epoch: [86]  [250/295]  eta: 0:00:12  lr: 0.000262  min_lr: 0.000262  loss: 3.0683 (3.0578)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0042  max mem: 3500\n",
            "Epoch: [86]  [260/295]  eta: 0:00:09  lr: 0.000260  min_lr: 0.000260  loss: 3.0909 (3.0545)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0030  max mem: 3500\n",
            "Epoch: [86]  [270/295]  eta: 0:00:06  lr: 0.000259  min_lr: 0.000259  loss: 3.1758 (3.0592)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0014  max mem: 3500\n",
            "Epoch: [86]  [280/295]  eta: 0:00:04  lr: 0.000258  min_lr: 0.000258  loss: 3.1924 (3.0633)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0012  max mem: 3500\n",
            "Epoch: [86]  [290/295]  eta: 0:00:01  lr: 0.000256  min_lr: 0.000256  loss: 3.1628 (3.0641)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0004  max mem: 3500\n",
            "Epoch: [86]  [294/295]  eta: 0:00:00  lr: 0.000256  min_lr: 0.000256  loss: 3.1734 (3.0645)  weight_decay: 0.0500 (0.0500)  time: 0.2209  data: 0.0002  max mem: 3500\n",
            "Epoch: [86] Total time: 0:01:20 (0.2732 s / it)\n",
            "Averaged stats: lr: 0.000256  min_lr: 0.000256  loss: 3.1734 (3.0645)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:52  loss: 0.6061 (0.6061)  acc1: 93.7500 (93.7500)  acc5: 95.8333 (95.8333)  time: 2.8400  data: 2.6728  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.6061 (0.5992)  acc1: 93.7500 (92.2349)  acc5: 100.0000 (98.1061)  time: 0.3741  data: 0.2451  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.6068 (0.6228)  acc1: 91.6667 (90.6746)  acc5: 100.0000 (98.4127)  time: 0.1271  data: 0.0023  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.7310 (0.7832)  acc1: 85.4167 (84.5430)  acc5: 97.9167 (98.3871)  time: 0.1253  data: 0.0033  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7310 (0.7594)  acc1: 85.4167 (85.6707)  acc5: 97.9167 (98.4248)  time: 0.1235  data: 0.0045  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7237 (0.7621)  acc1: 87.5000 (85.4984)  acc5: 100.0000 (98.4477)  time: 0.1242  data: 0.0048  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8232 (0.7794)  acc1: 83.3333 (84.9727)  acc5: 100.0000 (98.4290)  time: 0.1242  data: 0.0045  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8232 (0.7946)  acc1: 81.2500 (84.4190)  acc5: 97.9167 (98.2394)  time: 0.1202  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7298 (0.7774)  acc1: 87.5000 (85.2366)  acc5: 97.9167 (98.2768)  time: 0.1177  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7298 (0.7796)  acc1: 87.5000 (85.1975)  acc5: 97.9167 (98.2420)  time: 0.1165  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1634 s / it)\n",
            "* Acc@1 85.197 Acc@5 98.242 loss 0.780\n",
            "Accuracy of the model on the 3925 test images: 85.2%\n",
            "Max accuracy: 85.20%\n",
            "Test:  [ 0/82]  eta: 0:04:31  loss: 1.7227 (1.7227)  acc1: 37.5000 (37.5000)  acc5: 95.8333 (95.8333)  time: 3.3083  data: 3.1350  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 1.8595 (2.1036)  acc1: 31.2500 (27.8409)  acc5: 97.9167 (98.4849)  time: 0.4366  data: 0.2880  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 2.7111 (2.4905)  acc1: 14.5833 (19.9405)  acc5: 97.9167 (97.3214)  time: 0.1415  data: 0.0036  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.1008 (3.0710)  acc1: 6.2500 (14.5161)  acc5: 91.6667 (82.5269)  time: 0.1289  data: 0.0038  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.9963 (3.0721)  acc1: 8.3333 (16.8191)  acc5: 79.1667 (82.3171)  time: 0.1232  data: 0.0041  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.8037 (3.3536)  acc1: 8.3333 (14.4199)  acc5: 68.7500 (75.3268)  time: 0.1251  data: 0.0046  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.4243 (3.4481)  acc1: 2.0833 (12.5342)  acc5: 39.5833 (73.2582)  time: 0.1254  data: 0.0047  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.6027 (3.3144)  acc1: 2.0833 (16.6373)  acc5: 75.0000 (73.0047)  time: 0.1214  data: 0.0025  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9674 (3.0099)  acc1: 70.8333 (24.3313)  acc5: 97.9167 (76.1317)  time: 0.1196  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9674 (2.9861)  acc1: 72.9167 (24.7898)  acc5: 97.9167 (76.2803)  time: 0.1173  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1708 s / it)\n",
            "* Acc@1 24.790 Acc@5 76.280 loss 2.986\n",
            "Accuracy of the model EMA on 3925 test images: 24.8%\n",
            "Max EMA accuracy: 24.79%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [87]  [  0/295]  eta: 0:14:46  lr: 0.000256  min_lr: 0.000256  loss: 3.1678 (3.1678)  weight_decay: 0.0500 (0.0500)  time: 3.0046  data: 2.3696  max mem: 3500\n",
            "Epoch: [87]  [ 10/295]  eta: 0:02:40  lr: 0.000255  min_lr: 0.000255  loss: 3.1250 (3.0156)  weight_decay: 0.0500 (0.0500)  time: 0.5633  data: 0.2187  max mem: 3500\n",
            "Epoch: [87]  [ 20/295]  eta: 0:01:56  lr: 0.000253  min_lr: 0.000253  loss: 2.8617 (2.9512)  weight_decay: 0.0500 (0.0500)  time: 0.2934  data: 0.0025  max mem: 3500\n",
            "Epoch: [87]  [ 30/295]  eta: 0:01:38  lr: 0.000252  min_lr: 0.000252  loss: 2.8785 (2.9900)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0013  max mem: 3500\n",
            "Epoch: [87]  [ 40/295]  eta: 0:01:27  lr: 0.000251  min_lr: 0.000251  loss: 3.1645 (3.0210)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0013  max mem: 3500\n",
            "Epoch: [87]  [ 50/295]  eta: 0:01:20  lr: 0.000250  min_lr: 0.000250  loss: 3.1744 (3.0326)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0014  max mem: 3500\n",
            "Epoch: [87]  [ 60/295]  eta: 0:01:15  lr: 0.000248  min_lr: 0.000248  loss: 3.1706 (3.0453)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0027  max mem: 3500\n",
            "Epoch: [87]  [ 70/295]  eta: 0:01:10  lr: 0.000247  min_lr: 0.000247  loss: 3.0829 (3.0592)  weight_decay: 0.0500 (0.0500)  time: 0.2729  data: 0.0022  max mem: 3500\n",
            "Epoch: [87]  [ 80/295]  eta: 0:01:06  lr: 0.000246  min_lr: 0.000246  loss: 3.0555 (3.0440)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0012  max mem: 3500\n",
            "Epoch: [87]  [ 90/295]  eta: 0:01:02  lr: 0.000245  min_lr: 0.000245  loss: 3.0256 (3.0449)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0018  max mem: 3500\n",
            "Epoch: [87]  [100/295]  eta: 0:00:58  lr: 0.000243  min_lr: 0.000243  loss: 3.0392 (3.0410)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0022  max mem: 3500\n",
            "Epoch: [87]  [110/295]  eta: 0:00:54  lr: 0.000242  min_lr: 0.000242  loss: 3.0392 (3.0390)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0020  max mem: 3500\n",
            "Epoch: [87]  [120/295]  eta: 0:00:51  lr: 0.000240  min_lr: 0.000240  loss: 3.0293 (3.0357)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0020  max mem: 3500\n",
            "Epoch: [87]  [130/295]  eta: 0:00:48  lr: 0.000239  min_lr: 0.000239  loss: 2.9514 (3.0296)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0023  max mem: 3500\n",
            "Epoch: [87]  [140/295]  eta: 0:00:45  lr: 0.000238  min_lr: 0.000238  loss: 3.0528 (3.0366)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0021  max mem: 3500\n",
            "Epoch: [87]  [150/295]  eta: 0:00:41  lr: 0.000237  min_lr: 0.000237  loss: 3.0206 (3.0287)  weight_decay: 0.0500 (0.0500)  time: 0.2661  data: 0.0015  max mem: 3500\n",
            "Epoch: [87]  [160/295]  eta: 0:00:38  lr: 0.000235  min_lr: 0.000235  loss: 2.8817 (3.0264)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0015  max mem: 3500\n",
            "Epoch: [87]  [170/295]  eta: 0:00:35  lr: 0.000234  min_lr: 0.000234  loss: 2.9098 (3.0215)  weight_decay: 0.0500 (0.0500)  time: 0.2621  data: 0.0019  max mem: 3500\n",
            "Epoch: [87]  [180/295]  eta: 0:00:32  lr: 0.000233  min_lr: 0.000233  loss: 3.0741 (3.0303)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0015  max mem: 3500\n",
            "Epoch: [87]  [190/295]  eta: 0:00:29  lr: 0.000232  min_lr: 0.000232  loss: 3.1706 (3.0325)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0019  max mem: 3500\n",
            "Epoch: [87]  [200/295]  eta: 0:00:26  lr: 0.000230  min_lr: 0.000230  loss: 3.1551 (3.0431)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0023  max mem: 3500\n",
            "Epoch: [87]  [210/295]  eta: 0:00:23  lr: 0.000229  min_lr: 0.000229  loss: 3.1551 (3.0468)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0042  max mem: 3500\n",
            "Epoch: [87]  [220/295]  eta: 0:00:21  lr: 0.000228  min_lr: 0.000228  loss: 3.1078 (3.0472)  weight_decay: 0.0500 (0.0500)  time: 0.2758  data: 0.0045  max mem: 3500\n",
            "Epoch: [87]  [230/295]  eta: 0:00:18  lr: 0.000227  min_lr: 0.000227  loss: 3.0857 (3.0482)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0030  max mem: 3500\n",
            "Epoch: [87]  [240/295]  eta: 0:00:15  lr: 0.000225  min_lr: 0.000225  loss: 3.1415 (3.0503)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0024  max mem: 3500\n",
            "Epoch: [87]  [250/295]  eta: 0:00:12  lr: 0.000224  min_lr: 0.000224  loss: 3.1545 (3.0544)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0021  max mem: 3500\n",
            "Epoch: [87]  [260/295]  eta: 0:00:09  lr: 0.000223  min_lr: 0.000223  loss: 3.1353 (3.0537)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0017  max mem: 3500\n",
            "Epoch: [87]  [270/295]  eta: 0:00:06  lr: 0.000222  min_lr: 0.000222  loss: 2.9630 (3.0523)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0014  max mem: 3500\n",
            "Epoch: [87]  [280/295]  eta: 0:00:04  lr: 0.000220  min_lr: 0.000220  loss: 3.0172 (3.0503)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0015  max mem: 3500\n",
            "Epoch: [87]  [290/295]  eta: 0:00:01  lr: 0.000219  min_lr: 0.000219  loss: 3.1253 (3.0502)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0008  max mem: 3500\n",
            "Epoch: [87]  [294/295]  eta: 0:00:00  lr: 0.000219  min_lr: 0.000219  loss: 3.1059 (3.0483)  weight_decay: 0.0500 (0.0500)  time: 0.2202  data: 0.0002  max mem: 3500\n",
            "Epoch: [87] Total time: 0:01:21 (0.2763 s / it)\n",
            "Averaged stats: lr: 0.000219  min_lr: 0.000219  loss: 3.1059 (3.0483)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:51  loss: 0.5823 (0.5823)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 2.0932  data: 1.9249  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5735 (0.5749)  acc1: 91.6667 (91.4773)  acc5: 97.9167 (98.1061)  time: 0.3002  data: 0.1763  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5786 (0.6077)  acc1: 89.5833 (90.4762)  acc5: 100.0000 (98.5119)  time: 0.1205  data: 0.0025  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.7256 (0.7527)  acc1: 85.4167 (85.2151)  acc5: 97.9167 (98.4543)  time: 0.1381  data: 0.0030  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7483 (0.7359)  acc1: 83.3333 (86.0772)  acc5: 97.9167 (98.4756)  time: 0.1608  data: 0.0074  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7277 (0.7426)  acc1: 85.4167 (85.8252)  acc5: 100.0000 (98.6520)  time: 0.1677  data: 0.0226  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8067 (0.7466)  acc1: 85.4167 (85.6557)  acc5: 100.0000 (98.7363)  time: 0.1739  data: 0.0271  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8513 (0.7656)  acc1: 85.4167 (85.0059)  acc5: 97.9167 (98.5329)  time: 0.1560  data: 0.0123  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7559 (0.7503)  acc1: 87.5000 (85.5710)  acc5: 97.9167 (98.5340)  time: 0.1260  data: 0.0016  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7559 (0.7522)  acc1: 87.5000 (85.5541)  acc5: 97.9167 (98.4968)  time: 0.1220  data: 0.0016  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1745 s / it)\n",
            "* Acc@1 85.554 Acc@5 98.497 loss 0.752\n",
            "Accuracy of the model on the 3925 test images: 85.6%\n",
            "Max accuracy: 85.55%\n",
            "Test:  [ 0/82]  eta: 0:02:27  loss: 1.6822 (1.6822)  acc1: 39.5833 (39.5833)  acc5: 97.9167 (97.9167)  time: 1.7991  data: 1.6284  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 1.8208 (2.0676)  acc1: 31.2500 (29.1667)  acc5: 97.9167 (98.6742)  time: 0.3066  data: 0.1785  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.6817 (2.4614)  acc1: 14.5833 (20.7341)  acc5: 97.9167 (97.4206)  time: 0.1412  data: 0.0184  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 3.0667 (3.0422)  acc1: 6.2500 (15.0538)  acc5: 89.5833 (82.7957)  time: 0.1241  data: 0.0030  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.9860 (3.0395)  acc1: 8.3333 (17.2256)  acc5: 79.1667 (82.6728)  time: 0.1251  data: 0.0045  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.7702 (3.3212)  acc1: 8.3333 (14.6650)  acc5: 68.7500 (75.6944)  time: 0.1252  data: 0.0053  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.3818 (3.4145)  acc1: 2.0833 (12.7391)  acc5: 39.5833 (73.5997)  time: 0.1346  data: 0.0040  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.5658 (3.2822)  acc1: 2.0833 (16.8134)  acc5: 75.0000 (73.3275)  time: 0.1396  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9555 (2.9808)  acc1: 70.8333 (24.4856)  acc5: 97.9167 (76.4146)  time: 0.1261  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9555 (2.9572)  acc1: 72.9167 (24.9427)  acc5: 97.9167 (76.5605)  time: 0.1231  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1580 s / it)\n",
            "* Acc@1 24.943 Acc@5 76.561 loss 2.957\n",
            "Accuracy of the model EMA on 3925 test images: 24.9%\n",
            "Max EMA accuracy: 24.94%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [88]  [  0/295]  eta: 0:10:39  lr: 0.000219  min_lr: 0.000219  loss: 2.9865 (2.9865)  weight_decay: 0.0500 (0.0500)  time: 2.1668  data: 1.7434  max mem: 3500\n",
            "Epoch: [88]  [ 10/295]  eta: 0:02:06  lr: 0.000218  min_lr: 0.000218  loss: 3.0116 (3.0059)  weight_decay: 0.0500 (0.0500)  time: 0.4441  data: 0.1592  max mem: 3500\n",
            "Epoch: [88]  [ 20/295]  eta: 0:01:38  lr: 0.000216  min_lr: 0.000216  loss: 2.9369 (2.9526)  weight_decay: 0.0500 (0.0500)  time: 0.2670  data: 0.0011  max mem: 3500\n",
            "Epoch: [88]  [ 30/295]  eta: 0:01:26  lr: 0.000216  min_lr: 0.000216  loss: 2.9946 (2.9728)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0010  max mem: 3500\n",
            "Epoch: [88]  [ 40/295]  eta: 0:01:20  lr: 0.000214  min_lr: 0.000214  loss: 3.0739 (3.0125)  weight_decay: 0.0500 (0.0500)  time: 0.2681  data: 0.0012  max mem: 3500\n",
            "Epoch: [88]  [ 50/295]  eta: 0:01:14  lr: 0.000213  min_lr: 0.000213  loss: 3.0739 (3.0085)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0018  max mem: 3500\n",
            "Epoch: [88]  [ 60/295]  eta: 0:01:10  lr: 0.000212  min_lr: 0.000212  loss: 3.0543 (3.0339)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0016  max mem: 3500\n",
            "Epoch: [88]  [ 70/295]  eta: 0:01:06  lr: 0.000211  min_lr: 0.000211  loss: 3.2198 (3.0560)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0017  max mem: 3500\n",
            "Epoch: [88]  [ 80/295]  eta: 0:01:02  lr: 0.000209  min_lr: 0.000209  loss: 3.1592 (3.0351)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0017  max mem: 3500\n",
            "Epoch: [88]  [ 90/295]  eta: 0:00:58  lr: 0.000208  min_lr: 0.000208  loss: 2.9492 (3.0399)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0017  max mem: 3500\n",
            "Epoch: [88]  [100/295]  eta: 0:00:55  lr: 0.000207  min_lr: 0.000207  loss: 3.0217 (3.0393)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0030  max mem: 3500\n",
            "Epoch: [88]  [110/295]  eta: 0:00:52  lr: 0.000206  min_lr: 0.000206  loss: 3.0132 (3.0319)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0035  max mem: 3500\n",
            "Epoch: [88]  [120/295]  eta: 0:00:49  lr: 0.000205  min_lr: 0.000205  loss: 2.9918 (3.0368)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0019  max mem: 3500\n",
            "Epoch: [88]  [130/295]  eta: 0:00:46  lr: 0.000204  min_lr: 0.000204  loss: 3.1513 (3.0432)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0010  max mem: 3500\n",
            "Epoch: [88]  [140/295]  eta: 0:00:43  lr: 0.000202  min_lr: 0.000202  loss: 3.1513 (3.0458)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0019  max mem: 3500\n",
            "Epoch: [88]  [150/295]  eta: 0:00:40  lr: 0.000201  min_lr: 0.000201  loss: 3.0638 (3.0428)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0023  max mem: 3500\n",
            "Epoch: [88]  [160/295]  eta: 0:00:37  lr: 0.000200  min_lr: 0.000200  loss: 2.7660 (3.0258)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0021  max mem: 3500\n",
            "Epoch: [88]  [170/295]  eta: 0:00:34  lr: 0.000199  min_lr: 0.000199  loss: 2.7660 (3.0253)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0035  max mem: 3500\n",
            "Epoch: [88]  [180/295]  eta: 0:00:31  lr: 0.000197  min_lr: 0.000197  loss: 3.1682 (3.0358)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0048  max mem: 3500\n",
            "Epoch: [88]  [190/295]  eta: 0:00:29  lr: 0.000197  min_lr: 0.000197  loss: 3.1749 (3.0339)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0037  max mem: 3500\n",
            "Epoch: [88]  [200/295]  eta: 0:00:26  lr: 0.000195  min_lr: 0.000195  loss: 3.1250 (3.0376)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0022  max mem: 3500\n",
            "Epoch: [88]  [210/295]  eta: 0:00:23  lr: 0.000194  min_lr: 0.000194  loss: 3.1364 (3.0362)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0014  max mem: 3500\n",
            "Epoch: [88]  [220/295]  eta: 0:00:20  lr: 0.000193  min_lr: 0.000193  loss: 2.9697 (3.0389)  weight_decay: 0.0500 (0.0500)  time: 0.2592  data: 0.0014  max mem: 3500\n",
            "Epoch: [88]  [230/295]  eta: 0:00:17  lr: 0.000192  min_lr: 0.000192  loss: 2.9697 (3.0365)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0019  max mem: 3500\n",
            "Epoch: [88]  [240/295]  eta: 0:00:15  lr: 0.000191  min_lr: 0.000191  loss: 2.8930 (3.0286)  weight_decay: 0.0500 (0.0500)  time: 0.2675  data: 0.0011  max mem: 3500\n",
            "Epoch: [88]  [250/295]  eta: 0:00:12  lr: 0.000190  min_lr: 0.000190  loss: 2.9347 (3.0300)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0015  max mem: 3500\n",
            "Epoch: [88]  [260/295]  eta: 0:00:09  lr: 0.000188  min_lr: 0.000188  loss: 3.1227 (3.0302)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0023  max mem: 3500\n",
            "Epoch: [88]  [270/295]  eta: 0:00:06  lr: 0.000187  min_lr: 0.000187  loss: 2.9678 (3.0273)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0018  max mem: 3500\n",
            "Epoch: [88]  [280/295]  eta: 0:00:04  lr: 0.000186  min_lr: 0.000186  loss: 3.0758 (3.0320)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0014  max mem: 3500\n",
            "Epoch: [88]  [290/295]  eta: 0:00:01  lr: 0.000185  min_lr: 0.000185  loss: 3.1300 (3.0310)  weight_decay: 0.0500 (0.0500)  time: 0.2575  data: 0.0006  max mem: 3500\n",
            "Epoch: [88]  [294/295]  eta: 0:00:00  lr: 0.000185  min_lr: 0.000185  loss: 3.1459 (3.0318)  weight_decay: 0.0500 (0.0500)  time: 0.2196  data: 0.0002  max mem: 3500\n",
            "Epoch: [88] Total time: 0:01:20 (0.2713 s / it)\n",
            "Averaged stats: lr: 0.000185  min_lr: 0.000185  loss: 3.1459 (3.0318)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:04:30  loss: 0.6194 (0.6194)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 3.2933  data: 3.1272  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:34  loss: 0.5893 (0.5888)  acc1: 91.6667 (90.7197)  acc5: 100.0000 (98.4849)  time: 0.4737  data: 0.3140  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:19  loss: 0.5826 (0.5892)  acc1: 91.6667 (91.6667)  acc5: 100.0000 (98.8095)  time: 0.1595  data: 0.0183  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6854 (0.7514)  acc1: 87.5000 (85.6855)  acc5: 97.9167 (98.5887)  time: 0.1246  data: 0.0033  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7547 (0.7375)  acc1: 83.3333 (86.0772)  acc5: 100.0000 (98.6281)  time: 0.1242  data: 0.0030  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7486 (0.7367)  acc1: 85.4167 (85.8252)  acc5: 100.0000 (98.7337)  time: 0.1243  data: 0.0025  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7652 (0.7417)  acc1: 83.3333 (85.3825)  acc5: 100.0000 (98.7705)  time: 0.1223  data: 0.0043  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8666 (0.7659)  acc1: 81.2500 (84.5657)  acc5: 97.9167 (98.5035)  time: 0.1211  data: 0.0041  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7680 (0.7492)  acc1: 85.4167 (85.0823)  acc5: 97.9167 (98.5340)  time: 0.1188  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7680 (0.7511)  acc1: 85.4167 (85.0701)  acc5: 97.9167 (98.4713)  time: 0.1164  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1738 s / it)\n",
            "* Acc@1 85.070 Acc@5 98.471 loss 0.751\n",
            "Accuracy of the model on the 3925 test images: 85.1%\n",
            "Max accuracy: 85.55%\n",
            "Test:  [ 0/82]  eta: 0:02:42  loss: 1.6416 (1.6416)  acc1: 39.5833 (39.5833)  acc5: 97.9167 (97.9167)  time: 1.9855  data: 1.8186  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 1.7818 (2.0309)  acc1: 31.2500 (29.9242)  acc5: 97.9167 (98.6742)  time: 0.3648  data: 0.2257  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.6508 (2.4315)  acc1: 14.5833 (21.3294)  acc5: 97.9167 (97.5198)  time: 0.1986  data: 0.0607  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 3.0313 (3.0125)  acc1: 6.2500 (15.4570)  acc5: 89.5833 (82.9301)  time: 0.1814  data: 0.0485  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 2.9755 (3.0071)  acc1: 8.3333 (17.7337)  acc5: 79.1667 (82.8760)  time: 0.1615  data: 0.0264  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.7342 (3.2886)  acc1: 8.3333 (15.0735)  acc5: 68.7500 (75.8578)  time: 0.1513  data: 0.0195  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.3414 (3.3807)  acc1: 2.0833 (13.0806)  acc5: 39.5833 (73.8046)  time: 0.1375  data: 0.0151  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.5266 (3.2500)  acc1: 2.0833 (17.1068)  acc5: 75.0000 (73.5329)  time: 0.1244  data: 0.0011  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9448 (2.9517)  acc1: 70.8333 (24.7685)  acc5: 97.9167 (76.5947)  time: 0.1206  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9448 (2.9284)  acc1: 72.9167 (25.2229)  acc5: 97.9167 (76.7389)  time: 0.1192  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1834 s / it)\n",
            "* Acc@1 25.223 Acc@5 76.739 loss 2.928\n",
            "Accuracy of the model EMA on 3925 test images: 25.2%\n",
            "Max EMA accuracy: 25.22%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [89]  [  0/295]  eta: 0:15:54  lr: 0.000185  min_lr: 0.000185  loss: 3.0968 (3.0968)  weight_decay: 0.0500 (0.0500)  time: 3.2373  data: 2.7212  max mem: 3500\n",
            "Epoch: [89]  [ 10/295]  eta: 0:02:43  lr: 0.000184  min_lr: 0.000184  loss: 3.0413 (2.9662)  weight_decay: 0.0500 (0.0500)  time: 0.5719  data: 0.2512  max mem: 3500\n",
            "Epoch: [89]  [ 20/295]  eta: 0:01:58  lr: 0.000182  min_lr: 0.000182  loss: 3.0782 (3.0651)  weight_decay: 0.0500 (0.0500)  time: 0.2904  data: 0.0038  max mem: 3500\n",
            "Epoch: [89]  [ 30/295]  eta: 0:01:40  lr: 0.000182  min_lr: 0.000182  loss: 3.2055 (3.1053)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0046  max mem: 3500\n",
            "Epoch: [89]  [ 40/295]  eta: 0:01:29  lr: 0.000180  min_lr: 0.000180  loss: 3.1230 (3.0970)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0030  max mem: 3500\n",
            "Epoch: [89]  [ 50/295]  eta: 0:01:21  lr: 0.000179  min_lr: 0.000179  loss: 3.1230 (3.0805)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0003  max mem: 3500\n",
            "Epoch: [89]  [ 60/295]  eta: 0:01:15  lr: 0.000178  min_lr: 0.000178  loss: 2.9988 (3.0714)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0010  max mem: 3500\n",
            "Epoch: [89]  [ 70/295]  eta: 0:01:10  lr: 0.000177  min_lr: 0.000177  loss: 3.0511 (3.0635)  weight_decay: 0.0500 (0.0500)  time: 0.2647  data: 0.0015  max mem: 3500\n",
            "Epoch: [89]  [ 80/295]  eta: 0:01:06  lr: 0.000176  min_lr: 0.000176  loss: 3.0509 (3.0550)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0024  max mem: 3500\n",
            "Epoch: [89]  [ 90/295]  eta: 0:01:02  lr: 0.000175  min_lr: 0.000175  loss: 3.0509 (3.0533)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0032  max mem: 3500\n",
            "Epoch: [89]  [100/295]  eta: 0:00:58  lr: 0.000174  min_lr: 0.000174  loss: 3.0685 (3.0483)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0041  max mem: 3500\n",
            "Epoch: [89]  [110/295]  eta: 0:00:55  lr: 0.000173  min_lr: 0.000173  loss: 3.0094 (3.0451)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0037  max mem: 3500\n",
            "Epoch: [89]  [120/295]  eta: 0:00:51  lr: 0.000171  min_lr: 0.000171  loss: 2.9865 (3.0425)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0015  max mem: 3500\n",
            "Epoch: [89]  [130/295]  eta: 0:00:48  lr: 0.000171  min_lr: 0.000171  loss: 2.9865 (3.0386)  weight_decay: 0.0500 (0.0500)  time: 0.2622  data: 0.0011  max mem: 3500\n",
            "Epoch: [89]  [140/295]  eta: 0:00:45  lr: 0.000169  min_lr: 0.000169  loss: 2.9697 (3.0366)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0019  max mem: 3500\n",
            "Epoch: [89]  [150/295]  eta: 0:00:41  lr: 0.000168  min_lr: 0.000168  loss: 3.1793 (3.0487)  weight_decay: 0.0500 (0.0500)  time: 0.2692  data: 0.0033  max mem: 3500\n",
            "Epoch: [89]  [160/295]  eta: 0:00:38  lr: 0.000167  min_lr: 0.000167  loss: 3.0379 (3.0345)  weight_decay: 0.0500 (0.0500)  time: 0.2730  data: 0.0029  max mem: 3500\n",
            "Epoch: [89]  [170/295]  eta: 0:00:35  lr: 0.000166  min_lr: 0.000166  loss: 2.9595 (3.0325)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0014  max mem: 3500\n",
            "Epoch: [89]  [180/295]  eta: 0:00:32  lr: 0.000165  min_lr: 0.000165  loss: 2.9595 (3.0261)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0013  max mem: 3500\n",
            "Epoch: [89]  [190/295]  eta: 0:00:29  lr: 0.000164  min_lr: 0.000164  loss: 2.9111 (3.0216)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0017  max mem: 3500\n",
            "Epoch: [89]  [200/295]  eta: 0:00:26  lr: 0.000163  min_lr: 0.000163  loss: 2.9541 (3.0229)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0024  max mem: 3500\n",
            "Epoch: [89]  [210/295]  eta: 0:00:23  lr: 0.000162  min_lr: 0.000162  loss: 3.1165 (3.0283)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0032  max mem: 3500\n",
            "Epoch: [89]  [220/295]  eta: 0:00:21  lr: 0.000161  min_lr: 0.000161  loss: 3.0193 (3.0236)  weight_decay: 0.0500 (0.0500)  time: 0.2707  data: 0.0037  max mem: 3500\n",
            "Epoch: [89]  [230/295]  eta: 0:00:18  lr: 0.000160  min_lr: 0.000160  loss: 2.9462 (3.0229)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0042  max mem: 3500\n",
            "Epoch: [89]  [240/295]  eta: 0:00:15  lr: 0.000159  min_lr: 0.000159  loss: 3.0628 (3.0246)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0034  max mem: 3500\n",
            "Epoch: [89]  [250/295]  eta: 0:00:12  lr: 0.000158  min_lr: 0.000158  loss: 3.0630 (3.0272)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0021  max mem: 3500\n",
            "Epoch: [89]  [260/295]  eta: 0:00:09  lr: 0.000157  min_lr: 0.000157  loss: 3.1095 (3.0301)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0021  max mem: 3500\n",
            "Epoch: [89]  [270/295]  eta: 0:00:06  lr: 0.000156  min_lr: 0.000156  loss: 2.9648 (3.0266)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0032  max mem: 3500\n",
            "Epoch: [89]  [280/295]  eta: 0:00:04  lr: 0.000154  min_lr: 0.000154  loss: 2.8441 (3.0220)  weight_decay: 0.0500 (0.0500)  time: 0.2656  data: 0.0029  max mem: 3500\n",
            "Epoch: [89]  [290/295]  eta: 0:00:01  lr: 0.000154  min_lr: 0.000154  loss: 3.0785 (3.0240)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0009  max mem: 3500\n",
            "Epoch: [89]  [294/295]  eta: 0:00:00  lr: 0.000154  min_lr: 0.000154  loss: 3.0604 (3.0241)  weight_decay: 0.0500 (0.0500)  time: 0.2221  data: 0.0002  max mem: 3500\n",
            "Epoch: [89] Total time: 0:01:21 (0.2756 s / it)\n",
            "Averaged stats: lr: 0.000154  min_lr: 0.000154  loss: 3.0604 (3.0241)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:37  loss: 0.6012 (0.6012)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 1.9259  data: 1.7641  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5774 (0.5727)  acc1: 91.6667 (92.2349)  acc5: 97.9167 (98.6742)  time: 0.2928  data: 0.1621  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5774 (0.5857)  acc1: 91.6667 (91.6667)  acc5: 100.0000 (98.8095)  time: 0.1262  data: 0.0037  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6803 (0.7327)  acc1: 87.5000 (85.9543)  acc5: 97.9167 (98.6559)  time: 0.1241  data: 0.0054  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7086 (0.7098)  acc1: 87.5000 (87.0935)  acc5: 100.0000 (98.7805)  time: 0.1265  data: 0.0054  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.6842 (0.7254)  acc1: 87.5000 (86.5196)  acc5: 100.0000 (98.8154)  time: 0.1288  data: 0.0074  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8212 (0.7371)  acc1: 81.2500 (85.7582)  acc5: 100.0000 (98.8730)  time: 0.1348  data: 0.0071  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8646 (0.7622)  acc1: 81.2500 (84.8592)  acc5: 97.9167 (98.5916)  time: 0.1371  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7616 (0.7457)  acc1: 85.4167 (85.3652)  acc5: 97.9167 (98.5854)  time: 0.1263  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7616 (0.7476)  acc1: 85.4167 (85.3503)  acc5: 97.9167 (98.5478)  time: 0.1216  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1568 s / it)\n",
            "* Acc@1 85.350 Acc@5 98.548 loss 0.748\n",
            "Accuracy of the model on the 3925 test images: 85.4%\n",
            "Max accuracy: 85.55%\n",
            "Test:  [ 0/82]  eta: 0:04:15  loss: 1.6019 (1.6019)  acc1: 41.6667 (41.6667)  acc5: 97.9167 (97.9167)  time: 3.1185  data: 2.9365  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 1.7432 (1.9946)  acc1: 33.3333 (31.4394)  acc5: 97.9167 (98.6742)  time: 0.3953  data: 0.2704  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 2.6194 (2.4017)  acc1: 16.6667 (22.1230)  acc5: 97.9167 (97.5198)  time: 0.1231  data: 0.0039  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.9955 (2.9830)  acc1: 6.2500 (16.0618)  acc5: 89.5833 (83.0645)  time: 0.1231  data: 0.0035  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.9651 (2.9748)  acc1: 8.3333 (18.2927)  acc5: 79.1667 (83.1301)  time: 0.1229  data: 0.0040  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.6975 (3.2560)  acc1: 8.3333 (15.5229)  acc5: 68.7500 (76.0621)  time: 0.1237  data: 0.0050  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.3011 (3.3468)  acc1: 2.0833 (13.4563)  acc5: 39.5833 (73.9754)  time: 0.1240  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.4871 (3.2178)  acc1: 2.0833 (17.4296)  acc5: 75.0000 (73.6796)  time: 0.1205  data: 0.0025  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9343 (2.9226)  acc1: 70.8333 (25.0514)  acc5: 97.9167 (76.7490)  time: 0.1180  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9343 (2.8996)  acc1: 72.9167 (25.5032)  acc5: 97.9167 (76.8917)  time: 0.1168  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1647 s / it)\n",
            "* Acc@1 25.503 Acc@5 76.892 loss 2.900\n",
            "Accuracy of the model EMA on 3925 test images: 25.5%\n",
            "Max EMA accuracy: 25.50%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [90]  [  0/295]  eta: 0:15:35  lr: 0.000153  min_lr: 0.000153  loss: 2.8757 (2.8757)  weight_decay: 0.0500 (0.0500)  time: 3.1728  data: 2.6520  max mem: 3500\n",
            "Epoch: [90]  [ 10/295]  eta: 0:02:37  lr: 0.000152  min_lr: 0.000152  loss: 3.1253 (3.1221)  weight_decay: 0.0500 (0.0500)  time: 0.5538  data: 0.2432  max mem: 3500\n",
            "Epoch: [90]  [ 20/295]  eta: 0:01:53  lr: 0.000151  min_lr: 0.000151  loss: 3.1275 (3.1287)  weight_decay: 0.0500 (0.0500)  time: 0.2760  data: 0.0017  max mem: 3500\n",
            "Epoch: [90]  [ 30/295]  eta: 0:01:36  lr: 0.000150  min_lr: 0.000150  loss: 3.0475 (3.0789)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0009  max mem: 3500\n",
            "Epoch: [90]  [ 40/295]  eta: 0:01:26  lr: 0.000149  min_lr: 0.000149  loss: 3.0159 (3.0669)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0011  max mem: 3500\n",
            "Epoch: [90]  [ 50/295]  eta: 0:01:19  lr: 0.000148  min_lr: 0.000148  loss: 3.0181 (3.0754)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0011  max mem: 3500\n",
            "Epoch: [90]  [ 60/295]  eta: 0:01:14  lr: 0.000147  min_lr: 0.000147  loss: 3.0839 (3.0624)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0005  max mem: 3500\n",
            "Epoch: [90]  [ 70/295]  eta: 0:01:09  lr: 0.000146  min_lr: 0.000146  loss: 3.1568 (3.0838)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0012  max mem: 3500\n",
            "Epoch: [90]  [ 80/295]  eta: 0:01:05  lr: 0.000145  min_lr: 0.000145  loss: 3.2135 (3.0920)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0023  max mem: 3500\n",
            "Epoch: [90]  [ 90/295]  eta: 0:01:01  lr: 0.000144  min_lr: 0.000144  loss: 3.1829 (3.0983)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0019  max mem: 3500\n",
            "Epoch: [90]  [100/295]  eta: 0:00:57  lr: 0.000143  min_lr: 0.000143  loss: 3.0536 (3.0894)  weight_decay: 0.0500 (0.0500)  time: 0.2641  data: 0.0015  max mem: 3500\n",
            "Epoch: [90]  [110/295]  eta: 0:00:54  lr: 0.000142  min_lr: 0.000142  loss: 3.0708 (3.1028)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0020  max mem: 3500\n",
            "Epoch: [90]  [120/295]  eta: 0:00:51  lr: 0.000141  min_lr: 0.000141  loss: 3.1769 (3.1004)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0030  max mem: 3500\n",
            "Epoch: [90]  [130/295]  eta: 0:00:47  lr: 0.000140  min_lr: 0.000140  loss: 3.0872 (3.0950)  weight_decay: 0.0500 (0.0500)  time: 0.2731  data: 0.0038  max mem: 3500\n",
            "Epoch: [90]  [140/295]  eta: 0:00:44  lr: 0.000139  min_lr: 0.000139  loss: 3.0872 (3.0947)  weight_decay: 0.0500 (0.0500)  time: 0.2693  data: 0.0032  max mem: 3500\n",
            "Epoch: [90]  [150/295]  eta: 0:00:41  lr: 0.000138  min_lr: 0.000138  loss: 3.1250 (3.0956)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0021  max mem: 3500\n",
            "Epoch: [90]  [160/295]  eta: 0:00:38  lr: 0.000137  min_lr: 0.000137  loss: 3.1250 (3.0938)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0013  max mem: 3500\n",
            "Epoch: [90]  [170/295]  eta: 0:00:35  lr: 0.000136  min_lr: 0.000136  loss: 3.1346 (3.0920)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0007  max mem: 3500\n",
            "Epoch: [90]  [180/295]  eta: 0:00:32  lr: 0.000135  min_lr: 0.000135  loss: 3.0691 (3.0838)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0023  max mem: 3500\n",
            "Epoch: [90]  [190/295]  eta: 0:00:29  lr: 0.000134  min_lr: 0.000134  loss: 3.0691 (3.0841)  weight_decay: 0.0500 (0.0500)  time: 0.2682  data: 0.0028  max mem: 3500\n",
            "Epoch: [90]  [200/295]  eta: 0:00:26  lr: 0.000133  min_lr: 0.000133  loss: 3.1202 (3.0822)  weight_decay: 0.0500 (0.0500)  time: 0.2690  data: 0.0017  max mem: 3500\n",
            "Epoch: [90]  [210/295]  eta: 0:00:23  lr: 0.000133  min_lr: 0.000133  loss: 2.9986 (3.0762)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0024  max mem: 3500\n",
            "Epoch: [90]  [220/295]  eta: 0:00:21  lr: 0.000131  min_lr: 0.000131  loss: 2.9807 (3.0740)  weight_decay: 0.0500 (0.0500)  time: 0.2736  data: 0.0036  max mem: 3500\n",
            "Epoch: [90]  [230/295]  eta: 0:00:18  lr: 0.000131  min_lr: 0.000131  loss: 3.0192 (3.0708)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0040  max mem: 3500\n",
            "Epoch: [90]  [240/295]  eta: 0:00:15  lr: 0.000129  min_lr: 0.000129  loss: 2.8847 (3.0647)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0022  max mem: 3500\n",
            "Epoch: [90]  [250/295]  eta: 0:00:12  lr: 0.000129  min_lr: 0.000129  loss: 3.0206 (3.0647)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0015  max mem: 3500\n",
            "Epoch: [90]  [260/295]  eta: 0:00:09  lr: 0.000128  min_lr: 0.000128  loss: 3.0206 (3.0623)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0022  max mem: 3500\n",
            "Epoch: [90]  [270/295]  eta: 0:00:06  lr: 0.000127  min_lr: 0.000127  loss: 2.9256 (3.0566)  weight_decay: 0.0500 (0.0500)  time: 0.2698  data: 0.0028  max mem: 3500\n",
            "Epoch: [90]  [280/295]  eta: 0:00:04  lr: 0.000126  min_lr: 0.000126  loss: 3.0253 (3.0549)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0022  max mem: 3500\n",
            "Epoch: [90]  [290/295]  eta: 0:00:01  lr: 0.000125  min_lr: 0.000125  loss: 3.0124 (3.0513)  weight_decay: 0.0500 (0.0500)  time: 0.2584  data: 0.0005  max mem: 3500\n",
            "Epoch: [90]  [294/295]  eta: 0:00:00  lr: 0.000125  min_lr: 0.000125  loss: 3.0726 (3.0517)  weight_decay: 0.0500 (0.0500)  time: 0.2188  data: 0.0002  max mem: 3500\n",
            "Epoch: [90] Total time: 0:01:21 (0.2752 s / it)\n",
            "Averaged stats: lr: 0.000125  min_lr: 0.000125  loss: 3.0726 (3.0517)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:00  loss: 0.5936 (0.5936)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 2.1955  data: 2.0307  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.5818 (0.5740)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 0.3101  data: 0.1876  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5818 (0.5873)  acc1: 91.6667 (91.1706)  acc5: 97.9167 (98.4127)  time: 0.1376  data: 0.0021  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.6994 (0.7367)  acc1: 85.4167 (85.6183)  acc5: 97.9167 (98.3871)  time: 0.1633  data: 0.0043  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7295 (0.7221)  acc1: 85.4167 (86.4329)  acc5: 97.9167 (98.4756)  time: 0.1686  data: 0.0100  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7290 (0.7294)  acc1: 85.4167 (86.1111)  acc5: 100.0000 (98.6111)  time: 0.1638  data: 0.0111  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7804 (0.7384)  acc1: 85.4167 (85.7240)  acc5: 100.0000 (98.6339)  time: 0.1554  data: 0.0081  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8010 (0.7544)  acc1: 85.4167 (85.0939)  acc5: 97.9167 (98.3862)  time: 0.1407  data: 0.0034  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7162 (0.7377)  acc1: 87.5000 (85.5710)  acc5: 97.9167 (98.3796)  time: 0.1263  data: 0.0009  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7162 (0.7399)  acc1: 87.5000 (85.5541)  acc5: 97.9167 (98.3185)  time: 0.1243  data: 0.0009  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1762 s / it)\n",
            "* Acc@1 85.554 Acc@5 98.318 loss 0.740\n",
            "Accuracy of the model on the 3925 test images: 85.6%\n",
            "Max accuracy: 85.55%\n",
            "Test:  [ 0/82]  eta: 0:02:21  loss: 1.5632 (1.5632)  acc1: 43.7500 (43.7500)  acc5: 97.9167 (97.9167)  time: 1.7204  data: 1.5519  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.7049 (1.9592)  acc1: 35.4167 (32.3864)  acc5: 97.9167 (98.6742)  time: 0.2790  data: 0.1536  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.5891 (2.3723)  acc1: 18.7500 (22.8175)  acc5: 97.9167 (97.3214)  time: 0.1299  data: 0.0082  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.9765 (2.9533)  acc1: 6.2500 (16.5323)  acc5: 89.5833 (82.9973)  time: 0.1250  data: 0.0033  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.9529 (2.9424)  acc1: 8.3333 (18.8008)  acc5: 79.1667 (83.0793)  time: 0.1265  data: 0.0046  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.6611 (3.2231)  acc1: 8.3333 (15.9314)  acc5: 68.7500 (76.0212)  time: 0.1251  data: 0.0038  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.2594 (3.3127)  acc1: 2.0833 (13.8661)  acc5: 39.5833 (74.0096)  time: 0.1281  data: 0.0040  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.4481 (3.1853)  acc1: 2.0833 (17.7817)  acc5: 75.0000 (73.8263)  time: 0.1329  data: 0.0032  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9239 (2.8934)  acc1: 70.8333 (25.3858)  acc5: 97.9167 (76.8776)  time: 0.1253  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9239 (2.8706)  acc1: 70.8333 (25.8089)  acc5: 97.9167 (77.0191)  time: 0.1218  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1531 s / it)\n",
            "* Acc@1 25.809 Acc@5 77.019 loss 2.871\n",
            "Accuracy of the model EMA on 3925 test images: 25.8%\n",
            "Max EMA accuracy: 25.81%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [91]  [  0/295]  eta: 0:14:30  lr: 0.000125  min_lr: 0.000125  loss: 2.7696 (2.7696)  weight_decay: 0.0500 (0.0500)  time: 2.9524  data: 2.5746  max mem: 3500\n",
            "Epoch: [91]  [ 10/295]  eta: 0:02:24  lr: 0.000124  min_lr: 0.000124  loss: 2.9292 (2.9064)  weight_decay: 0.0500 (0.0500)  time: 0.5071  data: 0.2351  max mem: 3500\n",
            "Epoch: [91]  [ 20/295]  eta: 0:01:47  lr: 0.000123  min_lr: 0.000123  loss: 3.1209 (2.9896)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0012  max mem: 3500\n",
            "Epoch: [91]  [ 30/295]  eta: 0:01:32  lr: 0.000122  min_lr: 0.000122  loss: 3.0459 (3.0001)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0010  max mem: 3500\n",
            "Epoch: [91]  [ 40/295]  eta: 0:01:23  lr: 0.000121  min_lr: 0.000121  loss: 2.9376 (2.9904)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0010  max mem: 3500\n",
            "Epoch: [91]  [ 50/295]  eta: 0:01:17  lr: 0.000120  min_lr: 0.000120  loss: 2.9719 (2.9937)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0022  max mem: 3500\n",
            "Epoch: [91]  [ 60/295]  eta: 0:01:12  lr: 0.000119  min_lr: 0.000119  loss: 3.0422 (3.0063)  weight_decay: 0.0500 (0.0500)  time: 0.2720  data: 0.0030  max mem: 3500\n",
            "Epoch: [91]  [ 70/295]  eta: 0:01:08  lr: 0.000118  min_lr: 0.000118  loss: 3.0874 (3.0154)  weight_decay: 0.0500 (0.0500)  time: 0.2683  data: 0.0026  max mem: 3500\n",
            "Epoch: [91]  [ 80/295]  eta: 0:01:04  lr: 0.000117  min_lr: 0.000117  loss: 3.1215 (3.0193)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0021  max mem: 3500\n",
            "Epoch: [91]  [ 90/295]  eta: 0:01:00  lr: 0.000117  min_lr: 0.000117  loss: 3.1388 (3.0237)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0014  max mem: 3500\n",
            "Epoch: [91]  [100/295]  eta: 0:00:56  lr: 0.000115  min_lr: 0.000115  loss: 3.0637 (3.0187)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0007  max mem: 3500\n",
            "Epoch: [91]  [110/295]  eta: 0:00:53  lr: 0.000115  min_lr: 0.000115  loss: 3.0637 (3.0217)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0015  max mem: 3500\n",
            "Epoch: [91]  [120/295]  eta: 0:00:50  lr: 0.000114  min_lr: 0.000114  loss: 3.0947 (3.0255)  weight_decay: 0.0500 (0.0500)  time: 0.2722  data: 0.0028  max mem: 3500\n",
            "Epoch: [91]  [130/295]  eta: 0:00:47  lr: 0.000113  min_lr: 0.000113  loss: 3.0082 (3.0251)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0025  max mem: 3500\n",
            "Epoch: [91]  [140/295]  eta: 0:00:44  lr: 0.000112  min_lr: 0.000112  loss: 2.9994 (3.0237)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0014  max mem: 3500\n",
            "Epoch: [91]  [150/295]  eta: 0:00:41  lr: 0.000111  min_lr: 0.000111  loss: 3.0292 (3.0300)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0007  max mem: 3500\n",
            "Epoch: [91]  [160/295]  eta: 0:00:38  lr: 0.000110  min_lr: 0.000110  loss: 3.0450 (3.0279)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0020  max mem: 3500\n",
            "Epoch: [91]  [170/295]  eta: 0:00:35  lr: 0.000109  min_lr: 0.000109  loss: 3.0122 (3.0328)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0033  max mem: 3500\n",
            "Epoch: [91]  [180/295]  eta: 0:00:32  lr: 0.000108  min_lr: 0.000108  loss: 3.0353 (3.0345)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0027  max mem: 3500\n",
            "Epoch: [91]  [190/295]  eta: 0:00:29  lr: 0.000108  min_lr: 0.000108  loss: 3.0353 (3.0342)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0016  max mem: 3500\n",
            "Epoch: [91]  [200/295]  eta: 0:00:26  lr: 0.000107  min_lr: 0.000107  loss: 2.8019 (3.0194)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0018  max mem: 3500\n",
            "Epoch: [91]  [210/295]  eta: 0:00:23  lr: 0.000106  min_lr: 0.000106  loss: 2.7255 (3.0181)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0021  max mem: 3500\n",
            "Epoch: [91]  [220/295]  eta: 0:00:20  lr: 0.000105  min_lr: 0.000105  loss: 2.9557 (3.0145)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0009  max mem: 3500\n",
            "Epoch: [91]  [230/295]  eta: 0:00:17  lr: 0.000104  min_lr: 0.000104  loss: 2.9557 (3.0134)  weight_decay: 0.0500 (0.0500)  time: 0.2582  data: 0.0009  max mem: 3500\n",
            "Epoch: [91]  [240/295]  eta: 0:00:15  lr: 0.000103  min_lr: 0.000103  loss: 3.0613 (3.0136)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0015  max mem: 3500\n",
            "Epoch: [91]  [250/295]  eta: 0:00:12  lr: 0.000103  min_lr: 0.000103  loss: 3.0804 (3.0160)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0025  max mem: 3500\n",
            "Epoch: [91]  [260/295]  eta: 0:00:09  lr: 0.000102  min_lr: 0.000102  loss: 3.1005 (3.0182)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0030  max mem: 3500\n",
            "Epoch: [91]  [270/295]  eta: 0:00:06  lr: 0.000101  min_lr: 0.000101  loss: 2.9982 (3.0158)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0019  max mem: 3500\n",
            "Epoch: [91]  [280/295]  eta: 0:00:04  lr: 0.000100  min_lr: 0.000100  loss: 2.9464 (3.0153)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0007  max mem: 3500\n",
            "Epoch: [91]  [290/295]  eta: 0:00:01  lr: 0.000099  min_lr: 0.000099  loss: 2.9312 (3.0157)  weight_decay: 0.0500 (0.0500)  time: 0.2570  data: 0.0003  max mem: 3500\n",
            "Epoch: [91]  [294/295]  eta: 0:00:00  lr: 0.000099  min_lr: 0.000099  loss: 2.9281 (3.0154)  weight_decay: 0.0500 (0.0500)  time: 0.2188  data: 0.0002  max mem: 3500\n",
            "Epoch: [91] Total time: 0:01:20 (0.2724 s / it)\n",
            "Averaged stats: lr: 0.000099  min_lr: 0.000099  loss: 2.9281 (3.0154)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:30  loss: 0.6171 (0.6171)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 2.5691  data: 2.4010  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:28  loss: 0.5840 (0.5940)  acc1: 91.6667 (91.2879)  acc5: 97.9167 (97.7273)  time: 0.3905  data: 0.2476  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:20  loss: 0.5995 (0.6109)  acc1: 89.5833 (90.6746)  acc5: 97.9167 (98.2143)  time: 0.2104  data: 0.0467  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:14  loss: 0.7060 (0.7512)  acc1: 89.5833 (85.2151)  acc5: 97.9167 (98.0511)  time: 0.2195  data: 0.0321  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 0.7367 (0.7319)  acc1: 87.5000 (86.2805)  acc5: 97.9167 (98.3232)  time: 0.1627  data: 0.0034  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.7306 (0.7333)  acc1: 87.5000 (85.9477)  acc5: 100.0000 (98.4886)  time: 0.1294  data: 0.0029  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7498 (0.7354)  acc1: 85.4167 (85.6557)  acc5: 100.0000 (98.5997)  time: 0.1230  data: 0.0026  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8082 (0.7524)  acc1: 83.3333 (85.1232)  acc5: 97.9167 (98.4155)  time: 0.1205  data: 0.0017  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7334 (0.7363)  acc1: 85.4167 (85.5710)  acc5: 97.9167 (98.4054)  time: 0.1185  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7334 (0.7380)  acc1: 85.4167 (85.5541)  acc5: 97.9167 (98.3694)  time: 0.1169  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1871 s / it)\n",
            "* Acc@1 85.554 Acc@5 98.369 loss 0.738\n",
            "Accuracy of the model on the 3925 test images: 85.6%\n",
            "Max accuracy: 85.55%\n",
            "Test:  [ 0/82]  eta: 0:02:45  loss: 1.5258 (1.5258)  acc1: 43.7500 (43.7500)  acc5: 97.9167 (97.9167)  time: 2.0180  data: 1.8465  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 1.6679 (1.9250)  acc1: 35.4167 (33.1439)  acc5: 97.9167 (98.6742)  time: 0.3195  data: 0.1714  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 2.5600 (2.3440)  acc1: 18.7500 (23.4127)  acc5: 97.9167 (97.2222)  time: 0.1598  data: 0.0131  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 2.9495 (2.9247)  acc1: 6.2500 (17.1371)  acc5: 89.5833 (82.9973)  time: 0.1923  data: 0.0505  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 2.9412 (2.9111)  acc1: 10.4167 (19.5122)  acc5: 77.0833 (83.2317)  time: 0.2060  data: 0.0656  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.6255 (3.1917)  acc1: 6.2500 (16.4624)  acc5: 68.7500 (76.1846)  time: 0.1688  data: 0.0265  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.2174 (3.2799)  acc1: 2.0833 (14.3784)  acc5: 41.6667 (74.2828)  time: 0.1451  data: 0.0131  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.4102 (3.1539)  acc1: 4.1667 (18.2512)  acc5: 77.0833 (74.0317)  time: 0.1384  data: 0.0160  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9132 (2.8651)  acc1: 70.8333 (25.7973)  acc5: 97.9167 (77.0576)  time: 0.1231  data: 0.0033  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9132 (2.8426)  acc1: 70.8333 (26.2166)  acc5: 97.9167 (77.1975)  time: 0.1189  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1881 s / it)\n",
            "* Acc@1 26.217 Acc@5 77.197 loss 2.843\n",
            "Accuracy of the model EMA on 3925 test images: 26.2%\n",
            "Max EMA accuracy: 26.22%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [92]  [  0/295]  eta: 0:15:30  lr: 0.000099  min_lr: 0.000099  loss: 2.7569 (2.7569)  weight_decay: 0.0500 (0.0500)  time: 3.1557  data: 2.6004  max mem: 3500\n",
            "Epoch: [92]  [ 10/295]  eta: 0:02:33  lr: 0.000098  min_lr: 0.000098  loss: 2.9703 (2.9725)  weight_decay: 0.0500 (0.0500)  time: 0.5373  data: 0.2370  max mem: 3500\n",
            "Epoch: [92]  [ 20/295]  eta: 0:01:53  lr: 0.000097  min_lr: 0.000097  loss: 3.0502 (3.0277)  weight_decay: 0.0500 (0.0500)  time: 0.2742  data: 0.0021  max mem: 3500\n",
            "Epoch: [92]  [ 30/295]  eta: 0:01:37  lr: 0.000097  min_lr: 0.000097  loss: 3.0497 (2.9725)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0030  max mem: 3500\n",
            "Epoch: [92]  [ 40/295]  eta: 0:01:27  lr: 0.000096  min_lr: 0.000096  loss: 2.8342 (2.9771)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0017  max mem: 3500\n",
            "Epoch: [92]  [ 50/295]  eta: 0:01:19  lr: 0.000095  min_lr: 0.000095  loss: 3.0211 (3.0073)  weight_decay: 0.0500 (0.0500)  time: 0.2643  data: 0.0007  max mem: 3500\n",
            "Epoch: [92]  [ 60/295]  eta: 0:01:14  lr: 0.000094  min_lr: 0.000094  loss: 3.1640 (3.0255)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0004  max mem: 3500\n",
            "Epoch: [92]  [ 70/295]  eta: 0:01:09  lr: 0.000093  min_lr: 0.000093  loss: 3.0619 (3.0256)  weight_decay: 0.0500 (0.0500)  time: 0.2644  data: 0.0008  max mem: 3500\n",
            "Epoch: [92]  [ 80/295]  eta: 0:01:05  lr: 0.000092  min_lr: 0.000092  loss: 3.0266 (3.0242)  weight_decay: 0.0500 (0.0500)  time: 0.2708  data: 0.0016  max mem: 3500\n",
            "Epoch: [92]  [ 90/295]  eta: 0:01:01  lr: 0.000092  min_lr: 0.000092  loss: 3.0318 (3.0085)  weight_decay: 0.0500 (0.0500)  time: 0.2756  data: 0.0030  max mem: 3500\n",
            "Epoch: [92]  [100/295]  eta: 0:00:58  lr: 0.000091  min_lr: 0.000091  loss: 3.0087 (3.0080)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0031  max mem: 3500\n",
            "Epoch: [92]  [110/295]  eta: 0:00:54  lr: 0.000090  min_lr: 0.000090  loss: 3.0087 (3.0056)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0013  max mem: 3500\n",
            "Epoch: [92]  [120/295]  eta: 0:00:51  lr: 0.000089  min_lr: 0.000089  loss: 3.0973 (3.0149)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0011  max mem: 3500\n",
            "Epoch: [92]  [130/295]  eta: 0:00:47  lr: 0.000089  min_lr: 0.000089  loss: 3.0973 (3.0097)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0012  max mem: 3500\n",
            "Epoch: [92]  [140/295]  eta: 0:00:44  lr: 0.000088  min_lr: 0.000088  loss: 2.9416 (3.0099)  weight_decay: 0.0500 (0.0500)  time: 0.2658  data: 0.0021  max mem: 3500\n",
            "Epoch: [92]  [150/295]  eta: 0:00:41  lr: 0.000087  min_lr: 0.000087  loss: 2.9672 (3.0097)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0028  max mem: 3500\n",
            "Epoch: [92]  [160/295]  eta: 0:00:38  lr: 0.000086  min_lr: 0.000086  loss: 3.0211 (3.0146)  weight_decay: 0.0500 (0.0500)  time: 0.2702  data: 0.0018  max mem: 3500\n",
            "Epoch: [92]  [170/295]  eta: 0:00:35  lr: 0.000085  min_lr: 0.000085  loss: 3.0745 (3.0115)  weight_decay: 0.0500 (0.0500)  time: 0.2653  data: 0.0010  max mem: 3500\n",
            "Epoch: [92]  [180/295]  eta: 0:00:32  lr: 0.000084  min_lr: 0.000084  loss: 3.0745 (3.0134)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0008  max mem: 3500\n",
            "Epoch: [92]  [190/295]  eta: 0:00:29  lr: 0.000084  min_lr: 0.000084  loss: 3.0995 (3.0167)  weight_decay: 0.0500 (0.0500)  time: 0.2597  data: 0.0013  max mem: 3500\n",
            "Epoch: [92]  [200/295]  eta: 0:00:26  lr: 0.000083  min_lr: 0.000083  loss: 3.1254 (3.0203)  weight_decay: 0.0500 (0.0500)  time: 0.2599  data: 0.0012  max mem: 3500\n",
            "Epoch: [92]  [210/295]  eta: 0:00:23  lr: 0.000082  min_lr: 0.000082  loss: 3.0678 (3.0235)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0013  max mem: 3500\n",
            "Epoch: [92]  [220/295]  eta: 0:00:20  lr: 0.000081  min_lr: 0.000081  loss: 3.0368 (3.0285)  weight_decay: 0.0500 (0.0500)  time: 0.2671  data: 0.0030  max mem: 3500\n",
            "Epoch: [92]  [230/295]  eta: 0:00:18  lr: 0.000081  min_lr: 0.000081  loss: 3.0482 (3.0285)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0030  max mem: 3500\n",
            "Epoch: [92]  [240/295]  eta: 0:00:15  lr: 0.000080  min_lr: 0.000080  loss: 3.1547 (3.0303)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0015  max mem: 3500\n",
            "Epoch: [92]  [250/295]  eta: 0:00:12  lr: 0.000079  min_lr: 0.000079  loss: 3.1635 (3.0334)  weight_decay: 0.0500 (0.0500)  time: 0.2609  data: 0.0019  max mem: 3500\n",
            "Epoch: [92]  [260/295]  eta: 0:00:09  lr: 0.000078  min_lr: 0.000078  loss: 2.9935 (3.0323)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0024  max mem: 3500\n",
            "Epoch: [92]  [270/295]  eta: 0:00:06  lr: 0.000078  min_lr: 0.000078  loss: 3.0565 (3.0354)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0013  max mem: 3500\n",
            "Epoch: [92]  [280/295]  eta: 0:00:04  lr: 0.000077  min_lr: 0.000077  loss: 3.0672 (3.0364)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0004  max mem: 3500\n",
            "Epoch: [92]  [290/295]  eta: 0:00:01  lr: 0.000076  min_lr: 0.000076  loss: 3.0183 (3.0347)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0002  max mem: 3500\n",
            "Epoch: [92]  [294/295]  eta: 0:00:00  lr: 0.000076  min_lr: 0.000076  loss: 3.0183 (3.0356)  weight_decay: 0.0500 (0.0500)  time: 0.2218  data: 0.0002  max mem: 3500\n",
            "Epoch: [92] Total time: 0:01:20 (0.2744 s / it)\n",
            "Averaged stats: lr: 0.000076  min_lr: 0.000076  loss: 3.0183 (3.0356)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:06  loss: 0.6146 (0.6146)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 2.2769  data: 2.0992  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 0.5859 (0.5770)  acc1: 91.6667 (92.0455)  acc5: 97.9167 (98.1061)  time: 0.3175  data: 0.1947  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5859 (0.5943)  acc1: 91.6667 (91.2698)  acc5: 97.9167 (98.3135)  time: 0.1242  data: 0.0041  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6914 (0.7497)  acc1: 85.4167 (85.7527)  acc5: 97.9167 (98.2527)  time: 0.1251  data: 0.0042  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7379 (0.7319)  acc1: 85.4167 (86.5346)  acc5: 97.9167 (98.3740)  time: 0.1244  data: 0.0044  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7278 (0.7367)  acc1: 87.5000 (86.1928)  acc5: 100.0000 (98.5294)  time: 0.1228  data: 0.0031  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7577 (0.7473)  acc1: 85.4167 (85.6216)  acc5: 100.0000 (98.6339)  time: 0.1213  data: 0.0025  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8498 (0.7670)  acc1: 83.3333 (84.8298)  acc5: 97.9167 (98.4155)  time: 0.1206  data: 0.0018  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7602 (0.7481)  acc1: 85.4167 (85.4167)  acc5: 97.9167 (98.4054)  time: 0.1182  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7602 (0.7497)  acc1: 85.4167 (85.4268)  acc5: 97.9167 (98.3694)  time: 0.1168  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1548 s / it)\n",
            "* Acc@1 85.427 Acc@5 98.369 loss 0.750\n",
            "Accuracy of the model on the 3925 test images: 85.4%\n",
            "Max accuracy: 85.55%\n",
            "Test:  [ 0/82]  eta: 0:03:51  loss: 1.4895 (1.4895)  acc1: 47.9167 (47.9167)  acc5: 97.9167 (97.9167)  time: 2.8208  data: 2.6324  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 1.6317 (1.8918)  acc1: 39.5833 (34.4697)  acc5: 97.9167 (98.6742)  time: 0.3831  data: 0.2411  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 2.5317 (2.3166)  acc1: 20.8333 (24.2063)  acc5: 97.9167 (97.1230)  time: 0.1364  data: 0.0078  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 2.9308 (2.8972)  acc1: 6.2500 (17.6075)  acc5: 89.5833 (83.1317)  time: 0.1278  data: 0.0085  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.9308 (2.8810)  acc1: 10.4167 (20.0711)  acc5: 77.0833 (83.3333)  time: 0.1237  data: 0.0039  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.5909 (3.1616)  acc1: 8.3333 (16.9526)  acc5: 68.7500 (76.3072)  time: 0.1244  data: 0.0048  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.1763 (3.2483)  acc1: 4.1667 (14.8224)  acc5: 41.6667 (74.4536)  time: 0.1250  data: 0.0072  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.3734 (3.1236)  acc1: 4.1667 (18.6620)  acc5: 77.0833 (74.1784)  time: 0.1230  data: 0.0047  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.9025 (2.8377)  acc1: 72.9167 (26.1574)  acc5: 97.9167 (77.1862)  time: 0.1192  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.9025 (2.8155)  acc1: 72.9167 (26.5732)  acc5: 97.9167 (77.3248)  time: 0.1175  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1629 s / it)\n",
            "* Acc@1 26.573 Acc@5 77.325 loss 2.815\n",
            "Accuracy of the model EMA on 3925 test images: 26.6%\n",
            "Max EMA accuracy: 26.57%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [93]  [  0/295]  eta: 0:16:30  lr: 0.000076  min_lr: 0.000076  loss: 3.1810 (3.1810)  weight_decay: 0.0500 (0.0500)  time: 3.3592  data: 2.7462  max mem: 3500\n",
            "Epoch: [93]  [ 10/295]  eta: 0:02:46  lr: 0.000075  min_lr: 0.000075  loss: 2.9811 (3.0036)  weight_decay: 0.0500 (0.0500)  time: 0.5826  data: 0.2525  max mem: 3500\n",
            "Epoch: [93]  [ 20/295]  eta: 0:01:58  lr: 0.000075  min_lr: 0.000075  loss: 2.9811 (2.9755)  weight_decay: 0.0500 (0.0500)  time: 0.2835  data: 0.0020  max mem: 3500\n",
            "Epoch: [93]  [ 30/295]  eta: 0:01:39  lr: 0.000074  min_lr: 0.000074  loss: 3.0228 (2.9842)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0011  max mem: 3500\n",
            "Epoch: [93]  [ 40/295]  eta: 0:01:28  lr: 0.000073  min_lr: 0.000073  loss: 3.0069 (2.9716)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0008  max mem: 3500\n",
            "Epoch: [93]  [ 50/295]  eta: 0:01:21  lr: 0.000073  min_lr: 0.000073  loss: 3.0724 (2.9903)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0009  max mem: 3500\n",
            "Epoch: [93]  [ 60/295]  eta: 0:01:15  lr: 0.000072  min_lr: 0.000072  loss: 3.0767 (2.9960)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0023  max mem: 3500\n",
            "Epoch: [93]  [ 70/295]  eta: 0:01:10  lr: 0.000071  min_lr: 0.000071  loss: 2.9885 (2.9967)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0020  max mem: 3500\n",
            "Epoch: [93]  [ 80/295]  eta: 0:01:06  lr: 0.000070  min_lr: 0.000070  loss: 3.0685 (3.0097)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0018  max mem: 3500\n",
            "Epoch: [93]  [ 90/295]  eta: 0:01:02  lr: 0.000070  min_lr: 0.000070  loss: 3.0246 (3.0092)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0022  max mem: 3500\n",
            "Epoch: [93]  [100/295]  eta: 0:00:58  lr: 0.000069  min_lr: 0.000069  loss: 3.0637 (3.0260)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0021  max mem: 3500\n",
            "Epoch: [93]  [110/295]  eta: 0:00:54  lr: 0.000068  min_lr: 0.000068  loss: 3.1228 (3.0199)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0028  max mem: 3500\n",
            "Epoch: [93]  [120/295]  eta: 0:00:51  lr: 0.000068  min_lr: 0.000068  loss: 2.9513 (3.0184)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0038  max mem: 3500\n",
            "Epoch: [93]  [130/295]  eta: 0:00:48  lr: 0.000067  min_lr: 0.000067  loss: 2.9029 (3.0146)  weight_decay: 0.0500 (0.0500)  time: 0.2712  data: 0.0037  max mem: 3500\n",
            "Epoch: [93]  [140/295]  eta: 0:00:45  lr: 0.000066  min_lr: 0.000066  loss: 2.9712 (3.0153)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0034  max mem: 3500\n",
            "Epoch: [93]  [150/295]  eta: 0:00:41  lr: 0.000066  min_lr: 0.000066  loss: 3.0419 (3.0187)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0031  max mem: 3500\n",
            "Epoch: [93]  [160/295]  eta: 0:00:38  lr: 0.000065  min_lr: 0.000065  loss: 3.0651 (3.0133)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0024  max mem: 3500\n",
            "Epoch: [93]  [170/295]  eta: 0:00:35  lr: 0.000064  min_lr: 0.000064  loss: 2.9339 (3.0131)  weight_decay: 0.0500 (0.0500)  time: 0.2598  data: 0.0031  max mem: 3500\n",
            "Epoch: [93]  [180/295]  eta: 0:00:32  lr: 0.000063  min_lr: 0.000063  loss: 2.9300 (3.0076)  weight_decay: 0.0500 (0.0500)  time: 0.2606  data: 0.0032  max mem: 3500\n",
            "Epoch: [93]  [190/295]  eta: 0:00:29  lr: 0.000063  min_lr: 0.000063  loss: 2.8703 (3.0046)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0022  max mem: 3500\n",
            "Epoch: [93]  [200/295]  eta: 0:00:26  lr: 0.000062  min_lr: 0.000062  loss: 2.9127 (3.0019)  weight_decay: 0.0500 (0.0500)  time: 0.2783  data: 0.0027  max mem: 3500\n",
            "Epoch: [93]  [210/295]  eta: 0:00:24  lr: 0.000062  min_lr: 0.000062  loss: 2.9780 (3.0018)  weight_decay: 0.0500 (0.0500)  time: 0.2765  data: 0.0033  max mem: 3500\n",
            "Epoch: [93]  [220/295]  eta: 0:00:21  lr: 0.000061  min_lr: 0.000061  loss: 3.0145 (3.0037)  weight_decay: 0.0500 (0.0500)  time: 0.2776  data: 0.0034  max mem: 3500\n",
            "Epoch: [93]  [230/295]  eta: 0:00:18  lr: 0.000060  min_lr: 0.000060  loss: 3.0543 (3.0088)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0039  max mem: 3500\n",
            "Epoch: [93]  [240/295]  eta: 0:00:15  lr: 0.000060  min_lr: 0.000060  loss: 3.1144 (3.0142)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0025  max mem: 3500\n",
            "Epoch: [93]  [250/295]  eta: 0:00:12  lr: 0.000059  min_lr: 0.000059  loss: 3.1423 (3.0172)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0011  max mem: 3500\n",
            "Epoch: [93]  [260/295]  eta: 0:00:09  lr: 0.000058  min_lr: 0.000058  loss: 3.1235 (3.0180)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0009  max mem: 3500\n",
            "Epoch: [93]  [270/295]  eta: 0:00:06  lr: 0.000058  min_lr: 0.000058  loss: 3.0192 (3.0190)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0014  max mem: 3500\n",
            "Epoch: [93]  [280/295]  eta: 0:00:04  lr: 0.000057  min_lr: 0.000057  loss: 3.0554 (3.0187)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0024  max mem: 3500\n",
            "Epoch: [93]  [290/295]  eta: 0:00:01  lr: 0.000056  min_lr: 0.000056  loss: 3.0898 (3.0194)  weight_decay: 0.0500 (0.0500)  time: 0.2616  data: 0.0014  max mem: 3500\n",
            "Epoch: [93]  [294/295]  eta: 0:00:00  lr: 0.000056  min_lr: 0.000056  loss: 3.0554 (3.0188)  weight_decay: 0.0500 (0.0500)  time: 0.2211  data: 0.0002  max mem: 3500\n",
            "Epoch: [93] Total time: 0:01:21 (0.2767 s / it)\n",
            "Averaged stats: lr: 0.000056  min_lr: 0.000056  loss: 3.0554 (3.0188)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:11  loss: 0.6129 (0.6129)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 1.6053  data: 1.4420  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.5859 (0.5922)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 0.3223  data: 0.1999  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5887 (0.6066)  acc1: 91.6667 (90.8730)  acc5: 100.0000 (98.4127)  time: 0.1590  data: 0.0392  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6951 (0.7510)  acc1: 87.5000 (85.6855)  acc5: 97.9167 (98.3199)  time: 0.1242  data: 0.0046  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7284 (0.7307)  acc1: 87.5000 (86.5854)  acc5: 97.9167 (98.4756)  time: 0.1279  data: 0.0059  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7150 (0.7360)  acc1: 87.5000 (86.2745)  acc5: 100.0000 (98.5703)  time: 0.1415  data: 0.0086  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7812 (0.7404)  acc1: 85.4167 (85.8265)  acc5: 100.0000 (98.6680)  time: 0.1517  data: 0.0069  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8463 (0.7605)  acc1: 81.2500 (84.9765)  acc5: 100.0000 (98.4742)  time: 0.1404  data: 0.0026  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7456 (0.7423)  acc1: 85.4167 (85.5710)  acc5: 97.9167 (98.4825)  time: 0.1234  data: 0.0017  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7456 (0.7439)  acc1: 85.4167 (85.5796)  acc5: 97.9167 (98.4459)  time: 0.1207  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1645 s / it)\n",
            "* Acc@1 85.580 Acc@5 98.446 loss 0.744\n",
            "Accuracy of the model on the 3925 test images: 85.6%\n",
            "Max accuracy: 85.58%\n",
            "Test:  [ 0/82]  eta: 0:02:33  loss: 1.4529 (1.4529)  acc1: 50.0000 (50.0000)  acc5: 97.9167 (97.9167)  time: 1.8670  data: 1.7081  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.5950 (1.8583)  acc1: 39.5833 (35.0379)  acc5: 97.9167 (98.6742)  time: 0.2838  data: 0.1579  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.5032 (2.2891)  acc1: 20.8333 (24.5040)  acc5: 97.9167 (97.0238)  time: 0.1233  data: 0.0026  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.9206 (2.8697)  acc1: 6.2500 (17.8091)  acc5: 89.5833 (83.1989)  time: 0.1232  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.9206 (2.8511)  acc1: 10.4167 (20.3252)  acc5: 77.0833 (83.4858)  time: 0.1270  data: 0.0053  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.5557 (3.1316)  acc1: 8.3333 (17.1160)  acc5: 68.7500 (76.3889)  time: 0.1264  data: 0.0065  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.1345 (3.2168)  acc1: 4.1667 (15.0273)  acc5: 41.6667 (74.5560)  time: 0.1235  data: 0.0056  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.3364 (3.0934)  acc1: 4.1667 (18.8674)  acc5: 77.0833 (74.2958)  time: 0.1209  data: 0.0029  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8949 (2.8105)  acc1: 72.9167 (26.3374)  acc5: 97.9167 (77.3148)  time: 0.1187  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8949 (2.7885)  acc1: 72.9167 (26.7516)  acc5: 97.9167 (77.4522)  time: 0.1176  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1514 s / it)\n",
            "* Acc@1 26.752 Acc@5 77.452 loss 2.789\n",
            "Accuracy of the model EMA on 3925 test images: 26.8%\n",
            "Max EMA accuracy: 26.75%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [94]  [  0/295]  eta: 0:14:07  lr: 0.000056  min_lr: 0.000056  loss: 3.0770 (3.0770)  weight_decay: 0.0500 (0.0500)  time: 2.8729  data: 2.3983  max mem: 3500\n",
            "Epoch: [94]  [ 10/295]  eta: 0:02:25  lr: 0.000056  min_lr: 0.000056  loss: 3.0770 (3.0352)  weight_decay: 0.0500 (0.0500)  time: 0.5089  data: 0.2192  max mem: 3500\n",
            "Epoch: [94]  [ 20/295]  eta: 0:01:47  lr: 0.000055  min_lr: 0.000055  loss: 2.9970 (3.0112)  weight_decay: 0.0500 (0.0500)  time: 0.2672  data: 0.0011  max mem: 3500\n",
            "Epoch: [94]  [ 30/295]  eta: 0:01:32  lr: 0.000055  min_lr: 0.000055  loss: 3.0635 (3.0296)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0015  max mem: 3500\n",
            "Epoch: [94]  [ 40/295]  eta: 0:01:24  lr: 0.000054  min_lr: 0.000054  loss: 3.0697 (3.0353)  weight_decay: 0.0500 (0.0500)  time: 0.2648  data: 0.0022  max mem: 3500\n",
            "Epoch: [94]  [ 50/295]  eta: 0:01:17  lr: 0.000053  min_lr: 0.000053  loss: 3.0695 (3.0386)  weight_decay: 0.0500 (0.0500)  time: 0.2687  data: 0.0014  max mem: 3500\n",
            "Epoch: [94]  [ 60/295]  eta: 0:01:12  lr: 0.000053  min_lr: 0.000053  loss: 3.1829 (3.0599)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0006  max mem: 3500\n",
            "Epoch: [94]  [ 70/295]  eta: 0:01:08  lr: 0.000052  min_lr: 0.000052  loss: 3.1744 (3.0592)  weight_decay: 0.0500 (0.0500)  time: 0.2695  data: 0.0020  max mem: 3500\n",
            "Epoch: [94]  [ 80/295]  eta: 0:01:04  lr: 0.000051  min_lr: 0.000051  loss: 3.1318 (3.0638)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0020  max mem: 3500\n",
            "Epoch: [94]  [ 90/295]  eta: 0:01:00  lr: 0.000051  min_lr: 0.000051  loss: 3.0164 (3.0540)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0012  max mem: 3500\n",
            "Epoch: [94]  [100/295]  eta: 0:00:56  lr: 0.000050  min_lr: 0.000050  loss: 3.0059 (3.0528)  weight_decay: 0.0500 (0.0500)  time: 0.2638  data: 0.0017  max mem: 3500\n",
            "Epoch: [94]  [110/295]  eta: 0:00:53  lr: 0.000050  min_lr: 0.000050  loss: 3.0959 (3.0532)  weight_decay: 0.0500 (0.0500)  time: 0.2657  data: 0.0018  max mem: 3500\n",
            "Epoch: [94]  [120/295]  eta: 0:00:50  lr: 0.000049  min_lr: 0.000049  loss: 3.0931 (3.0555)  weight_decay: 0.0500 (0.0500)  time: 0.2719  data: 0.0031  max mem: 3500\n",
            "Epoch: [94]  [130/295]  eta: 0:00:47  lr: 0.000048  min_lr: 0.000048  loss: 3.1426 (3.0558)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0037  max mem: 3500\n",
            "Epoch: [94]  [140/295]  eta: 0:00:44  lr: 0.000048  min_lr: 0.000048  loss: 3.1740 (3.0632)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0025  max mem: 3500\n",
            "Epoch: [94]  [150/295]  eta: 0:00:41  lr: 0.000047  min_lr: 0.000047  loss: 3.1263 (3.0594)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0023  max mem: 3500\n",
            "Epoch: [94]  [160/295]  eta: 0:00:38  lr: 0.000047  min_lr: 0.000047  loss: 3.0458 (3.0599)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0021  max mem: 3500\n",
            "Epoch: [94]  [170/295]  eta: 0:00:35  lr: 0.000046  min_lr: 0.000046  loss: 3.0187 (3.0595)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0011  max mem: 3500\n",
            "Epoch: [94]  [180/295]  eta: 0:00:32  lr: 0.000046  min_lr: 0.000046  loss: 3.1023 (3.0605)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0022  max mem: 3500\n",
            "Epoch: [94]  [190/295]  eta: 0:00:29  lr: 0.000045  min_lr: 0.000045  loss: 3.1351 (3.0620)  weight_decay: 0.0500 (0.0500)  time: 0.2703  data: 0.0037  max mem: 3500\n",
            "Epoch: [94]  [200/295]  eta: 0:00:26  lr: 0.000044  min_lr: 0.000044  loss: 3.0713 (3.0600)  weight_decay: 0.0500 (0.0500)  time: 0.2669  data: 0.0041  max mem: 3500\n",
            "Epoch: [94]  [210/295]  eta: 0:00:23  lr: 0.000044  min_lr: 0.000044  loss: 2.9491 (3.0539)  weight_decay: 0.0500 (0.0500)  time: 0.2627  data: 0.0030  max mem: 3500\n",
            "Epoch: [94]  [220/295]  eta: 0:00:20  lr: 0.000043  min_lr: 0.000043  loss: 3.0869 (3.0621)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0012  max mem: 3500\n",
            "Epoch: [94]  [230/295]  eta: 0:00:17  lr: 0.000043  min_lr: 0.000043  loss: 3.1891 (3.0656)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0012  max mem: 3500\n",
            "Epoch: [94]  [240/295]  eta: 0:00:15  lr: 0.000042  min_lr: 0.000042  loss: 3.1563 (3.0651)  weight_decay: 0.0500 (0.0500)  time: 0.2613  data: 0.0020  max mem: 3500\n",
            "Epoch: [94]  [250/295]  eta: 0:00:12  lr: 0.000042  min_lr: 0.000042  loss: 3.0869 (3.0611)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0025  max mem: 3500\n",
            "Epoch: [94]  [260/295]  eta: 0:00:09  lr: 0.000041  min_lr: 0.000041  loss: 3.0806 (3.0629)  weight_decay: 0.0500 (0.0500)  time: 0.2717  data: 0.0025  max mem: 3500\n",
            "Epoch: [94]  [270/295]  eta: 0:00:06  lr: 0.000041  min_lr: 0.000041  loss: 3.2196 (3.0699)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0025  max mem: 3500\n",
            "Epoch: [94]  [280/295]  eta: 0:00:04  lr: 0.000040  min_lr: 0.000040  loss: 3.1270 (3.0692)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0014  max mem: 3500\n",
            "Epoch: [94]  [290/295]  eta: 0:00:01  lr: 0.000040  min_lr: 0.000040  loss: 2.9813 (3.0653)  weight_decay: 0.0500 (0.0500)  time: 0.2569  data: 0.0003  max mem: 3500\n",
            "Epoch: [94]  [294/295]  eta: 0:00:00  lr: 0.000040  min_lr: 0.000040  loss: 2.9719 (3.0643)  weight_decay: 0.0500 (0.0500)  time: 0.2191  data: 0.0002  max mem: 3500\n",
            "Epoch: [94] Total time: 0:01:20 (0.2726 s / it)\n",
            "Averaged stats: lr: 0.000040  min_lr: 0.000040  loss: 2.9719 (3.0643)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:27  loss: 0.6175 (0.6175)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 2.5244  data: 2.3332  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.5920 (0.5907)  acc1: 91.6667 (91.8561)  acc5: 97.9167 (97.9167)  time: 0.3876  data: 0.2172  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 0.5920 (0.5962)  acc1: 93.7500 (91.6667)  acc5: 100.0000 (98.3135)  time: 0.1800  data: 0.0141  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:13  loss: 0.6909 (0.7493)  acc1: 85.4167 (86.0887)  acc5: 97.9167 (98.2527)  time: 0.1790  data: 0.0299  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:10  loss: 0.7413 (0.7330)  acc1: 85.4167 (86.7378)  acc5: 97.9167 (98.4756)  time: 0.1901  data: 0.0356  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:07  loss: 0.7259 (0.7423)  acc1: 85.4167 (86.3562)  acc5: 100.0000 (98.5703)  time: 0.1787  data: 0.0186  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.8021 (0.7480)  acc1: 83.3333 (85.9290)  acc5: 100.0000 (98.6680)  time: 0.1357  data: 0.0039  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8368 (0.7663)  acc1: 83.3333 (85.2113)  acc5: 100.0000 (98.4742)  time: 0.1203  data: 0.0027  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7385 (0.7494)  acc1: 87.5000 (85.6996)  acc5: 100.0000 (98.5082)  time: 0.1183  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7385 (0.7512)  acc1: 87.5000 (85.6815)  acc5: 100.0000 (98.4713)  time: 0.1169  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1898 s / it)\n",
            "* Acc@1 85.682 Acc@5 98.471 loss 0.751\n",
            "Accuracy of the model on the 3925 test images: 85.7%\n",
            "Max accuracy: 85.68%\n",
            "Test:  [ 0/82]  eta: 0:02:20  loss: 1.4177 (1.4177)  acc1: 50.0000 (50.0000)  acc5: 97.9167 (97.9167)  time: 1.7141  data: 1.5500  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:20  loss: 1.5613 (1.8256)  acc1: 41.6667 (35.9848)  acc5: 97.9167 (98.6742)  time: 0.2904  data: 0.1660  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.4740 (2.2616)  acc1: 20.8333 (25.3968)  acc5: 97.9167 (96.9246)  time: 0.1461  data: 0.0169  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.8966 (2.8420)  acc1: 6.2500 (18.4140)  acc5: 89.5833 (83.1989)  time: 0.1512  data: 0.0042  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.9092 (2.8210)  acc1: 10.4167 (20.8841)  acc5: 77.0833 (83.5366)  time: 0.1597  data: 0.0049  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.5196 (3.1014)  acc1: 8.3333 (17.5654)  acc5: 68.7500 (76.3480)  time: 0.1701  data: 0.0226  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.0922 (3.1849)  acc1: 4.1667 (15.4372)  acc5: 41.6667 (74.5219)  time: 0.1670  data: 0.0315  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.2984 (3.0629)  acc1: 4.1667 (19.2488)  acc5: 77.0833 (74.3251)  time: 0.1731  data: 0.0276  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8890 (2.7831)  acc1: 72.9167 (26.6718)  acc5: 97.9167 (77.3405)  time: 0.1558  data: 0.0149  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8890 (2.7613)  acc1: 72.9167 (27.0828)  acc5: 97.9167 (77.5032)  time: 0.1388  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:15 (0.1840 s / it)\n",
            "* Acc@1 27.083 Acc@5 77.503 loss 2.761\n",
            "Accuracy of the model EMA on 3925 test images: 27.1%\n",
            "Max EMA accuracy: 27.08%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [95]  [  0/295]  eta: 0:14:13  lr: 0.000039  min_lr: 0.000039  loss: 3.3295 (3.3295)  weight_decay: 0.0500 (0.0500)  time: 2.8949  data: 2.3955  max mem: 3500\n",
            "Epoch: [95]  [ 10/295]  eta: 0:02:23  lr: 0.000039  min_lr: 0.000039  loss: 3.1105 (3.0156)  weight_decay: 0.0500 (0.0500)  time: 0.5038  data: 0.2189  max mem: 3500\n",
            "Epoch: [95]  [ 20/295]  eta: 0:01:48  lr: 0.000038  min_lr: 0.000038  loss: 2.9555 (2.9468)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0016  max mem: 3500\n",
            "Epoch: [95]  [ 30/295]  eta: 0:01:33  lr: 0.000038  min_lr: 0.000038  loss: 2.9814 (2.9873)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0018  max mem: 3500\n",
            "Epoch: [95]  [ 40/295]  eta: 0:01:24  lr: 0.000037  min_lr: 0.000037  loss: 2.9814 (2.9689)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0020  max mem: 3500\n",
            "Epoch: [95]  [ 50/295]  eta: 0:01:18  lr: 0.000037  min_lr: 0.000037  loss: 3.0048 (2.9995)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0017  max mem: 3500\n",
            "Epoch: [95]  [ 60/295]  eta: 0:01:12  lr: 0.000036  min_lr: 0.000036  loss: 2.9389 (2.9803)  weight_decay: 0.0500 (0.0500)  time: 0.2623  data: 0.0010  max mem: 3500\n",
            "Epoch: [95]  [ 70/295]  eta: 0:01:08  lr: 0.000036  min_lr: 0.000036  loss: 3.0203 (3.0118)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0008  max mem: 3500\n",
            "Epoch: [95]  [ 80/295]  eta: 0:01:04  lr: 0.000035  min_lr: 0.000035  loss: 3.2128 (3.0383)  weight_decay: 0.0500 (0.0500)  time: 0.2635  data: 0.0006  max mem: 3500\n",
            "Epoch: [95]  [ 90/295]  eta: 0:01:00  lr: 0.000035  min_lr: 0.000035  loss: 3.1775 (3.0466)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0013  max mem: 3500\n",
            "Epoch: [95]  [100/295]  eta: 0:00:57  lr: 0.000034  min_lr: 0.000034  loss: 3.1680 (3.0416)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0020  max mem: 3500\n",
            "Epoch: [95]  [110/295]  eta: 0:00:53  lr: 0.000034  min_lr: 0.000034  loss: 2.8845 (3.0287)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0028  max mem: 3500\n",
            "Epoch: [95]  [120/295]  eta: 0:00:50  lr: 0.000033  min_lr: 0.000033  loss: 2.8451 (3.0197)  weight_decay: 0.0500 (0.0500)  time: 0.2651  data: 0.0027  max mem: 3500\n",
            "Epoch: [95]  [130/295]  eta: 0:00:47  lr: 0.000033  min_lr: 0.000033  loss: 2.9433 (3.0220)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0012  max mem: 3500\n",
            "Epoch: [95]  [140/295]  eta: 0:00:44  lr: 0.000032  min_lr: 0.000032  loss: 2.9706 (3.0215)  weight_decay: 0.0500 (0.0500)  time: 0.2611  data: 0.0009  max mem: 3500\n",
            "Epoch: [95]  [150/295]  eta: 0:00:41  lr: 0.000032  min_lr: 0.000032  loss: 3.0268 (3.0202)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0012  max mem: 3500\n",
            "Epoch: [95]  [160/295]  eta: 0:00:38  lr: 0.000031  min_lr: 0.000031  loss: 3.0303 (3.0253)  weight_decay: 0.0500 (0.0500)  time: 0.2673  data: 0.0029  max mem: 3500\n",
            "Epoch: [95]  [170/295]  eta: 0:00:35  lr: 0.000031  min_lr: 0.000031  loss: 3.0790 (3.0269)  weight_decay: 0.0500 (0.0500)  time: 0.2713  data: 0.0046  max mem: 3500\n",
            "Epoch: [95]  [180/295]  eta: 0:00:32  lr: 0.000031  min_lr: 0.000031  loss: 3.0162 (3.0276)  weight_decay: 0.0500 (0.0500)  time: 0.2678  data: 0.0029  max mem: 3500\n",
            "Epoch: [95]  [190/295]  eta: 0:00:29  lr: 0.000030  min_lr: 0.000030  loss: 2.9864 (3.0241)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0009  max mem: 3500\n",
            "Epoch: [95]  [200/295]  eta: 0:00:26  lr: 0.000030  min_lr: 0.000030  loss: 2.9864 (3.0229)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0015  max mem: 3500\n",
            "Epoch: [95]  [210/295]  eta: 0:00:23  lr: 0.000029  min_lr: 0.000029  loss: 3.0304 (3.0220)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0019  max mem: 3500\n",
            "Epoch: [95]  [220/295]  eta: 0:00:20  lr: 0.000029  min_lr: 0.000029  loss: 3.1004 (3.0256)  weight_decay: 0.0500 (0.0500)  time: 0.2640  data: 0.0016  max mem: 3500\n",
            "Epoch: [95]  [230/295]  eta: 0:00:18  lr: 0.000028  min_lr: 0.000028  loss: 3.1067 (3.0255)  weight_decay: 0.0500 (0.0500)  time: 0.2697  data: 0.0023  max mem: 3500\n",
            "Epoch: [95]  [240/295]  eta: 0:00:15  lr: 0.000028  min_lr: 0.000028  loss: 3.0375 (3.0281)  weight_decay: 0.0500 (0.0500)  time: 0.2710  data: 0.0030  max mem: 3500\n",
            "Epoch: [95]  [250/295]  eta: 0:00:12  lr: 0.000028  min_lr: 0.000028  loss: 3.0609 (3.0299)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0018  max mem: 3500\n",
            "Epoch: [95]  [260/295]  eta: 0:00:09  lr: 0.000027  min_lr: 0.000027  loss: 3.0609 (3.0298)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0010  max mem: 3500\n",
            "Epoch: [95]  [270/295]  eta: 0:00:06  lr: 0.000027  min_lr: 0.000027  loss: 2.9983 (3.0270)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0014  max mem: 3500\n",
            "Epoch: [95]  [280/295]  eta: 0:00:04  lr: 0.000026  min_lr: 0.000026  loss: 3.0746 (3.0305)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0009  max mem: 3500\n",
            "Epoch: [95]  [290/295]  eta: 0:00:01  lr: 0.000026  min_lr: 0.000026  loss: 3.1212 (3.0339)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0002  max mem: 3500\n",
            "Epoch: [95]  [294/295]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 3.1212 (3.0334)  weight_decay: 0.0500 (0.0500)  time: 0.2217  data: 0.0002  max mem: 3500\n",
            "Epoch: [95] Total time: 0:01:20 (0.2732 s / it)\n",
            "Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 3.1212 (3.0334)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:57  loss: 0.5926 (0.5926)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.8979  data: 2.7362  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:27  loss: 0.5712 (0.5703)  acc1: 91.6667 (92.2349)  acc5: 97.9167 (97.9167)  time: 0.3829  data: 0.2497  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.5712 (0.5830)  acc1: 93.7500 (91.7659)  acc5: 100.0000 (98.3135)  time: 0.1276  data: 0.0028  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:11  loss: 0.6809 (0.7415)  acc1: 87.5000 (86.0215)  acc5: 97.9167 (98.2527)  time: 0.1237  data: 0.0048  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 0.7235 (0.7231)  acc1: 85.4167 (86.7378)  acc5: 97.9167 (98.4248)  time: 0.1221  data: 0.0032  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7097 (0.7329)  acc1: 85.4167 (86.2337)  acc5: 100.0000 (98.4886)  time: 0.1210  data: 0.0014  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.8020 (0.7373)  acc1: 85.4167 (85.9290)  acc5: 100.0000 (98.5656)  time: 0.1224  data: 0.0037  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8387 (0.7558)  acc1: 85.4167 (85.2113)  acc5: 100.0000 (98.4155)  time: 0.1202  data: 0.0030  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7395 (0.7402)  acc1: 87.5000 (85.6739)  acc5: 100.0000 (98.4311)  time: 0.1174  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7395 (0.7423)  acc1: 87.5000 (85.6561)  acc5: 100.0000 (98.3949)  time: 0.1162  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1632 s / it)\n",
            "* Acc@1 85.656 Acc@5 98.395 loss 0.742\n",
            "Accuracy of the model on the 3925 test images: 85.7%\n",
            "Max accuracy: 85.68%\n",
            "Test:  [ 0/82]  eta: 0:04:26  loss: 1.3835 (1.3835)  acc1: 52.0833 (52.0833)  acc5: 97.9167 (97.9167)  time: 3.2508  data: 3.0464  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:31  loss: 1.5289 (1.7934)  acc1: 41.6667 (36.7424)  acc5: 97.9167 (98.6742)  time: 0.4345  data: 0.2835  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:18  loss: 2.4445 (2.2342)  acc1: 20.8333 (25.9921)  acc5: 97.9167 (96.8254)  time: 0.1561  data: 0.0162  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 2.8636 (2.8142)  acc1: 8.3333 (18.8844)  acc5: 89.5833 (83.1989)  time: 0.1420  data: 0.0151  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 2.8974 (2.7911)  acc1: 12.5000 (21.4939)  acc5: 77.0833 (83.5366)  time: 0.1245  data: 0.0061  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.4834 (3.0713)  acc1: 8.3333 (18.0964)  acc5: 68.7500 (76.3072)  time: 0.1236  data: 0.0050  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 4.0508 (3.1532)  acc1: 4.1667 (15.9153)  acc5: 41.6667 (74.5902)  time: 0.1235  data: 0.0032  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.2602 (3.0326)  acc1: 4.1667 (19.6890)  acc5: 77.0833 (74.4718)  time: 0.1221  data: 0.0021  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8830 (2.7558)  acc1: 72.9167 (27.0833)  acc5: 97.9167 (77.4691)  time: 0.1194  data: 0.0005  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8830 (2.7343)  acc1: 72.9167 (27.4904)  acc5: 97.9167 (77.6306)  time: 0.1173  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1731 s / it)\n",
            "* Acc@1 27.490 Acc@5 77.631 loss 2.734\n",
            "Accuracy of the model EMA on 3925 test images: 27.5%\n",
            "Max EMA accuracy: 27.49%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [96]  [  0/295]  eta: 0:13:20  lr: 0.000026  min_lr: 0.000026  loss: 3.1297 (3.1297)  weight_decay: 0.0500 (0.0500)  time: 2.7144  data: 2.1361  max mem: 3500\n",
            "Epoch: [96]  [ 10/295]  eta: 0:02:39  lr: 0.000025  min_lr: 0.000025  loss: 3.1135 (3.0776)  weight_decay: 0.0500 (0.0500)  time: 0.5611  data: 0.1969  max mem: 3500\n",
            "Epoch: [96]  [ 20/295]  eta: 0:01:55  lr: 0.000025  min_lr: 0.000025  loss: 3.0934 (3.0614)  weight_decay: 0.0500 (0.0500)  time: 0.3037  data: 0.0017  max mem: 3500\n",
            "Epoch: [96]  [ 30/295]  eta: 0:01:37  lr: 0.000024  min_lr: 0.000024  loss: 3.1298 (3.0726)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0014  max mem: 3500\n",
            "Epoch: [96]  [ 40/295]  eta: 0:01:27  lr: 0.000024  min_lr: 0.000024  loss: 3.0999 (3.0389)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0018  max mem: 3500\n",
            "Epoch: [96]  [ 50/295]  eta: 0:01:20  lr: 0.000024  min_lr: 0.000024  loss: 2.9381 (3.0345)  weight_decay: 0.0500 (0.0500)  time: 0.2636  data: 0.0015  max mem: 3500\n",
            "Epoch: [96]  [ 60/295]  eta: 0:01:14  lr: 0.000023  min_lr: 0.000023  loss: 2.9381 (3.0258)  weight_decay: 0.0500 (0.0500)  time: 0.2694  data: 0.0019  max mem: 3500\n",
            "Epoch: [96]  [ 70/295]  eta: 0:01:10  lr: 0.000023  min_lr: 0.000023  loss: 3.0332 (3.0362)  weight_decay: 0.0500 (0.0500)  time: 0.2746  data: 0.0025  max mem: 3500\n",
            "Epoch: [96]  [ 80/295]  eta: 0:01:05  lr: 0.000022  min_lr: 0.000022  loss: 3.1599 (3.0437)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0018  max mem: 3500\n",
            "Epoch: [96]  [ 90/295]  eta: 0:01:01  lr: 0.000022  min_lr: 0.000022  loss: 3.1222 (3.0321)  weight_decay: 0.0500 (0.0500)  time: 0.2645  data: 0.0012  max mem: 3500\n",
            "Epoch: [96]  [100/295]  eta: 0:00:58  lr: 0.000022  min_lr: 0.000022  loss: 2.9851 (3.0274)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0009  max mem: 3500\n",
            "Epoch: [96]  [110/295]  eta: 0:00:54  lr: 0.000021  min_lr: 0.000021  loss: 2.9851 (3.0228)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0004  max mem: 3500\n",
            "Epoch: [96]  [120/295]  eta: 0:00:51  lr: 0.000021  min_lr: 0.000021  loss: 3.0106 (3.0200)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0008  max mem: 3500\n",
            "Epoch: [96]  [130/295]  eta: 0:00:47  lr: 0.000021  min_lr: 0.000021  loss: 3.0782 (3.0250)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0015  max mem: 3500\n",
            "Epoch: [96]  [140/295]  eta: 0:00:44  lr: 0.000020  min_lr: 0.000020  loss: 3.1628 (3.0306)  weight_decay: 0.0500 (0.0500)  time: 0.2711  data: 0.0019  max mem: 3500\n",
            "Epoch: [96]  [150/295]  eta: 0:00:41  lr: 0.000020  min_lr: 0.000020  loss: 3.0733 (3.0304)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0025  max mem: 3500\n",
            "Epoch: [96]  [160/295]  eta: 0:00:38  lr: 0.000019  min_lr: 0.000019  loss: 3.0517 (3.0282)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0024  max mem: 3500\n",
            "Epoch: [96]  [170/295]  eta: 0:00:35  lr: 0.000019  min_lr: 0.000019  loss: 3.0466 (3.0291)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0014  max mem: 3500\n",
            "Epoch: [96]  [180/295]  eta: 0:00:32  lr: 0.000019  min_lr: 0.000019  loss: 3.0496 (3.0345)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0010  max mem: 3500\n",
            "Epoch: [96]  [190/295]  eta: 0:00:29  lr: 0.000018  min_lr: 0.000018  loss: 3.0576 (3.0362)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0023  max mem: 3500\n",
            "Epoch: [96]  [200/295]  eta: 0:00:26  lr: 0.000018  min_lr: 0.000018  loss: 3.0028 (3.0358)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0033  max mem: 3500\n",
            "Epoch: [96]  [210/295]  eta: 0:00:23  lr: 0.000018  min_lr: 0.000018  loss: 3.0353 (3.0364)  weight_decay: 0.0500 (0.0500)  time: 0.2728  data: 0.0034  max mem: 3500\n",
            "Epoch: [96]  [220/295]  eta: 0:00:21  lr: 0.000017  min_lr: 0.000017  loss: 2.9751 (3.0360)  weight_decay: 0.0500 (0.0500)  time: 0.2764  data: 0.0042  max mem: 3500\n",
            "Epoch: [96]  [230/295]  eta: 0:00:18  lr: 0.000017  min_lr: 0.000017  loss: 2.9906 (3.0357)  weight_decay: 0.0500 (0.0500)  time: 0.2737  data: 0.0025  max mem: 3500\n",
            "Epoch: [96]  [240/295]  eta: 0:00:15  lr: 0.000017  min_lr: 0.000017  loss: 2.9877 (3.0333)  weight_decay: 0.0500 (0.0500)  time: 0.2652  data: 0.0016  max mem: 3500\n",
            "Epoch: [96]  [250/295]  eta: 0:00:12  lr: 0.000016  min_lr: 0.000016  loss: 2.9043 (3.0299)  weight_decay: 0.0500 (0.0500)  time: 0.2594  data: 0.0017  max mem: 3500\n",
            "Epoch: [96]  [260/295]  eta: 0:00:09  lr: 0.000016  min_lr: 0.000016  loss: 3.0684 (3.0319)  weight_decay: 0.0500 (0.0500)  time: 0.2586  data: 0.0015  max mem: 3500\n",
            "Epoch: [96]  [270/295]  eta: 0:00:06  lr: 0.000016  min_lr: 0.000016  loss: 3.0699 (3.0310)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0025  max mem: 3500\n",
            "Epoch: [96]  [280/295]  eta: 0:00:04  lr: 0.000015  min_lr: 0.000015  loss: 3.1130 (3.0327)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0019  max mem: 3500\n",
            "Epoch: [96]  [290/295]  eta: 0:00:01  lr: 0.000015  min_lr: 0.000015  loss: 3.0205 (3.0284)  weight_decay: 0.0500 (0.0500)  time: 0.2614  data: 0.0005  max mem: 3500\n",
            "Epoch: [96]  [294/295]  eta: 0:00:00  lr: 0.000015  min_lr: 0.000015  loss: 3.0205 (3.0287)  weight_decay: 0.0500 (0.0500)  time: 0.2209  data: 0.0002  max mem: 3500\n",
            "Epoch: [96] Total time: 0:01:21 (0.2754 s / it)\n",
            "Averaged stats: lr: 0.000015  min_lr: 0.000015  loss: 3.0205 (3.0287)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:03  loss: 0.6017 (0.6017)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 1.5028  data: 1.3242  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:23  loss: 0.5770 (0.5761)  acc1: 91.6667 (92.2349)  acc5: 97.9167 (97.9167)  time: 0.3240  data: 0.1945  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 0.5770 (0.5884)  acc1: 93.7500 (91.6667)  acc5: 100.0000 (98.3135)  time: 0.1645  data: 0.0421  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6896 (0.7449)  acc1: 87.5000 (86.1559)  acc5: 97.9167 (98.2527)  time: 0.1215  data: 0.0031  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7247 (0.7260)  acc1: 85.4167 (86.8902)  acc5: 97.9167 (98.4248)  time: 0.1222  data: 0.0047  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7094 (0.7342)  acc1: 85.4167 (86.3562)  acc5: 100.0000 (98.5294)  time: 0.1226  data: 0.0048  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7937 (0.7385)  acc1: 85.4167 (86.0314)  acc5: 100.0000 (98.5997)  time: 0.1314  data: 0.0028  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8392 (0.7563)  acc1: 85.4167 (85.2993)  acc5: 100.0000 (98.4742)  time: 0.1368  data: 0.0013  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7370 (0.7390)  acc1: 87.5000 (85.8282)  acc5: 100.0000 (98.4825)  time: 0.1244  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7370 (0.7408)  acc1: 87.5000 (85.8344)  acc5: 100.0000 (98.4459)  time: 0.1208  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1591 s / it)\n",
            "* Acc@1 85.834 Acc@5 98.446 loss 0.741\n",
            "Accuracy of the model on the 3925 test images: 85.8%\n",
            "Max accuracy: 85.83%\n",
            "Test:  [ 0/82]  eta: 0:03:23  loss: 1.3494 (1.3494)  acc1: 52.0833 (52.0833)  acc5: 97.9167 (97.9167)  time: 2.4822  data: 2.3204  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:24  loss: 1.4967 (1.7612)  acc1: 43.7500 (37.5000)  acc5: 97.9167 (98.6742)  time: 0.3417  data: 0.2163  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:14  loss: 2.4144 (2.2065)  acc1: 22.9167 (26.4881)  acc5: 97.9167 (96.8254)  time: 0.1255  data: 0.0042  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 2.8357 (2.7863)  acc1: 8.3333 (19.3548)  acc5: 89.5833 (83.4005)  time: 0.1234  data: 0.0037  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.8853 (2.7612)  acc1: 14.5833 (22.0528)  acc5: 77.0833 (83.9431)  time: 0.1232  data: 0.0055  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.4473 (3.0412)  acc1: 8.3333 (18.5866)  acc5: 68.7500 (76.6748)  time: 0.1234  data: 0.0049  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 4.0096 (3.1215)  acc1: 4.1667 (16.3934)  acc5: 41.6667 (74.8975)  time: 0.1260  data: 0.0049  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.2221 (3.0025)  acc1: 4.1667 (20.1291)  acc5: 77.0833 (74.7653)  time: 0.1234  data: 0.0034  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8773 (2.7287)  acc1: 72.9167 (27.4691)  acc5: 97.9167 (77.7263)  time: 0.1184  data: 0.0004  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8773 (2.7074)  acc1: 72.9167 (27.8726)  acc5: 97.9167 (77.8854)  time: 0.1171  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1591 s / it)\n",
            "* Acc@1 27.873 Acc@5 77.885 loss 2.707\n",
            "Accuracy of the model EMA on 3925 test images: 27.9%\n",
            "Max EMA accuracy: 27.87%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [97]  [  0/295]  eta: 0:14:19  lr: 0.000015  min_lr: 0.000015  loss: 3.1916 (3.1916)  weight_decay: 0.0500 (0.0500)  time: 2.9144  data: 2.2425  max mem: 3500\n",
            "Epoch: [97]  [ 10/295]  eta: 0:02:34  lr: 0.000015  min_lr: 0.000015  loss: 3.1900 (3.0400)  weight_decay: 0.0500 (0.0500)  time: 0.5417  data: 0.2069  max mem: 3500\n",
            "Epoch: [97]  [ 20/295]  eta: 0:01:52  lr: 0.000014  min_lr: 0.000014  loss: 3.1900 (3.0725)  weight_decay: 0.0500 (0.0500)  time: 0.2828  data: 0.0020  max mem: 3500\n",
            "Epoch: [97]  [ 30/295]  eta: 0:01:35  lr: 0.000014  min_lr: 0.000014  loss: 3.2112 (3.0863)  weight_decay: 0.0500 (0.0500)  time: 0.2604  data: 0.0005  max mem: 3500\n",
            "Epoch: [97]  [ 40/295]  eta: 0:01:25  lr: 0.000014  min_lr: 0.000014  loss: 3.1791 (3.0776)  weight_decay: 0.0500 (0.0500)  time: 0.2620  data: 0.0008  max mem: 3500\n",
            "Epoch: [97]  [ 50/295]  eta: 0:01:19  lr: 0.000013  min_lr: 0.000013  loss: 3.1525 (3.0660)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0010  max mem: 3500\n",
            "Epoch: [97]  [ 60/295]  eta: 0:01:14  lr: 0.000013  min_lr: 0.000013  loss: 2.9174 (3.0359)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0023  max mem: 3500\n",
            "Epoch: [97]  [ 70/295]  eta: 0:01:09  lr: 0.000013  min_lr: 0.000013  loss: 2.9673 (3.0283)  weight_decay: 0.0500 (0.0500)  time: 0.2716  data: 0.0026  max mem: 3500\n",
            "Epoch: [97]  [ 80/295]  eta: 0:01:05  lr: 0.000012  min_lr: 0.000012  loss: 3.0519 (3.0312)  weight_decay: 0.0500 (0.0500)  time: 0.2666  data: 0.0012  max mem: 3500\n",
            "Epoch: [97]  [ 90/295]  eta: 0:01:01  lr: 0.000012  min_lr: 0.000012  loss: 3.1757 (3.0339)  weight_decay: 0.0500 (0.0500)  time: 0.2646  data: 0.0009  max mem: 3500\n",
            "Epoch: [97]  [100/295]  eta: 0:00:57  lr: 0.000012  min_lr: 0.000012  loss: 2.9949 (3.0229)  weight_decay: 0.0500 (0.0500)  time: 0.2637  data: 0.0012  max mem: 3500\n",
            "Epoch: [97]  [110/295]  eta: 0:00:54  lr: 0.000012  min_lr: 0.000012  loss: 2.9406 (3.0211)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0013  max mem: 3500\n",
            "Epoch: [97]  [120/295]  eta: 0:00:51  lr: 0.000011  min_lr: 0.000011  loss: 3.0482 (3.0272)  weight_decay: 0.0500 (0.0500)  time: 0.2723  data: 0.0019  max mem: 3500\n",
            "Epoch: [97]  [130/295]  eta: 0:00:47  lr: 0.000011  min_lr: 0.000011  loss: 3.1248 (3.0390)  weight_decay: 0.0500 (0.0500)  time: 0.2753  data: 0.0038  max mem: 3500\n",
            "Epoch: [97]  [140/295]  eta: 0:00:44  lr: 0.000011  min_lr: 0.000011  loss: 3.1868 (3.0443)  weight_decay: 0.0500 (0.0500)  time: 0.2689  data: 0.0031  max mem: 3500\n",
            "Epoch: [97]  [150/295]  eta: 0:00:41  lr: 0.000011  min_lr: 0.000011  loss: 3.1455 (3.0427)  weight_decay: 0.0500 (0.0500)  time: 0.2634  data: 0.0016  max mem: 3500\n",
            "Epoch: [97]  [160/295]  eta: 0:00:38  lr: 0.000010  min_lr: 0.000010  loss: 2.9594 (3.0387)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0012  max mem: 3500\n",
            "Epoch: [97]  [170/295]  eta: 0:00:35  lr: 0.000010  min_lr: 0.000010  loss: 3.0321 (3.0413)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0015  max mem: 3500\n",
            "Epoch: [97]  [180/295]  eta: 0:00:32  lr: 0.000010  min_lr: 0.000010  loss: 3.1549 (3.0462)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0024  max mem: 3500\n",
            "Epoch: [97]  [190/295]  eta: 0:00:29  lr: 0.000010  min_lr: 0.000010  loss: 3.1132 (3.0411)  weight_decay: 0.0500 (0.0500)  time: 0.2721  data: 0.0032  max mem: 3500\n",
            "Epoch: [97]  [200/295]  eta: 0:00:26  lr: 0.000009  min_lr: 0.000009  loss: 3.0663 (3.0422)  weight_decay: 0.0500 (0.0500)  time: 0.2686  data: 0.0032  max mem: 3500\n",
            "Epoch: [97]  [210/295]  eta: 0:00:23  lr: 0.000009  min_lr: 0.000009  loss: 3.0058 (3.0367)  weight_decay: 0.0500 (0.0500)  time: 0.2639  data: 0.0017  max mem: 3500\n",
            "Epoch: [97]  [220/295]  eta: 0:00:20  lr: 0.000009  min_lr: 0.000009  loss: 3.0738 (3.0373)  weight_decay: 0.0500 (0.0500)  time: 0.2591  data: 0.0013  max mem: 3500\n",
            "Epoch: [97]  [230/295]  eta: 0:00:18  lr: 0.000009  min_lr: 0.000009  loss: 3.1681 (3.0423)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0014  max mem: 3500\n",
            "Epoch: [97]  [240/295]  eta: 0:00:15  lr: 0.000008  min_lr: 0.000008  loss: 3.1652 (3.0454)  weight_decay: 0.0500 (0.0500)  time: 0.2608  data: 0.0017  max mem: 3500\n",
            "Epoch: [97]  [250/295]  eta: 0:00:12  lr: 0.000008  min_lr: 0.000008  loss: 3.0035 (3.0454)  weight_decay: 0.0500 (0.0500)  time: 0.2664  data: 0.0015  max mem: 3500\n",
            "Epoch: [97]  [260/295]  eta: 0:00:09  lr: 0.000008  min_lr: 0.000008  loss: 3.0035 (3.0469)  weight_decay: 0.0500 (0.0500)  time: 0.2709  data: 0.0015  max mem: 3500\n",
            "Epoch: [97]  [270/295]  eta: 0:00:06  lr: 0.000008  min_lr: 0.000008  loss: 2.9266 (3.0430)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0020  max mem: 3500\n",
            "Epoch: [97]  [280/295]  eta: 0:00:04  lr: 0.000007  min_lr: 0.000007  loss: 2.9397 (3.0434)  weight_decay: 0.0500 (0.0500)  time: 0.2610  data: 0.0010  max mem: 3500\n",
            "Epoch: [97]  [290/295]  eta: 0:00:01  lr: 0.000007  min_lr: 0.000007  loss: 3.1369 (3.0468)  weight_decay: 0.0500 (0.0500)  time: 0.2568  data: 0.0002  max mem: 3500\n",
            "Epoch: [97]  [294/295]  eta: 0:00:00  lr: 0.000007  min_lr: 0.000007  loss: 3.1369 (3.0468)  weight_decay: 0.0500 (0.0500)  time: 0.2186  data: 0.0002  max mem: 3500\n",
            "Epoch: [97] Total time: 0:01:20 (0.2745 s / it)\n",
            "Averaged stats: lr: 0.000007  min_lr: 0.000007  loss: 3.1369 (3.0468)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:46  loss: 0.6037 (0.6037)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.0355  data: 1.8303  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.5775 (0.5761)  acc1: 91.6667 (92.4242)  acc5: 97.9167 (97.9167)  time: 0.3613  data: 0.2111  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:16  loss: 0.5775 (0.5866)  acc1: 93.7500 (91.8651)  acc5: 100.0000 (98.3135)  time: 0.1752  data: 0.0314  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 0.6860 (0.7442)  acc1: 87.5000 (86.1559)  acc5: 97.9167 (98.2527)  time: 0.1756  data: 0.0295  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:09  loss: 0.7276 (0.7262)  acc1: 85.4167 (86.9411)  acc5: 97.9167 (98.4248)  time: 0.1724  data: 0.0240  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 0.7101 (0.7348)  acc1: 85.4167 (86.3971)  acc5: 100.0000 (98.4886)  time: 0.1493  data: 0.0109  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:04  loss: 0.7933 (0.7395)  acc1: 83.3333 (86.0314)  acc5: 100.0000 (98.5997)  time: 0.1440  data: 0.0179  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 0.8362 (0.7570)  acc1: 83.3333 (85.2993)  acc5: 100.0000 (98.4742)  time: 0.1285  data: 0.0084  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7356 (0.7398)  acc1: 87.5000 (85.8025)  acc5: 100.0000 (98.4825)  time: 0.1176  data: 0.0001  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7356 (0.7417)  acc1: 87.5000 (85.8089)  acc5: 100.0000 (98.4459)  time: 0.1166  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:14 (0.1791 s / it)\n",
            "* Acc@1 85.809 Acc@5 98.446 loss 0.742\n",
            "Accuracy of the model on the 3925 test images: 85.8%\n",
            "Max accuracy: 85.83%\n",
            "Test:  [ 0/82]  eta: 0:02:20  loss: 1.3163 (1.3163)  acc1: 52.0833 (52.0833)  acc5: 97.9167 (97.9167)  time: 1.7131  data: 1.5497  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:19  loss: 1.4655 (1.7297)  acc1: 45.8333 (39.2045)  acc5: 97.9167 (98.6742)  time: 0.2740  data: 0.1478  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:12  loss: 2.3842 (2.1793)  acc1: 22.9167 (27.4802)  acc5: 97.9167 (96.8254)  time: 0.1288  data: 0.0045  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.8267 (2.7588)  acc1: 8.3333 (20.0269)  acc5: 89.5833 (83.6022)  time: 0.1246  data: 0.0028  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.8733 (2.7317)  acc1: 14.5833 (22.6626)  acc5: 77.0833 (84.1972)  time: 0.1389  data: 0.0032  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.4117 (3.0114)  acc1: 8.3333 (19.0768)  acc5: 68.7500 (76.8382)  time: 0.1601  data: 0.0016  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.9687 (3.0901)  acc1: 4.1667 (16.8374)  acc5: 41.6667 (75.1025)  time: 0.1480  data: 0.0020  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.1846 (2.9726)  acc1: 4.1667 (20.5399)  acc5: 77.0833 (74.9413)  time: 0.1508  data: 0.0147  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8718 (2.7018)  acc1: 72.9167 (27.8292)  acc5: 97.9167 (77.8807)  time: 0.1513  data: 0.0195  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8718 (2.6809)  acc1: 72.9167 (28.2293)  acc5: 97.9167 (78.0382)  time: 0.1369  data: 0.0064  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1678 s / it)\n",
            "* Acc@1 28.229 Acc@5 78.038 loss 2.681\n",
            "Accuracy of the model EMA on 3925 test images: 28.2%\n",
            "Max EMA accuracy: 28.23%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [98]  [  0/295]  eta: 0:15:46  lr: 0.000007  min_lr: 0.000007  loss: 2.9329 (2.9329)  weight_decay: 0.0500 (0.0500)  time: 3.2094  data: 2.6890  max mem: 3500\n",
            "Epoch: [98]  [ 10/295]  eta: 0:02:45  lr: 0.000007  min_lr: 0.000007  loss: 3.0378 (3.1152)  weight_decay: 0.0500 (0.0500)  time: 0.5793  data: 0.2517  max mem: 3500\n",
            "Epoch: [98]  [ 20/295]  eta: 0:01:58  lr: 0.000007  min_lr: 0.000007  loss: 3.1839 (3.1471)  weight_decay: 0.0500 (0.0500)  time: 0.2907  data: 0.0050  max mem: 3500\n",
            "Epoch: [98]  [ 30/295]  eta: 0:01:40  lr: 0.000007  min_lr: 0.000007  loss: 3.1132 (3.1043)  weight_decay: 0.0500 (0.0500)  time: 0.2663  data: 0.0024  max mem: 3500\n",
            "Epoch: [98]  [ 40/295]  eta: 0:01:29  lr: 0.000006  min_lr: 0.000006  loss: 3.1132 (3.1098)  weight_decay: 0.0500 (0.0500)  time: 0.2700  data: 0.0042  max mem: 3500\n",
            "Epoch: [98]  [ 50/295]  eta: 0:01:22  lr: 0.000006  min_lr: 0.000006  loss: 3.1643 (3.0984)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0049  max mem: 3500\n",
            "Epoch: [98]  [ 60/295]  eta: 0:01:16  lr: 0.000006  min_lr: 0.000006  loss: 2.9284 (3.0711)  weight_decay: 0.0500 (0.0500)  time: 0.2660  data: 0.0029  max mem: 3500\n",
            "Epoch: [98]  [ 70/295]  eta: 0:01:10  lr: 0.000006  min_lr: 0.000006  loss: 3.0234 (3.0782)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0016  max mem: 3500\n",
            "Epoch: [98]  [ 80/295]  eta: 0:01:06  lr: 0.000006  min_lr: 0.000006  loss: 3.1380 (3.0671)  weight_decay: 0.0500 (0.0500)  time: 0.2632  data: 0.0013  max mem: 3500\n",
            "Epoch: [98]  [ 90/295]  eta: 0:01:02  lr: 0.000005  min_lr: 0.000005  loss: 3.0826 (3.0678)  weight_decay: 0.0500 (0.0500)  time: 0.2649  data: 0.0016  max mem: 3500\n",
            "Epoch: [98]  [100/295]  eta: 0:00:58  lr: 0.000005  min_lr: 0.000005  loss: 3.0252 (3.0565)  weight_decay: 0.0500 (0.0500)  time: 0.2715  data: 0.0032  max mem: 3500\n",
            "Epoch: [98]  [110/295]  eta: 0:00:55  lr: 0.000005  min_lr: 0.000005  loss: 3.0348 (3.0594)  weight_decay: 0.0500 (0.0500)  time: 0.2758  data: 0.0049  max mem: 3500\n",
            "Epoch: [98]  [120/295]  eta: 0:00:51  lr: 0.000005  min_lr: 0.000005  loss: 3.1456 (3.0493)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0045  max mem: 3500\n",
            "Epoch: [98]  [130/295]  eta: 0:00:48  lr: 0.000005  min_lr: 0.000005  loss: 3.0018 (3.0503)  weight_decay: 0.0500 (0.0500)  time: 0.2633  data: 0.0024  max mem: 3500\n",
            "Epoch: [98]  [140/295]  eta: 0:00:45  lr: 0.000005  min_lr: 0.000005  loss: 3.0224 (3.0517)  weight_decay: 0.0500 (0.0500)  time: 0.2607  data: 0.0013  max mem: 3500\n",
            "Epoch: [98]  [150/295]  eta: 0:00:41  lr: 0.000004  min_lr: 0.000004  loss: 3.0224 (3.0490)  weight_decay: 0.0500 (0.0500)  time: 0.2602  data: 0.0015  max mem: 3500\n",
            "Epoch: [98]  [160/295]  eta: 0:00:38  lr: 0.000004  min_lr: 0.000004  loss: 3.0276 (3.0448)  weight_decay: 0.0500 (0.0500)  time: 0.2665  data: 0.0028  max mem: 3500\n",
            "Epoch: [98]  [170/295]  eta: 0:00:35  lr: 0.000004  min_lr: 0.000004  loss: 2.9775 (3.0360)  weight_decay: 0.0500 (0.0500)  time: 0.2725  data: 0.0048  max mem: 3500\n",
            "Epoch: [98]  [180/295]  eta: 0:00:32  lr: 0.000004  min_lr: 0.000004  loss: 2.8012 (3.0312)  weight_decay: 0.0500 (0.0500)  time: 0.2699  data: 0.0039  max mem: 3500\n",
            "Epoch: [98]  [190/295]  eta: 0:00:29  lr: 0.000004  min_lr: 0.000004  loss: 3.1080 (3.0343)  weight_decay: 0.0500 (0.0500)  time: 0.2631  data: 0.0016  max mem: 3500\n",
            "Epoch: [98]  [200/295]  eta: 0:00:26  lr: 0.000004  min_lr: 0.000004  loss: 3.1048 (3.0340)  weight_decay: 0.0500 (0.0500)  time: 0.2589  data: 0.0012  max mem: 3500\n",
            "Epoch: [98]  [210/295]  eta: 0:00:23  lr: 0.000004  min_lr: 0.000004  loss: 2.9494 (3.0325)  weight_decay: 0.0500 (0.0500)  time: 0.2595  data: 0.0013  max mem: 3500\n",
            "Epoch: [98]  [220/295]  eta: 0:00:21  lr: 0.000003  min_lr: 0.000003  loss: 2.9366 (3.0275)  weight_decay: 0.0500 (0.0500)  time: 0.2628  data: 0.0025  max mem: 3500\n",
            "Epoch: [98]  [230/295]  eta: 0:00:18  lr: 0.000003  min_lr: 0.000003  loss: 2.9463 (3.0289)  weight_decay: 0.0500 (0.0500)  time: 0.2684  data: 0.0034  max mem: 3500\n",
            "Epoch: [98]  [240/295]  eta: 0:00:15  lr: 0.000003  min_lr: 0.000003  loss: 3.1664 (3.0303)  weight_decay: 0.0500 (0.0500)  time: 0.2727  data: 0.0041  max mem: 3500\n",
            "Epoch: [98]  [250/295]  eta: 0:00:12  lr: 0.000003  min_lr: 0.000003  loss: 3.0705 (3.0288)  weight_decay: 0.0500 (0.0500)  time: 0.2696  data: 0.0035  max mem: 3500\n",
            "Epoch: [98]  [260/295]  eta: 0:00:09  lr: 0.000003  min_lr: 0.000003  loss: 3.0302 (3.0279)  weight_decay: 0.0500 (0.0500)  time: 0.2629  data: 0.0015  max mem: 3500\n",
            "Epoch: [98]  [270/295]  eta: 0:00:06  lr: 0.000003  min_lr: 0.000003  loss: 2.9796 (3.0250)  weight_decay: 0.0500 (0.0500)  time: 0.2603  data: 0.0015  max mem: 3500\n",
            "Epoch: [98]  [280/295]  eta: 0:00:04  lr: 0.000003  min_lr: 0.000003  loss: 2.9731 (3.0249)  weight_decay: 0.0500 (0.0500)  time: 0.2590  data: 0.0012  max mem: 3500\n",
            "Epoch: [98]  [290/295]  eta: 0:00:01  lr: 0.000003  min_lr: 0.000003  loss: 2.9623 (3.0230)  weight_decay: 0.0500 (0.0500)  time: 0.2585  data: 0.0003  max mem: 3500\n",
            "Epoch: [98]  [294/295]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000003  loss: 2.9731 (3.0236)  weight_decay: 0.0500 (0.0500)  time: 0.2208  data: 0.0002  max mem: 3500\n",
            "Epoch: [98] Total time: 0:01:21 (0.2765 s / it)\n",
            "Averaged stats: lr: 0.000003  min_lr: 0.000003  loss: 2.9731 (3.0236)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:03:45  loss: 0.6059 (0.6059)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.7475  data: 2.5855  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:26  loss: 0.5793 (0.5779)  acc1: 91.6667 (92.0455)  acc5: 97.9167 (97.9167)  time: 0.3662  data: 0.2388  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:15  loss: 0.5793 (0.5893)  acc1: 93.7500 (91.7659)  acc5: 100.0000 (98.3135)  time: 0.1256  data: 0.0049  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:10  loss: 0.6860 (0.7449)  acc1: 87.5000 (86.0887)  acc5: 97.9167 (98.2527)  time: 0.1223  data: 0.0040  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7315 (0.7273)  acc1: 85.4167 (86.8902)  acc5: 97.9167 (98.4248)  time: 0.1233  data: 0.0018  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7136 (0.7348)  acc1: 85.4167 (86.4379)  acc5: 100.0000 (98.4886)  time: 0.1251  data: 0.0032  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7906 (0.7389)  acc1: 85.4167 (86.1680)  acc5: 100.0000 (98.5656)  time: 0.1241  data: 0.0050  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8358 (0.7566)  acc1: 85.4167 (85.4167)  acc5: 100.0000 (98.4155)  time: 0.1210  data: 0.0032  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7373 (0.7396)  acc1: 87.5000 (85.9054)  acc5: 100.0000 (98.4311)  time: 0.1186  data: 0.0008  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7373 (0.7415)  acc1: 87.5000 (85.8854)  acc5: 100.0000 (98.3949)  time: 0.1169  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1609 s / it)\n",
            "* Acc@1 85.885 Acc@5 98.395 loss 0.741\n",
            "Accuracy of the model on the 3925 test images: 85.9%\n",
            "Max accuracy: 85.89%\n",
            "Test:  [ 0/82]  eta: 0:03:55  loss: 1.2841 (1.2841)  acc1: 52.0833 (52.0833)  acc5: 97.9167 (97.9167)  time: 2.8699  data: 2.6870  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:30  loss: 1.4350 (1.6987)  acc1: 45.8333 (39.7727)  acc5: 97.9167 (98.6742)  time: 0.4243  data: 0.2766  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:17  loss: 2.3539 (2.1523)  acc1: 22.9167 (27.8770)  acc5: 97.9167 (96.7262)  time: 0.1612  data: 0.0183  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:12  loss: 2.8176 (2.7315)  acc1: 8.3333 (20.3629)  acc5: 89.5833 (83.6022)  time: 0.1323  data: 0.0019  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:08  loss: 2.8612 (2.7025)  acc1: 14.5833 (23.0183)  acc5: 77.0833 (84.3496)  time: 0.1237  data: 0.0029  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:06  loss: 3.3760 (2.9819)  acc1: 8.3333 (19.4036)  acc5: 68.7500 (76.9608)  time: 0.1258  data: 0.0037  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.9282 (3.0590)  acc1: 4.1667 (17.1790)  acc5: 41.6667 (75.2732)  time: 0.1257  data: 0.0037  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:02  loss: 3.1473 (2.9430)  acc1: 6.2500 (20.8627)  acc5: 79.1667 (75.0880)  time: 0.1218  data: 0.0023  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8665 (2.6752)  acc1: 72.9167 (28.1379)  acc5: 97.9167 (78.0093)  time: 0.1184  data: 0.0007  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8665 (2.6545)  acc1: 72.9167 (28.5350)  acc5: 97.9167 (78.1656)  time: 0.1171  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1701 s / it)\n",
            "* Acc@1 28.535 Acc@5 78.166 loss 2.655\n",
            "Accuracy of the model EMA on 3925 test images: 28.5%\n",
            "Max EMA accuracy: 28.54%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [99]  [  0/295]  eta: 0:15:24  lr: 0.000003  min_lr: 0.000003  loss: 3.3417 (3.3417)  weight_decay: 0.0500 (0.0500)  time: 3.1342  data: 2.5849  max mem: 3500\n",
            "Epoch: [99]  [ 10/295]  eta: 0:02:44  lr: 0.000002  min_lr: 0.000002  loss: 3.2935 (3.1785)  weight_decay: 0.0500 (0.0500)  time: 0.5776  data: 0.2380  max mem: 3500\n",
            "Epoch: [99]  [ 20/295]  eta: 0:01:58  lr: 0.000002  min_lr: 0.000002  loss: 3.1668 (3.1449)  weight_decay: 0.0500 (0.0500)  time: 0.2944  data: 0.0023  max mem: 3500\n",
            "Epoch: [99]  [ 30/295]  eta: 0:01:39  lr: 0.000002  min_lr: 0.000002  loss: 3.1395 (3.1450)  weight_decay: 0.0500 (0.0500)  time: 0.2650  data: 0.0014  max mem: 3500\n",
            "Epoch: [99]  [ 40/295]  eta: 0:01:28  lr: 0.000002  min_lr: 0.000002  loss: 3.1727 (3.1393)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0013  max mem: 3500\n",
            "Epoch: [99]  [ 50/295]  eta: 0:01:21  lr: 0.000002  min_lr: 0.000002  loss: 3.1727 (3.1221)  weight_decay: 0.0500 (0.0500)  time: 0.2630  data: 0.0010  max mem: 3500\n",
            "Epoch: [99]  [ 60/295]  eta: 0:01:15  lr: 0.000002  min_lr: 0.000002  loss: 3.1695 (3.1191)  weight_decay: 0.0500 (0.0500)  time: 0.2676  data: 0.0022  max mem: 3500\n",
            "Epoch: [99]  [ 70/295]  eta: 0:01:10  lr: 0.000002  min_lr: 0.000002  loss: 3.0044 (3.0908)  weight_decay: 0.0500 (0.0500)  time: 0.2714  data: 0.0025  max mem: 3500\n",
            "Epoch: [99]  [ 80/295]  eta: 0:01:06  lr: 0.000002  min_lr: 0.000002  loss: 2.9418 (3.0760)  weight_decay: 0.0500 (0.0500)  time: 0.2740  data: 0.0030  max mem: 3500\n",
            "Epoch: [99]  [ 90/295]  eta: 0:01:02  lr: 0.000002  min_lr: 0.000002  loss: 2.9007 (3.0653)  weight_decay: 0.0500 (0.0500)  time: 0.2701  data: 0.0028  max mem: 3500\n",
            "Epoch: [99]  [100/295]  eta: 0:00:58  lr: 0.000002  min_lr: 0.000002  loss: 3.0333 (3.0638)  weight_decay: 0.0500 (0.0500)  time: 0.2625  data: 0.0008  max mem: 3500\n",
            "Epoch: [99]  [110/295]  eta: 0:00:54  lr: 0.000002  min_lr: 0.000002  loss: 3.1138 (3.0662)  weight_decay: 0.0500 (0.0500)  time: 0.2617  data: 0.0008  max mem: 3500\n",
            "Epoch: [99]  [120/295]  eta: 0:00:51  lr: 0.000002  min_lr: 0.000002  loss: 3.1855 (3.0681)  weight_decay: 0.0500 (0.0500)  time: 0.2619  data: 0.0012  max mem: 3500\n",
            "Epoch: [99]  [130/295]  eta: 0:00:48  lr: 0.000001  min_lr: 0.000001  loss: 3.0926 (3.0628)  weight_decay: 0.0500 (0.0500)  time: 0.2674  data: 0.0031  max mem: 3500\n",
            "Epoch: [99]  [140/295]  eta: 0:00:45  lr: 0.000001  min_lr: 0.000001  loss: 3.0203 (3.0483)  weight_decay: 0.0500 (0.0500)  time: 0.2735  data: 0.0051  max mem: 3500\n",
            "Epoch: [99]  [150/295]  eta: 0:00:41  lr: 0.000001  min_lr: 0.000001  loss: 2.9342 (3.0488)  weight_decay: 0.0500 (0.0500)  time: 0.2688  data: 0.0039  max mem: 3500\n",
            "Epoch: [99]  [160/295]  eta: 0:00:38  lr: 0.000001  min_lr: 0.000001  loss: 3.0450 (3.0459)  weight_decay: 0.0500 (0.0500)  time: 0.2624  data: 0.0024  max mem: 3500\n",
            "Epoch: [99]  [170/295]  eta: 0:00:35  lr: 0.000001  min_lr: 0.000001  loss: 3.0141 (3.0418)  weight_decay: 0.0500 (0.0500)  time: 0.2601  data: 0.0023  max mem: 3500\n",
            "Epoch: [99]  [180/295]  eta: 0:00:32  lr: 0.000001  min_lr: 0.000001  loss: 3.0469 (3.0465)  weight_decay: 0.0500 (0.0500)  time: 0.2593  data: 0.0027  max mem: 3500\n",
            "Epoch: [99]  [190/295]  eta: 0:00:29  lr: 0.000001  min_lr: 0.000001  loss: 3.0016 (3.0417)  weight_decay: 0.0500 (0.0500)  time: 0.2642  data: 0.0034  max mem: 3500\n",
            "Epoch: [99]  [200/295]  eta: 0:00:26  lr: 0.000001  min_lr: 0.000001  loss: 2.9795 (3.0442)  weight_decay: 0.0500 (0.0500)  time: 0.2705  data: 0.0043  max mem: 3500\n",
            "Epoch: [99]  [210/295]  eta: 0:00:24  lr: 0.000001  min_lr: 0.000001  loss: 3.1665 (3.0486)  weight_decay: 0.0500 (0.0500)  time: 0.2739  data: 0.0056  max mem: 3500\n",
            "Epoch: [99]  [220/295]  eta: 0:00:21  lr: 0.000001  min_lr: 0.000001  loss: 3.0191 (3.0418)  weight_decay: 0.0500 (0.0500)  time: 0.2782  data: 0.0057  max mem: 3500\n",
            "Epoch: [99]  [230/295]  eta: 0:00:18  lr: 0.000001  min_lr: 0.000001  loss: 3.0305 (3.0402)  weight_decay: 0.0500 (0.0500)  time: 0.2754  data: 0.0036  max mem: 3500\n",
            "Epoch: [99]  [240/295]  eta: 0:00:15  lr: 0.000001  min_lr: 0.000001  loss: 3.0367 (3.0389)  weight_decay: 0.0500 (0.0500)  time: 0.2677  data: 0.0032  max mem: 3500\n",
            "Epoch: [99]  [250/295]  eta: 0:00:12  lr: 0.000001  min_lr: 0.000001  loss: 2.9870 (3.0366)  weight_decay: 0.0500 (0.0500)  time: 0.2626  data: 0.0032  max mem: 3500\n",
            "Epoch: [99]  [260/295]  eta: 0:00:09  lr: 0.000001  min_lr: 0.000001  loss: 3.0760 (3.0395)  weight_decay: 0.0500 (0.0500)  time: 0.2612  data: 0.0025  max mem: 3500\n",
            "Epoch: [99]  [270/295]  eta: 0:00:06  lr: 0.000001  min_lr: 0.000001  loss: 3.1289 (3.0379)  weight_decay: 0.0500 (0.0500)  time: 0.2659  data: 0.0032  max mem: 3500\n",
            "Epoch: [99]  [280/295]  eta: 0:00:04  lr: 0.000001  min_lr: 0.000001  loss: 3.0624 (3.0401)  weight_decay: 0.0500 (0.0500)  time: 0.2679  data: 0.0027  max mem: 3500\n",
            "Epoch: [99]  [290/295]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000001  loss: 3.0579 (3.0382)  weight_decay: 0.0500 (0.0500)  time: 0.2618  data: 0.0009  max mem: 3500\n",
            "Epoch: [99]  [294/295]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 3.0118 (3.0381)  weight_decay: 0.0500 (0.0500)  time: 0.2202  data: 0.0002  max mem: 3500\n",
            "Epoch: [99] Total time: 0:01:21 (0.2769 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 3.0118 (3.0381)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/82]  eta: 0:02:50  loss: 0.6057 (0.6057)  acc1: 91.6667 (91.6667)  acc5: 95.8333 (95.8333)  time: 2.0829  data: 1.9169  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:21  loss: 0.5791 (0.5777)  acc1: 91.6667 (92.0455)  acc5: 97.9167 (97.9167)  time: 0.2992  data: 0.1758  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 0.5791 (0.5890)  acc1: 93.7500 (91.6667)  acc5: 100.0000 (98.3135)  time: 0.1202  data: 0.0016  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 0.6865 (0.7447)  acc1: 87.5000 (86.0215)  acc5: 97.9167 (98.2527)  time: 0.1232  data: 0.0030  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 0.7324 (0.7274)  acc1: 85.4167 (86.8394)  acc5: 97.9167 (98.4248)  time: 0.1320  data: 0.0060  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 0.7147 (0.7345)  acc1: 85.4167 (86.3971)  acc5: 100.0000 (98.4886)  time: 0.1426  data: 0.0050  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 0.7882 (0.7388)  acc1: 85.4167 (86.0997)  acc5: 100.0000 (98.5656)  time: 0.1470  data: 0.0018  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 0.8362 (0.7567)  acc1: 85.4167 (85.3580)  acc5: 100.0000 (98.4155)  time: 0.1413  data: 0.0006  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.7381 (0.7397)  acc1: 87.5000 (85.8282)  acc5: 100.0000 (98.4311)  time: 0.1277  data: 0.0002  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.7381 (0.7416)  acc1: 87.5000 (85.8089)  acc5: 100.0000 (98.3949)  time: 0.1263  data: 0.0001  max mem: 3500\n",
            "Test: Total time: 0:00:13 (0.1625 s / it)\n",
            "* Acc@1 85.809 Acc@5 98.395 loss 0.742\n",
            "Accuracy of the model on the 3925 test images: 85.8%\n",
            "Max accuracy: 85.89%\n",
            "Test:  [ 0/82]  eta: 0:02:28  loss: 1.2527 (1.2527)  acc1: 54.1667 (54.1667)  acc5: 97.9167 (97.9167)  time: 1.8061  data: 1.6410  max mem: 3500\n",
            "Test:  [10/82]  eta: 0:00:22  loss: 1.4052 (1.6683)  acc1: 45.8333 (40.7197)  acc5: 97.9167 (98.6742)  time: 0.3080  data: 0.1789  max mem: 3500\n",
            "Test:  [20/82]  eta: 0:00:13  loss: 2.3237 (2.1255)  acc1: 22.9167 (28.6706)  acc5: 97.9167 (96.7262)  time: 0.1414  data: 0.0175  max mem: 3500\n",
            "Test:  [30/82]  eta: 0:00:09  loss: 2.8081 (2.7043)  acc1: 10.4167 (21.0349)  acc5: 89.5833 (83.8038)  time: 0.1256  data: 0.0036  max mem: 3500\n",
            "Test:  [40/82]  eta: 0:00:07  loss: 2.8489 (2.6736)  acc1: 16.6667 (23.6789)  acc5: 77.0833 (84.6037)  time: 0.1258  data: 0.0044  max mem: 3500\n",
            "Test:  [50/82]  eta: 0:00:05  loss: 3.3404 (2.9525)  acc1: 8.3333 (19.9346)  acc5: 68.7500 (77.2467)  time: 0.1264  data: 0.0070  max mem: 3500\n",
            "Test:  [60/82]  eta: 0:00:03  loss: 3.8879 (3.0281)  acc1: 6.2500 (17.7254)  acc5: 45.8333 (75.6831)  time: 0.1242  data: 0.0069  max mem: 3500\n",
            "Test:  [70/82]  eta: 0:00:01  loss: 3.1101 (2.9136)  acc1: 6.2500 (21.3615)  acc5: 79.1667 (75.4695)  time: 0.1201  data: 0.0020  max mem: 3500\n",
            "Test:  [80/82]  eta: 0:00:00  loss: 0.8609 (2.6488)  acc1: 72.9167 (28.5751)  acc5: 97.9167 (78.3693)  time: 0.1194  data: 0.0003  max mem: 3500\n",
            "Test:  [81/82]  eta: 0:00:00  loss: 0.8609 (2.6284)  acc1: 72.9167 (28.9682)  acc5: 97.9167 (78.5223)  time: 0.1176  data: 0.0002  max mem: 3500\n",
            "Test: Total time: 0:00:12 (0.1551 s / it)\n",
            "* Acc@1 28.968 Acc@5 78.522 loss 2.628\n",
            "Accuracy of the model EMA on 3925 test images: 29.0%\n",
            "Max EMA accuracy: 28.97%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/result_tiny3)... Done. 12.7s\n",
            "Training time 3:06:58\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▁▂▂▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema ▁▁▁▁▁▂▄▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▁▂▄▅▅▆▆▇▇▇▇▇▇▇▇█▇▇██████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema ▁▁▁▁▂▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss █▇▇▆▆▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema ████▇▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss █▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr ▁▂▃▄▅▅▆▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr ▁▂▃▄▅▅▆▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss ██▇▇▇▇▇█▆▇▅▆▅▆▆▃▆▆▄▄▄▅▄▆▄▆▆▂▄▅▃▄▁▃▂▂▁▂▁▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ▁▂▃▄▅▆▇▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ▁▂▃▄▅▆▇▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 85.80892\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema 28.96815\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 98.39491\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema 78.5223\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.74159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema 2.62839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 3.03807\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 7299\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 3.01176\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 28589128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mroyal-night-21\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/n6rm4r31\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230305_062535-n6rm4r31/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python main.py --model convnext_tiny --eval true \\\n",
        "                --resume /content/result_tiny3/checkpoint-best.pth \\\n",
        "                --input_size 160 --drop_path 0.1 \\\n",
        "                --data_path /content/imagenette2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDFUmPLgLKNV",
        "outputId": "9e731f8e-29f3-4de1-8e9b-30a211b22730"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_tiny3/checkpoint-best.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7f773899fb80>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f773899f6a0>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f773899ffa0>\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 28589128\n",
            "LR = 0.00400000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 147\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 2940\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_tiny3/checkpoint-best.pth\n",
            "With optim & sched!\n",
            "Eval only mode\n",
            "Test:  [ 0/41]  eta: 0:04:26  loss: 0.5618 (0.5618)  acc1: 91.6667 (91.6667)  acc5: 97.9167 (97.9167)  time: 6.5097  data: 2.8342  max mem: 2077\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5878 (0.5944)  acc1: 91.6667 (91.5720)  acc5: 97.9167 (98.2955)  time: 0.7876  data: 0.2588  max mem: 2077\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6373 (0.7265)  acc1: 89.5833 (86.8552)  acc5: 97.9167 (98.4127)  time: 0.2288  data: 0.0062  max mem: 2077\n",
            "Test:  [30/41]  eta: 0:00:04  loss: 0.7225 (0.7462)  acc1: 85.4167 (85.8871)  acc5: 98.9583 (98.5215)  time: 0.2332  data: 0.0057  max mem: 2077\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7045 (0.7411)  acc1: 85.4167 (85.8854)  acc5: 98.9583 (98.3949)  time: 0.2224  data: 0.0002  max mem: 2077\n",
            "Test: Total time: 0:00:16 (0.3934 s / it)\n",
            "* Acc@1 85.885 Acc@5 98.395 loss 0.741\n",
            "Accuracy of the network on 3925 test images: 85.88535%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "85.885% Acc@1, it is higher than the paper's result which is 82%. \n",
        "\n",
        "I might have overfit from the small dataset though, but my approach has been optimized to overcome overfitting: using Tiny Architecture and smaller batch size."
      ],
      "metadata": {
        "id": "Px_J1bv6ZR2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConvNeXt-S -- Batch 32, Augmentation Default\n",
        "- Batch size: 32\n",
        "- Epochs: 100\n",
        "- Update Freq: 4\n",
        "- Input Size: 160 (Imagenette2-160)\n",
        "- Learning rate: 0.004\n",
        "- Drop: 0.2"
      ],
      "metadata": {
        "id": "ubE0G9sZNYOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/result_small_1\n",
        "%cd /content/ConvNeXt\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n",
        "                                    --model convnext_small \\\n",
        "                                    --epochs 100 \\\n",
        "                                    --batch_size 64 \\\n",
        "                                    --lr 4e-3 \\\n",
        "                                    --update_freq 4 \\\n",
        "                                    --model_ema true \\\n",
        "                                    --model_ema_eval true \\\n",
        "                                    --aa original \\\n",
        "                                    --drop_path 0.1 \\\n",
        "                                    --opt adamw \\\n",
        "                                    --train_interpolation bicubic \\\n",
        "                                    --input_size 160 \\\n",
        "                                    --data_path /content/imagenette2-160 \\\n",
        "                                    --nb_classes 10 \\\n",
        "                                    --output_dir /content/result_small_1 \\\n",
        "                                    --log_dir /content/result_small_1 \\\n",
        "                                    --enable_wandb true --wandb_ckpt true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BgR8xGXNbyo",
        "outputId": "37512e2a-b950-4f86-edf0-ad56c4f00284"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: [10]  [146/147]  eta: 0:00:00  lr: 0.002197  min_lr: 0.002197  loss: 2.9072 (2.9511)  weight_decay: 0.0500 (0.0500)  time: 0.7234  data: 0.0002  max mem: 7679\n",
            "Epoch: [10] Total time: 0:02:08 (0.8729 s / it)\n",
            "Averaged stats: lr: 0.002197  min_lr: 0.002197  loss: 2.9072 (2.9511)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:02  loss: 1.3286 (1.3286)  acc1: 77.0833 (77.0833)  acc5: 91.6667 (91.6667)  time: 2.9963  data: 2.5350  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 1.6801 (1.7207)  acc1: 55.2083 (50.3788)  acc5: 90.6250 (89.4886)  time: 0.6483  data: 0.2396  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 1.9541 (1.9681)  acc1: 31.2500 (35.2679)  acc5: 84.3750 (82.7877)  time: 0.4117  data: 0.0059  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 2.0139 (1.9571)  acc1: 28.1250 (36.2231)  acc5: 82.2917 (83.6694)  time: 0.4061  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.8107 (1.8309)  acc1: 46.8750 (42.0382)  acc5: 88.2353 (85.4013)  time: 0.4015  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4799 s / it)\n",
            "* Acc@1 42.038 Acc@5 85.401 loss 1.831\n",
            "Accuracy of the model on the 3925 test images: 42.0%\n",
            "Max accuracy: 42.04%\n",
            "Test:  [ 0/41]  eta: 0:02:08  loss: 6.9317 (6.9317)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 3.1440  data: 2.7137  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 6.9088 (6.7902)  acc1: 0.0000 (0.5682)  acc5: 1.0417 (4.3561)  time: 0.8016  data: 0.3834  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.9258 (6.8861)  acc1: 0.0000 (0.3968)  acc5: 0.0000 (2.5794)  time: 0.4928  data: 0.0781  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.9354 (6.8599)  acc1: 0.0000 (0.3696)  acc5: 0.0000 (2.4194)  time: 0.4134  data: 0.0030  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.8965 (6.8267)  acc1: 0.0000 (0.3057)  acc5: 0.0000 (1.9363)  time: 0.4074  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5259 s / it)\n",
            "* Acc@1 0.306 Acc@5 1.936 loss 6.827\n",
            "Accuracy of the model EMA on 3925 test images: 0.3%\n",
            "Max EMA accuracy: 0.31%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [11]  [  0/147]  eta: 0:13:05  lr: 0.002203  min_lr: 0.002203  loss: 2.9336 (2.9336)  weight_decay: 0.0500 (0.0500)  time: 5.3430  data: 4.1325  max mem: 7679\n",
            "Epoch: [11]  [ 10/147]  eta: 0:02:52  lr: 0.002214  min_lr: 0.002214  loss: 2.9336 (2.9369)  weight_decay: 0.0500 (0.0500)  time: 1.2565  data: 0.3760  max mem: 7679\n",
            "Epoch: [11]  [ 20/147]  eta: 0:02:15  lr: 0.002231  min_lr: 0.002231  loss: 2.9511 (2.9480)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0009  max mem: 7679\n",
            "Epoch: [11]  [ 30/147]  eta: 0:01:56  lr: 0.002242  min_lr: 0.002242  loss: 2.9526 (2.9498)  weight_decay: 0.0500 (0.0500)  time: 0.8565  data: 0.0009  max mem: 7679\n",
            "Epoch: [11]  [ 40/147]  eta: 0:01:43  lr: 0.002259  min_lr: 0.002259  loss: 2.9349 (2.9475)  weight_decay: 0.0500 (0.0500)  time: 0.8561  data: 0.0008  max mem: 7679\n",
            "Epoch: [11]  [ 50/147]  eta: 0:01:31  lr: 0.002270  min_lr: 0.002270  loss: 2.9269 (2.9382)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0009  max mem: 7679\n",
            "Epoch: [11]  [ 60/147]  eta: 0:01:20  lr: 0.002287  min_lr: 0.002287  loss: 2.8880 (2.9368)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0007  max mem: 7679\n",
            "Epoch: [11]  [ 70/147]  eta: 0:01:10  lr: 0.002298  min_lr: 0.002298  loss: 2.9387 (2.9402)  weight_decay: 0.0500 (0.0500)  time: 0.8453  data: 0.0008  max mem: 7679\n",
            "Epoch: [11]  [ 80/147]  eta: 0:01:00  lr: 0.002314  min_lr: 0.002314  loss: 2.9387 (2.9384)  weight_decay: 0.0500 (0.0500)  time: 0.8442  data: 0.0007  max mem: 7679\n",
            "Epoch: [11]  [ 90/147]  eta: 0:00:51  lr: 0.002325  min_lr: 0.002325  loss: 2.9206 (2.9393)  weight_decay: 0.0500 (0.0500)  time: 0.8442  data: 0.0012  max mem: 7679\n",
            "Epoch: [11]  [100/147]  eta: 0:00:42  lr: 0.002342  min_lr: 0.002342  loss: 2.9393 (2.9384)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0021  max mem: 7679\n",
            "Epoch: [11]  [110/147]  eta: 0:00:32  lr: 0.002353  min_lr: 0.002353  loss: 2.8612 (2.9322)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0017  max mem: 7679\n",
            "Epoch: [11]  [120/147]  eta: 0:00:23  lr: 0.002370  min_lr: 0.002370  loss: 2.8883 (2.9343)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.0014  max mem: 7679\n",
            "Epoch: [11]  [130/147]  eta: 0:00:15  lr: 0.002381  min_lr: 0.002381  loss: 2.9310 (2.9314)  weight_decay: 0.0500 (0.0500)  time: 0.8558  data: 0.0012  max mem: 7679\n",
            "Epoch: [11]  [140/147]  eta: 0:00:06  lr: 0.002398  min_lr: 0.002398  loss: 2.8713 (2.9278)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0003  max mem: 7679\n",
            "Epoch: [11]  [146/147]  eta: 0:00:00  lr: 0.002398  min_lr: 0.002398  loss: 2.8853 (2.9277)  weight_decay: 0.0500 (0.0500)  time: 0.7291  data: 0.0002  max mem: 7679\n",
            "Epoch: [11] Total time: 0:02:07 (0.8686 s / it)\n",
            "Averaged stats: lr: 0.002398  min_lr: 0.002398  loss: 2.8853 (2.9277)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:03  loss: 1.3052 (1.3052)  acc1: 75.0000 (75.0000)  acc5: 96.8750 (96.8750)  time: 3.0105  data: 2.5532  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 1.4718 (1.7305)  acc1: 63.5417 (46.4015)  acc5: 91.6667 (88.4470)  time: 0.6714  data: 0.2563  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 2.1457 (1.9621)  acc1: 21.8750 (34.1766)  acc5: 78.1250 (81.6964)  time: 0.4213  data: 0.0154  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 2.0142 (1.9690)  acc1: 25.0000 (33.2661)  acc5: 77.0833 (82.0565)  time: 0.4021  data: 0.0022  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.8115 (1.8549)  acc1: 40.6250 (38.7516)  acc5: 89.5833 (84.2038)  time: 0.4003  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4847 s / it)\n",
            "* Acc@1 38.752 Acc@5 84.204 loss 1.855\n",
            "Accuracy of the model on the 3925 test images: 38.8%\n",
            "Max accuracy: 42.04%\n",
            "Test:  [ 0/41]  eta: 0:03:07  loss: 6.9106 (6.9106)  acc1: 0.0000 (0.0000)  acc5: 1.0417 (1.0417)  time: 4.5612  data: 4.1160  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 6.8883 (6.7633)  acc1: 0.0000 (0.9470)  acc5: 3.1250 (5.7765)  time: 0.7876  data: 0.3787  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.9097 (6.8625)  acc1: 0.0000 (0.5952)  acc5: 1.0417 (3.4226)  time: 0.4130  data: 0.0058  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.9127 (6.8319)  acc1: 0.0000 (0.5712)  acc5: 0.0000 (3.1922)  time: 0.4142  data: 0.0034  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.8666 (6.7914)  acc1: 0.0000 (0.4586)  acc5: 0.0000 (2.5732)  time: 0.4088  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5218 s / it)\n",
            "* Acc@1 0.459 Acc@5 2.573 loss 6.791\n",
            "Accuracy of the model EMA on 3925 test images: 0.5%\n",
            "Max EMA accuracy: 0.46%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [12]  [  0/147]  eta: 0:11:24  lr: 0.002403  min_lr: 0.002403  loss: 2.8681 (2.8681)  weight_decay: 0.0500 (0.0500)  time: 4.6546  data: 3.6269  max mem: 7679\n",
            "Epoch: [12]  [ 10/147]  eta: 0:02:45  lr: 0.002414  min_lr: 0.002414  loss: 2.8835 (2.8962)  weight_decay: 0.0500 (0.0500)  time: 1.2075  data: 0.3303  max mem: 7679\n",
            "Epoch: [12]  [ 20/147]  eta: 0:02:12  lr: 0.002431  min_lr: 0.002431  loss: 2.8843 (2.8937)  weight_decay: 0.0500 (0.0500)  time: 0.8596  data: 0.0010  max mem: 7679\n",
            "Epoch: [12]  [ 30/147]  eta: 0:01:54  lr: 0.002442  min_lr: 0.002442  loss: 2.8843 (2.8983)  weight_decay: 0.0500 (0.0500)  time: 0.8556  data: 0.0014  max mem: 7679\n",
            "Epoch: [12]  [ 40/147]  eta: 0:01:41  lr: 0.002459  min_lr: 0.002459  loss: 2.8939 (2.9004)  weight_decay: 0.0500 (0.0500)  time: 0.8571  data: 0.0017  max mem: 7679\n",
            "Epoch: [12]  [ 50/147]  eta: 0:01:30  lr: 0.002470  min_lr: 0.002470  loss: 2.8939 (2.9033)  weight_decay: 0.0500 (0.0500)  time: 0.8533  data: 0.0019  max mem: 7679\n",
            "Epoch: [12]  [ 60/147]  eta: 0:01:19  lr: 0.002487  min_lr: 0.002487  loss: 2.8945 (2.9026)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0018  max mem: 7679\n",
            "Epoch: [12]  [ 70/147]  eta: 0:01:09  lr: 0.002498  min_lr: 0.002498  loss: 2.8965 (2.9053)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0016  max mem: 7679\n",
            "Epoch: [12]  [ 80/147]  eta: 0:01:00  lr: 0.002515  min_lr: 0.002515  loss: 2.9100 (2.9069)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0017  max mem: 7679\n",
            "Epoch: [12]  [ 90/147]  eta: 0:00:50  lr: 0.002526  min_lr: 0.002526  loss: 2.9264 (2.9120)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0013  max mem: 7679\n",
            "Epoch: [12]  [100/147]  eta: 0:00:41  lr: 0.002542  min_lr: 0.002542  loss: 2.9189 (2.9071)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0008  max mem: 7679\n",
            "Epoch: [12]  [110/147]  eta: 0:00:32  lr: 0.002554  min_lr: 0.002554  loss: 2.8926 (2.9069)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0009  max mem: 7679\n",
            "Epoch: [12]  [120/147]  eta: 0:00:23  lr: 0.002570  min_lr: 0.002570  loss: 2.8582 (2.9011)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0008  max mem: 7679\n",
            "Epoch: [12]  [130/147]  eta: 0:00:14  lr: 0.002581  min_lr: 0.002581  loss: 2.8697 (2.9031)  weight_decay: 0.0500 (0.0500)  time: 0.8568  data: 0.0012  max mem: 7679\n",
            "Epoch: [12]  [140/147]  eta: 0:00:06  lr: 0.002598  min_lr: 0.002598  loss: 2.9376 (2.9031)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0010  max mem: 7679\n",
            "Epoch: [12]  [146/147]  eta: 0:00:00  lr: 0.002598  min_lr: 0.002598  loss: 2.9287 (2.9009)  weight_decay: 0.0500 (0.0500)  time: 0.7246  data: 0.0002  max mem: 7679\n",
            "Epoch: [12] Total time: 0:02:07 (0.8648 s / it)\n",
            "Averaged stats: lr: 0.002598  min_lr: 0.002598  loss: 2.9287 (2.9009)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:51  loss: 1.3308 (1.3308)  acc1: 70.8333 (70.8333)  acc5: 93.7500 (93.7500)  time: 4.1844  data: 3.7581  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 1.6150 (1.7228)  acc1: 60.4167 (48.3902)  acc5: 85.4167 (86.3636)  time: 0.7462  data: 0.3452  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.9784 (1.8459)  acc1: 32.2917 (39.2857)  acc5: 86.4583 (88.1448)  time: 0.4022  data: 0.0029  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.9784 (1.8446)  acc1: 38.5417 (41.1962)  acc5: 88.5417 (86.7944)  time: 0.4031  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.7683 (1.8027)  acc1: 45.8333 (43.2611)  acc5: 86.4583 (86.0382)  time: 0.4033  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5037 s / it)\n",
            "* Acc@1 43.261 Acc@5 86.038 loss 1.803\n",
            "Accuracy of the model on the 3925 test images: 43.3%\n",
            "Max accuracy: 43.26%\n",
            "Test:  [ 0/41]  eta: 0:02:28  loss: 6.8887 (6.8887)  acc1: 0.0000 (0.0000)  acc5: 1.0417 (1.0417)  time: 3.6234  data: 3.0384  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 6.8632 (6.7351)  acc1: 0.0000 (1.7045)  acc5: 4.1667 (7.1023)  time: 0.7382  data: 0.3021  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.8994 (6.8378)  acc1: 0.0000 (1.0417)  acc5: 1.0417 (4.1171)  time: 0.4408  data: 0.0165  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.8994 (6.8025)  acc1: 0.0000 (0.9073)  acc5: 0.0000 (3.9987)  time: 0.4213  data: 0.0023  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.8333 (6.7542)  acc1: 0.0000 (0.7134)  acc5: 1.0417 (3.2357)  time: 0.4081  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5121 s / it)\n",
            "* Acc@1 0.713 Acc@5 3.236 loss 6.754\n",
            "Accuracy of the model EMA on 3925 test images: 0.7%\n",
            "Max EMA accuracy: 0.71%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [13]  [  0/147]  eta: 0:10:11  lr: 0.002604  min_lr: 0.002604  loss: 2.7631 (2.7631)  weight_decay: 0.0500 (0.0500)  time: 4.1565  data: 3.0358  max mem: 7679\n",
            "Epoch: [13]  [ 10/147]  eta: 0:02:41  lr: 0.002615  min_lr: 0.002615  loss: 2.9175 (2.8875)  weight_decay: 0.0500 (0.0500)  time: 1.1807  data: 0.2810  max mem: 7679\n",
            "Epoch: [13]  [ 20/147]  eta: 0:02:10  lr: 0.002631  min_lr: 0.002631  loss: 2.9233 (2.9092)  weight_decay: 0.0500 (0.0500)  time: 0.8710  data: 0.0032  max mem: 7679\n",
            "Epoch: [13]  [ 30/147]  eta: 0:01:53  lr: 0.002643  min_lr: 0.002643  loss: 2.9145 (2.9072)  weight_decay: 0.0500 (0.0500)  time: 0.8574  data: 0.0010  max mem: 7679\n",
            "Epoch: [13]  [ 40/147]  eta: 0:01:41  lr: 0.002659  min_lr: 0.002659  loss: 2.8997 (2.9010)  weight_decay: 0.0500 (0.0500)  time: 0.8581  data: 0.0011  max mem: 7679\n",
            "Epoch: [13]  [ 50/147]  eta: 0:01:29  lr: 0.002670  min_lr: 0.002670  loss: 2.8955 (2.9012)  weight_decay: 0.0500 (0.0500)  time: 0.8533  data: 0.0011  max mem: 7679\n",
            "Epoch: [13]  [ 60/147]  eta: 0:01:19  lr: 0.002687  min_lr: 0.002687  loss: 2.8626 (2.8946)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0007  max mem: 7679\n",
            "Epoch: [13]  [ 70/147]  eta: 0:01:09  lr: 0.002698  min_lr: 0.002698  loss: 2.8386 (2.8890)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0005  max mem: 7679\n",
            "Epoch: [13]  [ 80/147]  eta: 0:01:00  lr: 0.002715  min_lr: 0.002715  loss: 2.8417 (2.8893)  weight_decay: 0.0500 (0.0500)  time: 0.8440  data: 0.0006  max mem: 7679\n",
            "Epoch: [13]  [ 90/147]  eta: 0:00:50  lr: 0.002726  min_lr: 0.002726  loss: 2.8875 (2.8903)  weight_decay: 0.0500 (0.0500)  time: 0.8455  data: 0.0008  max mem: 7679\n",
            "Epoch: [13]  [100/147]  eta: 0:00:41  lr: 0.002743  min_lr: 0.002743  loss: 2.8801 (2.8887)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0016  max mem: 7679\n",
            "Epoch: [13]  [110/147]  eta: 0:00:32  lr: 0.002754  min_lr: 0.002754  loss: 2.8880 (2.8938)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0023  max mem: 7679\n",
            "Epoch: [13]  [120/147]  eta: 0:00:23  lr: 0.002771  min_lr: 0.002771  loss: 2.9236 (2.8954)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0018  max mem: 7679\n",
            "Epoch: [13]  [130/147]  eta: 0:00:14  lr: 0.002782  min_lr: 0.002782  loss: 2.8795 (2.8937)  weight_decay: 0.0500 (0.0500)  time: 0.8542  data: 0.0017  max mem: 7679\n",
            "Epoch: [13]  [140/147]  eta: 0:00:06  lr: 0.002798  min_lr: 0.002798  loss: 2.8898 (2.8951)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0012  max mem: 7679\n",
            "Epoch: [13]  [146/147]  eta: 0:00:00  lr: 0.002798  min_lr: 0.002798  loss: 2.9012 (2.8951)  weight_decay: 0.0500 (0.0500)  time: 0.7248  data: 0.0004  max mem: 7679\n",
            "Epoch: [13] Total time: 0:02:06 (0.8621 s / it)\n",
            "Averaged stats: lr: 0.002798  min_lr: 0.002798  loss: 2.9012 (2.8951)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:37  loss: 1.4390 (1.4390)  acc1: 75.0000 (75.0000)  acc5: 94.7917 (94.7917)  time: 3.8535  data: 3.3862  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 1.6789 (1.7167)  acc1: 55.2083 (48.3902)  acc5: 92.7083 (92.4242)  time: 0.7202  data: 0.3101  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.7416 (1.9495)  acc1: 37.5000 (37.8472)  acc5: 90.6250 (78.1746)  time: 0.4082  data: 0.0021  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.7416 (1.9200)  acc1: 39.5833 (38.3737)  acc5: 86.4583 (80.9812)  time: 0.4066  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.6619 (1.7951)  acc1: 48.9583 (43.7707)  acc5: 90.6250 (83.3376)  time: 0.4026  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4988 s / it)\n",
            "* Acc@1 43.771 Acc@5 83.338 loss 1.795\n",
            "Accuracy of the model on the 3925 test images: 43.8%\n",
            "Max accuracy: 43.77%\n",
            "Test:  [ 0/41]  eta: 0:03:16  loss: 6.8643 (6.8643)  acc1: 0.0000 (0.0000)  acc5: 1.0417 (1.0417)  time: 4.8042  data: 4.3155  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 6.8359 (6.7049)  acc1: 2.0833 (2.5568)  acc5: 4.1667 (8.0492)  time: 0.8501  data: 0.4271  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 6.8771 (6.8115)  acc1: 0.0000 (1.4881)  acc5: 1.0417 (4.6627)  time: 0.4330  data: 0.0205  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.8920 (6.7715)  acc1: 0.0000 (1.3105)  acc5: 0.0000 (5.0403)  time: 0.4112  data: 0.0014  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.7937 (6.7152)  acc1: 0.0000 (1.0701)  acc5: 5.2083 (5.5796)  time: 0.4096  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5451 s / it)\n",
            "* Acc@1 1.070 Acc@5 5.580 loss 6.715\n",
            "Accuracy of the model EMA on 3925 test images: 1.1%\n",
            "Max EMA accuracy: 1.07%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [14]  [  0/147]  eta: 0:09:18  lr: 0.002804  min_lr: 0.002804  loss: 2.8058 (2.8058)  weight_decay: 0.0500 (0.0500)  time: 3.7998  data: 2.8732  max mem: 7679\n",
            "Epoch: [14]  [ 10/147]  eta: 0:02:33  lr: 0.002815  min_lr: 0.002815  loss: 2.8518 (2.8801)  weight_decay: 0.0500 (0.0500)  time: 1.1192  data: 0.2619  max mem: 7679\n",
            "Epoch: [14]  [ 20/147]  eta: 0:02:06  lr: 0.002832  min_lr: 0.002832  loss: 2.8381 (2.8577)  weight_decay: 0.0500 (0.0500)  time: 0.8553  data: 0.0006  max mem: 7679\n",
            "Epoch: [14]  [ 30/147]  eta: 0:01:50  lr: 0.002843  min_lr: 0.002843  loss: 2.8724 (2.8657)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0005  max mem: 7679\n",
            "Epoch: [14]  [ 40/147]  eta: 0:01:39  lr: 0.002860  min_lr: 0.002860  loss: 2.9082 (2.8764)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0006  max mem: 7679\n",
            "Epoch: [14]  [ 50/147]  eta: 0:01:28  lr: 0.002871  min_lr: 0.002871  loss: 2.9149 (2.8806)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0005  max mem: 7679\n",
            "Epoch: [14]  [ 60/147]  eta: 0:01:18  lr: 0.002887  min_lr: 0.002887  loss: 2.9100 (2.8828)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0008  max mem: 7679\n",
            "Epoch: [14]  [ 70/147]  eta: 0:01:08  lr: 0.002898  min_lr: 0.002898  loss: 2.8905 (2.8817)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0008  max mem: 7679\n",
            "Epoch: [14]  [ 80/147]  eta: 0:00:59  lr: 0.002915  min_lr: 0.002915  loss: 2.8934 (2.8817)  weight_decay: 0.0500 (0.0500)  time: 0.8435  data: 0.0005  max mem: 7679\n",
            "Epoch: [14]  [ 90/147]  eta: 0:00:50  lr: 0.002926  min_lr: 0.002926  loss: 2.8652 (2.8784)  weight_decay: 0.0500 (0.0500)  time: 0.8447  data: 0.0008  max mem: 7679\n",
            "Epoch: [14]  [100/147]  eta: 0:00:41  lr: 0.002943  min_lr: 0.002943  loss: 2.8521 (2.8769)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0010  max mem: 7679\n",
            "Epoch: [14]  [110/147]  eta: 0:00:32  lr: 0.002954  min_lr: 0.002954  loss: 2.8820 (2.8781)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0008  max mem: 7679\n",
            "Epoch: [14]  [120/147]  eta: 0:00:23  lr: 0.002971  min_lr: 0.002971  loss: 2.8766 (2.8776)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0015  max mem: 7679\n",
            "Epoch: [14]  [130/147]  eta: 0:00:14  lr: 0.002982  min_lr: 0.002982  loss: 2.8671 (2.8759)  weight_decay: 0.0500 (0.0500)  time: 0.8554  data: 0.0021  max mem: 7679\n",
            "Epoch: [14]  [140/147]  eta: 0:00:06  lr: 0.002999  min_lr: 0.002999  loss: 2.8467 (2.8746)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0010  max mem: 7679\n",
            "Epoch: [14]  [146/147]  eta: 0:00:00  lr: 0.002999  min_lr: 0.002999  loss: 2.8467 (2.8735)  weight_decay: 0.0500 (0.0500)  time: 0.7256  data: 0.0002  max mem: 7679\n",
            "Epoch: [14] Total time: 0:02:05 (0.8561 s / it)\n",
            "Averaged stats: lr: 0.002999  min_lr: 0.002999  loss: 2.8467 (2.8735)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:02  loss: 1.0266 (1.0266)  acc1: 86.4583 (86.4583)  acc5: 94.7917 (94.7917)  time: 5.9036  data: 5.4285  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:28  loss: 1.3970 (1.3844)  acc1: 62.5000 (67.0455)  acc5: 92.7083 (93.2765)  time: 0.9085  data: 0.5006  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 1.5760 (1.6759)  acc1: 55.2083 (48.8095)  acc5: 90.6250 (88.8393)  time: 0.4039  data: 0.0054  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.7805 (1.7125)  acc1: 35.4167 (46.6734)  acc5: 89.5833 (88.6089)  time: 0.3999  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.6303 (1.6636)  acc1: 43.7500 (47.7452)  acc5: 90.6250 (89.2484)  time: 0.4013  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5508 s / it)\n",
            "* Acc@1 47.745 Acc@5 89.248 loss 1.664\n",
            "Accuracy of the model on the 3925 test images: 47.7%\n",
            "Max accuracy: 47.75%\n",
            "Test:  [ 0/41]  eta: 0:03:09  loss: 6.8385 (6.8385)  acc1: 0.0000 (0.0000)  acc5: 3.1250 (3.1250)  time: 4.6182  data: 4.1660  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 6.8069 (6.6726)  acc1: 2.0833 (3.2197)  acc5: 5.2083 (9.1856)  time: 0.7930  data: 0.3795  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.8471 (6.7835)  acc1: 0.0000 (1.8849)  acc5: 1.0417 (5.4067)  time: 0.4108  data: 0.0014  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.8701 (6.7384)  acc1: 0.0000 (1.7809)  acc5: 0.0000 (6.1828)  time: 0.4122  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.7516 (6.6741)  acc1: 2.0833 (1.9363)  acc5: 7.2917 (9.2994)  time: 0.4137  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5232 s / it)\n",
            "* Acc@1 1.936 Acc@5 9.299 loss 6.674\n",
            "Accuracy of the model EMA on 3925 test images: 1.9%\n",
            "Max EMA accuracy: 1.94%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [15]  [  0/147]  eta: 0:16:12  lr: 0.003004  min_lr: 0.003004  loss: 2.9302 (2.9302)  weight_decay: 0.0500 (0.0500)  time: 6.6124  data: 4.3128  max mem: 7679\n",
            "Epoch: [15]  [ 10/147]  eta: 0:03:08  lr: 0.003015  min_lr: 0.003015  loss: 2.8727 (2.8458)  weight_decay: 0.0500 (0.0500)  time: 1.3747  data: 0.3927  max mem: 7679\n",
            "Epoch: [15]  [ 20/147]  eta: 0:02:23  lr: 0.003032  min_lr: 0.003032  loss: 2.8751 (2.8700)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0009  max mem: 7679\n",
            "Epoch: [15]  [ 30/147]  eta: 0:02:01  lr: 0.003043  min_lr: 0.003043  loss: 2.9125 (2.8827)  weight_decay: 0.0500 (0.0500)  time: 0.8568  data: 0.0014  max mem: 7679\n",
            "Epoch: [15]  [ 40/147]  eta: 0:01:46  lr: 0.003060  min_lr: 0.003060  loss: 2.9126 (2.8783)  weight_decay: 0.0500 (0.0500)  time: 0.8546  data: 0.0017  max mem: 7679\n",
            "Epoch: [15]  [ 50/147]  eta: 0:01:33  lr: 0.003071  min_lr: 0.003071  loss: 2.8539 (2.8766)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0020  max mem: 7679\n",
            "Epoch: [15]  [ 60/147]  eta: 0:01:22  lr: 0.003088  min_lr: 0.003088  loss: 2.8587 (2.8772)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0017  max mem: 7679\n",
            "Epoch: [15]  [ 70/147]  eta: 0:01:11  lr: 0.003099  min_lr: 0.003099  loss: 2.9155 (2.8827)  weight_decay: 0.0500 (0.0500)  time: 0.8460  data: 0.0011  max mem: 7679\n",
            "Epoch: [15]  [ 80/147]  eta: 0:01:01  lr: 0.003115  min_lr: 0.003115  loss: 2.8663 (2.8791)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0018  max mem: 7679\n",
            "Epoch: [15]  [ 90/147]  eta: 0:00:52  lr: 0.003127  min_lr: 0.003127  loss: 2.8115 (2.8724)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0017  max mem: 7679\n",
            "Epoch: [15]  [100/147]  eta: 0:00:42  lr: 0.003143  min_lr: 0.003143  loss: 2.8026 (2.8655)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0014  max mem: 7679\n",
            "Epoch: [15]  [110/147]  eta: 0:00:33  lr: 0.003154  min_lr: 0.003154  loss: 2.8627 (2.8681)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0018  max mem: 7679\n",
            "Epoch: [15]  [120/147]  eta: 0:00:24  lr: 0.003171  min_lr: 0.003171  loss: 2.8898 (2.8685)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0019  max mem: 7679\n",
            "Epoch: [15]  [130/147]  eta: 0:00:15  lr: 0.003182  min_lr: 0.003182  loss: 2.8986 (2.8683)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.0015  max mem: 7679\n",
            "Epoch: [15]  [140/147]  eta: 0:00:06  lr: 0.003199  min_lr: 0.003199  loss: 2.8875 (2.8621)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0006  max mem: 7679\n",
            "Epoch: [15]  [146/147]  eta: 0:00:00  lr: 0.003199  min_lr: 0.003199  loss: 2.8969 (2.8629)  weight_decay: 0.0500 (0.0500)  time: 0.7233  data: 0.0004  max mem: 7679\n",
            "Epoch: [15] Total time: 0:02:08 (0.8766 s / it)\n",
            "Averaged stats: lr: 0.003199  min_lr: 0.003199  loss: 2.8969 (2.8629)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:59  loss: 1.0069 (1.0069)  acc1: 80.2083 (80.2083)  acc5: 94.7917 (94.7917)  time: 2.9125  data: 2.4471  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 1.3151 (1.3010)  acc1: 69.7917 (69.2235)  acc5: 95.8333 (95.8333)  time: 0.6734  data: 0.2659  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 1.4619 (1.6493)  acc1: 60.4167 (50.0992)  acc5: 93.7500 (87.9960)  time: 0.4274  data: 0.0266  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.7405 (1.6827)  acc1: 42.7083 (49.1599)  acc5: 90.6250 (88.7769)  time: 0.4044  data: 0.0028  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.7405 (1.6134)  acc1: 42.7083 (50.4968)  acc5: 92.9412 (89.8854)  time: 0.4029  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4860 s / it)\n",
            "* Acc@1 50.497 Acc@5 89.885 loss 1.613\n",
            "Accuracy of the model on the 3925 test images: 50.5%\n",
            "Max accuracy: 50.50%\n",
            "Test:  [ 0/41]  eta: 0:02:15  loss: 6.8120 (6.8120)  acc1: 0.0000 (0.0000)  acc5: 3.1250 (3.1250)  time: 3.2939  data: 2.8309  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.7764 (6.6386)  acc1: 2.0833 (3.9773)  acc5: 6.2500 (10.0379)  time: 0.7063  data: 0.2884  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.8138 (6.7539)  acc1: 0.0000 (2.3313)  acc5: 1.0417 (5.9524)  time: 0.4370  data: 0.0238  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.8427 (6.7033)  acc1: 0.0000 (2.0833)  acc5: 0.0000 (7.1909)  time: 0.4180  data: 0.0069  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.7052 (6.6311)  acc1: 2.0833 (3.5924)  acc5: 9.3750 (11.5924)  time: 0.4082  data: 0.0003  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5030 s / it)\n",
            "* Acc@1 3.592 Acc@5 11.592 loss 6.631\n",
            "Accuracy of the model EMA on 3925 test images: 3.6%\n",
            "Max EMA accuracy: 3.59%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [16]  [  0/147]  eta: 0:12:10  lr: 0.003204  min_lr: 0.003204  loss: 2.9292 (2.9292)  weight_decay: 0.0500 (0.0500)  time: 4.9692  data: 3.4927  max mem: 7679\n",
            "Epoch: [16]  [ 10/147]  eta: 0:02:51  lr: 0.003216  min_lr: 0.003216  loss: 2.7605 (2.7862)  weight_decay: 0.0500 (0.0500)  time: 1.2499  data: 0.3184  max mem: 7679\n",
            "Epoch: [16]  [ 20/147]  eta: 0:02:15  lr: 0.003232  min_lr: 0.003232  loss: 2.8613 (2.8450)  weight_decay: 0.0500 (0.0500)  time: 0.8698  data: 0.0013  max mem: 7679\n",
            "Epoch: [16]  [ 30/147]  eta: 0:01:56  lr: 0.003243  min_lr: 0.003243  loss: 2.8883 (2.8481)  weight_decay: 0.0500 (0.0500)  time: 0.8584  data: 0.0012  max mem: 7679\n",
            "Epoch: [16]  [ 40/147]  eta: 0:01:43  lr: 0.003260  min_lr: 0.003260  loss: 2.9168 (2.8674)  weight_decay: 0.0500 (0.0500)  time: 0.8570  data: 0.0005  max mem: 7679\n",
            "Epoch: [16]  [ 50/147]  eta: 0:01:31  lr: 0.003271  min_lr: 0.003271  loss: 2.8919 (2.8605)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0004  max mem: 7679\n",
            "Epoch: [16]  [ 60/147]  eta: 0:01:20  lr: 0.003288  min_lr: 0.003288  loss: 2.8353 (2.8536)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0008  max mem: 7679\n",
            "Epoch: [16]  [ 70/147]  eta: 0:01:10  lr: 0.003299  min_lr: 0.003299  loss: 2.8366 (2.8483)  weight_decay: 0.0500 (0.0500)  time: 0.8464  data: 0.0014  max mem: 7679\n",
            "Epoch: [16]  [ 80/147]  eta: 0:01:00  lr: 0.003316  min_lr: 0.003316  loss: 2.8476 (2.8450)  weight_decay: 0.0500 (0.0500)  time: 0.8443  data: 0.0014  max mem: 7679\n",
            "Epoch: [16]  [ 90/147]  eta: 0:00:51  lr: 0.003327  min_lr: 0.003327  loss: 2.8515 (2.8447)  weight_decay: 0.0500 (0.0500)  time: 0.8460  data: 0.0009  max mem: 7679\n",
            "Epoch: [16]  [100/147]  eta: 0:00:42  lr: 0.003344  min_lr: 0.003344  loss: 2.8666 (2.8454)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0015  max mem: 7679\n",
            "Epoch: [16]  [110/147]  eta: 0:00:32  lr: 0.003355  min_lr: 0.003355  loss: 2.8666 (2.8482)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0020  max mem: 7679\n",
            "Epoch: [16]  [120/147]  eta: 0:00:23  lr: 0.003371  min_lr: 0.003371  loss: 2.8824 (2.8533)  weight_decay: 0.0500 (0.0500)  time: 0.8536  data: 0.0016  max mem: 7679\n",
            "Epoch: [16]  [130/147]  eta: 0:00:15  lr: 0.003382  min_lr: 0.003382  loss: 2.8784 (2.8496)  weight_decay: 0.0500 (0.0500)  time: 0.8564  data: 0.0013  max mem: 7679\n",
            "Epoch: [16]  [140/147]  eta: 0:00:06  lr: 0.003399  min_lr: 0.003399  loss: 2.8034 (2.8456)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0006  max mem: 7679\n",
            "Epoch: [16]  [146/147]  eta: 0:00:00  lr: 0.003399  min_lr: 0.003399  loss: 2.8034 (2.8456)  weight_decay: 0.0500 (0.0500)  time: 0.7232  data: 0.0002  max mem: 7679\n",
            "Epoch: [16] Total time: 0:02:07 (0.8669 s / it)\n",
            "Averaged stats: lr: 0.003399  min_lr: 0.003399  loss: 2.8034 (2.8456)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:59  loss: 0.7844 (0.7844)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 4.3755  data: 3.8732  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.9432 (1.2481)  acc1: 78.1250 (67.0455)  acc5: 96.8750 (95.9280)  time: 0.7632  data: 0.3539  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.8459 (1.6013)  acc1: 39.5833 (47.7183)  acc5: 91.6667 (92.0635)  time: 0.4031  data: 0.0022  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.8515 (1.6475)  acc1: 40.6250 (46.6734)  acc5: 88.5417 (90.8602)  time: 0.4043  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.7539 (1.5985)  acc1: 44.7917 (48.7389)  acc5: 89.5833 (90.5223)  time: 0.4038  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5092 s / it)\n",
            "* Acc@1 48.739 Acc@5 90.522 loss 1.599\n",
            "Accuracy of the model on the 3925 test images: 48.7%\n",
            "Max accuracy: 50.50%\n",
            "Test:  [ 0/41]  eta: 0:03:12  loss: 6.7794 (6.7794)  acc1: 1.0417 (1.0417)  acc5: 5.2083 (5.2083)  time: 4.6886  data: 4.2387  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 6.7411 (6.6007)  acc1: 3.1250 (5.1136)  acc5: 7.2917 (11.7424)  time: 0.8044  data: 0.3870  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 6.7774 (6.7216)  acc1: 0.0000 (2.9266)  acc5: 1.0417 (6.9940)  time: 0.4196  data: 0.0050  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.8139 (6.6657)  acc1: 0.0000 (2.4866)  acc5: 1.0417 (8.8374)  time: 0.4167  data: 0.0042  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.6584 (6.5856)  acc1: 0.0000 (5.1975)  acc5: 11.4583 (13.9108)  time: 0.4081  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5273 s / it)\n",
            "* Acc@1 5.197 Acc@5 13.911 loss 6.586\n",
            "Accuracy of the model EMA on 3925 test images: 5.2%\n",
            "Max EMA accuracy: 5.20%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [17]  [  0/147]  eta: 0:10:55  lr: 0.003405  min_lr: 0.003405  loss: 2.6729 (2.6729)  weight_decay: 0.0500 (0.0500)  time: 4.4591  data: 3.4900  max mem: 7679\n",
            "Epoch: [17]  [ 10/147]  eta: 0:02:40  lr: 0.003416  min_lr: 0.003416  loss: 2.8736 (2.8630)  weight_decay: 0.0500 (0.0500)  time: 1.1745  data: 0.3179  max mem: 7679\n",
            "Epoch: [17]  [ 20/147]  eta: 0:02:10  lr: 0.003433  min_lr: 0.003433  loss: 2.8833 (2.8663)  weight_decay: 0.0500 (0.0500)  time: 0.8530  data: 0.0013  max mem: 7679\n",
            "Epoch: [17]  [ 30/147]  eta: 0:01:53  lr: 0.003444  min_lr: 0.003444  loss: 2.8604 (2.8646)  weight_decay: 0.0500 (0.0500)  time: 0.8573  data: 0.0013  max mem: 7679\n",
            "Epoch: [17]  [ 40/147]  eta: 0:01:40  lr: 0.003460  min_lr: 0.003460  loss: 2.8048 (2.8361)  weight_decay: 0.0500 (0.0500)  time: 0.8582  data: 0.0010  max mem: 7679\n",
            "Epoch: [17]  [ 50/147]  eta: 0:01:29  lr: 0.003471  min_lr: 0.003471  loss: 2.7968 (2.8362)  weight_decay: 0.0500 (0.0500)  time: 0.8541  data: 0.0009  max mem: 7679\n",
            "Epoch: [17]  [ 60/147]  eta: 0:01:19  lr: 0.003488  min_lr: 0.003488  loss: 2.8377 (2.8330)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0004  max mem: 7679\n",
            "Epoch: [17]  [ 70/147]  eta: 0:01:09  lr: 0.003499  min_lr: 0.003499  loss: 2.8350 (2.8337)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0006  max mem: 7679\n",
            "Epoch: [17]  [ 80/147]  eta: 0:01:00  lr: 0.003516  min_lr: 0.003516  loss: 2.7854 (2.8238)  weight_decay: 0.0500 (0.0500)  time: 0.8458  data: 0.0008  max mem: 7679\n",
            "Epoch: [17]  [ 90/147]  eta: 0:00:50  lr: 0.003527  min_lr: 0.003527  loss: 2.7460 (2.8168)  weight_decay: 0.0500 (0.0500)  time: 0.8454  data: 0.0007  max mem: 7679\n",
            "Epoch: [17]  [100/147]  eta: 0:00:41  lr: 0.003544  min_lr: 0.003544  loss: 2.7957 (2.8200)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0014  max mem: 7679\n",
            "Epoch: [17]  [110/147]  eta: 0:00:32  lr: 0.003555  min_lr: 0.003555  loss: 2.7976 (2.8176)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0014  max mem: 7679\n",
            "Epoch: [17]  [120/147]  eta: 0:00:23  lr: 0.003572  min_lr: 0.003572  loss: 2.7859 (2.8168)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0019  max mem: 7679\n",
            "Epoch: [17]  [130/147]  eta: 0:00:14  lr: 0.003583  min_lr: 0.003583  loss: 2.8418 (2.8224)  weight_decay: 0.0500 (0.0500)  time: 0.8552  data: 0.0020  max mem: 7679\n",
            "Epoch: [17]  [140/147]  eta: 0:00:06  lr: 0.003599  min_lr: 0.003599  loss: 2.8614 (2.8219)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0006  max mem: 7679\n",
            "Epoch: [17]  [146/147]  eta: 0:00:00  lr: 0.003599  min_lr: 0.003599  loss: 2.8614 (2.8236)  weight_decay: 0.0500 (0.0500)  time: 0.7262  data: 0.0002  max mem: 7679\n",
            "Epoch: [17] Total time: 0:02:06 (0.8613 s / it)\n",
            "Averaged stats: lr: 0.003599  min_lr: 0.003599  loss: 2.8614 (2.8236)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:15  loss: 1.5112 (1.5112)  acc1: 64.5833 (64.5833)  acc5: 92.7083 (92.7083)  time: 4.7585  data: 4.3285  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 1.6838 (1.6920)  acc1: 55.2083 (54.2614)  acc5: 88.5417 (89.1099)  time: 0.8040  data: 0.3967  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 1.7833 (1.8079)  acc1: 45.8333 (43.7996)  acc5: 87.5000 (88.8393)  time: 0.4141  data: 0.0025  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.7352 (1.7242)  acc1: 45.8333 (48.5887)  acc5: 89.5833 (89.9866)  time: 0.4120  data: 0.0008  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.4745 (1.6096)  acc1: 60.4167 (52.4331)  acc5: 94.7917 (91.1847)  time: 0.4030  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5298 s / it)\n",
            "* Acc@1 52.433 Acc@5 91.185 loss 1.610\n",
            "Accuracy of the model on the 3925 test images: 52.4%\n",
            "Max accuracy: 52.43%\n",
            "Test:  [ 0/41]  eta: 0:03:37  loss: 6.7430 (6.7430)  acc1: 2.0833 (2.0833)  acc5: 6.2500 (6.2500)  time: 5.3051  data: 4.8418  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 6.7023 (6.5601)  acc1: 3.1250 (5.5871)  acc5: 7.2917 (13.4470)  time: 0.8562  data: 0.4431  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 6.7398 (6.6875)  acc1: 0.0000 (3.2242)  acc5: 3.1250 (8.0853)  time: 0.4115  data: 0.0018  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.7860 (6.6262)  acc1: 0.0000 (2.7890)  acc5: 1.0417 (10.4503)  time: 0.4105  data: 0.0005  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.6075 (6.5379)  acc1: 0.0000 (6.9045)  acc5: 13.5417 (15.9490)  time: 0.4112  data: 0.0003  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5391 s / it)\n",
            "* Acc@1 6.904 Acc@5 15.949 loss 6.538\n",
            "Accuracy of the model EMA on 3925 test images: 6.9%\n",
            "Max EMA accuracy: 6.90%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [18]  [  0/147]  eta: 0:08:17  lr: 0.003605  min_lr: 0.003605  loss: 2.8014 (2.8014)  weight_decay: 0.0500 (0.0500)  time: 3.3845  data: 2.3943  max mem: 7679\n",
            "Epoch: [18]  [ 10/147]  eta: 0:02:30  lr: 0.003616  min_lr: 0.003616  loss: 2.8113 (2.8275)  weight_decay: 0.0500 (0.0500)  time: 1.0997  data: 0.2180  max mem: 7679\n",
            "Epoch: [18]  [ 20/147]  eta: 0:02:04  lr: 0.003633  min_lr: 0.003633  loss: 2.8218 (2.8168)  weight_decay: 0.0500 (0.0500)  time: 0.8640  data: 0.0005  max mem: 7679\n",
            "Epoch: [18]  [ 30/147]  eta: 0:01:50  lr: 0.003644  min_lr: 0.003644  loss: 2.8461 (2.8179)  weight_decay: 0.0500 (0.0500)  time: 0.8563  data: 0.0025  max mem: 7679\n",
            "Epoch: [18]  [ 40/147]  eta: 0:01:38  lr: 0.003661  min_lr: 0.003661  loss: 2.8461 (2.8313)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0024  max mem: 7679\n",
            "Epoch: [18]  [ 50/147]  eta: 0:01:27  lr: 0.003672  min_lr: 0.003672  loss: 2.8717 (2.8276)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0009  max mem: 7679\n",
            "Epoch: [18]  [ 60/147]  eta: 0:01:17  lr: 0.003688  min_lr: 0.003688  loss: 2.8028 (2.8233)  weight_decay: 0.0500 (0.0500)  time: 0.8464  data: 0.0009  max mem: 7679\n",
            "Epoch: [18]  [ 70/147]  eta: 0:01:08  lr: 0.003700  min_lr: 0.003700  loss: 2.8463 (2.8315)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0009  max mem: 7679\n",
            "Epoch: [18]  [ 80/147]  eta: 0:00:59  lr: 0.003716  min_lr: 0.003716  loss: 2.8343 (2.8215)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0014  max mem: 7679\n",
            "Epoch: [18]  [ 90/147]  eta: 0:00:50  lr: 0.003727  min_lr: 0.003727  loss: 2.7813 (2.8178)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0018  max mem: 7679\n",
            "Epoch: [18]  [100/147]  eta: 0:00:41  lr: 0.003744  min_lr: 0.003744  loss: 2.8037 (2.8163)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0012  max mem: 7679\n",
            "Epoch: [18]  [110/147]  eta: 0:00:32  lr: 0.003755  min_lr: 0.003755  loss: 2.8037 (2.8159)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0016  max mem: 7679\n",
            "Epoch: [18]  [120/147]  eta: 0:00:23  lr: 0.003772  min_lr: 0.003772  loss: 2.8204 (2.8190)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0017  max mem: 7679\n",
            "Epoch: [18]  [130/147]  eta: 0:00:14  lr: 0.003783  min_lr: 0.003783  loss: 2.8204 (2.8175)  weight_decay: 0.0500 (0.0500)  time: 0.8558  data: 0.0010  max mem: 7679\n",
            "Epoch: [18]  [140/147]  eta: 0:00:06  lr: 0.003800  min_lr: 0.003800  loss: 2.7703 (2.8167)  weight_decay: 0.0500 (0.0500)  time: 0.8566  data: 0.0010  max mem: 7679\n",
            "Epoch: [18]  [146/147]  eta: 0:00:00  lr: 0.003800  min_lr: 0.003800  loss: 2.7703 (2.8173)  weight_decay: 0.0500 (0.0500)  time: 0.7264  data: 0.0003  max mem: 7679\n",
            "Epoch: [18] Total time: 0:02:05 (0.8555 s / it)\n",
            "Averaged stats: lr: 0.003800  min_lr: 0.003800  loss: 2.7703 (2.8173)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:02  loss: 1.0492 (1.0492)  acc1: 81.2500 (81.2500)  acc5: 95.8333 (95.8333)  time: 5.9100  data: 5.4441  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 1.4955 (1.3986)  acc1: 62.5000 (65.4356)  acc5: 95.8333 (94.9811)  time: 0.9009  data: 0.4963  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 1.4955 (1.5470)  acc1: 61.4583 (53.8194)  acc5: 94.7917 (94.0972)  time: 0.3999  data: 0.0012  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.3992 (1.5575)  acc1: 62.5000 (55.1411)  acc5: 93.7500 (92.0363)  time: 0.4017  data: 0.0005  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.4205 (1.6026)  acc1: 62.5000 (51.9745)  acc5: 87.5000 (90.3440)  time: 0.4028  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5450 s / it)\n",
            "* Acc@1 51.975 Acc@5 90.344 loss 1.603\n",
            "Accuracy of the model on the 3925 test images: 52.0%\n",
            "Max accuracy: 52.43%\n",
            "Test:  [ 0/41]  eta: 0:03:00  loss: 6.7057 (6.7057)  acc1: 2.0833 (2.0833)  acc5: 7.2917 (7.2917)  time: 4.4115  data: 3.9611  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 6.6621 (6.5174)  acc1: 3.1250 (6.4394)  acc5: 9.3750 (15.3409)  time: 0.7761  data: 0.3654  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.6986 (6.6516)  acc1: 0.0000 (3.5714)  acc5: 3.1250 (9.4246)  time: 0.4142  data: 0.0047  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.7570 (6.5843)  acc1: 0.0000 (3.1250)  acc5: 2.0833 (12.3992)  time: 0.4161  data: 0.0019  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.5512 (6.4876)  acc1: 1.0417 (7.9236)  acc5: 16.6667 (17.9363)  time: 0.4135  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5202 s / it)\n",
            "* Acc@1 7.924 Acc@5 17.936 loss 6.488\n",
            "Accuracy of the model EMA on 3925 test images: 7.9%\n",
            "Max EMA accuracy: 7.92%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [19]  [  0/147]  eta: 0:12:04  lr: 0.003805  min_lr: 0.003805  loss: 3.0221 (3.0221)  weight_decay: 0.0500 (0.0500)  time: 4.9310  data: 3.8089  max mem: 7679\n",
            "Epoch: [19]  [ 10/147]  eta: 0:02:50  lr: 0.003816  min_lr: 0.003816  loss: 2.8248 (2.8292)  weight_decay: 0.0500 (0.0500)  time: 1.2469  data: 0.3471  max mem: 7679\n",
            "Epoch: [19]  [ 20/147]  eta: 0:02:14  lr: 0.003833  min_lr: 0.003833  loss: 2.7922 (2.8138)  weight_decay: 0.0500 (0.0500)  time: 0.8661  data: 0.0007  max mem: 7679\n",
            "Epoch: [19]  [ 30/147]  eta: 0:01:56  lr: 0.003844  min_lr: 0.003844  loss: 2.8225 (2.8126)  weight_decay: 0.0500 (0.0500)  time: 0.8557  data: 0.0011  max mem: 7679\n",
            "Epoch: [19]  [ 40/147]  eta: 0:01:42  lr: 0.003861  min_lr: 0.003861  loss: 2.7947 (2.7981)  weight_decay: 0.0500 (0.0500)  time: 0.8564  data: 0.0014  max mem: 7679\n",
            "Epoch: [19]  [ 50/147]  eta: 0:01:31  lr: 0.003872  min_lr: 0.003872  loss: 2.7969 (2.8036)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0008  max mem: 7679\n",
            "Epoch: [19]  [ 60/147]  eta: 0:01:20  lr: 0.003889  min_lr: 0.003889  loss: 2.8337 (2.7971)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0004  max mem: 7679\n",
            "Epoch: [19]  [ 70/147]  eta: 0:01:10  lr: 0.003900  min_lr: 0.003900  loss: 2.7725 (2.7978)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0005  max mem: 7679\n",
            "Epoch: [19]  [ 80/147]  eta: 0:01:00  lr: 0.003917  min_lr: 0.003917  loss: 2.7678 (2.7944)  weight_decay: 0.0500 (0.0500)  time: 0.8463  data: 0.0007  max mem: 7679\n",
            "Epoch: [19]  [ 90/147]  eta: 0:00:51  lr: 0.003928  min_lr: 0.003928  loss: 2.7479 (2.7878)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0015  max mem: 7679\n",
            "Epoch: [19]  [100/147]  eta: 0:00:42  lr: 0.003944  min_lr: 0.003944  loss: 2.7479 (2.7828)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0019  max mem: 7679\n",
            "Epoch: [19]  [110/147]  eta: 0:00:32  lr: 0.003955  min_lr: 0.003955  loss: 2.8212 (2.7883)  weight_decay: 0.0500 (0.0500)  time: 0.8530  data: 0.0018  max mem: 7679\n",
            "Epoch: [19]  [120/147]  eta: 0:00:23  lr: 0.003972  min_lr: 0.003972  loss: 2.8212 (2.7867)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0017  max mem: 7679\n",
            "Epoch: [19]  [130/147]  eta: 0:00:15  lr: 0.003983  min_lr: 0.003983  loss: 2.8007 (2.7836)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0007  max mem: 7679\n",
            "Epoch: [19]  [140/147]  eta: 0:00:06  lr: 0.004000  min_lr: 0.004000  loss: 2.7285 (2.7859)  weight_decay: 0.0500 (0.0500)  time: 0.8547  data: 0.0003  max mem: 7679\n",
            "Epoch: [19]  [146/147]  eta: 0:00:00  lr: 0.004000  min_lr: 0.004000  loss: 2.8285 (2.7861)  weight_decay: 0.0500 (0.0500)  time: 0.7253  data: 0.0002  max mem: 7679\n",
            "Epoch: [19] Total time: 0:02:07 (0.8671 s / it)\n",
            "Averaged stats: lr: 0.004000  min_lr: 0.004000  loss: 2.8285 (2.7861)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:00  loss: 1.2374 (1.2374)  acc1: 79.1667 (79.1667)  acc5: 93.7500 (93.7500)  time: 4.4084  data: 3.9554  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 1.4008 (1.4378)  acc1: 65.6250 (66.6667)  acc5: 93.7500 (93.3712)  time: 0.8667  data: 0.4561  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 1.4458 (1.5680)  acc1: 62.5000 (53.8194)  acc5: 93.7500 (93.9484)  time: 0.4593  data: 0.0552  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.4539 (1.5684)  acc1: 58.3333 (53.3938)  acc5: 93.7500 (93.7164)  time: 0.4054  data: 0.0022  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.4539 (1.5365)  acc1: 58.3333 (54.2675)  acc5: 91.6667 (92.9682)  time: 0.4037  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5470 s / it)\n",
            "* Acc@1 54.268 Acc@5 92.968 loss 1.536\n",
            "Accuracy of the model on the 3925 test images: 54.3%\n",
            "Max accuracy: 54.27%\n",
            "Test:  [ 0/41]  eta: 0:03:22  loss: 6.6672 (6.6672)  acc1: 2.0833 (2.0833)  acc5: 9.3750 (9.3750)  time: 4.9358  data: 4.4824  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 6.6203 (6.4715)  acc1: 5.2083 (6.9129)  acc5: 11.4583 (17.6136)  time: 0.8228  data: 0.4120  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 6.6533 (6.6136)  acc1: 0.0000 (3.8690)  acc5: 6.2500 (10.7639)  time: 0.4110  data: 0.0027  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.7266 (6.5404)  acc1: 0.0000 (3.5282)  acc5: 3.1250 (14.1465)  time: 0.4110  data: 0.0004  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.4939 (6.4354)  acc1: 1.0417 (8.5096)  acc5: 17.7083 (19.6688)  time: 0.4101  data: 0.0003  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5296 s / it)\n",
            "* Acc@1 8.510 Acc@5 19.669 loss 6.435\n",
            "Accuracy of the model EMA on 3925 test images: 8.5%\n",
            "Max EMA accuracy: 8.51%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [20]  [  0/147]  eta: 0:09:09  lr: 0.004000  min_lr: 0.004000  loss: 2.8508 (2.8508)  weight_decay: 0.0500 (0.0500)  time: 3.7405  data: 2.4979  max mem: 7679\n",
            "Epoch: [20]  [ 10/147]  eta: 0:02:33  lr: 0.004000  min_lr: 0.004000  loss: 2.8180 (2.7937)  weight_decay: 0.0500 (0.0500)  time: 1.1239  data: 0.2274  max mem: 7679\n",
            "Epoch: [20]  [ 20/147]  eta: 0:02:06  lr: 0.004000  min_lr: 0.004000  loss: 2.8136 (2.7904)  weight_decay: 0.0500 (0.0500)  time: 0.8597  data: 0.0004  max mem: 7679\n",
            "Epoch: [20]  [ 30/147]  eta: 0:01:51  lr: 0.004000  min_lr: 0.004000  loss: 2.8180 (2.8032)  weight_decay: 0.0500 (0.0500)  time: 0.8566  data: 0.0004  max mem: 7679\n",
            "Epoch: [20]  [ 40/147]  eta: 0:01:39  lr: 0.004000  min_lr: 0.004000  loss: 2.7963 (2.7830)  weight_decay: 0.0500 (0.0500)  time: 0.8537  data: 0.0009  max mem: 7679\n",
            "Epoch: [20]  [ 50/147]  eta: 0:01:28  lr: 0.004000  min_lr: 0.004000  loss: 2.7666 (2.7804)  weight_decay: 0.0500 (0.0500)  time: 0.8512  data: 0.0016  max mem: 7679\n",
            "Epoch: [20]  [ 60/147]  eta: 0:01:18  lr: 0.004000  min_lr: 0.004000  loss: 2.8179 (2.7874)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0013  max mem: 7679\n",
            "Epoch: [20]  [ 70/147]  eta: 0:01:08  lr: 0.004000  min_lr: 0.004000  loss: 2.8483 (2.7835)  weight_decay: 0.0500 (0.0500)  time: 0.8460  data: 0.0012  max mem: 7679\n",
            "Epoch: [20]  [ 80/147]  eta: 0:00:59  lr: 0.004000  min_lr: 0.004000  loss: 2.8514 (2.7929)  weight_decay: 0.0500 (0.0500)  time: 0.8460  data: 0.0010  max mem: 7679\n",
            "Epoch: [20]  [ 90/147]  eta: 0:00:50  lr: 0.003999  min_lr: 0.003999  loss: 2.7930 (2.7850)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0016  max mem: 7679\n",
            "Epoch: [20]  [100/147]  eta: 0:00:41  lr: 0.003999  min_lr: 0.003999  loss: 2.7544 (2.7847)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0019  max mem: 7679\n",
            "Epoch: [20]  [110/147]  eta: 0:00:32  lr: 0.003999  min_lr: 0.003999  loss: 2.7533 (2.7833)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0022  max mem: 7679\n",
            "Epoch: [20]  [120/147]  eta: 0:00:23  lr: 0.003999  min_lr: 0.003999  loss: 2.7319 (2.7802)  weight_decay: 0.0500 (0.0500)  time: 0.8541  data: 0.0024  max mem: 7679\n",
            "Epoch: [20]  [130/147]  eta: 0:00:14  lr: 0.003999  min_lr: 0.003999  loss: 2.7798 (2.7800)  weight_decay: 0.0500 (0.0500)  time: 0.8559  data: 0.0018  max mem: 7679\n",
            "Epoch: [20]  [140/147]  eta: 0:00:06  lr: 0.003999  min_lr: 0.003999  loss: 2.7650 (2.7780)  weight_decay: 0.0500 (0.0500)  time: 0.8556  data: 0.0012  max mem: 7679\n",
            "Epoch: [20]  [146/147]  eta: 0:00:00  lr: 0.003999  min_lr: 0.003999  loss: 2.7798 (2.7806)  weight_decay: 0.0500 (0.0500)  time: 0.7254  data: 0.0002  max mem: 7679\n",
            "Epoch: [20] Total time: 0:02:06 (0.8576 s / it)\n",
            "Averaged stats: lr: 0.003999  min_lr: 0.003999  loss: 2.7798 (2.7806)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:37  loss: 0.9520 (0.9520)  acc1: 84.3750 (84.3750)  acc5: 94.7917 (94.7917)  time: 5.3031  data: 4.8457  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:30  loss: 1.2044 (1.4198)  acc1: 71.8750 (61.4583)  acc5: 91.6667 (87.5000)  time: 0.9784  data: 0.5748  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:14  loss: 1.5585 (1.6127)  acc1: 52.0833 (49.0575)  acc5: 89.5833 (88.7897)  time: 0.4720  data: 0.0741  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.5585 (1.5422)  acc1: 54.1667 (52.4866)  acc5: 93.7500 (90.5578)  time: 0.4010  data: 0.0003  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.4661 (1.5054)  acc1: 56.2500 (54.4713)  acc5: 93.7500 (91.3631)  time: 0.4026  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:23 (0.5667 s / it)\n",
            "* Acc@1 54.471 Acc@5 91.363 loss 1.505\n",
            "Accuracy of the model on the 3925 test images: 54.5%\n",
            "Max accuracy: 54.47%\n",
            "Test:  [ 0/41]  eta: 0:02:16  loss: 6.6281 (6.6281)  acc1: 5.2083 (5.2083)  acc5: 11.4583 (11.4583)  time: 3.3263  data: 2.8930  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.5772 (6.4243)  acc1: 5.2083 (7.8598)  acc5: 12.5000 (19.7917)  time: 0.6811  data: 0.2637  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 6.6077 (6.5744)  acc1: 1.0417 (4.5635)  acc5: 8.3333 (12.1528)  time: 0.4188  data: 0.0024  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.6871 (6.4949)  acc1: 1.0417 (4.1667)  acc5: 4.1667 (16.0282)  time: 0.4183  data: 0.0021  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.4328 (6.3811)  acc1: 1.0417 (9.2739)  acc5: 17.7083 (21.7070)  time: 0.4147  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4979 s / it)\n",
            "* Acc@1 9.274 Acc@5 21.707 loss 6.381\n",
            "Accuracy of the model EMA on 3925 test images: 9.3%\n",
            "Max EMA accuracy: 9.27%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [21]  [  0/147]  eta: 0:12:33  lr: 0.003998  min_lr: 0.003998  loss: 3.1599 (3.1599)  weight_decay: 0.0500 (0.0500)  time: 5.1259  data: 3.1729  max mem: 7679\n",
            "Epoch: [21]  [ 10/147]  eta: 0:02:51  lr: 0.003998  min_lr: 0.003998  loss: 2.8784 (2.8415)  weight_decay: 0.0500 (0.0500)  time: 1.2504  data: 0.2889  max mem: 7679\n",
            "Epoch: [21]  [ 20/147]  eta: 0:02:15  lr: 0.003998  min_lr: 0.003998  loss: 2.7886 (2.7844)  weight_decay: 0.0500 (0.0500)  time: 0.8629  data: 0.0005  max mem: 7679\n",
            "Epoch: [21]  [ 30/147]  eta: 0:01:56  lr: 0.003998  min_lr: 0.003998  loss: 2.7493 (2.7845)  weight_decay: 0.0500 (0.0500)  time: 0.8604  data: 0.0006  max mem: 7679\n",
            "Epoch: [21]  [ 40/147]  eta: 0:01:43  lr: 0.003997  min_lr: 0.003997  loss: 2.7565 (2.7678)  weight_decay: 0.0500 (0.0500)  time: 0.8553  data: 0.0008  max mem: 7679\n",
            "Epoch: [21]  [ 50/147]  eta: 0:01:31  lr: 0.003997  min_lr: 0.003997  loss: 2.7751 (2.7812)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0009  max mem: 7679\n",
            "Epoch: [21]  [ 60/147]  eta: 0:01:20  lr: 0.003997  min_lr: 0.003997  loss: 2.7776 (2.7749)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0014  max mem: 7679\n",
            "Epoch: [21]  [ 70/147]  eta: 0:01:10  lr: 0.003997  min_lr: 0.003997  loss: 2.7847 (2.7859)  weight_decay: 0.0500 (0.0500)  time: 0.8445  data: 0.0012  max mem: 7679\n",
            "Epoch: [21]  [ 80/147]  eta: 0:01:00  lr: 0.003996  min_lr: 0.003996  loss: 2.8536 (2.7852)  weight_decay: 0.0500 (0.0500)  time: 0.8442  data: 0.0007  max mem: 7679\n",
            "Epoch: [21]  [ 90/147]  eta: 0:00:51  lr: 0.003996  min_lr: 0.003996  loss: 2.7761 (2.7864)  weight_decay: 0.0500 (0.0500)  time: 0.8463  data: 0.0020  max mem: 7679\n",
            "Epoch: [21]  [100/147]  eta: 0:00:42  lr: 0.003996  min_lr: 0.003996  loss: 2.8274 (2.7909)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0021  max mem: 7679\n",
            "Epoch: [21]  [110/147]  eta: 0:00:32  lr: 0.003995  min_lr: 0.003995  loss: 2.8852 (2.8018)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0013  max mem: 7679\n",
            "Epoch: [21]  [120/147]  eta: 0:00:23  lr: 0.003995  min_lr: 0.003995  loss: 2.8852 (2.8033)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0023  max mem: 7679\n",
            "Epoch: [21]  [130/147]  eta: 0:00:15  lr: 0.003995  min_lr: 0.003995  loss: 2.8248 (2.8028)  weight_decay: 0.0500 (0.0500)  time: 0.8576  data: 0.0024  max mem: 7679\n",
            "Epoch: [21]  [140/147]  eta: 0:00:06  lr: 0.003994  min_lr: 0.003994  loss: 2.7926 (2.8030)  weight_decay: 0.0500 (0.0500)  time: 0.8547  data: 0.0010  max mem: 7679\n",
            "Epoch: [21]  [146/147]  eta: 0:00:00  lr: 0.003994  min_lr: 0.003994  loss: 2.8272 (2.8042)  weight_decay: 0.0500 (0.0500)  time: 0.7261  data: 0.0002  max mem: 7679\n",
            "Epoch: [21] Total time: 0:02:07 (0.8687 s / it)\n",
            "Averaged stats: lr: 0.003994  min_lr: 0.003994  loss: 2.8272 (2.8042)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:52  loss: 1.2333 (1.2333)  acc1: 75.0000 (75.0000)  acc5: 95.8333 (95.8333)  time: 4.1994  data: 3.7769  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 1.4170 (1.4073)  acc1: 66.6667 (65.6250)  acc5: 95.8333 (94.8864)  time: 0.7525  data: 0.3447  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.4701 (1.5542)  acc1: 61.4583 (53.8194)  acc5: 94.7917 (93.7500)  time: 0.4048  data: 0.0012  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.4023 (1.5263)  acc1: 61.4583 (57.2917)  acc5: 94.7917 (93.0780)  time: 0.4026  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3269 (1.4978)  acc1: 65.6250 (58.3949)  acc5: 92.7083 (92.5860)  time: 0.4028  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5052 s / it)\n",
            "* Acc@1 58.395 Acc@5 92.586 loss 1.498\n",
            "Accuracy of the model on the 3925 test images: 58.4%\n",
            "Max accuracy: 58.39%\n",
            "Test:  [ 0/41]  eta: 0:02:52  loss: 6.5849 (6.5849)  acc1: 6.2500 (6.2500)  acc5: 12.5000 (12.5000)  time: 4.2033  data: 3.6838  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 6.5303 (6.3740)  acc1: 6.2500 (7.9545)  acc5: 15.6250 (22.1591)  time: 0.7626  data: 0.3365  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.5643 (6.5331)  acc1: 1.0417 (4.7123)  acc5: 10.4167 (13.6409)  time: 0.4233  data: 0.0027  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.6260 (6.4476)  acc1: 0.0000 (4.3683)  acc5: 6.2500 (17.6747)  time: 0.4207  data: 0.0019  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.3698 (6.3247)  acc1: 3.1250 (9.7325)  acc5: 20.8333 (23.6433)  time: 0.4097  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5179 s / it)\n",
            "* Acc@1 9.732 Acc@5 23.643 loss 6.325\n",
            "Accuracy of the model EMA on 3925 test images: 9.7%\n",
            "Max EMA accuracy: 9.73%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [22]  [  0/147]  eta: 0:12:25  lr: 0.003994  min_lr: 0.003994  loss: 2.8400 (2.8400)  weight_decay: 0.0500 (0.0500)  time: 5.0682  data: 3.8101  max mem: 7679\n",
            "Epoch: [22]  [ 10/147]  eta: 0:02:52  lr: 0.003993  min_lr: 0.003993  loss: 2.8290 (2.8282)  weight_decay: 0.0500 (0.0500)  time: 1.2624  data: 0.3475  max mem: 7679\n",
            "Epoch: [22]  [ 20/147]  eta: 0:02:16  lr: 0.003993  min_lr: 0.003993  loss: 2.8482 (2.8377)  weight_decay: 0.0500 (0.0500)  time: 0.8717  data: 0.0009  max mem: 7679\n",
            "Epoch: [22]  [ 30/147]  eta: 0:01:57  lr: 0.003993  min_lr: 0.003993  loss: 2.7785 (2.8153)  weight_decay: 0.0500 (0.0500)  time: 0.8600  data: 0.0004  max mem: 7679\n",
            "Epoch: [22]  [ 40/147]  eta: 0:01:43  lr: 0.003992  min_lr: 0.003992  loss: 2.7281 (2.8003)  weight_decay: 0.0500 (0.0500)  time: 0.8611  data: 0.0006  max mem: 7679\n",
            "Epoch: [22]  [ 50/147]  eta: 0:01:31  lr: 0.003992  min_lr: 0.003992  loss: 2.7252 (2.7787)  weight_decay: 0.0500 (0.0500)  time: 0.8551  data: 0.0007  max mem: 7679\n",
            "Epoch: [22]  [ 60/147]  eta: 0:01:20  lr: 0.003991  min_lr: 0.003991  loss: 2.7513 (2.7764)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0010  max mem: 7679\n",
            "Epoch: [22]  [ 70/147]  eta: 0:01:10  lr: 0.003991  min_lr: 0.003991  loss: 2.7977 (2.7811)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0012  max mem: 7679\n",
            "Epoch: [22]  [ 80/147]  eta: 0:01:00  lr: 0.003990  min_lr: 0.003990  loss: 2.7603 (2.7832)  weight_decay: 0.0500 (0.0500)  time: 0.8455  data: 0.0008  max mem: 7679\n",
            "Epoch: [22]  [ 90/147]  eta: 0:00:51  lr: 0.003989  min_lr: 0.003989  loss: 2.8051 (2.7840)  weight_decay: 0.0500 (0.0500)  time: 0.8455  data: 0.0012  max mem: 7679\n",
            "Epoch: [22]  [100/147]  eta: 0:00:42  lr: 0.003989  min_lr: 0.003989  loss: 2.7219 (2.7768)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0031  max mem: 7679\n",
            "Epoch: [22]  [110/147]  eta: 0:00:33  lr: 0.003988  min_lr: 0.003988  loss: 2.7797 (2.7833)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0028  max mem: 7679\n",
            "Epoch: [22]  [120/147]  eta: 0:00:24  lr: 0.003988  min_lr: 0.003988  loss: 2.8462 (2.7863)  weight_decay: 0.0500 (0.0500)  time: 0.8542  data: 0.0018  max mem: 7679\n",
            "Epoch: [22]  [130/147]  eta: 0:00:15  lr: 0.003987  min_lr: 0.003987  loss: 2.8136 (2.7900)  weight_decay: 0.0500 (0.0500)  time: 0.8557  data: 0.0025  max mem: 7679\n",
            "Epoch: [22]  [140/147]  eta: 0:00:06  lr: 0.003986  min_lr: 0.003986  loss: 2.7870 (2.7870)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0013  max mem: 7679\n",
            "Epoch: [22]  [146/147]  eta: 0:00:00  lr: 0.003986  min_lr: 0.003986  loss: 2.7773 (2.7871)  weight_decay: 0.0500 (0.0500)  time: 0.7245  data: 0.0003  max mem: 7679\n",
            "Epoch: [22] Total time: 0:02:07 (0.8688 s / it)\n",
            "Averaged stats: lr: 0.003986  min_lr: 0.003986  loss: 2.7773 (2.7871)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:33  loss: 0.8449 (0.8449)  acc1: 84.3750 (84.3750)  acc5: 96.8750 (96.8750)  time: 5.2058  data: 4.7621  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 1.1074 (1.3418)  acc1: 73.9583 (62.5000)  acc5: 93.7500 (92.3295)  time: 0.8448  data: 0.4354  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 1.1185 (1.4796)  acc1: 69.7917 (54.4147)  acc5: 92.7083 (92.0635)  time: 0.4117  data: 0.0045  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.6725 (1.5264)  acc1: 41.6667 (51.9825)  acc5: 94.7917 (92.4395)  time: 0.4091  data: 0.0032  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.5755 (1.4733)  acc1: 50.0000 (54.1911)  acc5: 94.7917 (92.7389)  time: 0.4027  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5344 s / it)\n",
            "* Acc@1 54.191 Acc@5 92.739 loss 1.473\n",
            "Accuracy of the model on the 3925 test images: 54.2%\n",
            "Max accuracy: 58.39%\n",
            "Test:  [ 0/41]  eta: 0:03:33  loss: 6.5360 (6.5360)  acc1: 9.3750 (9.3750)  acc5: 14.5833 (14.5833)  time: 5.1963  data: 4.7493  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 6.4784 (6.3207)  acc1: 8.3333 (8.9015)  acc5: 18.7500 (24.1477)  time: 0.8752  data: 0.4552  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 6.5175 (6.4893)  acc1: 2.0833 (5.3075)  acc5: 14.5833 (15.1786)  time: 0.4268  data: 0.0139  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.5597 (6.3983)  acc1: 0.0000 (5.2419)  acc5: 8.3333 (19.8589)  time: 0.4110  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.3048 (6.2658)  acc1: 3.1250 (10.5478)  acc5: 26.0417 (26.0637)  time: 0.4082  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5481 s / it)\n",
            "* Acc@1 10.548 Acc@5 26.064 loss 6.266\n",
            "Accuracy of the model EMA on 3925 test images: 10.5%\n",
            "Max EMA accuracy: 10.55%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [23]  [  0/147]  eta: 0:08:19  lr: 0.003986  min_lr: 0.003986  loss: 2.5058 (2.5058)  weight_decay: 0.0500 (0.0500)  time: 3.3974  data: 2.4543  max mem: 7679\n",
            "Epoch: [23]  [ 10/147]  eta: 0:02:28  lr: 0.003986  min_lr: 0.003986  loss: 2.7521 (2.7263)  weight_decay: 0.0500 (0.0500)  time: 1.0870  data: 0.2238  max mem: 7679\n",
            "Epoch: [23]  [ 20/147]  eta: 0:02:04  lr: 0.003985  min_lr: 0.003985  loss: 2.7227 (2.7021)  weight_decay: 0.0500 (0.0500)  time: 0.8568  data: 0.0006  max mem: 7679\n",
            "Epoch: [23]  [ 30/147]  eta: 0:01:49  lr: 0.003984  min_lr: 0.003984  loss: 2.6595 (2.7043)  weight_decay: 0.0500 (0.0500)  time: 0.8574  data: 0.0007  max mem: 7679\n",
            "Epoch: [23]  [ 40/147]  eta: 0:01:38  lr: 0.003983  min_lr: 0.003983  loss: 2.7487 (2.7023)  weight_decay: 0.0500 (0.0500)  time: 0.8573  data: 0.0008  max mem: 7679\n",
            "Epoch: [23]  [ 50/147]  eta: 0:01:27  lr: 0.003983  min_lr: 0.003983  loss: 2.7622 (2.7207)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0006  max mem: 7679\n",
            "Epoch: [23]  [ 60/147]  eta: 0:01:18  lr: 0.003982  min_lr: 0.003982  loss: 2.8512 (2.7402)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0010  max mem: 7679\n",
            "Epoch: [23]  [ 70/147]  eta: 0:01:08  lr: 0.003981  min_lr: 0.003981  loss: 2.7832 (2.7387)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0008  max mem: 7679\n",
            "Epoch: [23]  [ 80/147]  eta: 0:00:59  lr: 0.003981  min_lr: 0.003981  loss: 2.7252 (2.7384)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0006  max mem: 7679\n",
            "Epoch: [23]  [ 90/147]  eta: 0:00:50  lr: 0.003980  min_lr: 0.003980  loss: 2.7317 (2.7402)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0006  max mem: 7679\n",
            "Epoch: [23]  [100/147]  eta: 0:00:41  lr: 0.003979  min_lr: 0.003979  loss: 2.7402 (2.7477)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0011  max mem: 7679\n",
            "Epoch: [23]  [110/147]  eta: 0:00:32  lr: 0.003978  min_lr: 0.003978  loss: 2.8365 (2.7475)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0012  max mem: 7679\n",
            "Epoch: [23]  [120/147]  eta: 0:00:23  lr: 0.003977  min_lr: 0.003977  loss: 2.8018 (2.7447)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0006  max mem: 7679\n",
            "Epoch: [23]  [130/147]  eta: 0:00:14  lr: 0.003977  min_lr: 0.003977  loss: 2.7752 (2.7463)  weight_decay: 0.0500 (0.0500)  time: 0.8565  data: 0.0010  max mem: 7679\n",
            "Epoch: [23]  [140/147]  eta: 0:00:06  lr: 0.003976  min_lr: 0.003976  loss: 2.7752 (2.7452)  weight_decay: 0.0500 (0.0500)  time: 0.8543  data: 0.0008  max mem: 7679\n",
            "Epoch: [23]  [146/147]  eta: 0:00:00  lr: 0.003976  min_lr: 0.003976  loss: 2.7772 (2.7479)  weight_decay: 0.0500 (0.0500)  time: 0.7261  data: 0.0002  max mem: 7679\n",
            "Epoch: [23] Total time: 0:02:05 (0.8552 s / it)\n",
            "Averaged stats: lr: 0.003976  min_lr: 0.003976  loss: 2.7772 (2.7479)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:27  loss: 0.8764 (0.8764)  acc1: 82.2917 (82.2917)  acc5: 96.8750 (96.8750)  time: 5.0641  data: 4.6246  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:28  loss: 1.1812 (1.1584)  acc1: 75.0000 (72.4432)  acc5: 95.8333 (95.8333)  time: 0.9078  data: 0.5062  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:14  loss: 1.3434 (1.4416)  acc1: 59.3750 (56.8948)  acc5: 95.8333 (94.6925)  time: 0.4468  data: 0.0486  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.4431 (1.4182)  acc1: 57.2917 (59.9798)  acc5: 95.8333 (94.4556)  time: 0.4033  data: 0.0015  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3326 (1.3790)  acc1: 64.5833 (61.2229)  acc5: 94.7917 (94.0892)  time: 0.4042  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5527 s / it)\n",
            "* Acc@1 61.223 Acc@5 94.089 loss 1.379\n",
            "Accuracy of the model on the 3925 test images: 61.2%\n",
            "Max accuracy: 61.22%\n",
            "Test:  [ 0/41]  eta: 0:02:47  loss: 6.4867 (6.4867)  acc1: 9.3750 (9.3750)  acc5: 17.7083 (17.7083)  time: 4.0888  data: 3.6301  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 6.4255 (6.2663)  acc1: 9.3750 (9.3750)  acc5: 19.7917 (26.6098)  time: 0.7496  data: 0.3338  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.4649 (6.4445)  acc1: 2.0833 (5.9028)  acc5: 16.6667 (17.1131)  time: 0.4161  data: 0.0048  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.4877 (6.3476)  acc1: 1.0417 (5.9140)  acc5: 14.5833 (22.7151)  time: 0.4129  data: 0.0028  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.2365 (6.2049)  acc1: 4.1667 (11.3631)  acc5: 28.1250 (28.7643)  time: 0.4090  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5116 s / it)\n",
            "* Acc@1 11.363 Acc@5 28.764 loss 6.205\n",
            "Accuracy of the model EMA on 3925 test images: 11.4%\n",
            "Max EMA accuracy: 11.36%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [24]  [  0/147]  eta: 0:09:50  lr: 0.003975  min_lr: 0.003975  loss: 2.7727 (2.7727)  weight_decay: 0.0500 (0.0500)  time: 4.0149  data: 2.9119  max mem: 7679\n",
            "Epoch: [24]  [ 10/147]  eta: 0:02:41  lr: 0.003975  min_lr: 0.003975  loss: 2.7919 (2.7789)  weight_decay: 0.0500 (0.0500)  time: 1.1777  data: 0.2651  max mem: 7679\n",
            "Epoch: [24]  [ 20/147]  eta: 0:02:10  lr: 0.003974  min_lr: 0.003974  loss: 2.7466 (2.7499)  weight_decay: 0.0500 (0.0500)  time: 0.8757  data: 0.0006  max mem: 7679\n",
            "Epoch: [24]  [ 30/147]  eta: 0:01:53  lr: 0.003973  min_lr: 0.003973  loss: 2.7466 (2.7554)  weight_decay: 0.0500 (0.0500)  time: 0.8552  data: 0.0006  max mem: 7679\n",
            "Epoch: [24]  [ 40/147]  eta: 0:01:40  lr: 0.003972  min_lr: 0.003972  loss: 2.7572 (2.7527)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0005  max mem: 7679\n",
            "Epoch: [24]  [ 50/147]  eta: 0:01:29  lr: 0.003971  min_lr: 0.003971  loss: 2.7572 (2.7522)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0008  max mem: 7679\n",
            "Epoch: [24]  [ 60/147]  eta: 0:01:19  lr: 0.003970  min_lr: 0.003970  loss: 2.7978 (2.7530)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0009  max mem: 7679\n",
            "Epoch: [24]  [ 70/147]  eta: 0:01:09  lr: 0.003969  min_lr: 0.003969  loss: 2.7704 (2.7454)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0010  max mem: 7679\n",
            "Epoch: [24]  [ 80/147]  eta: 0:00:59  lr: 0.003968  min_lr: 0.003968  loss: 2.8140 (2.7591)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0018  max mem: 7679\n",
            "Epoch: [24]  [ 90/147]  eta: 0:00:50  lr: 0.003967  min_lr: 0.003967  loss: 2.8441 (2.7598)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0018  max mem: 7679\n",
            "Epoch: [24]  [100/147]  eta: 0:00:41  lr: 0.003966  min_lr: 0.003966  loss: 2.7600 (2.7594)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0015  max mem: 7679\n",
            "Epoch: [24]  [110/147]  eta: 0:00:32  lr: 0.003965  min_lr: 0.003965  loss: 2.7271 (2.7570)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0016  max mem: 7679\n",
            "Epoch: [24]  [120/147]  eta: 0:00:23  lr: 0.003964  min_lr: 0.003964  loss: 2.7050 (2.7495)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0021  max mem: 7679\n",
            "Epoch: [24]  [130/147]  eta: 0:00:14  lr: 0.003963  min_lr: 0.003963  loss: 2.7207 (2.7514)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0017  max mem: 7679\n",
            "Epoch: [24]  [140/147]  eta: 0:00:06  lr: 0.003962  min_lr: 0.003962  loss: 2.8483 (2.7596)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0005  max mem: 7679\n",
            "Epoch: [24]  [146/147]  eta: 0:00:00  lr: 0.003962  min_lr: 0.003962  loss: 2.8483 (2.7592)  weight_decay: 0.0500 (0.0500)  time: 0.7256  data: 0.0002  max mem: 7679\n",
            "Epoch: [24] Total time: 0:02:06 (0.8626 s / it)\n",
            "Averaged stats: lr: 0.003962  min_lr: 0.003962  loss: 2.8483 (2.7592)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:02  loss: 0.8779 (0.8779)  acc1: 81.2500 (81.2500)  acc5: 94.7917 (94.7917)  time: 2.9996  data: 2.5391  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 1.1023 (1.2322)  acc1: 76.0417 (69.6023)  acc5: 94.7917 (93.1818)  time: 0.6977  data: 0.2826  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 1.6588 (1.5841)  acc1: 51.0417 (53.1746)  acc5: 91.6667 (88.6409)  time: 0.4375  data: 0.0290  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.5177 (1.5219)  acc1: 56.2500 (55.9476)  acc5: 92.7083 (90.5242)  time: 0.4064  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2992 (1.4508)  acc1: 61.4583 (57.8599)  acc5: 94.7917 (91.5669)  time: 0.4051  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4942 s / it)\n",
            "* Acc@1 57.860 Acc@5 91.567 loss 1.451\n",
            "Accuracy of the model on the 3925 test images: 57.9%\n",
            "Max accuracy: 61.22%\n",
            "Test:  [ 0/41]  eta: 0:02:19  loss: 6.4347 (6.4347)  acc1: 10.4167 (10.4167)  acc5: 20.8333 (20.8333)  time: 3.4045  data: 2.9724  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.3699 (6.2100)  acc1: 9.3750 (9.9432)  acc5: 20.8333 (27.9356)  time: 0.6905  data: 0.2745  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 6.4083 (6.3983)  acc1: 2.0833 (6.2996)  acc5: 19.7917 (18.2540)  time: 0.4183  data: 0.0063  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.4285 (6.2960)  acc1: 1.0417 (6.2500)  acc5: 22.9167 (24.5968)  time: 0.4139  data: 0.0040  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.1672 (6.1432)  acc1: 4.1667 (11.7452)  acc5: 32.2917 (30.7006)  time: 0.4070  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4945 s / it)\n",
            "* Acc@1 11.745 Acc@5 30.701 loss 6.143\n",
            "Accuracy of the model EMA on 3925 test images: 11.7%\n",
            "Max EMA accuracy: 11.75%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [25]  [  0/147]  eta: 0:08:15  lr: 0.003962  min_lr: 0.003962  loss: 2.7188 (2.7188)  weight_decay: 0.0500 (0.0500)  time: 3.3688  data: 2.3996  max mem: 7679\n",
            "Epoch: [25]  [ 10/147]  eta: 0:02:33  lr: 0.003961  min_lr: 0.003961  loss: 2.7188 (2.7345)  weight_decay: 0.0500 (0.0500)  time: 1.1203  data: 0.2331  max mem: 7679\n",
            "Epoch: [25]  [ 20/147]  eta: 0:02:06  lr: 0.003959  min_lr: 0.003959  loss: 2.6782 (2.6985)  weight_decay: 0.0500 (0.0500)  time: 0.8750  data: 0.0086  max mem: 7679\n",
            "Epoch: [25]  [ 30/147]  eta: 0:01:50  lr: 0.003959  min_lr: 0.003959  loss: 2.6977 (2.7188)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0010  max mem: 7679\n",
            "Epoch: [25]  [ 40/147]  eta: 0:01:38  lr: 0.003957  min_lr: 0.003957  loss: 2.6977 (2.7066)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0011  max mem: 7679\n",
            "Epoch: [25]  [ 50/147]  eta: 0:01:28  lr: 0.003956  min_lr: 0.003956  loss: 2.7006 (2.7204)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0013  max mem: 7679\n",
            "Epoch: [25]  [ 60/147]  eta: 0:01:18  lr: 0.003955  min_lr: 0.003955  loss: 2.7025 (2.7129)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0013  max mem: 7679\n",
            "Epoch: [25]  [ 70/147]  eta: 0:01:08  lr: 0.003954  min_lr: 0.003954  loss: 2.6732 (2.7131)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0016  max mem: 7679\n",
            "Epoch: [25]  [ 80/147]  eta: 0:00:59  lr: 0.003953  min_lr: 0.003953  loss: 2.6514 (2.7038)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0015  max mem: 7679\n",
            "Epoch: [25]  [ 90/147]  eta: 0:00:50  lr: 0.003952  min_lr: 0.003952  loss: 2.7136 (2.7116)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0009  max mem: 7679\n",
            "Epoch: [25]  [100/147]  eta: 0:00:41  lr: 0.003950  min_lr: 0.003950  loss: 2.7378 (2.7119)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0015  max mem: 7679\n",
            "Epoch: [25]  [110/147]  eta: 0:00:32  lr: 0.003949  min_lr: 0.003949  loss: 2.7585 (2.7218)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0016  max mem: 7679\n",
            "Epoch: [25]  [120/147]  eta: 0:00:23  lr: 0.003948  min_lr: 0.003948  loss: 2.7371 (2.7170)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0009  max mem: 7679\n",
            "Epoch: [25]  [130/147]  eta: 0:00:14  lr: 0.003947  min_lr: 0.003947  loss: 2.6575 (2.7154)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0006  max mem: 7679\n",
            "Epoch: [25]  [140/147]  eta: 0:00:06  lr: 0.003945  min_lr: 0.003945  loss: 2.6625 (2.7152)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0005  max mem: 7679\n",
            "Epoch: [25]  [146/147]  eta: 0:00:00  lr: 0.003945  min_lr: 0.003945  loss: 2.6938 (2.7163)  weight_decay: 0.0500 (0.0500)  time: 0.7263  data: 0.0002  max mem: 7679\n",
            "Epoch: [25] Total time: 0:02:06 (0.8574 s / it)\n",
            "Averaged stats: lr: 0.003945  min_lr: 0.003945  loss: 2.6938 (2.7163)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:30  loss: 0.7844 (0.7844)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 3.6702  data: 3.2129  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.9918 (1.1325)  acc1: 77.0833 (72.9167)  acc5: 94.7917 (94.1288)  time: 0.7018  data: 0.2946  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 1.1261 (1.3910)  acc1: 69.7917 (60.3671)  acc5: 94.7917 (91.1706)  time: 0.4049  data: 0.0044  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.3268 (1.3605)  acc1: 62.5000 (61.6263)  acc5: 94.7917 (92.1035)  time: 0.4038  data: 0.0031  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3938 (1.3334)  acc1: 56.2500 (61.8854)  acc5: 93.7500 (92.7643)  time: 0.4032  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4924 s / it)\n",
            "* Acc@1 61.885 Acc@5 92.764 loss 1.333\n",
            "Accuracy of the model on the 3925 test images: 61.9%\n",
            "Max accuracy: 61.89%\n",
            "Test:  [ 0/41]  eta: 0:01:56  loss: 6.3795 (6.3795)  acc1: 10.4167 (10.4167)  acc5: 23.9583 (23.9583)  time: 2.8528  data: 2.3698  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 6.3108 (6.1514)  acc1: 10.4167 (11.0795)  acc5: 22.9167 (30.1136)  time: 0.7732  data: 0.3415  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.3483 (6.3510)  acc1: 2.0833 (7.1429)  acc5: 21.8750 (20.1389)  time: 0.4976  data: 0.0770  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.3900 (6.2435)  acc1: 1.0417 (7.4261)  acc5: 22.9167 (27.1169)  time: 0.4203  data: 0.0077  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.0998 (6.0810)  acc1: 8.3333 (12.8408)  acc5: 37.5000 (33.0446)  time: 0.4107  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5220 s / it)\n",
            "* Acc@1 12.841 Acc@5 33.045 loss 6.081\n",
            "Accuracy of the model EMA on 3925 test images: 12.8%\n",
            "Max EMA accuracy: 12.84%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [26]  [  0/147]  eta: 0:11:44  lr: 0.003945  min_lr: 0.003945  loss: 2.7491 (2.7491)  weight_decay: 0.0500 (0.0500)  time: 4.7896  data: 3.8480  max mem: 7679\n",
            "Epoch: [26]  [ 10/147]  eta: 0:02:45  lr: 0.003944  min_lr: 0.003944  loss: 2.7491 (2.7400)  weight_decay: 0.0500 (0.0500)  time: 1.2094  data: 0.3506  max mem: 7679\n",
            "Epoch: [26]  [ 20/147]  eta: 0:02:13  lr: 0.003942  min_lr: 0.003942  loss: 2.7501 (2.6970)  weight_decay: 0.0500 (0.0500)  time: 0.8675  data: 0.0018  max mem: 7679\n",
            "Epoch: [26]  [ 30/147]  eta: 0:01:55  lr: 0.003941  min_lr: 0.003941  loss: 2.6496 (2.6791)  weight_decay: 0.0500 (0.0500)  time: 0.8677  data: 0.0018  max mem: 7679\n",
            "Epoch: [26]  [ 40/147]  eta: 0:01:42  lr: 0.003940  min_lr: 0.003940  loss: 2.6354 (2.6722)  weight_decay: 0.0500 (0.0500)  time: 0.8558  data: 0.0010  max mem: 7679\n",
            "Epoch: [26]  [ 50/147]  eta: 0:01:30  lr: 0.003938  min_lr: 0.003938  loss: 2.6684 (2.6848)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0007  max mem: 7679\n",
            "Epoch: [26]  [ 60/147]  eta: 0:01:20  lr: 0.003937  min_lr: 0.003937  loss: 2.7520 (2.6817)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0013  max mem: 7679\n",
            "Epoch: [26]  [ 70/147]  eta: 0:01:10  lr: 0.003936  min_lr: 0.003936  loss: 2.7016 (2.6865)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0013  max mem: 7679\n",
            "Epoch: [26]  [ 80/147]  eta: 0:01:00  lr: 0.003934  min_lr: 0.003934  loss: 2.7318 (2.6992)  weight_decay: 0.0500 (0.0500)  time: 0.8470  data: 0.0020  max mem: 7679\n",
            "Epoch: [26]  [ 90/147]  eta: 0:00:51  lr: 0.003933  min_lr: 0.003933  loss: 2.7916 (2.7078)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0024  max mem: 7679\n",
            "Epoch: [26]  [100/147]  eta: 0:00:41  lr: 0.003931  min_lr: 0.003931  loss: 2.7692 (2.7068)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0021  max mem: 7679\n",
            "Epoch: [26]  [110/147]  eta: 0:00:32  lr: 0.003930  min_lr: 0.003930  loss: 2.6678 (2.7000)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0019  max mem: 7679\n",
            "Epoch: [26]  [120/147]  eta: 0:00:23  lr: 0.003928  min_lr: 0.003928  loss: 2.6678 (2.7066)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0016  max mem: 7679\n",
            "Epoch: [26]  [130/147]  eta: 0:00:15  lr: 0.003927  min_lr: 0.003927  loss: 2.7227 (2.7051)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0014  max mem: 7679\n",
            "Epoch: [26]  [140/147]  eta: 0:00:06  lr: 0.003926  min_lr: 0.003926  loss: 2.6990 (2.7076)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0002  max mem: 7679\n",
            "Epoch: [26]  [146/147]  eta: 0:00:00  lr: 0.003926  min_lr: 0.003926  loss: 2.6990 (2.7063)  weight_decay: 0.0500 (0.0500)  time: 0.7264  data: 0.0002  max mem: 7679\n",
            "Epoch: [26] Total time: 0:02:07 (0.8655 s / it)\n",
            "Averaged stats: lr: 0.003926  min_lr: 0.003926  loss: 2.6990 (2.7063)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:01  loss: 0.7361 (0.7361)  acc1: 88.5417 (88.5417)  acc5: 93.7500 (93.7500)  time: 4.4204  data: 3.9841  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 1.0235 (1.1374)  acc1: 75.0000 (71.9697)  acc5: 93.7500 (94.2235)  time: 0.7807  data: 0.3734  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.0581 (1.3082)  acc1: 70.8333 (63.5913)  acc5: 93.7500 (94.3452)  time: 0.4156  data: 0.0081  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.3747 (1.3347)  acc1: 58.3333 (62.1304)  acc5: 93.7500 (94.5229)  time: 0.4090  data: 0.0020  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3610 (1.3303)  acc1: 60.4167 (63.0828)  acc5: 93.7500 (94.2420)  time: 0.4045  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5169 s / it)\n",
            "* Acc@1 63.083 Acc@5 94.242 loss 1.330\n",
            "Accuracy of the model on the 3925 test images: 63.1%\n",
            "Max accuracy: 63.08%\n",
            "Test:  [ 0/41]  eta: 0:03:09  loss: 6.3254 (6.3254)  acc1: 11.4583 (11.4583)  acc5: 26.0417 (26.0417)  time: 4.6132  data: 4.1662  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 6.2527 (6.0924)  acc1: 11.4583 (12.1212)  acc5: 27.0833 (32.6705)  time: 0.8508  data: 0.4336  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 6.2901 (6.3033)  acc1: 3.1250 (8.0853)  acc5: 22.9167 (22.2222)  time: 0.4401  data: 0.0318  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.3523 (6.1909)  acc1: 1.0417 (8.5685)  acc5: 30.2083 (30.2083)  time: 0.4067  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 6.0307 (6.0182)  acc1: 11.4583 (13.8599)  acc5: 42.7083 (35.9236)  time: 0.4075  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5399 s / it)\n",
            "* Acc@1 13.860 Acc@5 35.924 loss 6.018\n",
            "Accuracy of the model EMA on 3925 test images: 13.9%\n",
            "Max EMA accuracy: 13.86%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [27]  [  0/147]  eta: 0:09:16  lr: 0.003925  min_lr: 0.003925  loss: 2.7199 (2.7199)  weight_decay: 0.0500 (0.0500)  time: 3.7854  data: 2.8593  max mem: 7679\n",
            "Epoch: [27]  [ 10/147]  eta: 0:02:34  lr: 0.003924  min_lr: 0.003924  loss: 2.7730 (2.7630)  weight_decay: 0.0500 (0.0500)  time: 1.1301  data: 0.2611  max mem: 7679\n",
            "Epoch: [27]  [ 20/147]  eta: 0:02:07  lr: 0.003922  min_lr: 0.003922  loss: 2.7730 (2.7400)  weight_decay: 0.0500 (0.0500)  time: 0.8621  data: 0.0011  max mem: 7679\n",
            "Epoch: [27]  [ 30/147]  eta: 0:01:51  lr: 0.003921  min_lr: 0.003921  loss: 2.7067 (2.7311)  weight_decay: 0.0500 (0.0500)  time: 0.8594  data: 0.0014  max mem: 7679\n",
            "Epoch: [27]  [ 40/147]  eta: 0:01:39  lr: 0.003919  min_lr: 0.003919  loss: 2.6917 (2.7176)  weight_decay: 0.0500 (0.0500)  time: 0.8576  data: 0.0017  max mem: 7679\n",
            "Epoch: [27]  [ 50/147]  eta: 0:01:28  lr: 0.003918  min_lr: 0.003918  loss: 2.7286 (2.7234)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0018  max mem: 7679\n",
            "Epoch: [27]  [ 60/147]  eta: 0:01:18  lr: 0.003916  min_lr: 0.003916  loss: 2.7285 (2.7260)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0015  max mem: 7679\n",
            "Epoch: [27]  [ 70/147]  eta: 0:01:08  lr: 0.003915  min_lr: 0.003915  loss: 2.6868 (2.7189)  weight_decay: 0.0500 (0.0500)  time: 0.8464  data: 0.0015  max mem: 7679\n",
            "Epoch: [27]  [ 80/147]  eta: 0:00:59  lr: 0.003913  min_lr: 0.003913  loss: 2.6860 (2.7157)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.0018  max mem: 7679\n",
            "Epoch: [27]  [ 90/147]  eta: 0:00:50  lr: 0.003911  min_lr: 0.003911  loss: 2.7711 (2.7217)  weight_decay: 0.0500 (0.0500)  time: 0.8472  data: 0.0015  max mem: 7679\n",
            "Epoch: [27]  [100/147]  eta: 0:00:41  lr: 0.003909  min_lr: 0.003909  loss: 2.7023 (2.7171)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0012  max mem: 7679\n",
            "Epoch: [27]  [110/147]  eta: 0:00:32  lr: 0.003908  min_lr: 0.003908  loss: 2.7030 (2.7195)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0013  max mem: 7679\n",
            "Epoch: [27]  [120/147]  eta: 0:00:23  lr: 0.003906  min_lr: 0.003906  loss: 2.7386 (2.7210)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0018  max mem: 7679\n",
            "Epoch: [27]  [130/147]  eta: 0:00:14  lr: 0.003905  min_lr: 0.003905  loss: 2.7322 (2.7248)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0012  max mem: 7679\n",
            "Epoch: [27]  [140/147]  eta: 0:00:06  lr: 0.003903  min_lr: 0.003903  loss: 2.7322 (2.7273)  weight_decay: 0.0500 (0.0500)  time: 0.8545  data: 0.0008  max mem: 7679\n",
            "Epoch: [27]  [146/147]  eta: 0:00:00  lr: 0.003903  min_lr: 0.003903  loss: 2.7322 (2.7264)  weight_decay: 0.0500 (0.0500)  time: 0.7290  data: 0.0007  max mem: 7679\n",
            "Epoch: [27] Total time: 0:02:06 (0.8593 s / it)\n",
            "Averaged stats: lr: 0.003903  min_lr: 0.003903  loss: 2.7322 (2.7264)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:48  loss: 1.0685 (1.0685)  acc1: 82.2917 (82.2917)  acc5: 93.7500 (93.7500)  time: 4.1119  data: 3.6437  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 1.1454 (1.1709)  acc1: 70.8333 (73.1061)  acc5: 94.7917 (94.6023)  time: 0.7464  data: 0.3335  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.4140 (1.4460)  acc1: 62.5000 (57.4901)  acc5: 93.7500 (93.4524)  time: 0.4064  data: 0.0035  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.3878 (1.4032)  acc1: 60.4167 (59.7782)  acc5: 93.7500 (93.8172)  time: 0.4028  data: 0.0024  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2986 (1.3770)  acc1: 61.4583 (60.1274)  acc5: 93.7500 (93.8344)  time: 0.4027  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5048 s / it)\n",
            "* Acc@1 60.127 Acc@5 93.834 loss 1.377\n",
            "Accuracy of the model on the 3925 test images: 60.1%\n",
            "Max accuracy: 63.08%\n",
            "Test:  [ 0/41]  eta: 0:02:15  loss: 6.2663 (6.2663)  acc1: 12.5000 (12.5000)  acc5: 31.2500 (31.2500)  time: 3.3149  data: 2.8809  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 6.1905 (6.0317)  acc1: 12.5000 (12.6894)  acc5: 30.2083 (34.9432)  time: 0.6813  data: 0.2697  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 6.2269 (6.2540)  acc1: 3.1250 (8.6310)  acc5: 26.0417 (23.9583)  time: 0.4162  data: 0.0070  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.3154 (6.1372)  acc1: 1.0417 (9.6774)  acc5: 30.2083 (32.2917)  time: 0.4140  data: 0.0029  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.9621 (5.9540)  acc1: 14.5833 (14.8280)  acc5: 44.7917 (37.7580)  time: 0.4110  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4953 s / it)\n",
            "* Acc@1 14.828 Acc@5 37.758 loss 5.954\n",
            "Accuracy of the model EMA on 3925 test images: 14.8%\n",
            "Max EMA accuracy: 14.83%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [28]  [  0/147]  eta: 0:10:08  lr: 0.003902  min_lr: 0.003902  loss: 2.9159 (2.9159)  weight_decay: 0.0500 (0.0500)  time: 4.1376  data: 2.9434  max mem: 7679\n",
            "Epoch: [28]  [ 10/147]  eta: 0:02:41  lr: 0.003901  min_lr: 0.003901  loss: 2.6865 (2.6379)  weight_decay: 0.0500 (0.0500)  time: 1.1764  data: 0.2686  max mem: 7679\n",
            "Epoch: [28]  [ 20/147]  eta: 0:02:10  lr: 0.003899  min_lr: 0.003899  loss: 2.6865 (2.6468)  weight_decay: 0.0500 (0.0500)  time: 0.8682  data: 0.0011  max mem: 7679\n",
            "Epoch: [28]  [ 30/147]  eta: 0:01:53  lr: 0.003897  min_lr: 0.003897  loss: 2.6992 (2.6664)  weight_decay: 0.0500 (0.0500)  time: 0.8567  data: 0.0014  max mem: 7679\n",
            "Epoch: [28]  [ 40/147]  eta: 0:01:40  lr: 0.003895  min_lr: 0.003895  loss: 2.6992 (2.6739)  weight_decay: 0.0500 (0.0500)  time: 0.8573  data: 0.0012  max mem: 7679\n",
            "Epoch: [28]  [ 50/147]  eta: 0:01:29  lr: 0.003894  min_lr: 0.003894  loss: 2.7024 (2.6701)  weight_decay: 0.0500 (0.0500)  time: 0.8549  data: 0.0009  max mem: 7679\n",
            "Epoch: [28]  [ 60/147]  eta: 0:01:19  lr: 0.003892  min_lr: 0.003892  loss: 2.6707 (2.6654)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0010  max mem: 7679\n",
            "Epoch: [28]  [ 70/147]  eta: 0:01:09  lr: 0.003890  min_lr: 0.003890  loss: 2.6844 (2.6749)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0010  max mem: 7679\n",
            "Epoch: [28]  [ 80/147]  eta: 0:01:00  lr: 0.003888  min_lr: 0.003888  loss: 2.7710 (2.6889)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0011  max mem: 7679\n",
            "Epoch: [28]  [ 90/147]  eta: 0:00:50  lr: 0.003887  min_lr: 0.003887  loss: 2.6954 (2.6786)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0012  max mem: 7679\n",
            "Epoch: [28]  [100/147]  eta: 0:00:41  lr: 0.003885  min_lr: 0.003885  loss: 2.6222 (2.6767)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0014  max mem: 7679\n",
            "Epoch: [28]  [110/147]  eta: 0:00:32  lr: 0.003883  min_lr: 0.003883  loss: 2.6532 (2.6784)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0015  max mem: 7679\n",
            "Epoch: [28]  [120/147]  eta: 0:00:23  lr: 0.003881  min_lr: 0.003881  loss: 2.7327 (2.6829)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0013  max mem: 7679\n",
            "Epoch: [28]  [130/147]  eta: 0:00:14  lr: 0.003879  min_lr: 0.003879  loss: 2.7327 (2.6848)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0014  max mem: 7679\n",
            "Epoch: [28]  [140/147]  eta: 0:00:06  lr: 0.003877  min_lr: 0.003877  loss: 2.7104 (2.6815)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0009  max mem: 7679\n",
            "Epoch: [28]  [146/147]  eta: 0:00:00  lr: 0.003877  min_lr: 0.003877  loss: 2.7037 (2.6802)  weight_decay: 0.0500 (0.0500)  time: 0.7244  data: 0.0002  max mem: 7679\n",
            "Epoch: [28] Total time: 0:02:06 (0.8639 s / it)\n",
            "Averaged stats: lr: 0.003877  min_lr: 0.003877  loss: 2.7037 (2.6802)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:39  loss: 0.6269 (0.6269)  acc1: 86.4583 (86.4583)  acc5: 94.7917 (94.7917)  time: 3.8794  data: 3.4135  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 1.0704 (0.9957)  acc1: 75.0000 (75.3788)  acc5: 95.8333 (95.7386)  time: 0.8028  data: 0.3969  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.1605 (1.2789)  acc1: 67.7083 (63.0952)  acc5: 95.8333 (94.7421)  time: 0.4495  data: 0.0492  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.2479 (1.2662)  acc1: 64.5833 (64.6841)  acc5: 94.7917 (94.3884)  time: 0.4043  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1607 (1.2299)  acc1: 66.6667 (65.9363)  acc5: 94.7917 (94.4968)  time: 0.4045  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5201 s / it)\n",
            "* Acc@1 65.936 Acc@5 94.497 loss 1.230\n",
            "Accuracy of the model on the 3925 test images: 65.9%\n",
            "Max accuracy: 65.94%\n",
            "Test:  [ 0/41]  eta: 0:01:55  loss: 6.2034 (6.2034)  acc1: 13.5417 (13.5417)  acc5: 33.3333 (33.3333)  time: 2.8257  data: 2.3744  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 6.1248 (5.9679)  acc1: 13.5417 (13.3523)  acc5: 32.2917 (37.9735)  time: 0.7414  data: 0.3297  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 6.1600 (6.2026)  acc1: 4.1667 (9.3254)  acc5: 28.1250 (26.1409)  time: 0.4765  data: 0.0639  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.2798 (6.0828)  acc1: 1.0417 (10.6183)  acc5: 32.2917 (34.4758)  time: 0.4156  data: 0.0014  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.8938 (5.8892)  acc1: 13.5417 (15.6433)  acc5: 46.8750 (39.6943)  time: 0.4078  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5109 s / it)\n",
            "* Acc@1 15.643 Acc@5 39.694 loss 5.889\n",
            "Accuracy of the model EMA on 3925 test images: 15.6%\n",
            "Max EMA accuracy: 15.64%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [29]  [  0/147]  eta: 0:10:21  lr: 0.003876  min_lr: 0.003876  loss: 2.5862 (2.5862)  weight_decay: 0.0500 (0.0500)  time: 4.2245  data: 3.1503  max mem: 7679\n",
            "Epoch: [29]  [ 10/147]  eta: 0:02:47  lr: 0.003875  min_lr: 0.003875  loss: 2.6064 (2.6717)  weight_decay: 0.0500 (0.0500)  time: 1.2235  data: 0.3379  max mem: 7679\n",
            "Epoch: [29]  [ 20/147]  eta: 0:02:13  lr: 0.003873  min_lr: 0.003873  loss: 2.7176 (2.6702)  weight_decay: 0.0500 (0.0500)  time: 0.8923  data: 0.0297  max mem: 7679\n",
            "Epoch: [29]  [ 30/147]  eta: 0:01:55  lr: 0.003871  min_lr: 0.003871  loss: 2.6807 (2.6623)  weight_decay: 0.0500 (0.0500)  time: 0.8576  data: 0.0016  max mem: 7679\n",
            "Epoch: [29]  [ 40/147]  eta: 0:01:42  lr: 0.003869  min_lr: 0.003869  loss: 2.7170 (2.6785)  weight_decay: 0.0500 (0.0500)  time: 0.8580  data: 0.0024  max mem: 7679\n",
            "Epoch: [29]  [ 50/147]  eta: 0:01:30  lr: 0.003867  min_lr: 0.003867  loss: 2.7723 (2.6950)  weight_decay: 0.0500 (0.0500)  time: 0.8542  data: 0.0024  max mem: 7679\n",
            "Epoch: [29]  [ 60/147]  eta: 0:01:20  lr: 0.003865  min_lr: 0.003865  loss: 2.6567 (2.6834)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0005  max mem: 7679\n",
            "Epoch: [29]  [ 70/147]  eta: 0:01:10  lr: 0.003863  min_lr: 0.003863  loss: 2.6567 (2.6889)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0008  max mem: 7679\n",
            "Epoch: [29]  [ 80/147]  eta: 0:01:00  lr: 0.003861  min_lr: 0.003861  loss: 2.6596 (2.6862)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0012  max mem: 7679\n",
            "Epoch: [29]  [ 90/147]  eta: 0:00:51  lr: 0.003859  min_lr: 0.003859  loss: 2.7180 (2.6915)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0011  max mem: 7679\n",
            "Epoch: [29]  [100/147]  eta: 0:00:41  lr: 0.003857  min_lr: 0.003857  loss: 2.7093 (2.6868)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0013  max mem: 7679\n",
            "Epoch: [29]  [110/147]  eta: 0:00:32  lr: 0.003855  min_lr: 0.003855  loss: 2.6498 (2.6851)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0018  max mem: 7679\n",
            "Epoch: [29]  [120/147]  eta: 0:00:23  lr: 0.003853  min_lr: 0.003853  loss: 2.7067 (2.6884)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0015  max mem: 7679\n",
            "Epoch: [29]  [130/147]  eta: 0:00:14  lr: 0.003851  min_lr: 0.003851  loss: 2.6221 (2.6783)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0005  max mem: 7679\n",
            "Epoch: [29]  [140/147]  eta: 0:00:06  lr: 0.003849  min_lr: 0.003849  loss: 2.5336 (2.6779)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0002  max mem: 7679\n",
            "Epoch: [29]  [146/147]  eta: 0:00:00  lr: 0.003849  min_lr: 0.003849  loss: 2.6221 (2.6799)  weight_decay: 0.0500 (0.0500)  time: 0.7259  data: 0.0002  max mem: 7679\n",
            "Epoch: [29] Total time: 0:02:07 (0.8664 s / it)\n",
            "Averaged stats: lr: 0.003849  min_lr: 0.003849  loss: 2.6221 (2.6799)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 0.7758 (0.7758)  acc1: 84.3750 (84.3750)  acc5: 93.7500 (93.7500)  time: 3.1808  data: 2.7235  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.8042 (0.8403)  acc1: 84.3750 (82.4811)  acc5: 96.8750 (96.2121)  time: 0.6743  data: 0.2681  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 1.0049 (1.2072)  acc1: 75.0000 (65.7242)  acc5: 95.8333 (93.4524)  time: 0.4180  data: 0.0134  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.3126 (1.2443)  acc1: 62.5000 (64.2473)  acc5: 94.7917 (93.5148)  time: 0.4075  data: 0.0022  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.3997 (1.2776)  acc1: 53.1250 (62.5987)  acc5: 93.7500 (93.3248)  time: 0.4035  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4874 s / it)\n",
            "* Acc@1 62.599 Acc@5 93.325 loss 1.278\n",
            "Accuracy of the model on the 3925 test images: 62.6%\n",
            "Max accuracy: 65.94%\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 6.1377 (6.1377)  acc1: 17.7083 (17.7083)  acc5: 35.4167 (35.4167)  time: 3.1740  data: 2.7095  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 6.0509 (5.9020)  acc1: 12.5000 (14.3939)  acc5: 35.4167 (40.5303)  time: 0.6724  data: 0.2542  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 6.0903 (6.1499)  acc1: 5.2083 (10.1687)  acc5: 31.2500 (27.7778)  time: 0.4238  data: 0.0086  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.2443 (6.0272)  acc1: 2.0833 (11.9960)  acc5: 32.2917 (36.3575)  time: 0.4192  data: 0.0044  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.8272 (5.8243)  acc1: 13.5417 (16.6879)  acc5: 48.9583 (41.3758)  time: 0.4084  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4926 s / it)\n",
            "* Acc@1 16.688 Acc@5 41.376 loss 5.824\n",
            "Accuracy of the model EMA on 3925 test images: 16.7%\n",
            "Max EMA accuracy: 16.69%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [30]  [  0/147]  eta: 0:13:38  lr: 0.003848  min_lr: 0.003848  loss: 2.5775 (2.5775)  weight_decay: 0.0500 (0.0500)  time: 5.5713  data: 4.3782  max mem: 7679\n",
            "Epoch: [30]  [ 10/147]  eta: 0:02:55  lr: 0.003846  min_lr: 0.003846  loss: 2.5959 (2.6216)  weight_decay: 0.0500 (0.0500)  time: 1.2817  data: 0.3988  max mem: 7679\n",
            "Epoch: [30]  [ 20/147]  eta: 0:02:17  lr: 0.003844  min_lr: 0.003844  loss: 2.6243 (2.6370)  weight_decay: 0.0500 (0.0500)  time: 0.8551  data: 0.0015  max mem: 7679\n",
            "Epoch: [30]  [ 30/147]  eta: 0:01:57  lr: 0.003842  min_lr: 0.003842  loss: 2.7057 (2.6511)  weight_decay: 0.0500 (0.0500)  time: 0.8565  data: 0.0013  max mem: 7679\n",
            "Epoch: [30]  [ 40/147]  eta: 0:01:44  lr: 0.003839  min_lr: 0.003839  loss: 2.6574 (2.6455)  weight_decay: 0.0500 (0.0500)  time: 0.8590  data: 0.0012  max mem: 7679\n",
            "Epoch: [30]  [ 50/147]  eta: 0:01:31  lr: 0.003838  min_lr: 0.003838  loss: 2.6637 (2.6489)  weight_decay: 0.0500 (0.0500)  time: 0.8561  data: 0.0014  max mem: 7679\n",
            "Epoch: [30]  [ 60/147]  eta: 0:01:21  lr: 0.003835  min_lr: 0.003835  loss: 2.7494 (2.6611)  weight_decay: 0.0500 (0.0500)  time: 0.8521  data: 0.0011  max mem: 7679\n",
            "Epoch: [30]  [ 70/147]  eta: 0:01:10  lr: 0.003833  min_lr: 0.003833  loss: 2.7287 (2.6634)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0010  max mem: 7679\n",
            "Epoch: [30]  [ 80/147]  eta: 0:01:01  lr: 0.003831  min_lr: 0.003831  loss: 2.7443 (2.6763)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0016  max mem: 7679\n",
            "Epoch: [30]  [ 90/147]  eta: 0:00:51  lr: 0.003829  min_lr: 0.003829  loss: 2.7836 (2.6897)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.0017  max mem: 7679\n",
            "Epoch: [30]  [100/147]  eta: 0:00:42  lr: 0.003826  min_lr: 0.003826  loss: 2.7836 (2.6970)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0012  max mem: 7679\n",
            "Epoch: [30]  [110/147]  eta: 0:00:33  lr: 0.003824  min_lr: 0.003824  loss: 2.7692 (2.6981)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0011  max mem: 7679\n",
            "Epoch: [30]  [120/147]  eta: 0:00:24  lr: 0.003822  min_lr: 0.003822  loss: 2.6399 (2.6950)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0022  max mem: 7679\n",
            "Epoch: [30]  [130/147]  eta: 0:00:15  lr: 0.003820  min_lr: 0.003820  loss: 2.6627 (2.6950)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0020  max mem: 7679\n",
            "Epoch: [30]  [140/147]  eta: 0:00:06  lr: 0.003817  min_lr: 0.003817  loss: 2.6994 (2.6930)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0002  max mem: 7679\n",
            "Epoch: [30]  [146/147]  eta: 0:00:00  lr: 0.003817  min_lr: 0.003817  loss: 2.7052 (2.6941)  weight_decay: 0.0500 (0.0500)  time: 0.7247  data: 0.0002  max mem: 7679\n",
            "Epoch: [30] Total time: 0:02:07 (0.8690 s / it)\n",
            "Averaged stats: lr: 0.003817  min_lr: 0.003817  loss: 2.7052 (2.6941)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:42  loss: 0.8449 (0.8449)  acc1: 82.2917 (82.2917)  acc5: 94.7917 (94.7917)  time: 6.8795  data: 6.4331  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:31  loss: 1.1980 (1.2375)  acc1: 65.6250 (65.9091)  acc5: 94.7917 (94.3182)  time: 1.0038  data: 0.5905  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:15  loss: 1.1980 (1.2586)  acc1: 63.5417 (64.7321)  acc5: 94.7917 (95.5357)  time: 0.4110  data: 0.0043  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.1963 (1.2331)  acc1: 67.7083 (66.0282)  acc5: 96.8750 (95.5981)  time: 0.4053  data: 0.0012  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1975 (1.2435)  acc1: 67.7083 (65.0955)  acc5: 92.9412 (94.7516)  time: 0.4054  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:23 (0.5814 s / it)\n",
            "* Acc@1 65.096 Acc@5 94.752 loss 1.244\n",
            "Accuracy of the model on the 3925 test images: 65.1%\n",
            "Max accuracy: 65.94%\n",
            "Test:  [ 0/41]  eta: 0:03:11  loss: 6.0707 (6.0707)  acc1: 18.7500 (18.7500)  acc5: 37.5000 (37.5000)  time: 4.6747  data: 4.1769  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 5.9755 (5.8361)  acc1: 15.6250 (14.8674)  acc5: 37.5000 (42.7083)  time: 0.8053  data: 0.3890  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 6.0198 (6.0972)  acc1: 6.2500 (10.4167)  acc5: 33.3333 (29.1171)  time: 0.4173  data: 0.0069  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.2101 (5.9716)  acc1: 2.0833 (12.8696)  acc5: 33.3333 (37.8024)  time: 0.4155  data: 0.0019  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.7578 (5.7590)  acc1: 12.5000 (17.4013)  acc5: 53.1250 (42.8535)  time: 0.4122  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5274 s / it)\n",
            "* Acc@1 17.401 Acc@5 42.854 loss 5.759\n",
            "Accuracy of the model EMA on 3925 test images: 17.4%\n",
            "Max EMA accuracy: 17.40%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [31]  [  0/147]  eta: 0:09:39  lr: 0.003816  min_lr: 0.003816  loss: 2.7203 (2.7203)  weight_decay: 0.0500 (0.0500)  time: 3.9402  data: 2.9799  max mem: 7679\n",
            "Epoch: [31]  [ 10/147]  eta: 0:02:35  lr: 0.003815  min_lr: 0.003815  loss: 2.7203 (2.7054)  weight_decay: 0.0500 (0.0500)  time: 1.1322  data: 0.2725  max mem: 7679\n",
            "Epoch: [31]  [ 20/147]  eta: 0:02:06  lr: 0.003812  min_lr: 0.003812  loss: 2.7494 (2.7373)  weight_decay: 0.0500 (0.0500)  time: 0.8518  data: 0.0013  max mem: 7679\n",
            "Epoch: [31]  [ 30/147]  eta: 0:01:51  lr: 0.003810  min_lr: 0.003810  loss: 2.6975 (2.6916)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0006  max mem: 7679\n",
            "Epoch: [31]  [ 40/147]  eta: 0:01:39  lr: 0.003807  min_lr: 0.003807  loss: 2.6587 (2.7078)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0003  max mem: 7679\n",
            "Epoch: [31]  [ 50/147]  eta: 0:01:28  lr: 0.003805  min_lr: 0.003805  loss: 2.6654 (2.6974)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0007  max mem: 7679\n",
            "Epoch: [31]  [ 60/147]  eta: 0:01:18  lr: 0.003802  min_lr: 0.003802  loss: 2.6982 (2.6981)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0010  max mem: 7679\n",
            "Epoch: [31]  [ 70/147]  eta: 0:01:08  lr: 0.003800  min_lr: 0.003800  loss: 2.7393 (2.6978)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0012  max mem: 7679\n",
            "Epoch: [31]  [ 80/147]  eta: 0:00:59  lr: 0.003798  min_lr: 0.003798  loss: 2.7486 (2.6973)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0011  max mem: 7679\n",
            "Epoch: [31]  [ 90/147]  eta: 0:00:50  lr: 0.003796  min_lr: 0.003796  loss: 2.7596 (2.7077)  weight_decay: 0.0500 (0.0500)  time: 0.8454  data: 0.0006  max mem: 7679\n",
            "Epoch: [31]  [100/147]  eta: 0:00:41  lr: 0.003793  min_lr: 0.003793  loss: 2.7709 (2.7066)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0009  max mem: 7679\n",
            "Epoch: [31]  [110/147]  eta: 0:00:32  lr: 0.003791  min_lr: 0.003791  loss: 2.7244 (2.7060)  weight_decay: 0.0500 (0.0500)  time: 0.8472  data: 0.0014  max mem: 7679\n",
            "Epoch: [31]  [120/147]  eta: 0:00:23  lr: 0.003788  min_lr: 0.003788  loss: 2.7246 (2.7062)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0010  max mem: 7679\n",
            "Epoch: [31]  [130/147]  eta: 0:00:14  lr: 0.003786  min_lr: 0.003786  loss: 2.6973 (2.7099)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0009  max mem: 7679\n",
            "Epoch: [31]  [140/147]  eta: 0:00:06  lr: 0.003783  min_lr: 0.003783  loss: 2.6884 (2.7042)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0007  max mem: 7679\n",
            "Epoch: [31]  [146/147]  eta: 0:00:00  lr: 0.003783  min_lr: 0.003783  loss: 2.6731 (2.7020)  weight_decay: 0.0500 (0.0500)  time: 0.7226  data: 0.0002  max mem: 7679\n",
            "Epoch: [31] Total time: 0:02:05 (0.8557 s / it)\n",
            "Averaged stats: lr: 0.003783  min_lr: 0.003783  loss: 2.6731 (2.7020)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:51  loss: 1.0391 (1.0391)  acc1: 79.1667 (79.1667)  acc5: 91.6667 (91.6667)  time: 4.1936  data: 3.7475  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 1.1169 (1.1177)  acc1: 71.8750 (71.7803)  acc5: 94.7917 (93.9394)  time: 0.7545  data: 0.3458  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.1169 (1.3242)  acc1: 69.7917 (60.2679)  acc5: 94.7917 (93.5020)  time: 0.4149  data: 0.0054  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.1215 (1.2821)  acc1: 64.5833 (61.9960)  acc5: 95.8333 (93.9516)  time: 0.4136  data: 0.0026  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2933 (1.2566)  acc1: 59.3750 (62.9299)  acc5: 95.8333 (94.2930)  time: 0.4059  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5115 s / it)\n",
            "* Acc@1 62.930 Acc@5 94.293 loss 1.257\n",
            "Accuracy of the model on the 3925 test images: 62.9%\n",
            "Max accuracy: 65.94%\n",
            "Test:  [ 0/41]  eta: 0:02:34  loss: 6.0000 (6.0000)  acc1: 20.8333 (20.8333)  acc5: 40.6250 (40.6250)  time: 3.7694  data: 3.2993  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 5.8991 (5.7694)  acc1: 15.6250 (16.1932)  acc5: 40.6250 (44.8864)  time: 0.7234  data: 0.3022  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.9459 (6.0445)  acc1: 8.3333 (11.2103)  acc5: 34.3750 (30.9028)  time: 0.4182  data: 0.0029  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.1787 (5.9168)  acc1: 2.0833 (14.0457)  acc5: 33.3333 (39.4489)  time: 0.4151  data: 0.0018  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.6861 (5.6945)  acc1: 12.5000 (18.3694)  acc5: 54.1667 (44.2803)  time: 0.4108  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5060 s / it)\n",
            "* Acc@1 18.369 Acc@5 44.280 loss 5.694\n",
            "Accuracy of the model EMA on 3925 test images: 18.4%\n",
            "Max EMA accuracy: 18.37%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [32]  [  0/147]  eta: 0:10:24  lr: 0.003782  min_lr: 0.003782  loss: 2.4704 (2.4704)  weight_decay: 0.0500 (0.0500)  time: 4.2453  data: 3.3346  max mem: 7679\n",
            "Epoch: [32]  [ 10/147]  eta: 0:02:37  lr: 0.003780  min_lr: 0.003780  loss: 2.6431 (2.6670)  weight_decay: 0.0500 (0.0500)  time: 1.1522  data: 0.3037  max mem: 7679\n",
            "Epoch: [32]  [ 20/147]  eta: 0:02:08  lr: 0.003777  min_lr: 0.003777  loss: 2.6276 (2.6442)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0012  max mem: 7679\n",
            "Epoch: [32]  [ 30/147]  eta: 0:01:52  lr: 0.003775  min_lr: 0.003775  loss: 2.5852 (2.6322)  weight_decay: 0.0500 (0.0500)  time: 0.8569  data: 0.0015  max mem: 7679\n",
            "Epoch: [32]  [ 40/147]  eta: 0:01:40  lr: 0.003772  min_lr: 0.003772  loss: 2.6649 (2.6468)  weight_decay: 0.0500 (0.0500)  time: 0.8558  data: 0.0008  max mem: 7679\n",
            "Epoch: [32]  [ 50/147]  eta: 0:01:29  lr: 0.003770  min_lr: 0.003770  loss: 2.6231 (2.6369)  weight_decay: 0.0500 (0.0500)  time: 0.8538  data: 0.0005  max mem: 7679\n",
            "Epoch: [32]  [ 60/147]  eta: 0:01:19  lr: 0.003767  min_lr: 0.003767  loss: 2.6177 (2.6291)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0007  max mem: 7679\n",
            "Epoch: [32]  [ 70/147]  eta: 0:01:09  lr: 0.003765  min_lr: 0.003765  loss: 2.6383 (2.6412)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0008  max mem: 7679\n",
            "Epoch: [32]  [ 80/147]  eta: 0:00:59  lr: 0.003762  min_lr: 0.003762  loss: 2.6383 (2.6369)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0013  max mem: 7679\n",
            "Epoch: [32]  [ 90/147]  eta: 0:00:50  lr: 0.003760  min_lr: 0.003760  loss: 2.6341 (2.6367)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0016  max mem: 7679\n",
            "Epoch: [32]  [100/147]  eta: 0:00:41  lr: 0.003757  min_lr: 0.003757  loss: 2.6531 (2.6406)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0011  max mem: 7679\n",
            "Epoch: [32]  [110/147]  eta: 0:00:32  lr: 0.003755  min_lr: 0.003755  loss: 2.6657 (2.6381)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0009  max mem: 7679\n",
            "Epoch: [32]  [120/147]  eta: 0:00:23  lr: 0.003751  min_lr: 0.003751  loss: 2.5777 (2.6350)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0012  max mem: 7679\n",
            "Epoch: [32]  [130/147]  eta: 0:00:14  lr: 0.003749  min_lr: 0.003749  loss: 2.6022 (2.6336)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0015  max mem: 7679\n",
            "Epoch: [32]  [140/147]  eta: 0:00:06  lr: 0.003746  min_lr: 0.003746  loss: 2.6578 (2.6361)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0010  max mem: 7679\n",
            "Epoch: [32]  [146/147]  eta: 0:00:00  lr: 0.003746  min_lr: 0.003746  loss: 2.6084 (2.6375)  weight_decay: 0.0500 (0.0500)  time: 0.7247  data: 0.0002  max mem: 7679\n",
            "Epoch: [32] Total time: 0:02:06 (0.8605 s / it)\n",
            "Averaged stats: lr: 0.003746  min_lr: 0.003746  loss: 2.6084 (2.6375)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:00  loss: 1.1515 (1.1515)  acc1: 78.1250 (78.1250)  acc5: 91.6667 (91.6667)  time: 4.3943  data: 3.9514  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 1.0229 (1.1055)  acc1: 73.9583 (73.3902)  acc5: 95.8333 (94.6023)  time: 0.7664  data: 0.3617  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.0229 (1.2274)  acc1: 72.9167 (66.0714)  acc5: 95.8333 (95.1885)  time: 0.4048  data: 0.0026  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.1041 (1.2145)  acc1: 66.6667 (66.0282)  acc5: 95.8333 (94.8925)  time: 0.4054  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1844 (1.2092)  acc1: 68.7500 (66.4459)  acc5: 94.7917 (94.6752)  time: 0.4048  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5160 s / it)\n",
            "* Acc@1 66.446 Acc@5 94.675 loss 1.209\n",
            "Accuracy of the model on the 3925 test images: 66.4%\n",
            "Max accuracy: 66.45%\n",
            "Test:  [ 0/41]  eta: 0:02:35  loss: 5.9299 (5.9299)  acc1: 20.8333 (20.8333)  acc5: 44.7917 (44.7917)  time: 3.7906  data: 3.3502  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 5.8219 (5.7021)  acc1: 15.6250 (16.6667)  acc5: 44.7917 (47.2538)  time: 0.7453  data: 0.3060  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.8731 (5.9920)  acc1: 8.3333 (11.5575)  acc5: 37.5000 (32.5397)  time: 0.4350  data: 0.0023  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.1482 (5.8622)  acc1: 2.0833 (14.7849)  acc5: 34.3750 (41.0954)  time: 0.4178  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.6130 (5.6315)  acc1: 14.5833 (19.0318)  acc5: 59.3750 (45.8599)  time: 0.4054  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5142 s / it)\n",
            "* Acc@1 19.032 Acc@5 45.860 loss 5.632\n",
            "Accuracy of the model EMA on 3925 test images: 19.0%\n",
            "Max EMA accuracy: 19.03%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [33]  [  0/147]  eta: 0:11:13  lr: 0.003745  min_lr: 0.003745  loss: 2.7329 (2.7329)  weight_decay: 0.0500 (0.0500)  time: 4.5832  data: 3.6109  max mem: 7679\n",
            "Epoch: [33]  [ 10/147]  eta: 0:02:42  lr: 0.003743  min_lr: 0.003743  loss: 2.6588 (2.6684)  weight_decay: 0.0500 (0.0500)  time: 1.1852  data: 0.3287  max mem: 7679\n",
            "Epoch: [33]  [ 20/147]  eta: 0:02:10  lr: 0.003740  min_lr: 0.003740  loss: 2.7046 (2.7093)  weight_decay: 0.0500 (0.0500)  time: 0.8530  data: 0.0004  max mem: 7679\n",
            "Epoch: [33]  [ 30/147]  eta: 0:01:54  lr: 0.003738  min_lr: 0.003738  loss: 2.7639 (2.6950)  weight_decay: 0.0500 (0.0500)  time: 0.8586  data: 0.0009  max mem: 7679\n",
            "Epoch: [33]  [ 40/147]  eta: 0:01:41  lr: 0.003734  min_lr: 0.003734  loss: 2.5945 (2.6637)  weight_decay: 0.0500 (0.0500)  time: 0.8569  data: 0.0010  max mem: 7679\n",
            "Epoch: [33]  [ 50/147]  eta: 0:01:29  lr: 0.003732  min_lr: 0.003732  loss: 2.6100 (2.6678)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0004  max mem: 7679\n",
            "Epoch: [33]  [ 60/147]  eta: 0:01:19  lr: 0.003729  min_lr: 0.003729  loss: 2.6725 (2.6767)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0003  max mem: 7679\n",
            "Epoch: [33]  [ 70/147]  eta: 0:01:09  lr: 0.003727  min_lr: 0.003727  loss: 2.6547 (2.6681)  weight_decay: 0.0500 (0.0500)  time: 0.8464  data: 0.0014  max mem: 7679\n",
            "Epoch: [33]  [ 80/147]  eta: 0:01:00  lr: 0.003723  min_lr: 0.003723  loss: 2.6547 (2.6693)  weight_decay: 0.0500 (0.0500)  time: 0.8463  data: 0.0022  max mem: 7679\n",
            "Epoch: [33]  [ 90/147]  eta: 0:00:50  lr: 0.003721  min_lr: 0.003721  loss: 2.6767 (2.6659)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0019  max mem: 7679\n",
            "Epoch: [33]  [100/147]  eta: 0:00:41  lr: 0.003718  min_lr: 0.003718  loss: 2.6529 (2.6610)  weight_decay: 0.0500 (0.0500)  time: 0.8489  data: 0.0018  max mem: 7679\n",
            "Epoch: [33]  [110/147]  eta: 0:00:32  lr: 0.003716  min_lr: 0.003716  loss: 2.6398 (2.6599)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0012  max mem: 7679\n",
            "Epoch: [33]  [120/147]  eta: 0:00:23  lr: 0.003712  min_lr: 0.003712  loss: 2.6854 (2.6649)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0011  max mem: 7679\n",
            "Epoch: [33]  [130/147]  eta: 0:00:14  lr: 0.003710  min_lr: 0.003710  loss: 2.7485 (2.6678)  weight_decay: 0.0500 (0.0500)  time: 0.8544  data: 0.0022  max mem: 7679\n",
            "Epoch: [33]  [140/147]  eta: 0:00:06  lr: 0.003706  min_lr: 0.003706  loss: 2.7485 (2.6677)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0016  max mem: 7679\n",
            "Epoch: [33]  [146/147]  eta: 0:00:00  lr: 0.003706  min_lr: 0.003706  loss: 2.7189 (2.6668)  weight_decay: 0.0500 (0.0500)  time: 0.7240  data: 0.0002  max mem: 7679\n",
            "Epoch: [33] Total time: 0:02:06 (0.8634 s / it)\n",
            "Averaged stats: lr: 0.003706  min_lr: 0.003706  loss: 2.7189 (2.6668)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:02  loss: 0.8803 (0.8803)  acc1: 83.3333 (83.3333)  acc5: 92.7083 (92.7083)  time: 2.9853  data: 2.5551  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.9761 (0.9642)  acc1: 80.2083 (78.2197)  acc5: 94.7917 (95.4545)  time: 0.6982  data: 0.2998  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 1.0635 (1.2596)  acc1: 73.9583 (64.3849)  acc5: 94.7917 (93.3036)  time: 0.4354  data: 0.0381  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.1564 (1.2192)  acc1: 65.6250 (65.7930)  acc5: 94.7917 (93.9180)  time: 0.4026  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1626 (1.2008)  acc1: 63.5417 (66.3185)  acc5: 94.7917 (94.3440)  time: 0.4029  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4910 s / it)\n",
            "* Acc@1 66.318 Acc@5 94.344 loss 1.201\n",
            "Accuracy of the model on the 3925 test images: 66.3%\n",
            "Max accuracy: 66.45%\n",
            "Test:  [ 0/41]  eta: 0:03:17  loss: 5.8561 (5.8561)  acc1: 21.8750 (21.8750)  acc5: 44.7917 (44.7917)  time: 4.8226  data: 4.3184  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 5.7511 (5.6326)  acc1: 16.6667 (17.6136)  acc5: 44.7917 (49.0530)  time: 0.8324  data: 0.4052  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.8051 (5.9381)  acc1: 9.3750 (12.1032)  acc5: 39.5833 (33.9286)  time: 0.4349  data: 0.0084  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.1086 (5.8075)  acc1: 2.0833 (15.5242)  acc5: 34.3750 (42.4731)  time: 0.4228  data: 0.0015  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.5405 (5.5686)  acc1: 15.6250 (19.6433)  acc5: 61.4583 (47.1083)  time: 0.4074  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5377 s / it)\n",
            "* Acc@1 19.643 Acc@5 47.108 loss 5.569\n",
            "Accuracy of the model EMA on 3925 test images: 19.6%\n",
            "Max EMA accuracy: 19.64%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [34]  [  0/147]  eta: 0:12:34  lr: 0.003705  min_lr: 0.003705  loss: 2.8184 (2.8184)  weight_decay: 0.0500 (0.0500)  time: 5.1343  data: 3.8444  max mem: 7679\n",
            "Epoch: [34]  [ 10/147]  eta: 0:02:50  lr: 0.003703  min_lr: 0.003703  loss: 2.7810 (2.6442)  weight_decay: 0.0500 (0.0500)  time: 1.2415  data: 0.3510  max mem: 7679\n",
            "Epoch: [34]  [ 20/147]  eta: 0:02:14  lr: 0.003700  min_lr: 0.003700  loss: 2.6451 (2.6633)  weight_decay: 0.0500 (0.0500)  time: 0.8554  data: 0.0011  max mem: 7679\n",
            "Epoch: [34]  [ 30/147]  eta: 0:01:56  lr: 0.003697  min_lr: 0.003697  loss: 2.6449 (2.6552)  weight_decay: 0.0500 (0.0500)  time: 0.8568  data: 0.0005  max mem: 7679\n",
            "Epoch: [34]  [ 40/147]  eta: 0:01:42  lr: 0.003694  min_lr: 0.003694  loss: 2.6006 (2.6543)  weight_decay: 0.0500 (0.0500)  time: 0.8577  data: 0.0007  max mem: 7679\n",
            "Epoch: [34]  [ 50/147]  eta: 0:01:31  lr: 0.003692  min_lr: 0.003692  loss: 2.6958 (2.6629)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0012  max mem: 7679\n",
            "Epoch: [34]  [ 60/147]  eta: 0:01:20  lr: 0.003688  min_lr: 0.003688  loss: 2.7187 (2.6770)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0018  max mem: 7679\n",
            "Epoch: [34]  [ 70/147]  eta: 0:01:10  lr: 0.003686  min_lr: 0.003686  loss: 2.7187 (2.6762)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0015  max mem: 7679\n",
            "Epoch: [34]  [ 80/147]  eta: 0:01:00  lr: 0.003682  min_lr: 0.003682  loss: 2.6914 (2.6718)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0009  max mem: 7679\n",
            "Epoch: [34]  [ 90/147]  eta: 0:00:51  lr: 0.003680  min_lr: 0.003680  loss: 2.6641 (2.6675)  weight_decay: 0.0500 (0.0500)  time: 0.8464  data: 0.0009  max mem: 7679\n",
            "Epoch: [34]  [100/147]  eta: 0:00:42  lr: 0.003676  min_lr: 0.003676  loss: 2.6641 (2.6655)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0025  max mem: 7679\n",
            "Epoch: [34]  [110/147]  eta: 0:00:32  lr: 0.003674  min_lr: 0.003674  loss: 2.7162 (2.6649)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0024  max mem: 7679\n",
            "Epoch: [34]  [120/147]  eta: 0:00:23  lr: 0.003670  min_lr: 0.003670  loss: 2.5613 (2.6524)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0009  max mem: 7679\n",
            "Epoch: [34]  [130/147]  eta: 0:00:15  lr: 0.003668  min_lr: 0.003668  loss: 2.4781 (2.6478)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0007  max mem: 7679\n",
            "Epoch: [34]  [140/147]  eta: 0:00:06  lr: 0.003664  min_lr: 0.003664  loss: 2.7015 (2.6530)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0002  max mem: 7679\n",
            "Epoch: [34]  [146/147]  eta: 0:00:00  lr: 0.003664  min_lr: 0.003664  loss: 2.6180 (2.6494)  weight_decay: 0.0500 (0.0500)  time: 0.7251  data: 0.0002  max mem: 7679\n",
            "Epoch: [34] Total time: 0:02:07 (0.8657 s / it)\n",
            "Averaged stats: lr: 0.003664  min_lr: 0.003664  loss: 2.6180 (2.6494)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:17  loss: 0.7702 (0.7702)  acc1: 85.4167 (85.4167)  acc5: 95.8333 (95.8333)  time: 4.8227  data: 4.3842  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 0.8486 (0.8118)  acc1: 80.2083 (80.7765)  acc5: 97.9167 (97.4432)  time: 0.8739  data: 0.4732  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 1.0179 (1.1791)  acc1: 75.0000 (66.2202)  acc5: 95.8333 (93.9980)  time: 0.4410  data: 0.0436  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.1583 (1.1584)  acc1: 65.6250 (66.7339)  acc5: 93.7500 (94.1196)  time: 0.4038  data: 0.0026  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1583 (1.1515)  acc1: 65.6250 (67.1338)  acc5: 94.7917 (94.4713)  time: 0.4037  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5449 s / it)\n",
            "* Acc@1 67.134 Acc@5 94.471 loss 1.151\n",
            "Accuracy of the model on the 3925 test images: 67.1%\n",
            "Max accuracy: 67.13%\n",
            "Test:  [ 0/41]  eta: 0:02:31  loss: 5.7786 (5.7786)  acc1: 23.9583 (23.9583)  acc5: 46.8750 (46.8750)  time: 3.7012  data: 3.2375  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 5.6839 (5.5627)  acc1: 15.6250 (18.4659)  acc5: 47.9167 (51.4205)  time: 0.7144  data: 0.2975  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.7492 (5.8843)  acc1: 9.3750 (12.6488)  acc5: 41.6667 (35.9623)  time: 0.4220  data: 0.0051  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 6.0639 (5.7540)  acc1: 2.0833 (16.0618)  acc5: 35.4167 (44.0188)  time: 0.4193  data: 0.0035  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.4746 (5.5070)  acc1: 14.5833 (20.1274)  acc5: 62.5000 (48.5605)  time: 0.4085  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5061 s / it)\n",
            "* Acc@1 20.127 Acc@5 48.561 loss 5.507\n",
            "Accuracy of the model EMA on 3925 test images: 20.1%\n",
            "Max EMA accuracy: 20.13%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [35]  [  0/147]  eta: 0:10:55  lr: 0.003663  min_lr: 0.003663  loss: 2.6560 (2.6560)  weight_decay: 0.0500 (0.0500)  time: 4.4576  data: 3.0990  max mem: 7679\n",
            "Epoch: [35]  [ 10/147]  eta: 0:02:41  lr: 0.003661  min_lr: 0.003661  loss: 2.7680 (2.7108)  weight_decay: 0.0500 (0.0500)  time: 1.1813  data: 0.2822  max mem: 7679\n",
            "Epoch: [35]  [ 20/147]  eta: 0:02:10  lr: 0.003657  min_lr: 0.003657  loss: 2.6979 (2.6907)  weight_decay: 0.0500 (0.0500)  time: 0.8582  data: 0.0006  max mem: 7679\n",
            "Epoch: [35]  [ 30/147]  eta: 0:01:54  lr: 0.003654  min_lr: 0.003654  loss: 2.6945 (2.6813)  weight_decay: 0.0500 (0.0500)  time: 0.8618  data: 0.0011  max mem: 7679\n",
            "Epoch: [35]  [ 40/147]  eta: 0:01:47  lr: 0.003651  min_lr: 0.003651  loss: 2.5764 (2.6380)  weight_decay: 0.0500 (0.0500)  time: 0.9760  data: 0.0032  max mem: 7679\n",
            "Epoch: [35]  [ 50/147]  eta: 0:01:34  lr: 0.003648  min_lr: 0.003648  loss: 2.5764 (2.6417)  weight_decay: 0.0500 (0.0500)  time: 0.9696  data: 0.0026  max mem: 7679\n",
            "Epoch: [35]  [ 60/147]  eta: 0:01:22  lr: 0.003645  min_lr: 0.003645  loss: 2.7028 (2.6498)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0008  max mem: 7679\n",
            "Epoch: [35]  [ 70/147]  eta: 0:01:12  lr: 0.003642  min_lr: 0.003642  loss: 2.7310 (2.6611)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0011  max mem: 7679\n",
            "Epoch: [35]  [ 80/147]  eta: 0:01:02  lr: 0.003638  min_lr: 0.003638  loss: 2.6958 (2.6568)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0008  max mem: 7679\n",
            "Epoch: [35]  [ 90/147]  eta: 0:00:52  lr: 0.003636  min_lr: 0.003636  loss: 2.6958 (2.6637)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0006  max mem: 7679\n",
            "Epoch: [35]  [100/147]  eta: 0:00:42  lr: 0.003632  min_lr: 0.003632  loss: 2.6618 (2.6546)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0007  max mem: 7679\n",
            "Epoch: [35]  [110/147]  eta: 0:00:33  lr: 0.003630  min_lr: 0.003630  loss: 2.5558 (2.6500)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0016  max mem: 7679\n",
            "Epoch: [35]  [120/147]  eta: 0:00:24  lr: 0.003626  min_lr: 0.003626  loss: 2.5984 (2.6458)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0016  max mem: 7679\n",
            "Epoch: [35]  [130/147]  eta: 0:00:15  lr: 0.003623  min_lr: 0.003623  loss: 2.6391 (2.6493)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0009  max mem: 7679\n",
            "Epoch: [35]  [140/147]  eta: 0:00:06  lr: 0.003619  min_lr: 0.003619  loss: 2.7521 (2.6563)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0007  max mem: 7679\n",
            "Epoch: [35]  [146/147]  eta: 0:00:00  lr: 0.003619  min_lr: 0.003619  loss: 2.6763 (2.6523)  weight_decay: 0.0500 (0.0500)  time: 0.7233  data: 0.0004  max mem: 7679\n",
            "Epoch: [35] Total time: 0:02:09 (0.8792 s / it)\n",
            "Averaged stats: lr: 0.003619  min_lr: 0.003619  loss: 2.6763 (2.6523)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:23  loss: 0.7473 (0.7473)  acc1: 86.4583 (86.4583)  acc5: 96.8750 (96.8750)  time: 3.4953  data: 3.0501  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.9353 (0.9311)  acc1: 79.1667 (79.2614)  acc5: 96.8750 (97.0644)  time: 0.6819  data: 0.2798  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.9812 (1.1472)  acc1: 76.0417 (70.1389)  acc5: 96.8750 (96.2302)  time: 0.4014  data: 0.0025  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.2385 (1.1721)  acc1: 68.7500 (70.1613)  acc5: 96.8750 (95.4301)  time: 0.4032  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2628 (1.1710)  acc1: 68.7500 (69.2739)  acc5: 95.8333 (95.4904)  time: 0.4035  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4872 s / it)\n",
            "* Acc@1 69.274 Acc@5 95.490 loss 1.171\n",
            "Accuracy of the model on the 3925 test images: 69.3%\n",
            "Max accuracy: 69.27%\n",
            "Test:  [ 0/41]  eta: 0:02:04  loss: 5.7028 (5.7028)  acc1: 27.0833 (27.0833)  acc5: 51.0417 (51.0417)  time: 3.0364  data: 2.4597  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 5.6070 (5.4943)  acc1: 15.6250 (18.9394)  acc5: 51.0417 (53.8826)  time: 0.7767  data: 0.3445  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.6701 (5.8319)  acc1: 10.4167 (12.9464)  acc5: 45.8333 (37.6984)  time: 0.4903  data: 0.0688  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 6.0208 (5.7022)  acc1: 2.0833 (16.3306)  acc5: 36.4583 (45.3293)  time: 0.4202  data: 0.0024  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.4105 (5.4480)  acc1: 15.6250 (20.3822)  acc5: 62.5000 (49.8854)  time: 0.4100  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5258 s / it)\n",
            "* Acc@1 20.382 Acc@5 49.885 loss 5.448\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "Max EMA accuracy: 20.38%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [36]  [  0/147]  eta: 0:09:46  lr: 0.003618  min_lr: 0.003618  loss: 2.8730 (2.8730)  weight_decay: 0.0500 (0.0500)  time: 3.9890  data: 3.0680  max mem: 7679\n",
            "Epoch: [36]  [ 10/147]  eta: 0:02:35  lr: 0.003616  min_lr: 0.003616  loss: 2.6858 (2.6030)  weight_decay: 0.0500 (0.0500)  time: 1.1363  data: 0.2794  max mem: 7679\n",
            "Epoch: [36]  [ 20/147]  eta: 0:02:07  lr: 0.003612  min_lr: 0.003612  loss: 2.6507 (2.6270)  weight_decay: 0.0500 (0.0500)  time: 0.8572  data: 0.0009  max mem: 7679\n",
            "Epoch: [36]  [ 30/147]  eta: 0:01:52  lr: 0.003609  min_lr: 0.003609  loss: 2.7109 (2.6454)  weight_decay: 0.0500 (0.0500)  time: 0.8597  data: 0.0009  max mem: 7679\n",
            "Epoch: [36]  [ 40/147]  eta: 0:01:39  lr: 0.003605  min_lr: 0.003605  loss: 2.7423 (2.6643)  weight_decay: 0.0500 (0.0500)  time: 0.8562  data: 0.0005  max mem: 7679\n",
            "Epoch: [36]  [ 50/147]  eta: 0:01:28  lr: 0.003603  min_lr: 0.003603  loss: 2.6590 (2.6555)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0010  max mem: 7679\n",
            "Epoch: [36]  [ 60/147]  eta: 0:01:18  lr: 0.003599  min_lr: 0.003599  loss: 2.7400 (2.6751)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0010  max mem: 7679\n",
            "Epoch: [36]  [ 70/147]  eta: 0:01:09  lr: 0.003596  min_lr: 0.003596  loss: 2.7450 (2.6669)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0019  max mem: 7679\n",
            "Epoch: [36]  [ 80/147]  eta: 0:00:59  lr: 0.003592  min_lr: 0.003592  loss: 2.6332 (2.6643)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0021  max mem: 7679\n",
            "Epoch: [36]  [ 90/147]  eta: 0:00:50  lr: 0.003589  min_lr: 0.003589  loss: 2.6861 (2.6579)  weight_decay: 0.0500 (0.0500)  time: 0.8470  data: 0.0007  max mem: 7679\n",
            "Epoch: [36]  [100/147]  eta: 0:00:41  lr: 0.003585  min_lr: 0.003585  loss: 2.6628 (2.6597)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0013  max mem: 7679\n",
            "Epoch: [36]  [110/147]  eta: 0:00:32  lr: 0.003583  min_lr: 0.003583  loss: 2.6789 (2.6562)  weight_decay: 0.0500 (0.0500)  time: 0.8512  data: 0.0023  max mem: 7679\n",
            "Epoch: [36]  [120/147]  eta: 0:00:23  lr: 0.003579  min_lr: 0.003579  loss: 2.6879 (2.6515)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0019  max mem: 7679\n",
            "Epoch: [36]  [130/147]  eta: 0:00:14  lr: 0.003576  min_lr: 0.003576  loss: 2.6164 (2.6467)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0012  max mem: 7679\n",
            "Epoch: [36]  [140/147]  eta: 0:00:06  lr: 0.003572  min_lr: 0.003572  loss: 2.6975 (2.6523)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0006  max mem: 7679\n",
            "Epoch: [36]  [146/147]  eta: 0:00:00  lr: 0.003572  min_lr: 0.003572  loss: 2.5732 (2.6498)  weight_decay: 0.0500 (0.0500)  time: 0.7244  data: 0.0002  max mem: 7679\n",
            "Epoch: [36] Total time: 0:02:06 (0.8596 s / it)\n",
            "Averaged stats: lr: 0.003572  min_lr: 0.003572  loss: 2.5732 (2.6498)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:55  loss: 0.6282 (0.6282)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 4.2776  data: 3.8127  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.8341 (0.8447)  acc1: 80.2083 (81.0606)  acc5: 96.8750 (96.7803)  time: 0.7562  data: 0.3499  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.9922 (1.1331)  acc1: 76.0417 (68.0556)  acc5: 95.8333 (95.5853)  time: 0.4036  data: 0.0032  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.0774 (1.1063)  acc1: 70.8333 (69.3884)  acc5: 95.8333 (95.4637)  time: 0.4029  data: 0.0014  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0301 (1.0972)  acc1: 69.7917 (69.5796)  acc5: 96.8750 (95.6178)  time: 0.4027  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5062 s / it)\n",
            "* Acc@1 69.580 Acc@5 95.618 loss 1.097\n",
            "Accuracy of the model on the 3925 test images: 69.6%\n",
            "Max accuracy: 69.58%\n",
            "Test:  [ 0/41]  eta: 0:03:12  loss: 5.6303 (5.6303)  acc1: 28.1250 (28.1250)  acc5: 54.1667 (54.1667)  time: 4.6871  data: 4.2101  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 5.5340 (5.4283)  acc1: 14.5833 (19.4129)  acc5: 54.1667 (56.6288)  time: 0.8057  data: 0.3868  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.5914 (5.7816)  acc1: 10.4167 (13.0456)  acc5: 47.9167 (40.3274)  time: 0.4155  data: 0.0045  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.9776 (5.6534)  acc1: 2.0833 (16.2970)  acc5: 38.5417 (47.3790)  time: 0.4119  data: 0.0024  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.3516 (5.3917)  acc1: 14.5833 (20.3822)  acc5: 65.6250 (51.5924)  time: 0.4099  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5330 s / it)\n",
            "* Acc@1 20.382 Acc@5 51.592 loss 5.392\n",
            "Accuracy of the model EMA on 3925 test images: 20.4%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [37]  [  0/147]  eta: 0:14:17  lr: 0.003571  min_lr: 0.003571  loss: 2.6146 (2.6146)  weight_decay: 0.0500 (0.0500)  time: 5.8317  data: 4.9119  max mem: 7679\n",
            "Epoch: [37]  [ 10/147]  eta: 0:02:59  lr: 0.003568  min_lr: 0.003568  loss: 2.5205 (2.5244)  weight_decay: 0.0500 (0.0500)  time: 1.3100  data: 0.4476  max mem: 7679\n",
            "Epoch: [37]  [ 20/147]  eta: 0:02:19  lr: 0.003564  min_lr: 0.003564  loss: 2.5945 (2.5871)  weight_decay: 0.0500 (0.0500)  time: 0.8600  data: 0.0011  max mem: 7679\n",
            "Epoch: [37]  [ 30/147]  eta: 0:01:59  lr: 0.003561  min_lr: 0.003561  loss: 2.7460 (2.6116)  weight_decay: 0.0500 (0.0500)  time: 0.8574  data: 0.0011  max mem: 7679\n",
            "Epoch: [37]  [ 40/147]  eta: 0:01:44  lr: 0.003557  min_lr: 0.003557  loss: 2.5493 (2.5710)  weight_decay: 0.0500 (0.0500)  time: 0.8546  data: 0.0009  max mem: 7679\n",
            "Epoch: [37]  [ 50/147]  eta: 0:01:32  lr: 0.003554  min_lr: 0.003554  loss: 2.5433 (2.5943)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0006  max mem: 7679\n",
            "Epoch: [37]  [ 60/147]  eta: 0:01:21  lr: 0.003550  min_lr: 0.003550  loss: 2.6440 (2.5940)  weight_decay: 0.0500 (0.0500)  time: 0.8497  data: 0.0015  max mem: 7679\n",
            "Epoch: [37]  [ 70/147]  eta: 0:01:11  lr: 0.003548  min_lr: 0.003548  loss: 2.6203 (2.5945)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0016  max mem: 7679\n",
            "Epoch: [37]  [ 80/147]  eta: 0:01:01  lr: 0.003543  min_lr: 0.003543  loss: 2.6568 (2.6101)  weight_decay: 0.0500 (0.0500)  time: 0.8463  data: 0.0008  max mem: 7679\n",
            "Epoch: [37]  [ 90/147]  eta: 0:00:51  lr: 0.003541  min_lr: 0.003541  loss: 2.6793 (2.6096)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0008  max mem: 7679\n",
            "Epoch: [37]  [100/147]  eta: 0:00:42  lr: 0.003536  min_lr: 0.003536  loss: 2.6188 (2.6077)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0012  max mem: 7679\n",
            "Epoch: [37]  [110/147]  eta: 0:00:33  lr: 0.003534  min_lr: 0.003534  loss: 2.5306 (2.6081)  weight_decay: 0.0500 (0.0500)  time: 0.8512  data: 0.0017  max mem: 7679\n",
            "Epoch: [37]  [120/147]  eta: 0:00:24  lr: 0.003529  min_lr: 0.003529  loss: 2.6544 (2.6152)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0027  max mem: 7679\n",
            "Epoch: [37]  [130/147]  eta: 0:00:15  lr: 0.003527  min_lr: 0.003527  loss: 2.6544 (2.6161)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0022  max mem: 7679\n",
            "Epoch: [37]  [140/147]  eta: 0:00:06  lr: 0.003522  min_lr: 0.003522  loss: 2.5332 (2.6138)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0004  max mem: 7679\n",
            "Epoch: [37]  [146/147]  eta: 0:00:00  lr: 0.003522  min_lr: 0.003522  loss: 2.5372 (2.6128)  weight_decay: 0.0500 (0.0500)  time: 0.7241  data: 0.0002  max mem: 7679\n",
            "Epoch: [37] Total time: 0:02:08 (0.8709 s / it)\n",
            "Averaged stats: lr: 0.003522  min_lr: 0.003522  loss: 2.5372 (2.6128)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:32  loss: 0.6805 (0.6805)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 3.7210  data: 3.2449  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.8494 (0.8696)  acc1: 79.1667 (79.3561)  acc5: 96.8750 (96.7803)  time: 0.7827  data: 0.3742  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.9900 (1.2731)  acc1: 71.8750 (63.6409)  acc5: 95.8333 (91.4683)  time: 0.4454  data: 0.0438  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.2252 (1.2418)  acc1: 65.6250 (64.7177)  acc5: 95.8333 (92.7083)  time: 0.4033  data: 0.0003  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0451 (1.1696)  acc1: 67.7083 (67.1338)  acc5: 96.8750 (93.7834)  time: 0.4039  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5143 s / it)\n",
            "* Acc@1 67.134 Acc@5 93.783 loss 1.170\n",
            "Accuracy of the model on the 3925 test images: 67.1%\n",
            "Max accuracy: 69.58%\n",
            "Test:  [ 0/41]  eta: 0:01:53  loss: 5.5543 (5.5543)  acc1: 29.1667 (29.1667)  acc5: 55.2083 (55.2083)  time: 2.7782  data: 2.3154  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 5.4580 (5.3614)  acc1: 15.6250 (20.1705)  acc5: 58.3333 (58.4280)  time: 0.7519  data: 0.3387  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.5099 (5.7308)  acc1: 10.4167 (13.4921)  acc5: 50.0000 (42.0139)  time: 0.4832  data: 0.0720  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.9315 (5.6047)  acc1: 3.1250 (16.6331)  acc5: 36.4583 (48.3535)  time: 0.4144  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.2982 (5.3361)  acc1: 14.5833 (20.7643)  acc5: 66.6667 (52.4841)  time: 0.4084  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5119 s / it)\n",
            "* Acc@1 20.764 Acc@5 52.484 loss 5.336\n",
            "Accuracy of the model EMA on 3925 test images: 20.8%\n",
            "Max EMA accuracy: 20.76%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [38]  [  0/147]  eta: 0:12:31  lr: 0.003521  min_lr: 0.003521  loss: 2.5136 (2.5136)  weight_decay: 0.0500 (0.0500)  time: 5.1094  data: 4.1765  max mem: 7679\n",
            "Epoch: [38]  [ 10/147]  eta: 0:03:00  lr: 0.003518  min_lr: 0.003518  loss: 2.6898 (2.6199)  weight_decay: 0.0500 (0.0500)  time: 1.3169  data: 0.3816  max mem: 7679\n",
            "Epoch: [38]  [ 20/147]  eta: 0:02:19  lr: 0.003514  min_lr: 0.003514  loss: 2.7083 (2.6745)  weight_decay: 0.0500 (0.0500)  time: 0.8962  data: 0.0015  max mem: 7679\n",
            "Epoch: [38]  [ 30/147]  eta: 0:01:59  lr: 0.003511  min_lr: 0.003511  loss: 2.6630 (2.6236)  weight_decay: 0.0500 (0.0500)  time: 0.8560  data: 0.0009  max mem: 7679\n",
            "Epoch: [38]  [ 40/147]  eta: 0:01:44  lr: 0.003507  min_lr: 0.003507  loss: 2.6125 (2.6471)  weight_decay: 0.0500 (0.0500)  time: 0.8576  data: 0.0009  max mem: 7679\n",
            "Epoch: [38]  [ 50/147]  eta: 0:01:32  lr: 0.003504  min_lr: 0.003504  loss: 2.6466 (2.6318)  weight_decay: 0.0500 (0.0500)  time: 0.8549  data: 0.0010  max mem: 7679\n",
            "Epoch: [38]  [ 60/147]  eta: 0:01:21  lr: 0.003499  min_lr: 0.003499  loss: 2.5970 (2.6201)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0017  max mem: 7679\n",
            "Epoch: [38]  [ 70/147]  eta: 0:01:11  lr: 0.003497  min_lr: 0.003497  loss: 2.6114 (2.6204)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0022  max mem: 7679\n",
            "Epoch: [38]  [ 80/147]  eta: 0:01:01  lr: 0.003492  min_lr: 0.003492  loss: 2.6657 (2.6309)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0018  max mem: 7679\n",
            "Epoch: [38]  [ 90/147]  eta: 0:00:51  lr: 0.003489  min_lr: 0.003489  loss: 2.6594 (2.6334)  weight_decay: 0.0500 (0.0500)  time: 0.8469  data: 0.0013  max mem: 7679\n",
            "Epoch: [38]  [100/147]  eta: 0:00:42  lr: 0.003485  min_lr: 0.003485  loss: 2.6824 (2.6353)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0025  max mem: 7679\n",
            "Epoch: [38]  [110/147]  eta: 0:00:33  lr: 0.003482  min_lr: 0.003482  loss: 2.7177 (2.6401)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0023  max mem: 7679\n",
            "Epoch: [38]  [120/147]  eta: 0:00:24  lr: 0.003478  min_lr: 0.003478  loss: 2.6234 (2.6357)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0019  max mem: 7679\n",
            "Epoch: [38]  [130/147]  eta: 0:00:15  lr: 0.003475  min_lr: 0.003475  loss: 2.6636 (2.6398)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0017  max mem: 7679\n",
            "Epoch: [38]  [140/147]  eta: 0:00:06  lr: 0.003470  min_lr: 0.003470  loss: 2.7477 (2.6459)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0004  max mem: 7679\n",
            "Epoch: [38]  [146/147]  eta: 0:00:00  lr: 0.003470  min_lr: 0.003470  loss: 2.7477 (2.6472)  weight_decay: 0.0500 (0.0500)  time: 0.7247  data: 0.0002  max mem: 7679\n",
            "Epoch: [38] Total time: 0:02:08 (0.8721 s / it)\n",
            "Averaged stats: lr: 0.003470  min_lr: 0.003470  loss: 2.7477 (2.6472)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:56  loss: 0.6186 (0.6186)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 4.3134  data: 3.8462  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 1.0664 (1.0357)  acc1: 71.8750 (75.0947)  acc5: 96.8750 (96.0227)  time: 0.8111  data: 0.3658  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 1.0664 (1.1994)  acc1: 70.8333 (66.3691)  acc5: 95.8333 (95.5853)  time: 0.4356  data: 0.0111  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.0958 (1.1733)  acc1: 68.7500 (68.1116)  acc5: 95.8333 (95.2285)  time: 0.4079  data: 0.0023  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1386 (1.1554)  acc1: 66.6667 (68.0255)  acc5: 95.8333 (95.4904)  time: 0.4051  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5317 s / it)\n",
            "* Acc@1 68.025 Acc@5 95.490 loss 1.155\n",
            "Accuracy of the model on the 3925 test images: 68.0%\n",
            "Max accuracy: 69.58%\n",
            "Test:  [ 0/41]  eta: 0:03:18  loss: 5.4796 (5.4796)  acc1: 29.1667 (29.1667)  acc5: 59.3750 (59.3750)  time: 4.8363  data: 4.3925  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 5.3833 (5.2950)  acc1: 16.6667 (20.1705)  acc5: 59.3750 (60.3220)  time: 0.8124  data: 0.4050  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.4271 (5.6802)  acc1: 11.4583 (13.4921)  acc5: 53.1250 (43.6508)  time: 0.4095  data: 0.0040  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.8825 (5.5566)  acc1: 3.1250 (16.7339)  acc5: 36.4583 (49.6976)  time: 0.4089  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.2358 (5.2817)  acc1: 16.6667 (21.0701)  acc5: 67.7083 (53.7325)  time: 0.4068  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5251 s / it)\n",
            "* Acc@1 21.070 Acc@5 53.732 loss 5.282\n",
            "Accuracy of the model EMA on 3925 test images: 21.1%\n",
            "Max EMA accuracy: 21.07%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [39]  [  0/147]  eta: 0:07:28  lr: 0.003469  min_lr: 0.003469  loss: 2.7068 (2.7068)  weight_decay: 0.0500 (0.0500)  time: 3.0492  data: 2.1001  max mem: 7679\n",
            "Epoch: [39]  [ 10/147]  eta: 0:02:24  lr: 0.003466  min_lr: 0.003466  loss: 2.6808 (2.6707)  weight_decay: 0.0500 (0.0500)  time: 1.0541  data: 0.1928  max mem: 7679\n",
            "Epoch: [39]  [ 20/147]  eta: 0:02:01  lr: 0.003461  min_lr: 0.003461  loss: 2.6777 (2.6641)  weight_decay: 0.0500 (0.0500)  time: 0.8560  data: 0.0019  max mem: 7679\n",
            "Epoch: [39]  [ 30/147]  eta: 0:01:48  lr: 0.003458  min_lr: 0.003458  loss: 2.6312 (2.6354)  weight_decay: 0.0500 (0.0500)  time: 0.8579  data: 0.0018  max mem: 7679\n",
            "Epoch: [39]  [ 40/147]  eta: 0:01:37  lr: 0.003454  min_lr: 0.003454  loss: 2.6495 (2.6683)  weight_decay: 0.0500 (0.0500)  time: 0.8548  data: 0.0013  max mem: 7679\n",
            "Epoch: [39]  [ 50/147]  eta: 0:01:27  lr: 0.003451  min_lr: 0.003451  loss: 2.6541 (2.6497)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0016  max mem: 7679\n",
            "Epoch: [39]  [ 60/147]  eta: 0:01:17  lr: 0.003446  min_lr: 0.003446  loss: 2.6181 (2.6519)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0018  max mem: 7679\n",
            "Epoch: [39]  [ 70/147]  eta: 0:01:08  lr: 0.003443  min_lr: 0.003443  loss: 2.6239 (2.6443)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0014  max mem: 7679\n",
            "Epoch: [39]  [ 80/147]  eta: 0:00:58  lr: 0.003439  min_lr: 0.003439  loss: 2.6949 (2.6454)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0016  max mem: 7679\n",
            "Epoch: [39]  [ 90/147]  eta: 0:00:49  lr: 0.003436  min_lr: 0.003436  loss: 2.6498 (2.6441)  weight_decay: 0.0500 (0.0500)  time: 0.8469  data: 0.0014  max mem: 7679\n",
            "Epoch: [39]  [100/147]  eta: 0:00:41  lr: 0.003431  min_lr: 0.003431  loss: 2.6317 (2.6294)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0016  max mem: 7679\n",
            "Epoch: [39]  [110/147]  eta: 0:00:32  lr: 0.003428  min_lr: 0.003428  loss: 2.5768 (2.6261)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0011  max mem: 7679\n",
            "Epoch: [39]  [120/147]  eta: 0:00:23  lr: 0.003424  min_lr: 0.003424  loss: 2.6064 (2.6232)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0013  max mem: 7679\n",
            "Epoch: [39]  [130/147]  eta: 0:00:14  lr: 0.003421  min_lr: 0.003421  loss: 2.5900 (2.6171)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0016  max mem: 7679\n",
            "Epoch: [39]  [140/147]  eta: 0:00:06  lr: 0.003416  min_lr: 0.003416  loss: 2.6064 (2.6226)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0007  max mem: 7679\n",
            "Epoch: [39]  [146/147]  eta: 0:00:00  lr: 0.003416  min_lr: 0.003416  loss: 2.7043 (2.6265)  weight_decay: 0.0500 (0.0500)  time: 0.7242  data: 0.0002  max mem: 7679\n",
            "Epoch: [39] Total time: 0:02:05 (0.8512 s / it)\n",
            "Averaged stats: lr: 0.003416  min_lr: 0.003416  loss: 2.7043 (2.6265)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:20  loss: 0.5226 (0.5226)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 3.4280  data: 3.0055  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.7603 (0.8554)  acc1: 85.4167 (81.7235)  acc5: 96.8750 (97.2538)  time: 0.7076  data: 0.2911  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 1.1089 (1.1214)  acc1: 72.9167 (69.9405)  acc5: 96.8750 (96.1806)  time: 0.4308  data: 0.0160  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.2112 (1.1616)  acc1: 66.6667 (68.6492)  acc5: 94.7917 (95.0941)  time: 0.4157  data: 0.0062  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1899 (1.1401)  acc1: 64.5833 (68.9427)  acc5: 94.7917 (95.3376)  time: 0.4033  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5000 s / it)\n",
            "* Acc@1 68.943 Acc@5 95.338 loss 1.140\n",
            "Accuracy of the model on the 3925 test images: 68.9%\n",
            "Max accuracy: 69.58%\n",
            "Test:  [ 0/41]  eta: 0:01:17  loss: 5.4025 (5.4025)  acc1: 31.2500 (31.2500)  acc5: 60.4167 (60.4167)  time: 1.8959  data: 1.4406  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 5.3070 (5.2290)  acc1: 16.6667 (20.5492)  acc5: 61.4583 (61.9318)  time: 0.7769  data: 0.3552  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.3613 (5.6300)  acc1: 12.5000 (13.7401)  acc5: 55.2083 (45.7341)  time: 0.5431  data: 0.1275  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.8312 (5.5102)  acc1: 3.1250 (16.9019)  acc5: 35.4167 (51.1425)  time: 0.4147  data: 0.0043  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.1601 (5.2291)  acc1: 16.6667 (21.3758)  acc5: 68.7500 (55.1847)  time: 0.4057  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5186 s / it)\n",
            "* Acc@1 21.376 Acc@5 55.185 loss 5.229\n",
            "Accuracy of the model EMA on 3925 test images: 21.4%\n",
            "Max EMA accuracy: 21.38%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [40]  [  0/147]  eta: 0:13:29  lr: 0.003414  min_lr: 0.003414  loss: 2.3843 (2.3843)  weight_decay: 0.0500 (0.0500)  time: 5.5046  data: 4.0654  max mem: 7679\n",
            "Epoch: [40]  [ 10/147]  eta: 0:02:55  lr: 0.003411  min_lr: 0.003411  loss: 2.6397 (2.5706)  weight_decay: 0.0500 (0.0500)  time: 1.2804  data: 0.3701  max mem: 7679\n",
            "Epoch: [40]  [ 20/147]  eta: 0:02:17  lr: 0.003407  min_lr: 0.003407  loss: 2.6399 (2.6036)  weight_decay: 0.0500 (0.0500)  time: 0.8584  data: 0.0008  max mem: 7679\n",
            "Epoch: [40]  [ 30/147]  eta: 0:01:58  lr: 0.003404  min_lr: 0.003404  loss: 2.6089 (2.5828)  weight_decay: 0.0500 (0.0500)  time: 0.8651  data: 0.0008  max mem: 7679\n",
            "Epoch: [40]  [ 40/147]  eta: 0:01:44  lr: 0.003399  min_lr: 0.003399  loss: 2.6930 (2.6336)  weight_decay: 0.0500 (0.0500)  time: 0.8665  data: 0.0005  max mem: 7679\n",
            "Epoch: [40]  [ 50/147]  eta: 0:01:32  lr: 0.003396  min_lr: 0.003396  loss: 2.7012 (2.6193)  weight_decay: 0.0500 (0.0500)  time: 0.8564  data: 0.0007  max mem: 7679\n",
            "Epoch: [40]  [ 60/147]  eta: 0:01:21  lr: 0.003391  min_lr: 0.003391  loss: 2.6347 (2.6138)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0006  max mem: 7679\n",
            "Epoch: [40]  [ 70/147]  eta: 0:01:10  lr: 0.003388  min_lr: 0.003388  loss: 2.6758 (2.6237)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.0005  max mem: 7679\n",
            "Epoch: [40]  [ 80/147]  eta: 0:01:01  lr: 0.003383  min_lr: 0.003383  loss: 2.7172 (2.6297)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0014  max mem: 7679\n",
            "Epoch: [40]  [ 90/147]  eta: 0:00:51  lr: 0.003380  min_lr: 0.003380  loss: 2.7220 (2.6344)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0016  max mem: 7679\n",
            "Epoch: [40]  [100/147]  eta: 0:00:42  lr: 0.003375  min_lr: 0.003375  loss: 2.6522 (2.6341)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0016  max mem: 7679\n",
            "Epoch: [40]  [110/147]  eta: 0:00:33  lr: 0.003372  min_lr: 0.003372  loss: 2.5854 (2.6276)  weight_decay: 0.0500 (0.0500)  time: 0.8489  data: 0.0015  max mem: 7679\n",
            "Epoch: [40]  [120/147]  eta: 0:00:24  lr: 0.003367  min_lr: 0.003367  loss: 2.5690 (2.6172)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0016  max mem: 7679\n",
            "Epoch: [40]  [130/147]  eta: 0:00:15  lr: 0.003364  min_lr: 0.003364  loss: 2.4394 (2.6112)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0016  max mem: 7679\n",
            "Epoch: [40]  [140/147]  eta: 0:00:06  lr: 0.003359  min_lr: 0.003359  loss: 2.5467 (2.6069)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0004  max mem: 7679\n",
            "Epoch: [40]  [146/147]  eta: 0:00:00  lr: 0.003359  min_lr: 0.003359  loss: 2.5961 (2.6071)  weight_decay: 0.0500 (0.0500)  time: 0.7250  data: 0.0002  max mem: 7679\n",
            "Epoch: [40] Total time: 0:02:07 (0.8701 s / it)\n",
            "Averaged stats: lr: 0.003359  min_lr: 0.003359  loss: 2.5961 (2.6071)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:33  loss: 0.6566 (0.6566)  acc1: 86.4583 (86.4583)  acc5: 96.8750 (96.8750)  time: 3.7328  data: 3.2745  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.8115 (0.7932)  acc1: 83.3333 (81.7235)  acc5: 96.8750 (97.6326)  time: 0.7681  data: 0.3493  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.8115 (0.9686)  acc1: 78.1250 (73.6607)  acc5: 96.8750 (97.3214)  time: 0.4407  data: 0.0296  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.0396 (1.0180)  acc1: 69.7917 (72.2782)  acc5: 95.8333 (96.3710)  time: 0.4068  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0401 (1.0315)  acc1: 69.7917 (72.3567)  acc5: 94.7917 (95.8726)  time: 0.4037  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5182 s / it)\n",
            "* Acc@1 72.357 Acc@5 95.873 loss 1.032\n",
            "Accuracy of the model on the 3925 test images: 72.4%\n",
            "Max accuracy: 72.36%\n",
            "Test:  [ 0/41]  eta: 0:01:49  loss: 5.3303 (5.3303)  acc1: 31.2500 (31.2500)  acc5: 61.4583 (61.4583)  time: 2.6675  data: 2.2015  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 5.2365 (5.1659)  acc1: 17.7083 (21.0227)  acc5: 61.4583 (62.8788)  time: 0.7182  data: 0.3077  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.2993 (5.5817)  acc1: 12.5000 (13.9385)  acc5: 56.2500 (47.3214)  time: 0.4678  data: 0.0611  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.7779 (5.4656)  acc1: 3.1250 (17.0699)  acc5: 35.4167 (52.2177)  time: 0.4098  data: 0.0020  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 5.0825 (5.1781)  acc1: 17.7083 (21.7070)  acc5: 71.8750 (56.2293)  time: 0.4069  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5008 s / it)\n",
            "* Acc@1 21.707 Acc@5 56.229 loss 5.178\n",
            "Accuracy of the model EMA on 3925 test images: 21.7%\n",
            "Max EMA accuracy: 21.71%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [41]  [  0/147]  eta: 0:08:28  lr: 0.003358  min_lr: 0.003358  loss: 2.1145 (2.1145)  weight_decay: 0.0500 (0.0500)  time: 3.4610  data: 2.5532  max mem: 7679\n",
            "Epoch: [41]  [ 10/147]  eta: 0:02:32  lr: 0.003355  min_lr: 0.003355  loss: 2.5311 (2.5034)  weight_decay: 0.0500 (0.0500)  time: 1.1129  data: 0.2354  max mem: 7679\n",
            "Epoch: [41]  [ 20/147]  eta: 0:02:05  lr: 0.003350  min_lr: 0.003350  loss: 2.5574 (2.5366)  weight_decay: 0.0500 (0.0500)  time: 0.8675  data: 0.0020  max mem: 7679\n",
            "Epoch: [41]  [ 30/147]  eta: 0:01:50  lr: 0.003347  min_lr: 0.003347  loss: 2.6402 (2.5465)  weight_decay: 0.0500 (0.0500)  time: 0.8559  data: 0.0006  max mem: 7679\n",
            "Epoch: [41]  [ 40/147]  eta: 0:01:39  lr: 0.003342  min_lr: 0.003342  loss: 2.6796 (2.5832)  weight_decay: 0.0500 (0.0500)  time: 0.8574  data: 0.0009  max mem: 7679\n",
            "Epoch: [41]  [ 50/147]  eta: 0:01:28  lr: 0.003338  min_lr: 0.003338  loss: 2.7197 (2.6102)  weight_decay: 0.0500 (0.0500)  time: 0.8555  data: 0.0009  max mem: 7679\n",
            "Epoch: [41]  [ 60/147]  eta: 0:01:18  lr: 0.003334  min_lr: 0.003334  loss: 2.7480 (2.6296)  weight_decay: 0.0500 (0.0500)  time: 0.8497  data: 0.0009  max mem: 7679\n",
            "Epoch: [41]  [ 70/147]  eta: 0:01:08  lr: 0.003330  min_lr: 0.003330  loss: 2.7379 (2.6357)  weight_decay: 0.0500 (0.0500)  time: 0.8460  data: 0.0007  max mem: 7679\n",
            "Epoch: [41]  [ 80/147]  eta: 0:00:59  lr: 0.003325  min_lr: 0.003325  loss: 2.6942 (2.6383)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0013  max mem: 7679\n",
            "Epoch: [41]  [ 90/147]  eta: 0:00:50  lr: 0.003322  min_lr: 0.003322  loss: 2.6674 (2.6375)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0023  max mem: 7679\n",
            "Epoch: [41]  [100/147]  eta: 0:00:41  lr: 0.003317  min_lr: 0.003317  loss: 2.7062 (2.6461)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0026  max mem: 7679\n",
            "Epoch: [41]  [110/147]  eta: 0:00:32  lr: 0.003314  min_lr: 0.003314  loss: 2.6977 (2.6486)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0029  max mem: 7679\n",
            "Epoch: [41]  [120/147]  eta: 0:00:23  lr: 0.003309  min_lr: 0.003309  loss: 2.6450 (2.6482)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0027  max mem: 7679\n",
            "Epoch: [41]  [130/147]  eta: 0:00:14  lr: 0.003306  min_lr: 0.003306  loss: 2.7472 (2.6554)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0017  max mem: 7679\n",
            "Epoch: [41]  [140/147]  eta: 0:00:06  lr: 0.003301  min_lr: 0.003301  loss: 2.7396 (2.6571)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0009  max mem: 7679\n",
            "Epoch: [41]  [146/147]  eta: 0:00:00  lr: 0.003301  min_lr: 0.003301  loss: 2.6986 (2.6539)  weight_decay: 0.0500 (0.0500)  time: 0.7257  data: 0.0002  max mem: 7679\n",
            "Epoch: [41] Total time: 0:02:05 (0.8567 s / it)\n",
            "Averaged stats: lr: 0.003301  min_lr: 0.003301  loss: 2.6986 (2.6539)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:44  loss: 0.6480 (0.6480)  acc1: 89.5833 (89.5833)  acc5: 94.7917 (94.7917)  time: 2.5477  data: 2.1099  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.8126 (0.8560)  acc1: 84.3750 (82.6705)  acc5: 96.8750 (96.5909)  time: 0.7017  data: 0.2903  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.8849 (1.0280)  acc1: 81.2500 (74.7024)  acc5: 96.8750 (97.2222)  time: 0.4669  data: 0.0588  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.2452 (1.1060)  acc1: 66.6667 (71.4382)  acc5: 95.8333 (96.1022)  time: 0.4102  data: 0.0047  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2108 (1.0942)  acc1: 67.7083 (71.6178)  acc5: 95.8333 (96.1529)  time: 0.4036  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4962 s / it)\n",
            "* Acc@1 71.618 Acc@5 96.153 loss 1.094\n",
            "Accuracy of the model on the 3925 test images: 71.6%\n",
            "Max accuracy: 72.36%\n",
            "Test:  [ 0/41]  eta: 0:03:00  loss: 5.2622 (5.2622)  acc1: 31.2500 (31.2500)  acc5: 62.5000 (62.5000)  time: 4.4051  data: 3.9675  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 5.1699 (5.1052)  acc1: 18.7500 (21.2121)  acc5: 62.5000 (63.9205)  time: 0.7847  data: 0.3629  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.2339 (5.5354)  acc1: 13.5417 (14.0873)  acc5: 57.2917 (49.3056)  time: 0.4178  data: 0.0027  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.7279 (5.4237)  acc1: 3.1250 (17.2715)  acc5: 33.3333 (53.4946)  time: 0.4107  data: 0.0015  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.9954 (5.1298)  acc1: 18.7500 (22.0892)  acc5: 71.8750 (57.3503)  time: 0.4073  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5242 s / it)\n",
            "* Acc@1 22.089 Acc@5 57.350 loss 5.130\n",
            "Accuracy of the model EMA on 3925 test images: 22.1%\n",
            "Max EMA accuracy: 22.09%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [42]  [  0/147]  eta: 0:09:06  lr: 0.003299  min_lr: 0.003299  loss: 2.6309 (2.6309)  weight_decay: 0.0500 (0.0500)  time: 3.7199  data: 2.8351  max mem: 7679\n",
            "Epoch: [42]  [ 10/147]  eta: 0:02:32  lr: 0.003296  min_lr: 0.003296  loss: 2.6838 (2.6662)  weight_decay: 0.0500 (0.0500)  time: 1.1107  data: 0.2604  max mem: 7679\n",
            "Epoch: [42]  [ 20/147]  eta: 0:02:05  lr: 0.003291  min_lr: 0.003291  loss: 2.6838 (2.6647)  weight_decay: 0.0500 (0.0500)  time: 0.8544  data: 0.0024  max mem: 7679\n",
            "Epoch: [42]  [ 30/147]  eta: 0:01:50  lr: 0.003287  min_lr: 0.003287  loss: 2.6446 (2.6387)  weight_decay: 0.0500 (0.0500)  time: 0.8559  data: 0.0016  max mem: 7679\n",
            "Epoch: [42]  [ 40/147]  eta: 0:01:38  lr: 0.003282  min_lr: 0.003282  loss: 2.6003 (2.6196)  weight_decay: 0.0500 (0.0500)  time: 0.8542  data: 0.0015  max mem: 7679\n",
            "Epoch: [42]  [ 50/147]  eta: 0:01:28  lr: 0.003279  min_lr: 0.003279  loss: 2.5862 (2.5965)  weight_decay: 0.0500 (0.0500)  time: 0.8524  data: 0.0013  max mem: 7679\n",
            "Epoch: [42]  [ 60/147]  eta: 0:01:18  lr: 0.003274  min_lr: 0.003274  loss: 2.5515 (2.6050)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0014  max mem: 7679\n",
            "Epoch: [42]  [ 70/147]  eta: 0:01:08  lr: 0.003271  min_lr: 0.003271  loss: 2.6336 (2.5917)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0011  max mem: 7679\n",
            "Epoch: [42]  [ 80/147]  eta: 0:00:59  lr: 0.003266  min_lr: 0.003266  loss: 2.4960 (2.5850)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0006  max mem: 7679\n",
            "Epoch: [42]  [ 90/147]  eta: 0:00:50  lr: 0.003262  min_lr: 0.003262  loss: 2.6170 (2.5904)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0004  max mem: 7679\n",
            "Epoch: [42]  [100/147]  eta: 0:00:41  lr: 0.003257  min_lr: 0.003257  loss: 2.6559 (2.5855)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0009  max mem: 7679\n",
            "Epoch: [42]  [110/147]  eta: 0:00:32  lr: 0.003254  min_lr: 0.003254  loss: 2.5922 (2.5860)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0012  max mem: 7679\n",
            "Epoch: [42]  [120/147]  eta: 0:00:23  lr: 0.003249  min_lr: 0.003249  loss: 2.6131 (2.5893)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0013  max mem: 7679\n",
            "Epoch: [42]  [130/147]  eta: 0:00:14  lr: 0.003245  min_lr: 0.003245  loss: 2.6650 (2.5979)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0011  max mem: 7679\n",
            "Epoch: [42]  [140/147]  eta: 0:00:06  lr: 0.003240  min_lr: 0.003240  loss: 2.6650 (2.5955)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0003  max mem: 7679\n",
            "Epoch: [42]  [146/147]  eta: 0:00:00  lr: 0.003240  min_lr: 0.003240  loss: 2.6532 (2.5952)  weight_decay: 0.0500 (0.0500)  time: 0.7227  data: 0.0002  max mem: 7679\n",
            "Epoch: [42] Total time: 0:02:05 (0.8570 s / it)\n",
            "Averaged stats: lr: 0.003240  min_lr: 0.003240  loss: 2.6532 (2.5952)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:21  loss: 0.4380 (0.4380)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 4.9177  data: 4.4686  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 0.7730 (0.7241)  acc1: 84.3750 (84.9432)  acc5: 96.8750 (97.1591)  time: 0.8198  data: 0.4108  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.8680 (0.9971)  acc1: 81.2500 (73.9087)  acc5: 95.8333 (96.7262)  time: 0.4074  data: 0.0035  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.2432 (1.0676)  acc1: 68.7500 (71.6398)  acc5: 95.8333 (96.0013)  time: 0.4044  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.2432 (1.0705)  acc1: 60.4167 (70.4204)  acc5: 96.4706 (95.9490)  time: 0.4040  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5332 s / it)\n",
            "* Acc@1 70.420 Acc@5 95.949 loss 1.070\n",
            "Accuracy of the model on the 3925 test images: 70.4%\n",
            "Max accuracy: 72.36%\n",
            "Test:  [ 0/41]  eta: 0:02:53  loss: 5.1911 (5.1911)  acc1: 30.2083 (30.2083)  acc5: 64.5833 (64.5833)  time: 4.2375  data: 3.7191  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 5.0977 (5.0430)  acc1: 18.7500 (21.2121)  acc5: 65.6250 (65.9091)  time: 0.8642  data: 0.4504  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.1682 (5.4885)  acc1: 13.5417 (14.0873)  acc5: 58.3333 (51.2401)  time: 0.4686  data: 0.0626  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.6775 (5.3825)  acc1: 4.1667 (17.2715)  acc5: 34.3750 (54.8723)  time: 0.4113  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.9080 (5.0831)  acc1: 20.8333 (22.2675)  acc5: 71.8750 (58.4713)  time: 0.4092  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5403 s / it)\n",
            "* Acc@1 22.268 Acc@5 58.471 loss 5.083\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "Max EMA accuracy: 22.27%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [43]  [  0/147]  eta: 0:08:14  lr: 0.003238  min_lr: 0.003238  loss: 2.2262 (2.2262)  weight_decay: 0.0500 (0.0500)  time: 3.3648  data: 2.4117  max mem: 7679\n",
            "Epoch: [43]  [ 10/147]  eta: 0:02:28  lr: 0.003235  min_lr: 0.003235  loss: 2.6306 (2.5618)  weight_decay: 0.0500 (0.0500)  time: 1.0815  data: 0.2209  max mem: 7679\n",
            "Epoch: [43]  [ 20/147]  eta: 0:02:03  lr: 0.003230  min_lr: 0.003230  loss: 2.6250 (2.5423)  weight_decay: 0.0500 (0.0500)  time: 0.8538  data: 0.0010  max mem: 7679\n",
            "Epoch: [43]  [ 30/147]  eta: 0:01:49  lr: 0.003226  min_lr: 0.003226  loss: 2.4743 (2.5219)  weight_decay: 0.0500 (0.0500)  time: 0.8551  data: 0.0006  max mem: 7679\n",
            "Epoch: [43]  [ 40/147]  eta: 0:01:37  lr: 0.003221  min_lr: 0.003221  loss: 2.4460 (2.5205)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0008  max mem: 7679\n",
            "Epoch: [43]  [ 50/147]  eta: 0:01:27  lr: 0.003218  min_lr: 0.003218  loss: 2.6080 (2.5391)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0008  max mem: 7679\n",
            "Epoch: [43]  [ 60/147]  eta: 0:01:17  lr: 0.003213  min_lr: 0.003213  loss: 2.6607 (2.5543)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0008  max mem: 7679\n",
            "Epoch: [43]  [ 70/147]  eta: 0:01:08  lr: 0.003209  min_lr: 0.003209  loss: 2.6531 (2.5534)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0021  max mem: 7679\n",
            "Epoch: [43]  [ 80/147]  eta: 0:00:59  lr: 0.003204  min_lr: 0.003204  loss: 2.6543 (2.5682)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0021  max mem: 7679\n",
            "Epoch: [43]  [ 90/147]  eta: 0:00:50  lr: 0.003200  min_lr: 0.003200  loss: 2.6724 (2.5650)  weight_decay: 0.0500 (0.0500)  time: 0.8497  data: 0.0021  max mem: 7679\n",
            "Epoch: [43]  [100/147]  eta: 0:00:41  lr: 0.003195  min_lr: 0.003195  loss: 2.5435 (2.5654)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0024  max mem: 7679\n",
            "Epoch: [43]  [110/147]  eta: 0:00:32  lr: 0.003192  min_lr: 0.003192  loss: 2.5989 (2.5711)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0019  max mem: 7679\n",
            "Epoch: [43]  [120/147]  eta: 0:00:23  lr: 0.003186  min_lr: 0.003186  loss: 2.5876 (2.5706)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0021  max mem: 7679\n",
            "Epoch: [43]  [130/147]  eta: 0:00:14  lr: 0.003183  min_lr: 0.003183  loss: 2.4967 (2.5718)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0019  max mem: 7679\n",
            "Epoch: [43]  [140/147]  eta: 0:00:06  lr: 0.003178  min_lr: 0.003178  loss: 2.6029 (2.5723)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0012  max mem: 7679\n",
            "Epoch: [43]  [146/147]  eta: 0:00:00  lr: 0.003178  min_lr: 0.003178  loss: 2.6321 (2.5721)  weight_decay: 0.0500 (0.0500)  time: 0.7244  data: 0.0002  max mem: 7679\n",
            "Epoch: [43] Total time: 0:02:05 (0.8553 s / it)\n",
            "Averaged stats: lr: 0.003178  min_lr: 0.003178  loss: 2.6321 (2.5721)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:16  loss: 0.6415 (0.6415)  acc1: 86.4583 (86.4583)  acc5: 95.8333 (95.8333)  time: 3.3376  data: 2.8580  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.7486 (0.7874)  acc1: 83.3333 (81.3447)  acc5: 96.8750 (97.0644)  time: 0.6823  data: 0.2714  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.8805 (1.0065)  acc1: 78.1250 (72.0238)  acc5: 96.8750 (96.9246)  time: 0.4116  data: 0.0076  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.9459 (0.9770)  acc1: 76.0417 (73.7231)  acc5: 96.8750 (96.5054)  time: 0.4046  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0186 (0.9861)  acc1: 74.1176 (73.5796)  acc5: 95.8333 (96.3567)  time: 0.4021  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4876 s / it)\n",
            "* Acc@1 73.580 Acc@5 96.357 loss 0.986\n",
            "Accuracy of the model on the 3925 test images: 73.6%\n",
            "Max accuracy: 73.58%\n",
            "Test:  [ 0/41]  eta: 0:02:03  loss: 5.1217 (5.1217)  acc1: 29.1667 (29.1667)  acc5: 65.6250 (65.6250)  time: 3.0124  data: 2.5363  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 5.0354 (4.9839)  acc1: 18.7500 (21.1174)  acc5: 66.6667 (67.1402)  time: 0.7649  data: 0.3317  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.1067 (5.4442)  acc1: 14.5833 (13.9881)  acc5: 59.3750 (52.6786)  time: 0.4864  data: 0.0592  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.6277 (5.3451)  acc1: 4.1667 (17.2379)  acc5: 37.5000 (55.7796)  time: 0.4195  data: 0.0037  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.8223 (5.0396)  acc1: 20.8333 (22.2930)  acc5: 72.9167 (59.4140)  time: 0.4036  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5234 s / it)\n",
            "* Acc@1 22.293 Acc@5 59.414 loss 5.040\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "Max EMA accuracy: 22.29%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [44]  [  0/147]  eta: 0:10:32  lr: 0.003176  min_lr: 0.003176  loss: 2.6024 (2.6024)  weight_decay: 0.0500 (0.0500)  time: 4.3031  data: 3.3586  max mem: 7679\n",
            "Epoch: [44]  [ 10/147]  eta: 0:02:39  lr: 0.003172  min_lr: 0.003172  loss: 2.6238 (2.6024)  weight_decay: 0.0500 (0.0500)  time: 1.1673  data: 0.3061  max mem: 7679\n",
            "Epoch: [44]  [ 20/147]  eta: 0:02:09  lr: 0.003167  min_lr: 0.003167  loss: 2.6800 (2.6265)  weight_decay: 0.0500 (0.0500)  time: 0.8567  data: 0.0012  max mem: 7679\n",
            "Epoch: [44]  [ 30/147]  eta: 0:01:53  lr: 0.003163  min_lr: 0.003163  loss: 2.7140 (2.6349)  weight_decay: 0.0500 (0.0500)  time: 0.8597  data: 0.0012  max mem: 7679\n",
            "Epoch: [44]  [ 40/147]  eta: 0:01:40  lr: 0.003158  min_lr: 0.003158  loss: 2.7109 (2.6547)  weight_decay: 0.0500 (0.0500)  time: 0.8583  data: 0.0005  max mem: 7679\n",
            "Epoch: [44]  [ 50/147]  eta: 0:01:29  lr: 0.003155  min_lr: 0.003155  loss: 2.6865 (2.6335)  weight_decay: 0.0500 (0.0500)  time: 0.8536  data: 0.0016  max mem: 7679\n",
            "Epoch: [44]  [ 60/147]  eta: 0:01:19  lr: 0.003149  min_lr: 0.003149  loss: 2.5110 (2.6192)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0018  max mem: 7679\n",
            "Epoch: [44]  [ 70/147]  eta: 0:01:09  lr: 0.003146  min_lr: 0.003146  loss: 2.5542 (2.6145)  weight_decay: 0.0500 (0.0500)  time: 0.8474  data: 0.0008  max mem: 7679\n",
            "Epoch: [44]  [ 80/147]  eta: 0:00:59  lr: 0.003140  min_lr: 0.003140  loss: 2.5570 (2.6037)  weight_decay: 0.0500 (0.0500)  time: 0.8455  data: 0.0006  max mem: 7679\n",
            "Epoch: [44]  [ 90/147]  eta: 0:00:50  lr: 0.003137  min_lr: 0.003137  loss: 2.5116 (2.5923)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0010  max mem: 7679\n",
            "Epoch: [44]  [100/147]  eta: 0:00:41  lr: 0.003131  min_lr: 0.003131  loss: 2.4702 (2.5879)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0016  max mem: 7679\n",
            "Epoch: [44]  [110/147]  eta: 0:00:32  lr: 0.003128  min_lr: 0.003128  loss: 2.6814 (2.5920)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0021  max mem: 7679\n",
            "Epoch: [44]  [120/147]  eta: 0:00:23  lr: 0.003122  min_lr: 0.003122  loss: 2.6300 (2.5937)  weight_decay: 0.0500 (0.0500)  time: 0.8516  data: 0.0019  max mem: 7679\n",
            "Epoch: [44]  [130/147]  eta: 0:00:14  lr: 0.003119  min_lr: 0.003119  loss: 2.6256 (2.5904)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0016  max mem: 7679\n",
            "Epoch: [44]  [140/147]  eta: 0:00:06  lr: 0.003113  min_lr: 0.003113  loss: 2.5932 (2.5918)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0012  max mem: 7679\n",
            "Epoch: [44]  [146/147]  eta: 0:00:00  lr: 0.003113  min_lr: 0.003113  loss: 2.6481 (2.5942)  weight_decay: 0.0500 (0.0500)  time: 0.7246  data: 0.0002  max mem: 7679\n",
            "Epoch: [44] Total time: 0:02:06 (0.8628 s / it)\n",
            "Averaged stats: lr: 0.003113  min_lr: 0.003113  loss: 2.6481 (2.5942)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:09  loss: 0.5249 (0.5249)  acc1: 91.6667 (91.6667)  acc5: 96.8750 (96.8750)  time: 4.6292  data: 4.1642  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.6660 (0.6874)  acc1: 86.4583 (85.7955)  acc5: 98.9583 (98.2008)  time: 0.7797  data: 0.3799  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.8246 (0.9612)  acc1: 81.2500 (73.9583)  acc5: 97.9167 (97.0238)  time: 0.3979  data: 0.0024  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.0824 (0.9977)  acc1: 68.7500 (72.8495)  acc5: 96.8750 (96.4718)  time: 0.4018  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.1106 (1.0073)  acc1: 67.7083 (71.9745)  acc5: 96.8750 (96.3312)  time: 0.4017  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5126 s / it)\n",
            "* Acc@1 71.975 Acc@5 96.331 loss 1.007\n",
            "Accuracy of the model on the 3925 test images: 72.0%\n",
            "Max accuracy: 73.58%\n",
            "Test:  [ 0/41]  eta: 0:02:34  loss: 5.0537 (5.0537)  acc1: 29.1667 (29.1667)  acc5: 65.6250 (65.6250)  time: 3.7574  data: 3.2767  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 4.9715 (4.9277)  acc1: 19.7917 (20.8333)  acc5: 68.7500 (68.2765)  time: 0.7238  data: 0.3012  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0602 (5.4024)  acc1: 13.5417 (13.7401)  acc5: 60.4167 (54.0675)  time: 0.4201  data: 0.0023  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.5792 (5.3103)  acc1: 4.1667 (17.0699)  acc5: 40.6250 (56.6868)  time: 0.4161  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.7324 (4.9982)  acc1: 21.8750 (22.4459)  acc5: 71.8750 (60.1783)  time: 0.4097  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5068 s / it)\n",
            "* Acc@1 22.446 Acc@5 60.178 loss 4.998\n",
            "Accuracy of the model EMA on 3925 test images: 22.4%\n",
            "Max EMA accuracy: 22.45%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [45]  [  0/147]  eta: 0:13:00  lr: 0.003111  min_lr: 0.003111  loss: 2.5055 (2.5055)  weight_decay: 0.0500 (0.0500)  time: 5.3072  data: 3.6016  max mem: 7679\n",
            "Epoch: [45]  [ 10/147]  eta: 0:02:56  lr: 0.003108  min_lr: 0.003108  loss: 2.3689 (2.4063)  weight_decay: 0.0500 (0.0500)  time: 1.2903  data: 0.3278  max mem: 7679\n",
            "Epoch: [45]  [ 20/147]  eta: 0:02:17  lr: 0.003102  min_lr: 0.003102  loss: 2.5170 (2.5174)  weight_decay: 0.0500 (0.0500)  time: 0.8728  data: 0.0007  max mem: 7679\n",
            "Epoch: [45]  [ 30/147]  eta: 0:01:58  lr: 0.003099  min_lr: 0.003099  loss: 2.6954 (2.5500)  weight_decay: 0.0500 (0.0500)  time: 0.8556  data: 0.0007  max mem: 7679\n",
            "Epoch: [45]  [ 40/147]  eta: 0:01:44  lr: 0.003093  min_lr: 0.003093  loss: 2.5695 (2.5385)  weight_decay: 0.0500 (0.0500)  time: 0.8558  data: 0.0003  max mem: 7679\n",
            "Epoch: [45]  [ 50/147]  eta: 0:01:31  lr: 0.003090  min_lr: 0.003090  loss: 2.5302 (2.5470)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0004  max mem: 7679\n",
            "Epoch: [45]  [ 60/147]  eta: 0:01:21  lr: 0.003084  min_lr: 0.003084  loss: 2.5389 (2.5458)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0004  max mem: 7679\n",
            "Epoch: [45]  [ 70/147]  eta: 0:01:10  lr: 0.003080  min_lr: 0.003080  loss: 2.5499 (2.5598)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0006  max mem: 7679\n",
            "Epoch: [45]  [ 80/147]  eta: 0:01:01  lr: 0.003075  min_lr: 0.003075  loss: 2.7284 (2.5741)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0013  max mem: 7679\n",
            "Epoch: [45]  [ 90/147]  eta: 0:00:51  lr: 0.003071  min_lr: 0.003071  loss: 2.5960 (2.5725)  weight_decay: 0.0500 (0.0500)  time: 0.8474  data: 0.0018  max mem: 7679\n",
            "Epoch: [45]  [100/147]  eta: 0:00:42  lr: 0.003066  min_lr: 0.003066  loss: 2.5960 (2.5775)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0024  max mem: 7679\n",
            "Epoch: [45]  [110/147]  eta: 0:00:33  lr: 0.003062  min_lr: 0.003062  loss: 2.6313 (2.5707)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0022  max mem: 7679\n",
            "Epoch: [45]  [120/147]  eta: 0:00:24  lr: 0.003056  min_lr: 0.003056  loss: 2.3713 (2.5636)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0010  max mem: 7679\n",
            "Epoch: [45]  [130/147]  eta: 0:00:15  lr: 0.003053  min_lr: 0.003053  loss: 2.5942 (2.5653)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0007  max mem: 7679\n",
            "Epoch: [45]  [140/147]  eta: 0:00:06  lr: 0.003047  min_lr: 0.003047  loss: 2.6189 (2.5662)  weight_decay: 0.0500 (0.0500)  time: 0.8455  data: 0.0005  max mem: 7679\n",
            "Epoch: [45]  [146/147]  eta: 0:00:00  lr: 0.003047  min_lr: 0.003047  loss: 2.6189 (2.5667)  weight_decay: 0.0500 (0.0500)  time: 0.7207  data: 0.0003  max mem: 7679\n",
            "Epoch: [45] Total time: 0:02:07 (0.8687 s / it)\n",
            "Averaged stats: lr: 0.003047  min_lr: 0.003047  loss: 2.6189 (2.5667)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:44  loss: 0.6938 (0.6938)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 5.4638  data: 4.9778  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 0.7847 (0.8074)  acc1: 83.3333 (82.1970)  acc5: 97.9167 (97.6326)  time: 0.8657  data: 0.4587  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.8615 (1.0142)  acc1: 78.1250 (73.9583)  acc5: 96.8750 (96.9246)  time: 0.4027  data: 0.0039  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.0891 (0.9964)  acc1: 70.8333 (73.8239)  acc5: 95.8333 (96.6062)  time: 0.4020  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0248 (0.9927)  acc1: 70.8333 (73.7580)  acc5: 96.8750 (96.7643)  time: 0.4031  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5345 s / it)\n",
            "* Acc@1 73.758 Acc@5 96.764 loss 0.993\n",
            "Accuracy of the model on the 3925 test images: 73.8%\n",
            "Max accuracy: 73.76%\n",
            "Test:  [ 0/41]  eta: 0:01:25  loss: 4.9922 (4.9922)  acc1: 28.1250 (28.1250)  acc5: 65.6250 (65.6250)  time: 2.0888  data: 1.6373  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 4.9410 (4.8748)  acc1: 20.8333 (20.7386)  acc5: 69.7917 (69.0341)  time: 0.7618  data: 0.3455  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0436 (5.3626)  acc1: 13.5417 (13.7401)  acc5: 61.4583 (55.1587)  time: 0.5233  data: 0.1121  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.5318 (5.2766)  acc1: 4.1667 (17.1371)  acc5: 41.6667 (57.4597)  time: 0.4152  data: 0.0040  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6431 (4.9582)  acc1: 23.9583 (22.6752)  acc5: 71.8750 (60.8917)  time: 0.4105  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5154 s / it)\n",
            "* Acc@1 22.675 Acc@5 60.892 loss 4.958\n",
            "Accuracy of the model EMA on 3925 test images: 22.7%\n",
            "Max EMA accuracy: 22.68%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [46]  [  0/147]  eta: 0:10:31  lr: 0.003045  min_lr: 0.003045  loss: 2.6641 (2.6641)  weight_decay: 0.0500 (0.0500)  time: 4.2951  data: 3.0882  max mem: 7679\n",
            "Epoch: [46]  [ 10/147]  eta: 0:02:42  lr: 0.003042  min_lr: 0.003042  loss: 2.4779 (2.4931)  weight_decay: 0.0500 (0.0500)  time: 1.1886  data: 0.2823  max mem: 7679\n",
            "Epoch: [46]  [ 20/147]  eta: 0:02:10  lr: 0.003036  min_lr: 0.003036  loss: 2.5359 (2.5574)  weight_decay: 0.0500 (0.0500)  time: 0.8682  data: 0.0014  max mem: 7679\n",
            "Epoch: [46]  [ 30/147]  eta: 0:01:53  lr: 0.003032  min_lr: 0.003032  loss: 2.6265 (2.5611)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0006  max mem: 7679\n",
            "Epoch: [46]  [ 40/147]  eta: 0:01:41  lr: 0.003027  min_lr: 0.003027  loss: 2.5530 (2.5690)  weight_decay: 0.0500 (0.0500)  time: 0.8524  data: 0.0008  max mem: 7679\n",
            "Epoch: [46]  [ 50/147]  eta: 0:01:29  lr: 0.003023  min_lr: 0.003023  loss: 2.7320 (2.5945)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0011  max mem: 7679\n",
            "Epoch: [46]  [ 60/147]  eta: 0:01:19  lr: 0.003017  min_lr: 0.003017  loss: 2.6757 (2.5958)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0010  max mem: 7679\n",
            "Epoch: [46]  [ 70/147]  eta: 0:01:09  lr: 0.003013  min_lr: 0.003013  loss: 2.5354 (2.5841)  weight_decay: 0.0500 (0.0500)  time: 0.8470  data: 0.0007  max mem: 7679\n",
            "Epoch: [46]  [ 80/147]  eta: 0:01:00  lr: 0.003008  min_lr: 0.003008  loss: 2.5354 (2.5845)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0012  max mem: 7679\n",
            "Epoch: [46]  [ 90/147]  eta: 0:00:50  lr: 0.003004  min_lr: 0.003004  loss: 2.5210 (2.5725)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0013  max mem: 7679\n",
            "Epoch: [46]  [100/147]  eta: 0:00:41  lr: 0.002998  min_lr: 0.002998  loss: 2.3914 (2.5560)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0017  max mem: 7679\n",
            "Epoch: [46]  [110/147]  eta: 0:00:32  lr: 0.002995  min_lr: 0.002995  loss: 2.4082 (2.5573)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0023  max mem: 7679\n",
            "Epoch: [46]  [120/147]  eta: 0:00:23  lr: 0.002989  min_lr: 0.002989  loss: 2.6859 (2.5686)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0023  max mem: 7679\n",
            "Epoch: [46]  [130/147]  eta: 0:00:14  lr: 0.002985  min_lr: 0.002985  loss: 2.6410 (2.5695)  weight_decay: 0.0500 (0.0500)  time: 0.8537  data: 0.0019  max mem: 7679\n",
            "Epoch: [46]  [140/147]  eta: 0:00:06  lr: 0.002979  min_lr: 0.002979  loss: 2.6304 (2.5765)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0007  max mem: 7679\n",
            "Epoch: [46]  [146/147]  eta: 0:00:00  lr: 0.002979  min_lr: 0.002979  loss: 2.6509 (2.5776)  weight_decay: 0.0500 (0.0500)  time: 0.7245  data: 0.0002  max mem: 7679\n",
            "Epoch: [46] Total time: 0:02:06 (0.8617 s / it)\n",
            "Averaged stats: lr: 0.002979  min_lr: 0.002979  loss: 2.6509 (2.5776)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:14  loss: 0.6416 (0.6416)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 4.7532  data: 4.2517  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 0.7778 (0.8029)  acc1: 85.4167 (85.7008)  acc5: 97.9167 (97.8220)  time: 0.8100  data: 0.3886  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.8370 (1.0163)  acc1: 84.3750 (75.6448)  acc5: 97.9167 (97.0238)  time: 0.4130  data: 0.0021  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 1.0503 (1.0675)  acc1: 71.8750 (73.7567)  acc5: 96.8750 (96.5390)  time: 0.4075  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0354 (1.0684)  acc1: 72.9167 (73.3758)  acc5: 95.8333 (96.1274)  time: 0.4042  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5272 s / it)\n",
            "* Acc@1 73.376 Acc@5 96.127 loss 1.068\n",
            "Accuracy of the model on the 3925 test images: 73.4%\n",
            "Max accuracy: 73.76%\n",
            "Test:  [ 0/41]  eta: 0:03:06  loss: 4.9302 (4.9302)  acc1: 28.1250 (28.1250)  acc5: 64.5833 (64.5833)  time: 4.5491  data: 4.1060  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 4.8825 (4.8227)  acc1: 20.8333 (20.8333)  acc5: 69.7917 (69.6970)  time: 0.7904  data: 0.3750  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0337 (5.3251)  acc1: 12.5000 (13.7401)  acc5: 63.5417 (55.9028)  time: 0.4113  data: 0.0015  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.4865 (5.2466)  acc1: 4.1667 (17.1371)  acc5: 42.7083 (57.7957)  time: 0.4071  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5517 (4.9211)  acc1: 25.0000 (22.7771)  acc5: 71.8750 (61.4013)  time: 0.4051  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5181 s / it)\n",
            "* Acc@1 22.777 Acc@5 61.401 loss 4.921\n",
            "Accuracy of the model EMA on 3925 test images: 22.8%\n",
            "Max EMA accuracy: 22.78%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [47]  [  0/147]  eta: 0:07:51  lr: 0.002977  min_lr: 0.002977  loss: 2.7491 (2.7491)  weight_decay: 0.0500 (0.0500)  time: 3.2041  data: 2.2858  max mem: 7679\n",
            "Epoch: [47]  [ 10/147]  eta: 0:02:27  lr: 0.002974  min_lr: 0.002974  loss: 2.7491 (2.6451)  weight_decay: 0.0500 (0.0500)  time: 1.0736  data: 0.2118  max mem: 7679\n",
            "Epoch: [47]  [ 20/147]  eta: 0:02:03  lr: 0.002968  min_lr: 0.002968  loss: 2.6949 (2.6637)  weight_decay: 0.0500 (0.0500)  time: 0.8572  data: 0.0025  max mem: 7679\n",
            "Epoch: [47]  [ 30/147]  eta: 0:01:49  lr: 0.002964  min_lr: 0.002964  loss: 2.6411 (2.6215)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0006  max mem: 7679\n",
            "Epoch: [47]  [ 40/147]  eta: 0:01:37  lr: 0.002958  min_lr: 0.002958  loss: 2.6165 (2.6195)  weight_decay: 0.0500 (0.0500)  time: 0.8589  data: 0.0005  max mem: 7679\n",
            "Epoch: [47]  [ 50/147]  eta: 0:01:27  lr: 0.002955  min_lr: 0.002955  loss: 2.5472 (2.5955)  weight_decay: 0.0500 (0.0500)  time: 0.8564  data: 0.0006  max mem: 7679\n",
            "Epoch: [47]  [ 60/147]  eta: 0:01:17  lr: 0.002949  min_lr: 0.002949  loss: 2.5132 (2.5925)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0005  max mem: 7679\n",
            "Epoch: [47]  [ 70/147]  eta: 0:01:08  lr: 0.002945  min_lr: 0.002945  loss: 2.4689 (2.5698)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0003  max mem: 7679\n",
            "Epoch: [47]  [ 80/147]  eta: 0:00:59  lr: 0.002939  min_lr: 0.002939  loss: 2.5512 (2.5701)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0004  max mem: 7679\n",
            "Epoch: [47]  [ 90/147]  eta: 0:00:50  lr: 0.002935  min_lr: 0.002935  loss: 2.6520 (2.5779)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0007  max mem: 7679\n",
            "Epoch: [47]  [100/147]  eta: 0:00:41  lr: 0.002930  min_lr: 0.002930  loss: 2.6504 (2.5820)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0010  max mem: 7679\n",
            "Epoch: [47]  [110/147]  eta: 0:00:32  lr: 0.002926  min_lr: 0.002926  loss: 2.5839 (2.5762)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0008  max mem: 7679\n",
            "Epoch: [47]  [120/147]  eta: 0:00:23  lr: 0.002920  min_lr: 0.002920  loss: 2.4070 (2.5676)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0008  max mem: 7679\n",
            "Epoch: [47]  [130/147]  eta: 0:00:14  lr: 0.002916  min_lr: 0.002916  loss: 2.5417 (2.5752)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0007  max mem: 7679\n",
            "Epoch: [47]  [140/147]  eta: 0:00:06  lr: 0.002910  min_lr: 0.002910  loss: 2.7008 (2.5778)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0003  max mem: 7679\n",
            "Epoch: [47]  [146/147]  eta: 0:00:00  lr: 0.002910  min_lr: 0.002910  loss: 2.6987 (2.5778)  weight_decay: 0.0500 (0.0500)  time: 0.7275  data: 0.0002  max mem: 7679\n",
            "Epoch: [47] Total time: 0:02:05 (0.8552 s / it)\n",
            "Averaged stats: lr: 0.002910  min_lr: 0.002910  loss: 2.6987 (2.5778)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:17  loss: 0.7045 (0.7045)  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 3.3477  data: 2.8956  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.8997 (0.9008)  acc1: 79.1667 (80.1136)  acc5: 96.8750 (97.6326)  time: 0.7110  data: 0.2855  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.9397 (1.0992)  acc1: 77.0833 (71.0814)  acc5: 96.8750 (96.4782)  time: 0.4355  data: 0.0133  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.0073 (1.0472)  acc1: 73.9583 (72.6479)  acc5: 96.8750 (96.5726)  time: 0.4133  data: 0.0011  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8387 (0.9918)  acc1: 76.0417 (74.1656)  acc5: 96.8750 (96.5605)  time: 0.4043  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5005 s / it)\n",
            "* Acc@1 74.166 Acc@5 96.561 loss 0.992\n",
            "Accuracy of the model on the 3925 test images: 74.2%\n",
            "Max accuracy: 74.17%\n",
            "Test:  [ 0/41]  eta: 0:03:25  loss: 4.8667 (4.8667)  acc1: 28.1250 (28.1250)  acc5: 64.5833 (64.5833)  time: 5.0019  data: 4.5532  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 4.8236 (4.7701)  acc1: 20.8333 (20.5492)  acc5: 70.8333 (71.3068)  time: 0.8331  data: 0.4169  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.0259 (5.2868)  acc1: 11.4583 (13.6905)  acc5: 63.5417 (57.1925)  time: 0.4111  data: 0.0020  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.4387 (5.2158)  acc1: 4.1667 (17.1035)  acc5: 43.7500 (58.6694)  time: 0.4062  data: 0.0004  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5150 (4.8844)  acc1: 25.0000 (22.9045)  acc5: 72.9167 (62.1147)  time: 0.4049  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5356 s / it)\n",
            "* Acc@1 22.904 Acc@5 62.115 loss 4.884\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "Max EMA accuracy: 22.90%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [48]  [  0/147]  eta: 0:08:43  lr: 0.002908  min_lr: 0.002908  loss: 2.8816 (2.8816)  weight_decay: 0.0500 (0.0500)  time: 3.5629  data: 2.6369  max mem: 7679\n",
            "Epoch: [48]  [ 10/147]  eta: 0:02:31  lr: 0.002904  min_lr: 0.002904  loss: 2.5742 (2.5393)  weight_decay: 0.0500 (0.0500)  time: 1.1060  data: 0.2414  max mem: 7679\n",
            "Epoch: [48]  [ 20/147]  eta: 0:02:05  lr: 0.002899  min_lr: 0.002899  loss: 2.5742 (2.5604)  weight_decay: 0.0500 (0.0500)  time: 0.8598  data: 0.0012  max mem: 7679\n",
            "Epoch: [48]  [ 30/147]  eta: 0:01:50  lr: 0.002895  min_lr: 0.002895  loss: 2.5876 (2.5554)  weight_decay: 0.0500 (0.0500)  time: 0.8585  data: 0.0013  max mem: 7679\n",
            "Epoch: [48]  [ 40/147]  eta: 0:01:38  lr: 0.002889  min_lr: 0.002889  loss: 2.5921 (2.5621)  weight_decay: 0.0500 (0.0500)  time: 0.8551  data: 0.0015  max mem: 7679\n",
            "Epoch: [48]  [ 50/147]  eta: 0:01:28  lr: 0.002885  min_lr: 0.002885  loss: 2.5436 (2.5668)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0010  max mem: 7679\n",
            "Epoch: [48]  [ 60/147]  eta: 0:01:18  lr: 0.002879  min_lr: 0.002879  loss: 2.5525 (2.5696)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0012  max mem: 7679\n",
            "Epoch: [48]  [ 70/147]  eta: 0:01:08  lr: 0.002875  min_lr: 0.002875  loss: 2.6214 (2.5670)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0011  max mem: 7679\n",
            "Epoch: [48]  [ 80/147]  eta: 0:00:59  lr: 0.002869  min_lr: 0.002869  loss: 2.5387 (2.5620)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0008  max mem: 7679\n",
            "Epoch: [48]  [ 90/147]  eta: 0:00:50  lr: 0.002865  min_lr: 0.002865  loss: 2.4205 (2.5503)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0021  max mem: 7679\n",
            "Epoch: [48]  [100/147]  eta: 0:00:41  lr: 0.002859  min_lr: 0.002859  loss: 2.3776 (2.5390)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0025  max mem: 7679\n",
            "Epoch: [48]  [110/147]  eta: 0:00:32  lr: 0.002855  min_lr: 0.002855  loss: 2.5936 (2.5518)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0014  max mem: 7679\n",
            "Epoch: [48]  [120/147]  eta: 0:00:23  lr: 0.002849  min_lr: 0.002849  loss: 2.6453 (2.5462)  weight_decay: 0.0500 (0.0500)  time: 0.8521  data: 0.0009  max mem: 7679\n",
            "Epoch: [48]  [130/147]  eta: 0:00:14  lr: 0.002846  min_lr: 0.002846  loss: 2.6027 (2.5468)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0013  max mem: 7679\n",
            "Epoch: [48]  [140/147]  eta: 0:00:06  lr: 0.002840  min_lr: 0.002840  loss: 2.5648 (2.5493)  weight_decay: 0.0500 (0.0500)  time: 0.8512  data: 0.0012  max mem: 7679\n",
            "Epoch: [48]  [146/147]  eta: 0:00:00  lr: 0.002840  min_lr: 0.002840  loss: 2.5648 (2.5501)  weight_decay: 0.0500 (0.0500)  time: 0.7233  data: 0.0002  max mem: 7679\n",
            "Epoch: [48] Total time: 0:02:05 (0.8562 s / it)\n",
            "Averaged stats: lr: 0.002840  min_lr: 0.002840  loss: 2.5648 (2.5501)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:32  loss: 0.5805 (0.5805)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 5.1812  data: 4.7126  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 0.8315 (0.8894)  acc1: 83.3333 (80.4924)  acc5: 97.9167 (97.3485)  time: 0.8384  data: 0.4330  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.8315 (0.9860)  acc1: 79.1667 (74.2560)  acc5: 97.9167 (97.3710)  time: 0.4110  data: 0.0055  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.9015 (1.0020)  acc1: 73.9583 (73.4543)  acc5: 97.9167 (96.9086)  time: 0.4102  data: 0.0030  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0535 (0.9960)  acc1: 70.8333 (73.4268)  acc5: 95.8333 (96.5605)  time: 0.4038  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5332 s / it)\n",
            "* Acc@1 73.427 Acc@5 96.561 loss 0.996\n",
            "Accuracy of the model on the 3925 test images: 73.4%\n",
            "Max accuracy: 74.17%\n",
            "Test:  [ 0/41]  eta: 0:03:10  loss: 4.8040 (4.8040)  acc1: 27.0833 (27.0833)  acc5: 65.6250 (65.6250)  time: 4.6568  data: 4.1749  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 4.7654 (4.7209)  acc1: 20.8333 (20.1705)  acc5: 71.8750 (72.5379)  time: 0.8072  data: 0.3816  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.0194 (5.2511)  acc1: 10.4167 (13.6409)  acc5: 66.6667 (58.4325)  time: 0.4186  data: 0.0020  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3915 (5.1875)  acc1: 4.1667 (16.9355)  acc5: 46.8750 (59.4758)  time: 0.4128  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5032 (4.8493)  acc1: 25.0000 (22.9045)  acc5: 75.0000 (62.8535)  time: 0.4089  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5324 s / it)\n",
            "* Acc@1 22.904 Acc@5 62.854 loss 4.849\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "Max EMA accuracy: 22.90%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [49]  [  0/147]  eta: 0:09:38  lr: 0.002838  min_lr: 0.002838  loss: 2.4433 (2.4433)  weight_decay: 0.0500 (0.0500)  time: 3.9372  data: 3.0352  max mem: 7679\n",
            "Epoch: [49]  [ 10/147]  eta: 0:02:34  lr: 0.002834  min_lr: 0.002834  loss: 2.5920 (2.5545)  weight_decay: 0.0500 (0.0500)  time: 1.1279  data: 0.2766  max mem: 7679\n",
            "Epoch: [49]  [ 20/147]  eta: 0:02:07  lr: 0.002828  min_lr: 0.002828  loss: 2.5708 (2.5309)  weight_decay: 0.0500 (0.0500)  time: 0.8535  data: 0.0012  max mem: 7679\n",
            "Epoch: [49]  [ 30/147]  eta: 0:01:51  lr: 0.002824  min_lr: 0.002824  loss: 2.5920 (2.5631)  weight_decay: 0.0500 (0.0500)  time: 0.8563  data: 0.0012  max mem: 7679\n",
            "Epoch: [49]  [ 40/147]  eta: 0:01:39  lr: 0.002818  min_lr: 0.002818  loss: 2.6000 (2.5598)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0011  max mem: 7679\n",
            "Epoch: [49]  [ 50/147]  eta: 0:01:28  lr: 0.002814  min_lr: 0.002814  loss: 2.5936 (2.5472)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0012  max mem: 7679\n",
            "Epoch: [49]  [ 60/147]  eta: 0:01:18  lr: 0.002808  min_lr: 0.002808  loss: 2.5492 (2.5484)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0009  max mem: 7679\n",
            "Epoch: [49]  [ 70/147]  eta: 0:01:08  lr: 0.002804  min_lr: 0.002804  loss: 2.5334 (2.5408)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0018  max mem: 7679\n",
            "Epoch: [49]  [ 80/147]  eta: 0:00:59  lr: 0.002798  min_lr: 0.002798  loss: 2.5011 (2.5430)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.0017  max mem: 7679\n",
            "Epoch: [49]  [ 90/147]  eta: 0:00:50  lr: 0.002794  min_lr: 0.002794  loss: 2.6256 (2.5561)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0010  max mem: 7679\n",
            "Epoch: [49]  [100/147]  eta: 0:00:41  lr: 0.002788  min_lr: 0.002788  loss: 2.6256 (2.5549)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0012  max mem: 7679\n",
            "Epoch: [49]  [110/147]  eta: 0:00:32  lr: 0.002784  min_lr: 0.002784  loss: 2.5490 (2.5520)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0008  max mem: 7679\n",
            "Epoch: [49]  [120/147]  eta: 0:00:23  lr: 0.002778  min_lr: 0.002778  loss: 2.6500 (2.5544)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0009  max mem: 7679\n",
            "Epoch: [49]  [130/147]  eta: 0:00:14  lr: 0.002774  min_lr: 0.002774  loss: 2.6575 (2.5552)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0008  max mem: 7679\n",
            "Epoch: [49]  [140/147]  eta: 0:00:06  lr: 0.002768  min_lr: 0.002768  loss: 2.5785 (2.5555)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0003  max mem: 7679\n",
            "Epoch: [49]  [146/147]  eta: 0:00:00  lr: 0.002768  min_lr: 0.002768  loss: 2.5785 (2.5553)  weight_decay: 0.0500 (0.0500)  time: 0.7238  data: 0.0002  max mem: 7679\n",
            "Epoch: [49] Total time: 0:02:06 (0.8580 s / it)\n",
            "Averaged stats: lr: 0.002768  min_lr: 0.002768  loss: 2.5785 (2.5553)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:03  loss: 0.6183 (0.6183)  acc1: 87.5000 (87.5000)  acc5: 95.8333 (95.8333)  time: 4.4765  data: 4.0305  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.8253 (0.8270)  acc1: 83.3333 (82.5758)  acc5: 96.8750 (97.2538)  time: 0.7713  data: 0.3688  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.8608 (0.9860)  acc1: 79.1667 (74.1071)  acc5: 97.9167 (97.3710)  time: 0.4014  data: 0.0018  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.9000 (0.9773)  acc1: 76.0417 (74.7648)  acc5: 97.9167 (96.9758)  time: 0.4037  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.9907 (0.9553)  acc1: 72.9167 (75.2866)  acc5: 96.8750 (96.7898)  time: 0.4054  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5171 s / it)\n",
            "* Acc@1 75.287 Acc@5 96.790 loss 0.955\n",
            "Accuracy of the model on the 3925 test images: 75.3%\n",
            "Max accuracy: 75.29%\n",
            "Test:  [ 0/41]  eta: 0:03:11  loss: 4.7437 (4.7437)  acc1: 26.0417 (26.0417)  acc5: 64.5833 (64.5833)  time: 4.6721  data: 4.1779  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 4.7100 (4.6730)  acc1: 20.8333 (20.0758)  acc5: 72.9167 (73.2008)  time: 0.8180  data: 0.4067  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.0145 (5.2164)  acc1: 10.4167 (13.5913)  acc5: 67.7083 (59.1766)  time: 0.4195  data: 0.0156  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3445 (5.1610)  acc1: 4.1667 (16.9355)  acc5: 47.9167 (60.1142)  time: 0.4059  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4969 (4.8158)  acc1: 26.0417 (22.9809)  acc5: 75.0000 (63.3631)  time: 0.4056  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5251 s / it)\n",
            "* Acc@1 22.981 Acc@5 63.363 loss 4.816\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "Max EMA accuracy: 22.98%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [50]  [  0/147]  eta: 0:09:40  lr: 0.002766  min_lr: 0.002766  loss: 2.4172 (2.4172)  weight_decay: 0.0500 (0.0500)  time: 3.9474  data: 2.5256  max mem: 7679\n",
            "Epoch: [50]  [ 10/147]  eta: 0:02:55  lr: 0.002762  min_lr: 0.002762  loss: 2.4172 (2.5076)  weight_decay: 0.0500 (0.0500)  time: 1.2784  data: 0.2369  max mem: 7679\n",
            "Epoch: [50]  [ 20/147]  eta: 0:02:17  lr: 0.002756  min_lr: 0.002756  loss: 2.3981 (2.4859)  weight_decay: 0.0500 (0.0500)  time: 0.9415  data: 0.0046  max mem: 7679\n",
            "Epoch: [50]  [ 30/147]  eta: 0:01:58  lr: 0.002752  min_lr: 0.002752  loss: 2.4853 (2.5024)  weight_decay: 0.0500 (0.0500)  time: 0.8674  data: 0.0016  max mem: 7679\n",
            "Epoch: [50]  [ 40/147]  eta: 0:01:44  lr: 0.002745  min_lr: 0.002745  loss: 2.5558 (2.5242)  weight_decay: 0.0500 (0.0500)  time: 0.8577  data: 0.0013  max mem: 7679\n",
            "Epoch: [50]  [ 50/147]  eta: 0:01:32  lr: 0.002741  min_lr: 0.002741  loss: 2.5851 (2.5322)  weight_decay: 0.0500 (0.0500)  time: 0.8512  data: 0.0009  max mem: 7679\n",
            "Epoch: [50]  [ 60/147]  eta: 0:01:21  lr: 0.002735  min_lr: 0.002735  loss: 2.5851 (2.5421)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0009  max mem: 7679\n",
            "Epoch: [50]  [ 70/147]  eta: 0:01:10  lr: 0.002731  min_lr: 0.002731  loss: 2.5662 (2.5422)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0008  max mem: 7679\n",
            "Epoch: [50]  [ 80/147]  eta: 0:01:01  lr: 0.002725  min_lr: 0.002725  loss: 2.4993 (2.5321)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0012  max mem: 7679\n",
            "Epoch: [50]  [ 90/147]  eta: 0:00:51  lr: 0.002721  min_lr: 0.002721  loss: 2.6027 (2.5450)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0022  max mem: 7679\n",
            "Epoch: [50]  [100/147]  eta: 0:00:42  lr: 0.002715  min_lr: 0.002715  loss: 2.6027 (2.5467)  weight_decay: 0.0500 (0.0500)  time: 0.8489  data: 0.0024  max mem: 7679\n",
            "Epoch: [50]  [110/147]  eta: 0:00:33  lr: 0.002711  min_lr: 0.002711  loss: 2.5445 (2.5481)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0025  max mem: 7679\n",
            "Epoch: [50]  [120/147]  eta: 0:00:24  lr: 0.002705  min_lr: 0.002705  loss: 2.5110 (2.5403)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0020  max mem: 7679\n",
            "Epoch: [50]  [130/147]  eta: 0:00:15  lr: 0.002701  min_lr: 0.002701  loss: 2.5478 (2.5446)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0011  max mem: 7679\n",
            "Epoch: [50]  [140/147]  eta: 0:00:06  lr: 0.002695  min_lr: 0.002695  loss: 2.6769 (2.5532)  weight_decay: 0.0500 (0.0500)  time: 0.8512  data: 0.0008  max mem: 7679\n",
            "Epoch: [50]  [146/147]  eta: 0:00:00  lr: 0.002695  min_lr: 0.002695  loss: 2.6573 (2.5506)  weight_decay: 0.0500 (0.0500)  time: 0.7258  data: 0.0002  max mem: 7679\n",
            "Epoch: [50] Total time: 0:02:08 (0.8728 s / it)\n",
            "Averaged stats: lr: 0.002695  min_lr: 0.002695  loss: 2.6573 (2.5506)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:08  loss: 0.4590 (0.4590)  acc1: 91.6667 (91.6667)  acc5: 96.8750 (96.8750)  time: 3.1391  data: 2.6995  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.7070 (0.6725)  acc1: 86.4583 (86.9318)  acc5: 97.9167 (98.3902)  time: 0.6606  data: 0.2479  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.8058 (0.9399)  acc1: 81.2500 (75.5952)  acc5: 96.8750 (96.8750)  time: 0.4114  data: 0.0022  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 1.0070 (0.9655)  acc1: 72.9167 (75.0000)  acc5: 95.8333 (96.4718)  time: 0.4068  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 1.0070 (0.9678)  acc1: 72.9167 (75.3376)  acc5: 95.8333 (96.4586)  time: 0.4041  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4840 s / it)\n",
            "* Acc@1 75.338 Acc@5 96.459 loss 0.968\n",
            "Accuracy of the model on the 3925 test images: 75.3%\n",
            "Max accuracy: 75.34%\n",
            "Test:  [ 0/41]  eta: 0:02:02  loss: 4.6844 (4.6844)  acc1: 23.9583 (23.9583)  acc5: 64.5833 (64.5833)  time: 2.9978  data: 2.5369  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 4.6561 (4.6273)  acc1: 20.8333 (19.6023)  acc5: 73.9583 (74.0530)  time: 0.7773  data: 0.3648  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0147 (5.1825)  acc1: 10.4167 (13.4425)  acc5: 69.7917 (60.1191)  time: 0.4990  data: 0.0760  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2950 (5.1359)  acc1: 6.2500 (16.6667)  acc5: 48.9583 (60.6183)  time: 0.4267  data: 0.0022  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4439 (4.7835)  acc1: 25.0000 (22.9045)  acc5: 78.1250 (63.8217)  time: 0.4070  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5267 s / it)\n",
            "* Acc@1 22.904 Acc@5 63.822 loss 4.783\n",
            "Accuracy of the model EMA on 3925 test images: 22.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [51]  [  0/147]  eta: 0:10:08  lr: 0.002693  min_lr: 0.002693  loss: 2.6925 (2.6925)  weight_decay: 0.0500 (0.0500)  time: 4.1418  data: 2.7941  max mem: 7679\n",
            "Epoch: [51]  [ 10/147]  eta: 0:02:42  lr: 0.002688  min_lr: 0.002688  loss: 2.6272 (2.5451)  weight_decay: 0.0500 (0.0500)  time: 1.1882  data: 0.2554  max mem: 7679\n",
            "Epoch: [51]  [ 20/147]  eta: 0:02:11  lr: 0.002682  min_lr: 0.002682  loss: 2.6272 (2.5465)  weight_decay: 0.0500 (0.0500)  time: 0.8764  data: 0.0011  max mem: 7679\n",
            "Epoch: [51]  [ 30/147]  eta: 0:01:53  lr: 0.002678  min_lr: 0.002678  loss: 2.6285 (2.5805)  weight_decay: 0.0500 (0.0500)  time: 0.8564  data: 0.0007  max mem: 7679\n",
            "Epoch: [51]  [ 40/147]  eta: 0:01:41  lr: 0.002672  min_lr: 0.002672  loss: 2.6150 (2.5529)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0006  max mem: 7679\n",
            "Epoch: [51]  [ 50/147]  eta: 0:01:29  lr: 0.002668  min_lr: 0.002668  loss: 2.5751 (2.5628)  weight_decay: 0.0500 (0.0500)  time: 0.8489  data: 0.0006  max mem: 7679\n",
            "Epoch: [51]  [ 60/147]  eta: 0:01:19  lr: 0.002662  min_lr: 0.002662  loss: 2.6212 (2.5698)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0009  max mem: 7679\n",
            "Epoch: [51]  [ 70/147]  eta: 0:01:09  lr: 0.002658  min_lr: 0.002658  loss: 2.6222 (2.5426)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0014  max mem: 7679\n",
            "Epoch: [51]  [ 80/147]  eta: 0:01:00  lr: 0.002651  min_lr: 0.002651  loss: 2.3584 (2.5369)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0020  max mem: 7679\n",
            "Epoch: [51]  [ 90/147]  eta: 0:00:50  lr: 0.002647  min_lr: 0.002647  loss: 2.5350 (2.5303)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0016  max mem: 7679\n",
            "Epoch: [51]  [100/147]  eta: 0:00:41  lr: 0.002641  min_lr: 0.002641  loss: 2.4808 (2.5272)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0014  max mem: 7679\n",
            "Epoch: [51]  [110/147]  eta: 0:00:32  lr: 0.002637  min_lr: 0.002637  loss: 2.4912 (2.5290)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0013  max mem: 7679\n",
            "Epoch: [51]  [120/147]  eta: 0:00:23  lr: 0.002631  min_lr: 0.002631  loss: 2.6239 (2.5340)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0020  max mem: 7679\n",
            "Epoch: [51]  [130/147]  eta: 0:00:14  lr: 0.002627  min_lr: 0.002627  loss: 2.5354 (2.5263)  weight_decay: 0.0500 (0.0500)  time: 0.8533  data: 0.0020  max mem: 7679\n",
            "Epoch: [51]  [140/147]  eta: 0:00:06  lr: 0.002620  min_lr: 0.002620  loss: 2.5354 (2.5307)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0005  max mem: 7679\n",
            "Epoch: [51]  [146/147]  eta: 0:00:00  lr: 0.002620  min_lr: 0.002620  loss: 2.5462 (2.5335)  weight_decay: 0.0500 (0.0500)  time: 0.7241  data: 0.0003  max mem: 7679\n",
            "Epoch: [51] Total time: 0:02:06 (0.8621 s / it)\n",
            "Averaged stats: lr: 0.002620  min_lr: 0.002620  loss: 2.5462 (2.5335)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:22  loss: 0.5840 (0.5840)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 4.9350  data: 4.4951  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 0.7857 (0.7654)  acc1: 81.2500 (82.3864)  acc5: 97.9167 (97.9167)  time: 0.8229  data: 0.4124  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.8120 (0.9045)  acc1: 80.2083 (76.0417)  acc5: 97.9167 (97.5198)  time: 0.4116  data: 0.0041  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.8301 (0.9097)  acc1: 79.1667 (76.0417)  acc5: 97.9167 (97.1438)  time: 0.4073  data: 0.0021  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8400 (0.9136)  acc1: 79.1667 (76.1783)  acc5: 96.8750 (96.8917)  time: 0.4022  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5328 s / it)\n",
            "* Acc@1 76.178 Acc@5 96.892 loss 0.914\n",
            "Accuracy of the model on the 3925 test images: 76.2%\n",
            "Max accuracy: 76.18%\n",
            "Test:  [ 0/41]  eta: 0:03:00  loss: 4.6264 (4.6264)  acc1: 23.9583 (23.9583)  acc5: 65.6250 (65.6250)  time: 4.4041  data: 3.9595  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 4.6043 (4.5835)  acc1: 20.8333 (19.4129)  acc5: 73.9583 (75.1894)  time: 0.7739  data: 0.3690  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0149 (5.1503)  acc1: 10.4167 (13.2937)  acc5: 68.7500 (61.4087)  time: 0.4092  data: 0.0060  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.2450 (5.1136)  acc1: 6.2500 (16.5995)  acc5: 50.0000 (61.4919)  time: 0.4058  data: 0.0012  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3836 (4.7534)  acc1: 27.0833 (23.0064)  acc5: 79.1667 (64.6369)  time: 0.4024  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5120 s / it)\n",
            "* Acc@1 23.006 Acc@5 64.637 loss 4.753\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "Max EMA accuracy: 23.01%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [52]  [  0/147]  eta: 0:09:34  lr: 0.002618  min_lr: 0.002618  loss: 2.3970 (2.3970)  weight_decay: 0.0500 (0.0500)  time: 3.9063  data: 2.9028  max mem: 7679\n",
            "Epoch: [52]  [ 10/147]  eta: 0:02:42  lr: 0.002614  min_lr: 0.002614  loss: 2.5156 (2.4566)  weight_decay: 0.0500 (0.0500)  time: 1.1862  data: 0.2652  max mem: 7679\n",
            "Epoch: [52]  [ 20/147]  eta: 0:02:09  lr: 0.002608  min_lr: 0.002608  loss: 2.4011 (2.4468)  weight_decay: 0.0500 (0.0500)  time: 0.8775  data: 0.0012  max mem: 7679\n",
            "Epoch: [52]  [ 30/147]  eta: 0:01:52  lr: 0.002604  min_lr: 0.002604  loss: 2.6016 (2.4932)  weight_decay: 0.0500 (0.0500)  time: 0.8406  data: 0.0007  max mem: 7679\n",
            "Epoch: [52]  [ 40/147]  eta: 0:01:39  lr: 0.002598  min_lr: 0.002598  loss: 2.6738 (2.5152)  weight_decay: 0.0500 (0.0500)  time: 0.8382  data: 0.0005  max mem: 7679\n",
            "Epoch: [52]  [ 50/147]  eta: 0:01:28  lr: 0.002593  min_lr: 0.002593  loss: 2.5898 (2.5083)  weight_decay: 0.0500 (0.0500)  time: 0.8386  data: 0.0004  max mem: 7679\n",
            "Epoch: [52]  [ 60/147]  eta: 0:01:18  lr: 0.002587  min_lr: 0.002587  loss: 2.5898 (2.5124)  weight_decay: 0.0500 (0.0500)  time: 0.8403  data: 0.0004  max mem: 7679\n",
            "Epoch: [52]  [ 70/147]  eta: 0:01:08  lr: 0.002583  min_lr: 0.002583  loss: 2.6017 (2.5120)  weight_decay: 0.0500 (0.0500)  time: 0.8424  data: 0.0010  max mem: 7679\n",
            "Epoch: [52]  [ 80/147]  eta: 0:00:59  lr: 0.002577  min_lr: 0.002577  loss: 2.4539 (2.4997)  weight_decay: 0.0500 (0.0500)  time: 0.8443  data: 0.0010  max mem: 7679\n",
            "Epoch: [52]  [ 90/147]  eta: 0:00:50  lr: 0.002573  min_lr: 0.002573  loss: 2.4513 (2.4945)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0008  max mem: 7679\n",
            "Epoch: [52]  [100/147]  eta: 0:00:41  lr: 0.002566  min_lr: 0.002566  loss: 2.5010 (2.5018)  weight_decay: 0.0500 (0.0500)  time: 0.8516  data: 0.0010  max mem: 7679\n",
            "Epoch: [52]  [110/147]  eta: 0:00:32  lr: 0.002562  min_lr: 0.002562  loss: 2.6340 (2.5047)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0023  max mem: 7679\n",
            "Epoch: [52]  [120/147]  eta: 0:00:23  lr: 0.002556  min_lr: 0.002556  loss: 2.6092 (2.5099)  weight_decay: 0.0500 (0.0500)  time: 0.8550  data: 0.0022  max mem: 7679\n",
            "Epoch: [52]  [130/147]  eta: 0:00:14  lr: 0.002552  min_lr: 0.002552  loss: 2.5672 (2.5059)  weight_decay: 0.0500 (0.0500)  time: 0.8536  data: 0.0014  max mem: 7679\n",
            "Epoch: [52]  [140/147]  eta: 0:00:06  lr: 0.002545  min_lr: 0.002545  loss: 2.4605 (2.5013)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0012  max mem: 7679\n",
            "Epoch: [52]  [146/147]  eta: 0:00:00  lr: 0.002545  min_lr: 0.002545  loss: 2.4665 (2.5047)  weight_decay: 0.0500 (0.0500)  time: 0.7243  data: 0.0003  max mem: 7679\n",
            "Epoch: [52] Total time: 0:02:06 (0.8588 s / it)\n",
            "Averaged stats: lr: 0.002545  min_lr: 0.002545  loss: 2.4665 (2.5047)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:51  loss: 0.5171 (0.5171)  acc1: 89.5833 (89.5833)  acc5: 96.8750 (96.8750)  time: 4.1886  data: 3.6993  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.6919 (0.6914)  acc1: 86.4583 (84.7538)  acc5: 97.9167 (98.1061)  time: 0.7458  data: 0.3388  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.7142 (0.8877)  acc1: 83.3333 (76.1409)  acc5: 96.8750 (97.0238)  time: 0.4020  data: 0.0030  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.8414 (0.8851)  acc1: 79.1667 (76.4113)  acc5: 96.8750 (96.4718)  time: 0.3997  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8462 (0.8739)  acc1: 77.0833 (76.7898)  acc5: 96.8750 (96.7134)  time: 0.3951  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4999 s / it)\n",
            "* Acc@1 76.790 Acc@5 96.713 loss 0.874\n",
            "Accuracy of the model on the 3925 test images: 76.8%\n",
            "Max accuracy: 76.79%\n",
            "Test:  [ 0/41]  eta: 0:03:24  loss: 4.5680 (4.5680)  acc1: 22.9167 (22.9167)  acc5: 65.6250 (65.6250)  time: 4.9848  data: 4.5592  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 4.5520 (4.5411)  acc1: 20.8333 (19.7917)  acc5: 77.0833 (76.0417)  time: 0.8281  data: 0.4169  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.0175 (5.1191)  acc1: 10.4167 (13.6409)  acc5: 69.7917 (62.3512)  time: 0.4039  data: 0.0036  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2311 (5.0925)  acc1: 6.2500 (16.7003)  acc5: 53.1250 (61.9288)  time: 0.3917  data: 0.0024  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3651 (4.7248)  acc1: 28.1250 (23.1083)  acc5: 80.2083 (65.0446)  time: 0.3859  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5211 s / it)\n",
            "* Acc@1 23.108 Acc@5 65.045 loss 4.725\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "Max EMA accuracy: 23.11%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [53]  [  0/147]  eta: 0:08:13  lr: 0.002543  min_lr: 0.002543  loss: 2.8035 (2.8035)  weight_decay: 0.0500 (0.0500)  time: 3.3563  data: 2.3903  max mem: 7679\n",
            "Epoch: [53]  [ 10/147]  eta: 0:02:27  lr: 0.002539  min_lr: 0.002539  loss: 2.6293 (2.5879)  weight_decay: 0.0500 (0.0500)  time: 1.0738  data: 0.2185  max mem: 7679\n",
            "Epoch: [53]  [ 20/147]  eta: 0:02:03  lr: 0.002533  min_lr: 0.002533  loss: 2.5868 (2.5263)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0018  max mem: 7679\n",
            "Epoch: [53]  [ 30/147]  eta: 0:01:50  lr: 0.002529  min_lr: 0.002529  loss: 2.5698 (2.5413)  weight_decay: 0.0500 (0.0500)  time: 0.8677  data: 0.0022  max mem: 7679\n",
            "Epoch: [53]  [ 40/147]  eta: 0:01:39  lr: 0.002522  min_lr: 0.002522  loss: 2.5084 (2.5209)  weight_decay: 0.0500 (0.0500)  time: 0.8771  data: 0.0014  max mem: 7679\n",
            "Epoch: [53]  [ 50/147]  eta: 0:01:28  lr: 0.002518  min_lr: 0.002518  loss: 2.5084 (2.5384)  weight_decay: 0.0500 (0.0500)  time: 0.8735  data: 0.0009  max mem: 7679\n",
            "Epoch: [53]  [ 60/147]  eta: 0:01:18  lr: 0.002512  min_lr: 0.002512  loss: 2.6396 (2.5487)  weight_decay: 0.0500 (0.0500)  time: 0.8608  data: 0.0018  max mem: 7679\n",
            "Epoch: [53]  [ 70/147]  eta: 0:01:09  lr: 0.002507  min_lr: 0.002507  loss: 2.5621 (2.5325)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0023  max mem: 7679\n",
            "Epoch: [53]  [ 80/147]  eta: 0:00:59  lr: 0.002501  min_lr: 0.002501  loss: 2.5480 (2.5341)  weight_decay: 0.0500 (0.0500)  time: 0.8445  data: 0.0017  max mem: 7679\n",
            "Epoch: [53]  [ 90/147]  eta: 0:00:50  lr: 0.002497  min_lr: 0.002497  loss: 2.5480 (2.5247)  weight_decay: 0.0500 (0.0500)  time: 0.8426  data: 0.0014  max mem: 7679\n",
            "Epoch: [53]  [100/147]  eta: 0:00:41  lr: 0.002491  min_lr: 0.002491  loss: 2.4669 (2.5125)  weight_decay: 0.0500 (0.0500)  time: 0.8411  data: 0.0011  max mem: 7679\n",
            "Epoch: [53]  [110/147]  eta: 0:00:32  lr: 0.002486  min_lr: 0.002486  loss: 2.4835 (2.5122)  weight_decay: 0.0500 (0.0500)  time: 0.8437  data: 0.0027  max mem: 7679\n",
            "Epoch: [53]  [120/147]  eta: 0:00:23  lr: 0.002480  min_lr: 0.002480  loss: 2.4820 (2.5119)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0028  max mem: 7679\n",
            "Epoch: [53]  [130/147]  eta: 0:00:14  lr: 0.002476  min_lr: 0.002476  loss: 2.4766 (2.5110)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0015  max mem: 7679\n",
            "Epoch: [53]  [140/147]  eta: 0:00:06  lr: 0.002469  min_lr: 0.002469  loss: 2.5386 (2.5126)  weight_decay: 0.0500 (0.0500)  time: 0.8545  data: 0.0012  max mem: 7679\n",
            "Epoch: [53]  [146/147]  eta: 0:00:00  lr: 0.002469  min_lr: 0.002469  loss: 2.5386 (2.5114)  weight_decay: 0.0500 (0.0500)  time: 0.7285  data: 0.0002  max mem: 7679\n",
            "Epoch: [53] Total time: 0:02:06 (0.8585 s / it)\n",
            "Averaged stats: lr: 0.002469  min_lr: 0.002469  loss: 2.5386 (2.5114)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:30  loss: 0.8584 (0.8584)  acc1: 80.2083 (80.2083)  acc5: 92.7083 (92.7083)  time: 2.2085  data: 1.7828  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.8532 (0.8060)  acc1: 81.2500 (82.4811)  acc5: 97.9167 (97.0644)  time: 0.6683  data: 0.2609  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.8532 (0.9397)  acc1: 81.2500 (76.2401)  acc5: 97.9167 (97.2222)  time: 0.4587  data: 0.0552  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.9883 (0.9767)  acc1: 75.0000 (75.2688)  acc5: 96.8750 (96.8750)  time: 0.4036  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8915 (0.9193)  acc1: 79.1667 (77.1975)  acc5: 96.8750 (97.1210)  time: 0.4027  data: 0.0003  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4833 s / it)\n",
            "* Acc@1 77.197 Acc@5 97.121 loss 0.919\n",
            "Accuracy of the model on the 3925 test images: 77.2%\n",
            "Max accuracy: 77.20%\n",
            "Test:  [ 0/41]  eta: 0:01:43  loss: 4.5160 (4.5160)  acc1: 22.9167 (22.9167)  acc5: 65.6250 (65.6250)  time: 2.5192  data: 2.0539  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 4.5061 (4.5010)  acc1: 19.7917 (19.8864)  acc5: 77.0833 (76.9886)  time: 0.6997  data: 0.2805  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 5.0288 (5.0885)  acc1: 10.4167 (13.7897)  acc5: 69.7917 (63.6409)  time: 0.4696  data: 0.0526  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.2325 (5.0732)  acc1: 7.2917 (16.6667)  acc5: 57.2917 (62.8360)  time: 0.4134  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2659 (4.6978)  acc1: 27.0833 (23.2102)  acc5: 80.2083 (65.9108)  time: 0.4039  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4976 s / it)\n",
            "* Acc@1 23.210 Acc@5 65.911 loss 4.698\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "Max EMA accuracy: 23.21%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [54]  [  0/147]  eta: 0:11:56  lr: 0.002467  min_lr: 0.002467  loss: 2.6965 (2.6965)  weight_decay: 0.0500 (0.0500)  time: 4.8736  data: 3.9572  max mem: 7679\n",
            "Epoch: [54]  [ 10/147]  eta: 0:02:45  lr: 0.002463  min_lr: 0.002463  loss: 2.4091 (2.3902)  weight_decay: 0.0500 (0.0500)  time: 1.2111  data: 0.3600  max mem: 7679\n",
            "Epoch: [54]  [ 20/147]  eta: 0:02:12  lr: 0.002457  min_lr: 0.002457  loss: 2.4414 (2.4742)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0005  max mem: 7679\n",
            "Epoch: [54]  [ 30/147]  eta: 0:01:55  lr: 0.002452  min_lr: 0.002452  loss: 2.5920 (2.4774)  weight_decay: 0.0500 (0.0500)  time: 0.8588  data: 0.0005  max mem: 7679\n",
            "Epoch: [54]  [ 40/147]  eta: 0:01:42  lr: 0.002446  min_lr: 0.002446  loss: 2.5287 (2.4882)  weight_decay: 0.0500 (0.0500)  time: 0.8596  data: 0.0003  max mem: 7679\n",
            "Epoch: [54]  [ 50/147]  eta: 0:01:30  lr: 0.002442  min_lr: 0.002442  loss: 2.4279 (2.4650)  weight_decay: 0.0500 (0.0500)  time: 0.8585  data: 0.0004  max mem: 7679\n",
            "Epoch: [54]  [ 60/147]  eta: 0:01:20  lr: 0.002435  min_lr: 0.002435  loss: 2.4368 (2.4728)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0007  max mem: 7679\n",
            "Epoch: [54]  [ 70/147]  eta: 0:01:10  lr: 0.002431  min_lr: 0.002431  loss: 2.4852 (2.4725)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0006  max mem: 7679\n",
            "Epoch: [54]  [ 80/147]  eta: 0:01:00  lr: 0.002425  min_lr: 0.002425  loss: 2.5034 (2.4862)  weight_decay: 0.0500 (0.0500)  time: 0.8446  data: 0.0004  max mem: 7679\n",
            "Epoch: [54]  [ 90/147]  eta: 0:00:51  lr: 0.002420  min_lr: 0.002420  loss: 2.6777 (2.4990)  weight_decay: 0.0500 (0.0500)  time: 0.8441  data: 0.0005  max mem: 7679\n",
            "Epoch: [54]  [100/147]  eta: 0:00:41  lr: 0.002414  min_lr: 0.002414  loss: 2.6576 (2.5072)  weight_decay: 0.0500 (0.0500)  time: 0.8542  data: 0.0008  max mem: 7679\n",
            "Epoch: [54]  [110/147]  eta: 0:00:32  lr: 0.002410  min_lr: 0.002410  loss: 2.5703 (2.5078)  weight_decay: 0.0500 (0.0500)  time: 0.8577  data: 0.0013  max mem: 7679\n",
            "Epoch: [54]  [120/147]  eta: 0:00:23  lr: 0.002403  min_lr: 0.002403  loss: 2.5932 (2.5102)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0013  max mem: 7679\n",
            "Epoch: [54]  [130/147]  eta: 0:00:15  lr: 0.002399  min_lr: 0.002399  loss: 2.6585 (2.5165)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0012  max mem: 7679\n",
            "Epoch: [54]  [140/147]  eta: 0:00:06  lr: 0.002393  min_lr: 0.002393  loss: 2.5965 (2.5204)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0007  max mem: 7679\n",
            "Epoch: [54]  [146/147]  eta: 0:00:00  lr: 0.002393  min_lr: 0.002393  loss: 2.5243 (2.5217)  weight_decay: 0.0500 (0.0500)  time: 0.7242  data: 0.0002  max mem: 7679\n",
            "Epoch: [54] Total time: 0:02:07 (0.8666 s / it)\n",
            "Averaged stats: lr: 0.002393  min_lr: 0.002393  loss: 2.5243 (2.5217)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:50  loss: 0.5862 (0.5862)  acc1: 86.4583 (86.4583)  acc5: 96.8750 (96.8750)  time: 4.1513  data: 3.6937  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.6361 (0.6617)  acc1: 86.4583 (86.2689)  acc5: 97.9167 (97.6326)  time: 0.7453  data: 0.3414  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.7589 (0.9838)  acc1: 81.2500 (73.1647)  acc5: 96.8750 (95.1885)  time: 0.4037  data: 0.0046  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.8401 (0.9393)  acc1: 77.0833 (74.7648)  acc5: 96.8750 (95.6653)  time: 0.4035  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8153 (0.9095)  acc1: 79.1667 (76.1783)  acc5: 97.9167 (96.1529)  time: 0.4028  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5041 s / it)\n",
            "* Acc@1 76.178 Acc@5 96.153 loss 0.909\n",
            "Accuracy of the model on the 3925 test images: 76.2%\n",
            "Max accuracy: 77.20%\n",
            "Test:  [ 0/41]  eta: 0:02:42  loss: 4.4683 (4.4683)  acc1: 19.7917 (19.7917)  acc5: 67.7083 (67.7083)  time: 3.9687  data: 3.5284  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 4.4645 (4.4637)  acc1: 18.7500 (19.4129)  acc5: 78.1250 (77.8409)  time: 0.7348  data: 0.3219  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0424 (5.0599)  acc1: 10.4167 (13.4921)  acc5: 70.8333 (64.4345)  time: 0.4122  data: 0.0034  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.2358 (5.0556)  acc1: 6.2500 (16.3642)  acc5: 57.2917 (63.3065)  time: 0.4112  data: 0.0029  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1770 (4.6722)  acc1: 28.1250 (23.0828)  acc5: 80.2083 (66.3440)  time: 0.4080  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5061 s / it)\n",
            "* Acc@1 23.083 Acc@5 66.344 loss 4.672\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [55]  [  0/147]  eta: 0:10:01  lr: 0.002391  min_lr: 0.002391  loss: 2.6091 (2.6091)  weight_decay: 0.0500 (0.0500)  time: 4.0908  data: 2.8369  max mem: 7679\n",
            "Epoch: [55]  [ 10/147]  eta: 0:02:37  lr: 0.002386  min_lr: 0.002386  loss: 2.5152 (2.5004)  weight_decay: 0.0500 (0.0500)  time: 1.1505  data: 0.2585  max mem: 7679\n",
            "Epoch: [55]  [ 20/147]  eta: 0:02:08  lr: 0.002380  min_lr: 0.002380  loss: 2.4556 (2.4764)  weight_decay: 0.0500 (0.0500)  time: 0.8558  data: 0.0012  max mem: 7679\n",
            "Epoch: [55]  [ 30/147]  eta: 0:01:52  lr: 0.002376  min_lr: 0.002376  loss: 2.4150 (2.4595)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0011  max mem: 7679\n",
            "Epoch: [55]  [ 40/147]  eta: 0:01:39  lr: 0.002369  min_lr: 0.002369  loss: 2.4720 (2.4605)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0009  max mem: 7679\n",
            "Epoch: [55]  [ 50/147]  eta: 0:01:28  lr: 0.002365  min_lr: 0.002365  loss: 2.5488 (2.4679)  weight_decay: 0.0500 (0.0500)  time: 0.8472  data: 0.0009  max mem: 7679\n",
            "Epoch: [55]  [ 60/147]  eta: 0:01:18  lr: 0.002358  min_lr: 0.002358  loss: 2.5386 (2.4707)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0008  max mem: 7679\n",
            "Epoch: [55]  [ 70/147]  eta: 0:01:08  lr: 0.002354  min_lr: 0.002354  loss: 2.4491 (2.4671)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0017  max mem: 7679\n",
            "Epoch: [55]  [ 80/147]  eta: 0:00:59  lr: 0.002348  min_lr: 0.002348  loss: 2.5031 (2.4789)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0016  max mem: 7679\n",
            "Epoch: [55]  [ 90/147]  eta: 0:00:50  lr: 0.002343  min_lr: 0.002343  loss: 2.5076 (2.4789)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0014  max mem: 7679\n",
            "Epoch: [55]  [100/147]  eta: 0:00:41  lr: 0.002337  min_lr: 0.002337  loss: 2.5076 (2.4880)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0018  max mem: 7679\n",
            "Epoch: [55]  [110/147]  eta: 0:00:32  lr: 0.002333  min_lr: 0.002333  loss: 2.6077 (2.4871)  weight_decay: 0.0500 (0.0500)  time: 0.8516  data: 0.0017  max mem: 7679\n",
            "Epoch: [55]  [120/147]  eta: 0:00:23  lr: 0.002326  min_lr: 0.002326  loss: 2.4203 (2.4849)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0020  max mem: 7679\n",
            "Epoch: [55]  [130/147]  eta: 0:00:14  lr: 0.002322  min_lr: 0.002322  loss: 2.5522 (2.4879)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0019  max mem: 7679\n",
            "Epoch: [55]  [140/147]  eta: 0:00:06  lr: 0.002315  min_lr: 0.002315  loss: 2.4459 (2.4773)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0007  max mem: 7679\n",
            "Epoch: [55]  [146/147]  eta: 0:00:00  lr: 0.002315  min_lr: 0.002315  loss: 2.3585 (2.4766)  weight_decay: 0.0500 (0.0500)  time: 0.7254  data: 0.0002  max mem: 7679\n",
            "Epoch: [55] Total time: 0:02:06 (0.8588 s / it)\n",
            "Averaged stats: lr: 0.002315  min_lr: 0.002315  loss: 2.3585 (2.4766)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:34  loss: 0.5261 (0.5261)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 3.7786  data: 3.3236  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5903 (0.6031)  acc1: 87.5000 (87.2159)  acc5: 97.9167 (97.9167)  time: 0.7174  data: 0.3119  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6810 (0.8024)  acc1: 83.3333 (78.8194)  acc5: 97.9167 (97.4702)  time: 0.4165  data: 0.0065  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.9318 (0.8533)  acc1: 75.0000 (77.2849)  acc5: 96.8750 (96.7742)  time: 0.4121  data: 0.0012  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8800 (0.8452)  acc1: 75.0000 (77.7580)  acc5: 95.8333 (96.8408)  time: 0.4018  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5018 s / it)\n",
            "* Acc@1 77.758 Acc@5 96.841 loss 0.845\n",
            "Accuracy of the model on the 3925 test images: 77.8%\n",
            "Max accuracy: 77.76%\n",
            "Test:  [ 0/41]  eta: 0:03:54  loss: 4.4200 (4.4200)  acc1: 20.8333 (20.8333)  acc5: 67.7083 (67.7083)  time: 5.7092  data: 5.2202  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 4.4200 (4.4290)  acc1: 18.7500 (18.9394)  acc5: 78.1250 (78.7879)  time: 0.8880  data: 0.4760  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 5.0338 (5.0325)  acc1: 10.4167 (13.2440)  acc5: 69.7917 (65.4762)  time: 0.4045  data: 0.0017  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.1834 (5.0389)  acc1: 6.2500 (16.1626)  acc5: 58.3333 (63.8105)  time: 0.4046  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1744 (4.6473)  acc1: 29.1667 (23.1847)  acc5: 81.2500 (66.8280)  time: 0.4063  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5447 s / it)\n",
            "* Acc@1 23.185 Acc@5 66.828 loss 4.647\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [56]  [  0/147]  eta: 0:07:38  lr: 0.002313  min_lr: 0.002313  loss: 2.5821 (2.5821)  weight_decay: 0.0500 (0.0500)  time: 3.1185  data: 2.1398  max mem: 7679\n",
            "Epoch: [56]  [ 10/147]  eta: 0:02:27  lr: 0.002309  min_lr: 0.002309  loss: 2.5793 (2.5466)  weight_decay: 0.0500 (0.0500)  time: 1.0755  data: 0.1949  max mem: 7679\n",
            "Epoch: [56]  [ 20/147]  eta: 0:02:03  lr: 0.002303  min_lr: 0.002303  loss: 2.5103 (2.4736)  weight_decay: 0.0500 (0.0500)  time: 0.8677  data: 0.0005  max mem: 7679\n",
            "Epoch: [56]  [ 30/147]  eta: 0:01:49  lr: 0.002298  min_lr: 0.002298  loss: 2.4197 (2.4729)  weight_decay: 0.0500 (0.0500)  time: 0.8580  data: 0.0006  max mem: 7679\n",
            "Epoch: [56]  [ 40/147]  eta: 0:01:37  lr: 0.002292  min_lr: 0.002292  loss: 2.5445 (2.5071)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0010  max mem: 7679\n",
            "Epoch: [56]  [ 50/147]  eta: 0:01:27  lr: 0.002287  min_lr: 0.002287  loss: 2.5696 (2.5261)  weight_decay: 0.0500 (0.0500)  time: 0.8464  data: 0.0009  max mem: 7679\n",
            "Epoch: [56]  [ 60/147]  eta: 0:01:17  lr: 0.002281  min_lr: 0.002281  loss: 2.5842 (2.5362)  weight_decay: 0.0500 (0.0500)  time: 0.8437  data: 0.0008  max mem: 7679\n",
            "Epoch: [56]  [ 70/147]  eta: 0:01:08  lr: 0.002277  min_lr: 0.002277  loss: 2.6391 (2.5491)  weight_decay: 0.0500 (0.0500)  time: 0.8433  data: 0.0018  max mem: 7679\n",
            "Epoch: [56]  [ 80/147]  eta: 0:00:58  lr: 0.002270  min_lr: 0.002270  loss: 2.5334 (2.5262)  weight_decay: 0.0500 (0.0500)  time: 0.8452  data: 0.0014  max mem: 7679\n",
            "Epoch: [56]  [ 90/147]  eta: 0:00:49  lr: 0.002266  min_lr: 0.002266  loss: 2.4593 (2.5217)  weight_decay: 0.0500 (0.0500)  time: 0.8489  data: 0.0007  max mem: 7679\n",
            "Epoch: [56]  [100/147]  eta: 0:00:41  lr: 0.002259  min_lr: 0.002259  loss: 2.5269 (2.5275)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0008  max mem: 7679\n",
            "Epoch: [56]  [110/147]  eta: 0:00:32  lr: 0.002255  min_lr: 0.002255  loss: 2.5063 (2.5185)  weight_decay: 0.0500 (0.0500)  time: 0.8554  data: 0.0009  max mem: 7679\n",
            "Epoch: [56]  [120/147]  eta: 0:00:23  lr: 0.002249  min_lr: 0.002249  loss: 2.4849 (2.5151)  weight_decay: 0.0500 (0.0500)  time: 0.8557  data: 0.0012  max mem: 7679\n",
            "Epoch: [56]  [130/147]  eta: 0:00:14  lr: 0.002244  min_lr: 0.002244  loss: 2.4476 (2.5059)  weight_decay: 0.0500 (0.0500)  time: 0.8516  data: 0.0011  max mem: 7679\n",
            "Epoch: [56]  [140/147]  eta: 0:00:06  lr: 0.002238  min_lr: 0.002238  loss: 2.4380 (2.5023)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0006  max mem: 7679\n",
            "Epoch: [56]  [146/147]  eta: 0:00:00  lr: 0.002238  min_lr: 0.002238  loss: 2.4380 (2.4997)  weight_decay: 0.0500 (0.0500)  time: 0.7236  data: 0.0002  max mem: 7679\n",
            "Epoch: [56] Total time: 0:02:05 (0.8551 s / it)\n",
            "Averaged stats: lr: 0.002238  min_lr: 0.002238  loss: 2.4380 (2.4997)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:07  loss: 0.5176 (0.5176)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 4.5765  data: 4.1373  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.6407 (0.6343)  acc1: 87.5000 (87.6894)  acc5: 97.9167 (98.2008)  time: 0.7779  data: 0.3770  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.7320 (0.8763)  acc1: 84.3750 (77.2817)  acc5: 97.9167 (97.3710)  time: 0.4000  data: 0.0031  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.9819 (0.8948)  acc1: 72.9167 (76.7137)  acc5: 96.8750 (96.8414)  time: 0.4019  data: 0.0028  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7997 (0.8629)  acc1: 80.0000 (78.1401)  acc5: 97.9167 (97.0955)  time: 0.4019  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5120 s / it)\n",
            "* Acc@1 78.140 Acc@5 97.096 loss 0.863\n",
            "Accuracy of the model on the 3925 test images: 78.1%\n",
            "Max accuracy: 78.14%\n",
            "Test:  [ 0/41]  eta: 0:01:44  loss: 4.3731 (4.3731)  acc1: 20.8333 (20.8333)  acc5: 67.7083 (67.7083)  time: 2.5536  data: 2.0966  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 4.3731 (4.3956)  acc1: 16.6667 (18.6553)  acc5: 78.1250 (79.4508)  time: 0.7893  data: 0.3625  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0265 (5.0064)  acc1: 9.3750 (13.1448)  acc5: 69.7917 (66.6171)  time: 0.5138  data: 0.0961  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.1628 (5.0238)  acc1: 6.2500 (15.9610)  acc5: 60.4167 (64.4825)  time: 0.4118  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1741 (4.6240)  acc1: 28.1250 (23.1338)  acc5: 80.2083 (67.4140)  time: 0.4080  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5293 s / it)\n",
            "* Acc@1 23.134 Acc@5 67.414 loss 4.624\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [57]  [  0/147]  eta: 0:10:46  lr: 0.002236  min_lr: 0.002236  loss: 2.1263 (2.1263)  weight_decay: 0.0500 (0.0500)  time: 4.3966  data: 3.0713  max mem: 7679\n",
            "Epoch: [57]  [ 10/147]  eta: 0:02:44  lr: 0.002231  min_lr: 0.002231  loss: 2.4564 (2.4741)  weight_decay: 0.0500 (0.0500)  time: 1.2025  data: 0.2828  max mem: 7679\n",
            "Epoch: [57]  [ 20/147]  eta: 0:02:12  lr: 0.002225  min_lr: 0.002225  loss: 2.5269 (2.5131)  weight_decay: 0.0500 (0.0500)  time: 0.8733  data: 0.0024  max mem: 7679\n",
            "Epoch: [57]  [ 30/147]  eta: 0:01:54  lr: 0.002220  min_lr: 0.002220  loss: 2.5730 (2.5217)  weight_decay: 0.0500 (0.0500)  time: 0.8564  data: 0.0007  max mem: 7679\n",
            "Epoch: [57]  [ 40/147]  eta: 0:01:41  lr: 0.002214  min_lr: 0.002214  loss: 2.5744 (2.5407)  weight_decay: 0.0500 (0.0500)  time: 0.8521  data: 0.0021  max mem: 7679\n",
            "Epoch: [57]  [ 50/147]  eta: 0:01:30  lr: 0.002210  min_lr: 0.002210  loss: 2.4749 (2.5082)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0019  max mem: 7679\n",
            "Epoch: [57]  [ 60/147]  eta: 0:01:19  lr: 0.002203  min_lr: 0.002203  loss: 2.3980 (2.5047)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0022  max mem: 7679\n",
            "Epoch: [57]  [ 70/147]  eta: 0:01:09  lr: 0.002199  min_lr: 0.002199  loss: 2.4605 (2.4962)  weight_decay: 0.0500 (0.0500)  time: 0.8455  data: 0.0025  max mem: 7679\n",
            "Epoch: [57]  [ 80/147]  eta: 0:01:00  lr: 0.002192  min_lr: 0.002192  loss: 2.5162 (2.5026)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0031  max mem: 7679\n",
            "Epoch: [57]  [ 90/147]  eta: 0:00:50  lr: 0.002188  min_lr: 0.002188  loss: 2.5162 (2.4976)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0029  max mem: 7679\n",
            "Epoch: [57]  [100/147]  eta: 0:00:41  lr: 0.002181  min_lr: 0.002181  loss: 2.5038 (2.5060)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0014  max mem: 7679\n",
            "Epoch: [57]  [110/147]  eta: 0:00:32  lr: 0.002177  min_lr: 0.002177  loss: 2.4400 (2.4951)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0024  max mem: 7679\n",
            "Epoch: [57]  [120/147]  eta: 0:00:23  lr: 0.002170  min_lr: 0.002170  loss: 2.4230 (2.4912)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.0027  max mem: 7679\n",
            "Epoch: [57]  [130/147]  eta: 0:00:14  lr: 0.002166  min_lr: 0.002166  loss: 2.5235 (2.4957)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0023  max mem: 7679\n",
            "Epoch: [57]  [140/147]  eta: 0:00:06  lr: 0.002160  min_lr: 0.002160  loss: 2.4915 (2.4951)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0010  max mem: 7679\n",
            "Epoch: [57]  [146/147]  eta: 0:00:00  lr: 0.002160  min_lr: 0.002160  loss: 2.4713 (2.4942)  weight_decay: 0.0500 (0.0500)  time: 0.7234  data: 0.0002  max mem: 7679\n",
            "Epoch: [57] Total time: 0:02:06 (0.8633 s / it)\n",
            "Averaged stats: lr: 0.002160  min_lr: 0.002160  loss: 2.4713 (2.4942)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:03  loss: 0.5842 (0.5842)  acc1: 87.5000 (87.5000)  acc5: 97.9167 (97.9167)  time: 5.9433  data: 5.5186  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:28  loss: 0.6230 (0.6359)  acc1: 87.5000 (86.8371)  acc5: 97.9167 (97.9167)  time: 0.9058  data: 0.5049  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.6710 (0.8499)  acc1: 83.3333 (78.1746)  acc5: 96.8750 (97.3214)  time: 0.4007  data: 0.0022  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.8822 (0.8476)  acc1: 76.0417 (77.7554)  acc5: 96.8750 (97.1438)  time: 0.4012  data: 0.0005  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8068 (0.8439)  acc1: 79.1667 (78.1656)  acc5: 96.8750 (97.1720)  time: 0.4022  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5455 s / it)\n",
            "* Acc@1 78.166 Acc@5 97.172 loss 0.844\n",
            "Accuracy of the model on the 3925 test images: 78.2%\n",
            "Max accuracy: 78.17%\n",
            "Test:  [ 0/41]  eta: 0:02:44  loss: 4.3254 (4.3254)  acc1: 20.8333 (20.8333)  acc5: 70.8333 (70.8333)  time: 4.0003  data: 3.5354  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 4.3254 (4.3638)  acc1: 16.6667 (18.5606)  acc5: 78.1250 (80.3977)  time: 0.7386  data: 0.3230  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 5.0329 (4.9815)  acc1: 9.3750 (13.2937)  acc5: 69.7917 (67.5595)  time: 0.4150  data: 0.0036  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.1145 (5.0108)  acc1: 7.2917 (15.8602)  acc5: 62.5000 (64.9866)  time: 0.4170  data: 0.0028  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1793 (4.6024)  acc1: 27.0833 (23.2357)  acc5: 80.2083 (67.8217)  time: 0.4150  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5114 s / it)\n",
            "* Acc@1 23.236 Acc@5 67.822 loss 4.602\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "Max EMA accuracy: 23.24%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [58]  [  0/147]  eta: 0:12:36  lr: 0.002157  min_lr: 0.002157  loss: 2.5645 (2.5645)  weight_decay: 0.0500 (0.0500)  time: 5.1458  data: 3.9475  max mem: 7679\n",
            "Epoch: [58]  [ 10/147]  eta: 0:02:50  lr: 0.002153  min_lr: 0.002153  loss: 2.5650 (2.4857)  weight_decay: 0.0500 (0.0500)  time: 1.2446  data: 0.3592  max mem: 7679\n",
            "Epoch: [58]  [ 20/147]  eta: 0:02:14  lr: 0.002147  min_lr: 0.002147  loss: 2.5650 (2.5024)  weight_decay: 0.0500 (0.0500)  time: 0.8578  data: 0.0008  max mem: 7679\n",
            "Epoch: [58]  [ 30/147]  eta: 0:01:56  lr: 0.002142  min_lr: 0.002142  loss: 2.5340 (2.5198)  weight_decay: 0.0500 (0.0500)  time: 0.8574  data: 0.0009  max mem: 7679\n",
            "Epoch: [58]  [ 40/147]  eta: 0:01:42  lr: 0.002136  min_lr: 0.002136  loss: 2.5117 (2.5279)  weight_decay: 0.0500 (0.0500)  time: 0.8553  data: 0.0013  max mem: 7679\n",
            "Epoch: [58]  [ 50/147]  eta: 0:01:30  lr: 0.002131  min_lr: 0.002131  loss: 2.5389 (2.5343)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0014  max mem: 7679\n",
            "Epoch: [58]  [ 60/147]  eta: 0:01:20  lr: 0.002125  min_lr: 0.002125  loss: 2.5324 (2.5277)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0011  max mem: 7679\n",
            "Epoch: [58]  [ 70/147]  eta: 0:01:10  lr: 0.002120  min_lr: 0.002120  loss: 2.3922 (2.5015)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0011  max mem: 7679\n",
            "Epoch: [58]  [ 80/147]  eta: 0:01:00  lr: 0.002114  min_lr: 0.002114  loss: 2.3712 (2.4991)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0018  max mem: 7679\n",
            "Epoch: [58]  [ 90/147]  eta: 0:00:51  lr: 0.002110  min_lr: 0.002110  loss: 2.5067 (2.5056)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0021  max mem: 7679\n",
            "Epoch: [58]  [100/147]  eta: 0:00:42  lr: 0.002103  min_lr: 0.002103  loss: 2.4440 (2.4921)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0020  max mem: 7679\n",
            "Epoch: [58]  [110/147]  eta: 0:00:32  lr: 0.002099  min_lr: 0.002099  loss: 2.3813 (2.4904)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0018  max mem: 7679\n",
            "Epoch: [58]  [120/147]  eta: 0:00:23  lr: 0.002092  min_lr: 0.002092  loss: 2.3813 (2.4777)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0017  max mem: 7679\n",
            "Epoch: [58]  [130/147]  eta: 0:00:15  lr: 0.002088  min_lr: 0.002088  loss: 2.2196 (2.4654)  weight_decay: 0.0500 (0.0500)  time: 0.8524  data: 0.0013  max mem: 7679\n",
            "Epoch: [58]  [140/147]  eta: 0:00:06  lr: 0.002081  min_lr: 0.002081  loss: 2.2435 (2.4651)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0003  max mem: 7679\n",
            "Epoch: [58]  [146/147]  eta: 0:00:00  lr: 0.002081  min_lr: 0.002081  loss: 2.5305 (2.4692)  weight_decay: 0.0500 (0.0500)  time: 0.7244  data: 0.0002  max mem: 7679\n",
            "Epoch: [58] Total time: 0:02:07 (0.8658 s / it)\n",
            "Averaged stats: lr: 0.002081  min_lr: 0.002081  loss: 2.5305 (2.4692)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:01  loss: 0.7099 (0.7099)  acc1: 86.4583 (86.4583)  acc5: 94.7917 (94.7917)  time: 5.8909  data: 5.3965  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:28  loss: 0.6411 (0.6549)  acc1: 84.3750 (85.3220)  acc5: 96.8750 (97.1591)  time: 0.9154  data: 0.4929  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:14  loss: 0.6976 (0.7870)  acc1: 82.2917 (78.7202)  acc5: 97.9167 (97.3710)  time: 0.4144  data: 0.0084  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.7877 (0.7947)  acc1: 77.0833 (78.5954)  acc5: 97.9167 (97.2782)  time: 0.4084  data: 0.0071  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7368 (0.7866)  acc1: 79.1667 (79.0318)  acc5: 97.6471 (97.2994)  time: 0.4049  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5559 s / it)\n",
            "* Acc@1 79.032 Acc@5 97.299 loss 0.787\n",
            "Accuracy of the model on the 3925 test images: 79.0%\n",
            "Max accuracy: 79.03%\n",
            "Test:  [ 0/41]  eta: 0:01:53  loss: 4.2806 (4.2806)  acc1: 19.7917 (19.7917)  acc5: 76.0417 (76.0417)  time: 2.7773  data: 2.3312  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 4.2874 (4.3340)  acc1: 16.6667 (18.1818)  acc5: 77.0833 (81.2500)  time: 0.7056  data: 0.2923  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 5.0083 (4.9573)  acc1: 9.3750 (13.0952)  acc5: 72.9167 (68.8492)  time: 0.4573  data: 0.0461  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.0599 (4.9982)  acc1: 7.2917 (15.5578)  acc5: 62.5000 (65.9274)  time: 0.4136  data: 0.0019  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1864 (4.5817)  acc1: 27.0833 (23.2102)  acc5: 81.2500 (68.5860)  time: 0.4092  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4996 s / it)\n",
            "* Acc@1 23.210 Acc@5 68.586 loss 4.582\n",
            "Accuracy of the model EMA on 3925 test images: 23.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [59]  [  0/147]  eta: 0:09:33  lr: 0.002079  min_lr: 0.002079  loss: 1.9681 (1.9681)  weight_decay: 0.0500 (0.0500)  time: 3.8986  data: 2.9802  max mem: 7679\n",
            "Epoch: [59]  [ 10/147]  eta: 0:02:35  lr: 0.002075  min_lr: 0.002075  loss: 2.5511 (2.4700)  weight_decay: 0.0500 (0.0500)  time: 1.1354  data: 0.2730  max mem: 7679\n",
            "Epoch: [59]  [ 20/147]  eta: 0:02:07  lr: 0.002068  min_lr: 0.002068  loss: 2.4896 (2.4344)  weight_decay: 0.0500 (0.0500)  time: 0.8590  data: 0.0016  max mem: 7679\n",
            "Epoch: [59]  [ 30/147]  eta: 0:01:51  lr: 0.002064  min_lr: 0.002064  loss: 2.3299 (2.4303)  weight_decay: 0.0500 (0.0500)  time: 0.8566  data: 0.0013  max mem: 7679\n",
            "Epoch: [59]  [ 40/147]  eta: 0:01:39  lr: 0.002057  min_lr: 0.002057  loss: 2.3543 (2.4206)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0012  max mem: 7679\n",
            "Epoch: [59]  [ 50/147]  eta: 0:01:28  lr: 0.002053  min_lr: 0.002053  loss: 2.4208 (2.4360)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0006  max mem: 7679\n",
            "Epoch: [59]  [ 60/147]  eta: 0:01:18  lr: 0.002046  min_lr: 0.002046  loss: 2.5097 (2.4477)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0010  max mem: 7679\n",
            "Epoch: [59]  [ 70/147]  eta: 0:01:08  lr: 0.002042  min_lr: 0.002042  loss: 2.5113 (2.4555)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0018  max mem: 7679\n",
            "Epoch: [59]  [ 80/147]  eta: 0:00:59  lr: 0.002035  min_lr: 0.002035  loss: 2.4437 (2.4542)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0014  max mem: 7679\n",
            "Epoch: [59]  [ 90/147]  eta: 0:00:50  lr: 0.002031  min_lr: 0.002031  loss: 2.4641 (2.4557)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0007  max mem: 7679\n",
            "Epoch: [59]  [100/147]  eta: 0:00:41  lr: 0.002024  min_lr: 0.002024  loss: 2.5136 (2.4624)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0020  max mem: 7679\n",
            "Epoch: [59]  [110/147]  eta: 0:00:32  lr: 0.002020  min_lr: 0.002020  loss: 2.5524 (2.4698)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0016  max mem: 7679\n",
            "Epoch: [59]  [120/147]  eta: 0:00:23  lr: 0.002014  min_lr: 0.002014  loss: 2.5524 (2.4693)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0017  max mem: 7679\n",
            "Epoch: [59]  [130/147]  eta: 0:00:14  lr: 0.002009  min_lr: 0.002009  loss: 2.3834 (2.4652)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0018  max mem: 7679\n",
            "Epoch: [59]  [140/147]  eta: 0:00:06  lr: 0.002003  min_lr: 0.002003  loss: 2.3978 (2.4681)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0003  max mem: 7679\n",
            "Epoch: [59]  [146/147]  eta: 0:00:00  lr: 0.002003  min_lr: 0.002003  loss: 2.4117 (2.4672)  weight_decay: 0.0500 (0.0500)  time: 0.7225  data: 0.0002  max mem: 7679\n",
            "Epoch: [59] Total time: 0:02:06 (0.8575 s / it)\n",
            "Averaged stats: lr: 0.002003  min_lr: 0.002003  loss: 2.4117 (2.4672)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:31  loss: 0.5115 (0.5115)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 3.6835  data: 3.2101  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.6379 (0.6450)  acc1: 87.5000 (86.8371)  acc5: 97.9167 (98.4849)  time: 0.7329  data: 0.3106  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.7048 (0.9152)  acc1: 82.2917 (75.4960)  acc5: 97.9167 (97.3214)  time: 0.4256  data: 0.0150  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.9661 (0.9366)  acc1: 73.9583 (75.3696)  acc5: 96.8750 (96.9422)  time: 0.4075  data: 0.0047  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8259 (0.8942)  acc1: 81.2500 (76.7134)  acc5: 97.9167 (97.0446)  time: 0.4015  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5121 s / it)\n",
            "* Acc@1 76.713 Acc@5 97.045 loss 0.894\n",
            "Accuracy of the model on the 3925 test images: 76.7%\n",
            "Max accuracy: 79.03%\n",
            "Test:  [ 0/41]  eta: 0:03:45  loss: 4.2376 (4.2376)  acc1: 18.7500 (18.7500)  acc5: 77.0833 (77.0833)  time: 5.5056  data: 5.0496  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:29  loss: 4.2528 (4.3054)  acc1: 14.5833 (18.0871)  acc5: 78.1250 (81.5341)  time: 0.9414  data: 0.5169  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:14  loss: 4.9533 (4.9345)  acc1: 9.3750 (13.0456)  acc5: 73.9583 (69.6429)  time: 0.4485  data: 0.0346  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.0092 (4.9866)  acc1: 7.2917 (15.3226)  acc5: 62.5000 (66.2970)  time: 0.4104  data: 0.0028  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.1939 (4.5618)  acc1: 28.1250 (23.1083)  acc5: 81.2500 (68.9936)  time: 0.4078  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:23 (0.5673 s / it)\n",
            "* Acc@1 23.108 Acc@5 68.994 loss 4.562\n",
            "Accuracy of the model EMA on 3925 test images: 23.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [60]  [  0/147]  eta: 0:10:35  lr: 0.002001  min_lr: 0.002001  loss: 2.4537 (2.4537)  weight_decay: 0.0500 (0.0500)  time: 4.3226  data: 3.2551  max mem: 7679\n",
            "Epoch: [60]  [ 10/147]  eta: 0:02:40  lr: 0.001996  min_lr: 0.001996  loss: 2.4004 (2.3739)  weight_decay: 0.0500 (0.0500)  time: 1.1684  data: 0.2965  max mem: 7679\n",
            "Epoch: [60]  [ 20/147]  eta: 0:02:09  lr: 0.001990  min_lr: 0.001990  loss: 2.3170 (2.2976)  weight_decay: 0.0500 (0.0500)  time: 0.8575  data: 0.0005  max mem: 7679\n",
            "Epoch: [60]  [ 30/147]  eta: 0:01:53  lr: 0.001985  min_lr: 0.001985  loss: 2.3465 (2.3716)  weight_decay: 0.0500 (0.0500)  time: 0.8560  data: 0.0005  max mem: 7679\n",
            "Epoch: [60]  [ 40/147]  eta: 0:01:40  lr: 0.001979  min_lr: 0.001979  loss: 2.5878 (2.4242)  weight_decay: 0.0500 (0.0500)  time: 0.8534  data: 0.0012  max mem: 7679\n",
            "Epoch: [60]  [ 50/147]  eta: 0:01:29  lr: 0.001974  min_lr: 0.001974  loss: 2.5704 (2.4201)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0012  max mem: 7679\n",
            "Epoch: [60]  [ 60/147]  eta: 0:01:19  lr: 0.001968  min_lr: 0.001968  loss: 2.5494 (2.4458)  weight_decay: 0.0500 (0.0500)  time: 0.8448  data: 0.0012  max mem: 7679\n",
            "Epoch: [60]  [ 70/147]  eta: 0:01:09  lr: 0.001963  min_lr: 0.001963  loss: 2.4661 (2.4392)  weight_decay: 0.0500 (0.0500)  time: 0.8453  data: 0.0015  max mem: 7679\n",
            "Epoch: [60]  [ 80/147]  eta: 0:00:59  lr: 0.001957  min_lr: 0.001957  loss: 2.4642 (2.4549)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0016  max mem: 7679\n",
            "Epoch: [60]  [ 90/147]  eta: 0:00:50  lr: 0.001953  min_lr: 0.001953  loss: 2.3737 (2.4456)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0017  max mem: 7679\n",
            "Epoch: [60]  [100/147]  eta: 0:00:41  lr: 0.001946  min_lr: 0.001946  loss: 2.5863 (2.4669)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0024  max mem: 7679\n",
            "Epoch: [60]  [110/147]  eta: 0:00:32  lr: 0.001942  min_lr: 0.001942  loss: 2.6212 (2.4718)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0027  max mem: 7679\n",
            "Epoch: [60]  [120/147]  eta: 0:00:23  lr: 0.001935  min_lr: 0.001935  loss: 2.4560 (2.4768)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0015  max mem: 7679\n",
            "Epoch: [60]  [130/147]  eta: 0:00:14  lr: 0.001931  min_lr: 0.001931  loss: 2.5730 (2.4830)  weight_decay: 0.0500 (0.0500)  time: 0.8516  data: 0.0006  max mem: 7679\n",
            "Epoch: [60]  [140/147]  eta: 0:00:06  lr: 0.001924  min_lr: 0.001924  loss: 2.5383 (2.4806)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0004  max mem: 7679\n",
            "Epoch: [60]  [146/147]  eta: 0:00:00  lr: 0.001924  min_lr: 0.001924  loss: 2.5031 (2.4809)  weight_decay: 0.0500 (0.0500)  time: 0.7236  data: 0.0003  max mem: 7679\n",
            "Epoch: [60] Total time: 0:02:06 (0.8608 s / it)\n",
            "Averaged stats: lr: 0.001924  min_lr: 0.001924  loss: 2.5031 (2.4809)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:40  loss: 0.6421 (0.6421)  acc1: 85.4167 (85.4167)  acc5: 94.7917 (94.7917)  time: 3.9071  data: 3.4323  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.6421 (0.6340)  acc1: 86.4583 (86.9318)  acc5: 97.9167 (97.9167)  time: 0.7280  data: 0.3188  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6957 (0.8069)  acc1: 85.4167 (80.2083)  acc5: 97.9167 (97.7183)  time: 0.4080  data: 0.0065  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.8674 (0.8194)  acc1: 77.0833 (79.3683)  acc5: 97.9167 (97.4798)  time: 0.4052  data: 0.0028  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8697 (0.8265)  acc1: 75.0000 (78.8280)  acc5: 96.8750 (97.1975)  time: 0.4033  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5001 s / it)\n",
            "* Acc@1 78.828 Acc@5 97.197 loss 0.826\n",
            "Accuracy of the model on the 3925 test images: 78.8%\n",
            "Max accuracy: 79.03%\n",
            "Test:  [ 0/41]  eta: 0:02:43  loss: 4.1973 (4.1973)  acc1: 17.7083 (17.7083)  acc5: 77.0833 (77.0833)  time: 3.9807  data: 3.5444  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 4.2206 (4.2779)  acc1: 14.5833 (17.9924)  acc5: 79.1667 (81.7235)  time: 0.7357  data: 0.3250  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 4.8956 (4.9122)  acc1: 8.3333 (12.9960)  acc5: 75.0000 (69.8909)  time: 0.4127  data: 0.0051  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 4.9737 (4.9761)  acc1: 7.2917 (15.0202)  acc5: 61.4583 (66.3642)  time: 0.4127  data: 0.0036  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2046 (4.5433)  acc1: 30.2083 (22.9809)  acc5: 81.2500 (69.0701)  time: 0.4083  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5068 s / it)\n",
            "* Acc@1 22.981 Acc@5 69.070 loss 4.543\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [61]  [  0/147]  eta: 0:13:05  lr: 0.001922  min_lr: 0.001922  loss: 2.8234 (2.8234)  weight_decay: 0.0500 (0.0500)  time: 5.3436  data: 4.2555  max mem: 7679\n",
            "Epoch: [61]  [ 10/147]  eta: 0:02:53  lr: 0.001918  min_lr: 0.001918  loss: 2.5278 (2.4609)  weight_decay: 0.0500 (0.0500)  time: 1.2698  data: 0.3891  max mem: 7679\n",
            "Epoch: [61]  [ 20/147]  eta: 0:02:15  lr: 0.001911  min_lr: 0.001911  loss: 2.5152 (2.4696)  weight_decay: 0.0500 (0.0500)  time: 0.8569  data: 0.0015  max mem: 7679\n",
            "Epoch: [61]  [ 30/147]  eta: 0:01:57  lr: 0.001907  min_lr: 0.001907  loss: 2.4707 (2.4337)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0007  max mem: 7679\n",
            "Epoch: [61]  [ 40/147]  eta: 0:01:43  lr: 0.001900  min_lr: 0.001900  loss: 2.4472 (2.4260)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0008  max mem: 7679\n",
            "Epoch: [61]  [ 50/147]  eta: 0:01:31  lr: 0.001896  min_lr: 0.001896  loss: 2.5013 (2.4403)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0008  max mem: 7679\n",
            "Epoch: [61]  [ 60/147]  eta: 0:01:20  lr: 0.001889  min_lr: 0.001889  loss: 2.5984 (2.4442)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0008  max mem: 7679\n",
            "Epoch: [61]  [ 70/147]  eta: 0:01:10  lr: 0.001885  min_lr: 0.001885  loss: 2.5984 (2.4575)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0011  max mem: 7679\n",
            "Epoch: [61]  [ 80/147]  eta: 0:01:00  lr: 0.001878  min_lr: 0.001878  loss: 2.5814 (2.4698)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0011  max mem: 7679\n",
            "Epoch: [61]  [ 90/147]  eta: 0:00:51  lr: 0.001874  min_lr: 0.001874  loss: 2.5183 (2.4711)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0022  max mem: 7679\n",
            "Epoch: [61]  [100/147]  eta: 0:00:42  lr: 0.001868  min_lr: 0.001868  loss: 2.5878 (2.4798)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0027  max mem: 7679\n",
            "Epoch: [61]  [110/147]  eta: 0:00:32  lr: 0.001863  min_lr: 0.001863  loss: 2.5899 (2.4795)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0020  max mem: 7679\n",
            "Epoch: [61]  [120/147]  eta: 0:00:23  lr: 0.001857  min_lr: 0.001857  loss: 2.4157 (2.4724)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0025  max mem: 7679\n",
            "Epoch: [61]  [130/147]  eta: 0:00:15  lr: 0.001852  min_lr: 0.001852  loss: 2.3490 (2.4657)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0017  max mem: 7679\n",
            "Epoch: [61]  [140/147]  eta: 0:00:06  lr: 0.001846  min_lr: 0.001846  loss: 2.4305 (2.4592)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0005  max mem: 7679\n",
            "Epoch: [61]  [146/147]  eta: 0:00:00  lr: 0.001846  min_lr: 0.001846  loss: 2.4462 (2.4633)  weight_decay: 0.0500 (0.0500)  time: 0.7214  data: 0.0003  max mem: 7679\n",
            "Epoch: [61] Total time: 0:02:07 (0.8666 s / it)\n",
            "Averaged stats: lr: 0.001846  min_lr: 0.001846  loss: 2.4462 (2.4633)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:19  loss: 0.5764 (0.5764)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 3.4063  data: 2.9441  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5878 (0.5996)  acc1: 86.4583 (86.6477)  acc5: 97.9167 (97.8220)  time: 0.6750  data: 0.2700  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6134 (0.7356)  acc1: 85.4167 (80.8036)  acc5: 97.9167 (97.9167)  time: 0.4074  data: 0.0019  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.8320 (0.7765)  acc1: 76.0417 (79.6371)  acc5: 97.9167 (97.7487)  time: 0.4094  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8320 (0.7799)  acc1: 79.1667 (79.7707)  acc5: 97.9167 (97.6051)  time: 0.4046  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4890 s / it)\n",
            "* Acc@1 79.771 Acc@5 97.605 loss 0.780\n",
            "Accuracy of the model on the 3925 test images: 79.8%\n",
            "Max accuracy: 79.77%\n",
            "Test:  [ 0/41]  eta: 0:02:42  loss: 4.1587 (4.1587)  acc1: 16.6667 (16.6667)  acc5: 77.0833 (77.0833)  time: 3.9514  data: 3.4844  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 4.1904 (4.2529)  acc1: 13.5417 (17.8030)  acc5: 80.2083 (81.8182)  time: 0.8705  data: 0.4392  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.8409 (4.8916)  acc1: 8.3333 (12.9960)  acc5: 76.0417 (70.6349)  time: 0.4860  data: 0.0679  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 4.9958 (4.9677)  acc1: 7.2917 (14.9194)  acc5: 62.5000 (66.7339)  time: 0.4088  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2189 (4.5268)  acc1: 31.2500 (23.0318)  acc5: 81.2500 (69.4013)  time: 0.4080  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5471 s / it)\n",
            "* Acc@1 23.032 Acc@5 69.401 loss 4.527\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [62]  [  0/147]  eta: 0:17:26  lr: 0.001844  min_lr: 0.001844  loss: 2.3863 (2.3863)  weight_decay: 0.0500 (0.0500)  time: 7.1221  data: 3.5121  max mem: 7679\n",
            "Epoch: [62]  [ 10/147]  eta: 0:03:16  lr: 0.001839  min_lr: 0.001839  loss: 2.4960 (2.4543)  weight_decay: 0.0500 (0.0500)  time: 1.4310  data: 0.3211  max mem: 7679\n",
            "Epoch: [62]  [ 20/147]  eta: 0:02:29  lr: 0.001833  min_lr: 0.001833  loss: 2.4960 (2.4565)  weight_decay: 0.0500 (0.0500)  time: 0.8770  data: 0.0016  max mem: 7679\n",
            "Epoch: [62]  [ 30/147]  eta: 0:02:05  lr: 0.001828  min_lr: 0.001828  loss: 2.4182 (2.4450)  weight_decay: 0.0500 (0.0500)  time: 0.8789  data: 0.0009  max mem: 7679\n",
            "Epoch: [62]  [ 40/147]  eta: 0:01:49  lr: 0.001822  min_lr: 0.001822  loss: 2.4182 (2.4388)  weight_decay: 0.0500 (0.0500)  time: 0.8591  data: 0.0006  max mem: 7679\n",
            "Epoch: [62]  [ 50/147]  eta: 0:01:35  lr: 0.001818  min_lr: 0.001818  loss: 2.4963 (2.4614)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0006  max mem: 7679\n",
            "Epoch: [62]  [ 60/147]  eta: 0:01:23  lr: 0.001811  min_lr: 0.001811  loss: 2.5667 (2.4534)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0008  max mem: 7679\n",
            "Epoch: [62]  [ 70/147]  eta: 0:01:12  lr: 0.001807  min_lr: 0.001807  loss: 2.5051 (2.4528)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0008  max mem: 7679\n",
            "Epoch: [62]  [ 80/147]  eta: 0:01:02  lr: 0.001800  min_lr: 0.001800  loss: 2.5228 (2.4601)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0005  max mem: 7679\n",
            "Epoch: [62]  [ 90/147]  eta: 0:00:52  lr: 0.001796  min_lr: 0.001796  loss: 2.5392 (2.4605)  weight_decay: 0.0500 (0.0500)  time: 0.8465  data: 0.0013  max mem: 7679\n",
            "Epoch: [62]  [100/147]  eta: 0:00:43  lr: 0.001789  min_lr: 0.001789  loss: 2.5531 (2.4681)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0017  max mem: 7679\n",
            "Epoch: [62]  [110/147]  eta: 0:00:33  lr: 0.001785  min_lr: 0.001785  loss: 2.5540 (2.4729)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0012  max mem: 7679\n",
            "Epoch: [62]  [120/147]  eta: 0:00:24  lr: 0.001778  min_lr: 0.001778  loss: 2.5349 (2.4745)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0021  max mem: 7679\n",
            "Epoch: [62]  [130/147]  eta: 0:00:15  lr: 0.001774  min_lr: 0.001774  loss: 2.5096 (2.4752)  weight_decay: 0.0500 (0.0500)  time: 0.8537  data: 0.0015  max mem: 7679\n",
            "Epoch: [62]  [140/147]  eta: 0:00:06  lr: 0.001768  min_lr: 0.001768  loss: 2.5096 (2.4729)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0002  max mem: 7679\n",
            "Epoch: [62]  [146/147]  eta: 0:00:00  lr: 0.001768  min_lr: 0.001768  loss: 2.5380 (2.4789)  weight_decay: 0.0500 (0.0500)  time: 0.7252  data: 0.0002  max mem: 7679\n",
            "Epoch: [62] Total time: 0:02:09 (0.8837 s / it)\n",
            "Averaged stats: lr: 0.001768  min_lr: 0.001768  loss: 2.5380 (2.4789)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:31  loss: 0.5238 (0.5238)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 3.6846  data: 3.2283  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.6357 (0.6378)  acc1: 87.5000 (86.6477)  acc5: 97.9167 (98.1061)  time: 0.7123  data: 0.2942  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6358 (0.7202)  acc1: 85.4167 (82.7877)  acc5: 98.9583 (98.3135)  time: 0.4171  data: 0.0015  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.8038 (0.7689)  acc1: 79.1667 (81.1828)  acc5: 97.9167 (97.9839)  time: 0.4116  data: 0.0012  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8503 (0.7820)  acc1: 79.1667 (80.5605)  acc5: 96.8750 (97.7580)  time: 0.4030  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4999 s / it)\n",
            "* Acc@1 80.561 Acc@5 97.758 loss 0.782\n",
            "Accuracy of the model on the 3925 test images: 80.6%\n",
            "Max accuracy: 80.56%\n",
            "Test:  [ 0/41]  eta: 0:03:28  loss: 4.1191 (4.1191)  acc1: 14.5833 (14.5833)  acc5: 78.1250 (78.1250)  time: 5.0910  data: 4.6486  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 4.1587 (4.2297)  acc1: 12.5000 (17.7083)  acc5: 80.2083 (82.1023)  time: 0.8361  data: 0.4256  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.8122 (4.8720)  acc1: 8.3333 (12.9960)  acc5: 77.0833 (71.1806)  time: 0.4090  data: 0.0045  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.0212 (4.9601)  acc1: 7.2917 (14.7177)  acc5: 62.5000 (67.0027)  time: 0.4068  data: 0.0029  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2341 (4.5112)  acc1: 32.2917 (22.9554)  acc5: 81.2500 (69.5796)  time: 0.4064  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5317 s / it)\n",
            "* Acc@1 22.955 Acc@5 69.580 loss 4.511\n",
            "Accuracy of the model EMA on 3925 test images: 23.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [63]  [  0/147]  eta: 0:07:36  lr: 0.001765  min_lr: 0.001765  loss: 2.2908 (2.2908)  weight_decay: 0.0500 (0.0500)  time: 3.1047  data: 2.1648  max mem: 7679\n",
            "Epoch: [63]  [ 10/147]  eta: 0:02:26  lr: 0.001761  min_lr: 0.001761  loss: 2.4127 (2.4312)  weight_decay: 0.0500 (0.0500)  time: 1.0680  data: 0.1973  max mem: 7679\n",
            "Epoch: [63]  [ 20/147]  eta: 0:02:03  lr: 0.001755  min_lr: 0.001755  loss: 2.4864 (2.4422)  weight_decay: 0.0500 (0.0500)  time: 0.8628  data: 0.0006  max mem: 7679\n",
            "Epoch: [63]  [ 30/147]  eta: 0:01:49  lr: 0.001750  min_lr: 0.001750  loss: 2.5460 (2.4563)  weight_decay: 0.0500 (0.0500)  time: 0.8570  data: 0.0009  max mem: 7679\n",
            "Epoch: [63]  [ 40/147]  eta: 0:01:37  lr: 0.001744  min_lr: 0.001744  loss: 2.4130 (2.4446)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0008  max mem: 7679\n",
            "Epoch: [63]  [ 50/147]  eta: 0:01:27  lr: 0.001740  min_lr: 0.001740  loss: 2.4087 (2.4378)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0018  max mem: 7679\n",
            "Epoch: [63]  [ 60/147]  eta: 0:01:17  lr: 0.001733  min_lr: 0.001733  loss: 2.4087 (2.4269)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0019  max mem: 7679\n",
            "Epoch: [63]  [ 70/147]  eta: 0:01:08  lr: 0.001729  min_lr: 0.001729  loss: 2.3577 (2.4163)  weight_decay: 0.0500 (0.0500)  time: 0.8443  data: 0.0008  max mem: 7679\n",
            "Epoch: [63]  [ 80/147]  eta: 0:00:58  lr: 0.001722  min_lr: 0.001722  loss: 2.2455 (2.4026)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0012  max mem: 7679\n",
            "Epoch: [63]  [ 90/147]  eta: 0:00:49  lr: 0.001718  min_lr: 0.001718  loss: 2.3534 (2.4081)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0009  max mem: 7679\n",
            "Epoch: [63]  [100/147]  eta: 0:00:41  lr: 0.001711  min_lr: 0.001711  loss: 2.5513 (2.4278)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0011  max mem: 7679\n",
            "Epoch: [63]  [110/147]  eta: 0:00:32  lr: 0.001707  min_lr: 0.001707  loss: 2.5343 (2.4297)  weight_decay: 0.0500 (0.0500)  time: 0.8512  data: 0.0012  max mem: 7679\n",
            "Epoch: [63]  [120/147]  eta: 0:00:23  lr: 0.001701  min_lr: 0.001701  loss: 2.4912 (2.4280)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.0013  max mem: 7679\n",
            "Epoch: [63]  [130/147]  eta: 0:00:14  lr: 0.001696  min_lr: 0.001696  loss: 2.3658 (2.4197)  weight_decay: 0.0500 (0.0500)  time: 0.8524  data: 0.0013  max mem: 7679\n",
            "Epoch: [63]  [140/147]  eta: 0:00:06  lr: 0.001690  min_lr: 0.001690  loss: 2.4181 (2.4243)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0003  max mem: 7679\n",
            "Epoch: [63]  [146/147]  eta: 0:00:00  lr: 0.001690  min_lr: 0.001690  loss: 2.4211 (2.4252)  weight_decay: 0.0500 (0.0500)  time: 0.7232  data: 0.0002  max mem: 7679\n",
            "Epoch: [63] Total time: 0:02:05 (0.8518 s / it)\n",
            "Averaged stats: lr: 0.001690  min_lr: 0.001690  loss: 2.4211 (2.4252)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:42  loss: 0.5391 (0.5391)  acc1: 89.5833 (89.5833)  acc5: 94.7917 (94.7917)  time: 3.9658  data: 3.5105  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.6273 (0.6350)  acc1: 85.4167 (85.2273)  acc5: 97.9167 (97.7273)  time: 0.7307  data: 0.3214  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.7220 (0.7741)  acc1: 83.3333 (79.8611)  acc5: 97.9167 (98.0159)  time: 0.4038  data: 0.0016  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7383 (0.7650)  acc1: 80.2083 (80.1747)  acc5: 97.9167 (97.8159)  time: 0.4021  data: 0.0005  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7282 (0.7525)  acc1: 81.2500 (80.8662)  acc5: 96.8750 (97.6815)  time: 0.4031  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4998 s / it)\n",
            "* Acc@1 80.866 Acc@5 97.682 loss 0.752\n",
            "Accuracy of the model on the 3925 test images: 80.9%\n",
            "Max accuracy: 80.87%\n",
            "Test:  [ 0/41]  eta: 0:02:48  loss: 4.0800 (4.0800)  acc1: 13.5417 (13.5417)  acc5: 78.1250 (78.1250)  time: 4.1037  data: 3.6661  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 4.1252 (4.2068)  acc1: 12.5000 (17.4242)  acc5: 80.2083 (82.0076)  time: 0.7539  data: 0.3348  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 4.7772 (4.8522)  acc1: 8.3333 (12.6984)  acc5: 76.0417 (71.5278)  time: 0.4162  data: 0.0031  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.0429 (4.9519)  acc1: 7.2917 (14.3145)  acc5: 62.5000 (67.1707)  time: 0.4121  data: 0.0023  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2500 (4.4955)  acc1: 34.3750 (22.8025)  acc5: 81.2500 (69.6561)  time: 0.4087  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5115 s / it)\n",
            "* Acc@1 22.803 Acc@5 69.656 loss 4.496\n",
            "Accuracy of the model EMA on 3925 test images: 22.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [64]  [  0/147]  eta: 0:09:02  lr: 0.001688  min_lr: 0.001688  loss: 2.6881 (2.6881)  weight_decay: 0.0500 (0.0500)  time: 3.6929  data: 2.5918  max mem: 7679\n",
            "Epoch: [64]  [ 10/147]  eta: 0:02:34  lr: 0.001683  min_lr: 0.001683  loss: 2.5266 (2.4394)  weight_decay: 0.0500 (0.0500)  time: 1.1296  data: 0.2360  max mem: 7679\n",
            "Epoch: [64]  [ 20/147]  eta: 0:02:07  lr: 0.001677  min_lr: 0.001677  loss: 2.4958 (2.4372)  weight_decay: 0.0500 (0.0500)  time: 0.8663  data: 0.0005  max mem: 7679\n",
            "Epoch: [64]  [ 30/147]  eta: 0:01:51  lr: 0.001673  min_lr: 0.001673  loss: 2.5439 (2.4947)  weight_decay: 0.0500 (0.0500)  time: 0.8552  data: 0.0005  max mem: 7679\n",
            "Epoch: [64]  [ 40/147]  eta: 0:01:39  lr: 0.001666  min_lr: 0.001666  loss: 2.6339 (2.5194)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0007  max mem: 7679\n",
            "Epoch: [64]  [ 50/147]  eta: 0:01:28  lr: 0.001662  min_lr: 0.001662  loss: 2.5085 (2.5058)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0010  max mem: 7679\n",
            "Epoch: [64]  [ 60/147]  eta: 0:01:18  lr: 0.001655  min_lr: 0.001655  loss: 2.3878 (2.4829)  weight_decay: 0.0500 (0.0500)  time: 0.8452  data: 0.0009  max mem: 7679\n",
            "Epoch: [64]  [ 70/147]  eta: 0:01:08  lr: 0.001651  min_lr: 0.001651  loss: 2.4349 (2.4876)  weight_decay: 0.0500 (0.0500)  time: 0.8431  data: 0.0007  max mem: 7679\n",
            "Epoch: [64]  [ 80/147]  eta: 0:00:59  lr: 0.001645  min_lr: 0.001645  loss: 2.4349 (2.4757)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0005  max mem: 7679\n",
            "Epoch: [64]  [ 90/147]  eta: 0:00:50  lr: 0.001640  min_lr: 0.001640  loss: 2.4051 (2.4834)  weight_decay: 0.0500 (0.0500)  time: 0.8541  data: 0.0010  max mem: 7679\n",
            "Epoch: [64]  [100/147]  eta: 0:00:41  lr: 0.001634  min_lr: 0.001634  loss: 2.4532 (2.4843)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0010  max mem: 7679\n",
            "Epoch: [64]  [110/147]  eta: 0:00:32  lr: 0.001630  min_lr: 0.001630  loss: 2.4496 (2.4778)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0012  max mem: 7679\n",
            "Epoch: [64]  [120/147]  eta: 0:00:23  lr: 0.001623  min_lr: 0.001623  loss: 2.3129 (2.4617)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0011  max mem: 7679\n",
            "Epoch: [64]  [130/147]  eta: 0:00:14  lr: 0.001619  min_lr: 0.001619  loss: 2.4514 (2.4684)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0011  max mem: 7679\n",
            "Epoch: [64]  [140/147]  eta: 0:00:06  lr: 0.001613  min_lr: 0.001613  loss: 2.4830 (2.4704)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0010  max mem: 7679\n",
            "Epoch: [64]  [146/147]  eta: 0:00:00  lr: 0.001613  min_lr: 0.001613  loss: 2.4653 (2.4693)  weight_decay: 0.0500 (0.0500)  time: 0.7230  data: 0.0002  max mem: 7679\n",
            "Epoch: [64] Total time: 0:02:06 (0.8583 s / it)\n",
            "Averaged stats: lr: 0.001613  min_lr: 0.001613  loss: 2.4653 (2.4693)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:14  loss: 0.4723 (0.4723)  acc1: 89.5833 (89.5833)  acc5: 96.8750 (96.8750)  time: 3.2819  data: 2.8299  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5795 (0.6200)  acc1: 87.5000 (86.7424)  acc5: 97.9167 (97.9167)  time: 0.7036  data: 0.3002  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.7111 (0.7963)  acc1: 84.3750 (80.2579)  acc5: 97.9167 (97.7679)  time: 0.4261  data: 0.0255  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7756 (0.8074)  acc1: 82.2917 (80.2419)  acc5: 96.8750 (97.4462)  time: 0.4050  data: 0.0019  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.8010 (0.8025)  acc1: 82.2917 (80.5350)  acc5: 96.8750 (97.3503)  time: 0.4028  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4930 s / it)\n",
            "* Acc@1 80.535 Acc@5 97.350 loss 0.803\n",
            "Accuracy of the model on the 3925 test images: 80.5%\n",
            "Max accuracy: 80.87%\n",
            "Test:  [ 0/41]  eta: 0:02:02  loss: 4.0438 (4.0438)  acc1: 13.5417 (13.5417)  acc5: 80.2083 (80.2083)  time: 2.9839  data: 2.5442  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 4.0925 (4.1847)  acc1: 11.4583 (16.8561)  acc5: 81.2500 (82.1970)  time: 0.6888  data: 0.2774  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.7266 (4.8333)  acc1: 7.2917 (12.3512)  acc5: 75.0000 (71.7262)  time: 0.4401  data: 0.0268  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.0606 (4.9433)  acc1: 7.2917 (13.7433)  acc5: 62.5000 (67.2379)  time: 0.4176  data: 0.0015  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2627 (4.4797)  acc1: 31.2500 (22.5987)  acc5: 81.2500 (69.7070)  time: 0.4100  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4965 s / it)\n",
            "* Acc@1 22.599 Acc@5 69.707 loss 4.480\n",
            "Accuracy of the model EMA on 3925 test images: 22.6%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [65]  [  0/147]  eta: 0:10:03  lr: 0.001610  min_lr: 0.001610  loss: 2.1473 (2.1473)  weight_decay: 0.0500 (0.0500)  time: 4.1048  data: 2.9317  max mem: 7679\n",
            "Epoch: [65]  [ 10/147]  eta: 0:02:40  lr: 0.001606  min_lr: 0.001606  loss: 2.3138 (2.3648)  weight_decay: 0.0500 (0.0500)  time: 1.1713  data: 0.2671  max mem: 7679\n",
            "Epoch: [65]  [ 20/147]  eta: 0:02:09  lr: 0.001600  min_lr: 0.001600  loss: 2.3396 (2.3635)  weight_decay: 0.0500 (0.0500)  time: 0.8666  data: 0.0010  max mem: 7679\n",
            "Epoch: [65]  [ 30/147]  eta: 0:01:53  lr: 0.001595  min_lr: 0.001595  loss: 2.4212 (2.3885)  weight_decay: 0.0500 (0.0500)  time: 0.8530  data: 0.0010  max mem: 7679\n",
            "Epoch: [65]  [ 40/147]  eta: 0:01:40  lr: 0.001589  min_lr: 0.001589  loss: 2.5295 (2.4328)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0010  max mem: 7679\n",
            "Epoch: [65]  [ 50/147]  eta: 0:01:29  lr: 0.001585  min_lr: 0.001585  loss: 2.5092 (2.4396)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0011  max mem: 7679\n",
            "Epoch: [65]  [ 60/147]  eta: 0:01:18  lr: 0.001578  min_lr: 0.001578  loss: 2.4345 (2.4260)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0013  max mem: 7679\n",
            "Epoch: [65]  [ 70/147]  eta: 0:01:09  lr: 0.001574  min_lr: 0.001574  loss: 2.4345 (2.4395)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0014  max mem: 7679\n",
            "Epoch: [65]  [ 80/147]  eta: 0:00:59  lr: 0.001568  min_lr: 0.001568  loss: 2.5798 (2.4472)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0019  max mem: 7679\n",
            "Epoch: [65]  [ 90/147]  eta: 0:00:50  lr: 0.001563  min_lr: 0.001563  loss: 2.5323 (2.4474)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0020  max mem: 7679\n",
            "Epoch: [65]  [100/147]  eta: 0:00:41  lr: 0.001557  min_lr: 0.001557  loss: 2.4631 (2.4449)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0014  max mem: 7679\n",
            "Epoch: [65]  [110/147]  eta: 0:00:32  lr: 0.001553  min_lr: 0.001553  loss: 2.4631 (2.4530)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0011  max mem: 7679\n",
            "Epoch: [65]  [120/147]  eta: 0:00:23  lr: 0.001546  min_lr: 0.001546  loss: 2.5820 (2.4578)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0019  max mem: 7679\n",
            "Epoch: [65]  [130/147]  eta: 0:00:14  lr: 0.001542  min_lr: 0.001542  loss: 2.4286 (2.4527)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0020  max mem: 7679\n",
            "Epoch: [65]  [140/147]  eta: 0:00:06  lr: 0.001536  min_lr: 0.001536  loss: 2.4299 (2.4524)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0005  max mem: 7679\n",
            "Epoch: [65]  [146/147]  eta: 0:00:00  lr: 0.001536  min_lr: 0.001536  loss: 2.4299 (2.4533)  weight_decay: 0.0500 (0.0500)  time: 0.7236  data: 0.0002  max mem: 7679\n",
            "Epoch: [65] Total time: 0:02:06 (0.8591 s / it)\n",
            "Averaged stats: lr: 0.001536  min_lr: 0.001536  loss: 2.4299 (2.4533)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:49  loss: 0.5721 (0.5721)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 2.6626  data: 2.1974  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.6320 (0.6502)  acc1: 86.4583 (86.7424)  acc5: 97.9167 (98.2955)  time: 0.6870  data: 0.2664  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6408 (0.7794)  acc1: 85.4167 (81.1508)  acc5: 97.9167 (98.2639)  time: 0.4516  data: 0.0389  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7900 (0.7950)  acc1: 78.1250 (80.3763)  acc5: 96.8750 (97.9167)  time: 0.4093  data: 0.0023  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7239 (0.7737)  acc1: 81.1765 (81.1465)  acc5: 96.8750 (97.8344)  time: 0.4052  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4944 s / it)\n",
            "* Acc@1 81.146 Acc@5 97.834 loss 0.774\n",
            "Accuracy of the model on the 3925 test images: 81.1%\n",
            "Max accuracy: 81.15%\n",
            "Test:  [ 0/41]  eta: 0:03:56  loss: 4.0086 (4.0086)  acc1: 12.5000 (12.5000)  acc5: 80.2083 (80.2083)  time: 5.7595  data: 5.2992  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:28  loss: 4.0601 (4.1644)  acc1: 11.4583 (16.6667)  acc5: 82.2917 (82.6705)  time: 0.9290  data: 0.4845  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:14  loss: 4.6738 (4.8147)  acc1: 7.2917 (12.2024)  acc5: 76.0417 (72.2222)  time: 0.4244  data: 0.0023  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.0789 (4.9359)  acc1: 7.2917 (13.5081)  acc5: 63.5417 (67.5739)  time: 0.4039  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2808 (4.4650)  acc1: 30.2083 (22.4968)  acc5: 81.2500 (70.0892)  time: 0.4046  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5601 s / it)\n",
            "* Acc@1 22.497 Acc@5 70.089 loss 4.465\n",
            "Accuracy of the model EMA on 3925 test images: 22.5%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [66]  [  0/147]  eta: 0:11:47  lr: 0.001534  min_lr: 0.001534  loss: 2.2722 (2.2722)  weight_decay: 0.0500 (0.0500)  time: 4.8134  data: 3.1667  max mem: 7679\n",
            "Epoch: [66]  [ 10/147]  eta: 0:02:47  lr: 0.001529  min_lr: 0.001529  loss: 2.2758 (2.3169)  weight_decay: 0.0500 (0.0500)  time: 1.2198  data: 0.2882  max mem: 7679\n",
            "Epoch: [66]  [ 20/147]  eta: 0:02:13  lr: 0.001523  min_lr: 0.001523  loss: 2.2831 (2.3343)  weight_decay: 0.0500 (0.0500)  time: 0.8608  data: 0.0005  max mem: 7679\n",
            "Epoch: [66]  [ 30/147]  eta: 0:01:55  lr: 0.001519  min_lr: 0.001519  loss: 2.4024 (2.3525)  weight_decay: 0.0500 (0.0500)  time: 0.8553  data: 0.0005  max mem: 7679\n",
            "Epoch: [66]  [ 40/147]  eta: 0:01:42  lr: 0.001513  min_lr: 0.001513  loss: 2.4729 (2.3985)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.0012  max mem: 7679\n",
            "Epoch: [66]  [ 50/147]  eta: 0:01:30  lr: 0.001508  min_lr: 0.001508  loss: 2.5896 (2.4300)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0013  max mem: 7679\n",
            "Epoch: [66]  [ 60/147]  eta: 0:01:19  lr: 0.001502  min_lr: 0.001502  loss: 2.5577 (2.4221)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.0006  max mem: 7679\n",
            "Epoch: [66]  [ 70/147]  eta: 0:01:09  lr: 0.001498  min_lr: 0.001498  loss: 2.3671 (2.4015)  weight_decay: 0.0500 (0.0500)  time: 0.8450  data: 0.0010  max mem: 7679\n",
            "Epoch: [66]  [ 80/147]  eta: 0:01:00  lr: 0.001491  min_lr: 0.001491  loss: 2.3923 (2.4070)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0020  max mem: 7679\n",
            "Epoch: [66]  [ 90/147]  eta: 0:00:50  lr: 0.001487  min_lr: 0.001487  loss: 2.4437 (2.4081)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0025  max mem: 7679\n",
            "Epoch: [66]  [100/147]  eta: 0:00:41  lr: 0.001481  min_lr: 0.001481  loss: 2.4795 (2.4195)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0024  max mem: 7679\n",
            "Epoch: [66]  [110/147]  eta: 0:00:32  lr: 0.001477  min_lr: 0.001477  loss: 2.4879 (2.4126)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0015  max mem: 7679\n",
            "Epoch: [66]  [120/147]  eta: 0:00:23  lr: 0.001470  min_lr: 0.001470  loss: 2.3585 (2.4067)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0014  max mem: 7679\n",
            "Epoch: [66]  [130/147]  eta: 0:00:14  lr: 0.001466  min_lr: 0.001466  loss: 2.3585 (2.4009)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0017  max mem: 7679\n",
            "Epoch: [66]  [140/147]  eta: 0:00:06  lr: 0.001460  min_lr: 0.001460  loss: 2.4990 (2.4137)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0009  max mem: 7679\n",
            "Epoch: [66]  [146/147]  eta: 0:00:00  lr: 0.001460  min_lr: 0.001460  loss: 2.4536 (2.4117)  weight_decay: 0.0500 (0.0500)  time: 0.7266  data: 0.0004  max mem: 7679\n",
            "Epoch: [66] Total time: 0:02:07 (0.8651 s / it)\n",
            "Averaged stats: lr: 0.001460  min_lr: 0.001460  loss: 2.4536 (2.4117)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:25  loss: 0.5782 (0.5782)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 3.5513  data: 3.0691  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.6315 (0.6682)  acc1: 86.4583 (84.9432)  acc5: 97.9167 (97.9167)  time: 0.6911  data: 0.2813  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.7184 (0.8024)  acc1: 82.2917 (79.3155)  acc5: 97.9167 (97.8671)  time: 0.4032  data: 0.0021  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7838 (0.7962)  acc1: 80.2083 (79.8051)  acc5: 97.9167 (97.8831)  time: 0.4021  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6760 (0.7595)  acc1: 83.3333 (81.1975)  acc5: 97.9167 (97.9108)  time: 0.4022  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4880 s / it)\n",
            "* Acc@1 81.197 Acc@5 97.911 loss 0.760\n",
            "Accuracy of the model on the 3925 test images: 81.2%\n",
            "Max accuracy: 81.20%\n",
            "Test:  [ 0/41]  eta: 0:03:01  loss: 3.9783 (3.9783)  acc1: 11.4583 (11.4583)  acc5: 80.2083 (80.2083)  time: 4.4360  data: 3.9756  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 4.0279 (4.1448)  acc1: 9.3750 (16.0038)  acc5: 84.3750 (83.0492)  time: 0.7815  data: 0.3644  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 4.6248 (4.7974)  acc1: 7.2917 (11.8552)  acc5: 78.1250 (72.6687)  time: 0.4154  data: 0.0043  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.0997 (4.9296)  acc1: 7.2917 (13.1720)  acc5: 63.5417 (67.7083)  time: 0.4107  data: 0.0028  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.2995 (4.4517)  acc1: 29.1667 (22.3185)  acc5: 80.2083 (70.3185)  time: 0.4060  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5184 s / it)\n",
            "* Acc@1 22.318 Acc@5 70.318 loss 4.452\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [67]  [  0/147]  eta: 0:12:01  lr: 0.001458  min_lr: 0.001458  loss: 2.5666 (2.5666)  weight_decay: 0.0500 (0.0500)  time: 4.9112  data: 3.8313  max mem: 7679\n",
            "Epoch: [67]  [ 10/147]  eta: 0:02:51  lr: 0.001454  min_lr: 0.001454  loss: 2.5356 (2.4504)  weight_decay: 0.0500 (0.0500)  time: 1.2502  data: 0.3492  max mem: 7679\n",
            "Epoch: [67]  [ 20/147]  eta: 0:02:15  lr: 0.001447  min_lr: 0.001447  loss: 2.5297 (2.4783)  weight_decay: 0.0500 (0.0500)  time: 0.8723  data: 0.0011  max mem: 7679\n",
            "Epoch: [67]  [ 30/147]  eta: 0:01:56  lr: 0.001443  min_lr: 0.001443  loss: 2.5452 (2.4845)  weight_decay: 0.0500 (0.0500)  time: 0.8548  data: 0.0007  max mem: 7679\n",
            "Epoch: [67]  [ 40/147]  eta: 0:01:42  lr: 0.001437  min_lr: 0.001437  loss: 2.5747 (2.4762)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0005  max mem: 7679\n",
            "Epoch: [67]  [ 50/147]  eta: 0:01:31  lr: 0.001433  min_lr: 0.001433  loss: 2.3934 (2.4560)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0007  max mem: 7679\n",
            "Epoch: [67]  [ 60/147]  eta: 0:01:20  lr: 0.001426  min_lr: 0.001426  loss: 2.4257 (2.4499)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0013  max mem: 7679\n",
            "Epoch: [67]  [ 70/147]  eta: 0:01:10  lr: 0.001422  min_lr: 0.001422  loss: 2.5250 (2.4454)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0016  max mem: 7679\n",
            "Epoch: [67]  [ 80/147]  eta: 0:01:00  lr: 0.001416  min_lr: 0.001416  loss: 2.4512 (2.4319)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0015  max mem: 7679\n",
            "Epoch: [67]  [ 90/147]  eta: 0:00:51  lr: 0.001412  min_lr: 0.001412  loss: 2.4923 (2.4435)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.0014  max mem: 7679\n",
            "Epoch: [67]  [100/147]  eta: 0:00:42  lr: 0.001405  min_lr: 0.001405  loss: 2.5433 (2.4382)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0019  max mem: 7679\n",
            "Epoch: [67]  [110/147]  eta: 0:00:32  lr: 0.001401  min_lr: 0.001401  loss: 2.4643 (2.4361)  weight_decay: 0.0500 (0.0500)  time: 0.8521  data: 0.0018  max mem: 7679\n",
            "Epoch: [67]  [120/147]  eta: 0:00:23  lr: 0.001395  min_lr: 0.001395  loss: 2.4517 (2.4323)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0016  max mem: 7679\n",
            "Epoch: [67]  [130/147]  eta: 0:00:15  lr: 0.001391  min_lr: 0.001391  loss: 2.4247 (2.4323)  weight_decay: 0.0500 (0.0500)  time: 0.8518  data: 0.0016  max mem: 7679\n",
            "Epoch: [67]  [140/147]  eta: 0:00:06  lr: 0.001385  min_lr: 0.001385  loss: 2.4354 (2.4282)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0005  max mem: 7679\n",
            "Epoch: [67]  [146/147]  eta: 0:00:00  lr: 0.001385  min_lr: 0.001385  loss: 2.4719 (2.4312)  weight_decay: 0.0500 (0.0500)  time: 0.7227  data: 0.0002  max mem: 7679\n",
            "Epoch: [67] Total time: 0:02:07 (0.8656 s / it)\n",
            "Averaged stats: lr: 0.001385  min_lr: 0.001385  loss: 2.4719 (2.4312)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:14  loss: 0.4618 (0.4618)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 4.7499  data: 4.2790  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5987 (0.6086)  acc1: 87.5000 (86.5530)  acc5: 97.9167 (98.1061)  time: 0.7968  data: 0.3911  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6155 (0.7513)  acc1: 86.4583 (80.5556)  acc5: 97.9167 (97.7183)  time: 0.4013  data: 0.0018  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7587 (0.7763)  acc1: 77.0833 (79.6035)  acc5: 97.9167 (97.6479)  time: 0.4018  data: 0.0007  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6747 (0.7496)  acc1: 84.3750 (80.6115)  acc5: 97.9167 (97.7070)  time: 0.4020  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5238 s / it)\n",
            "* Acc@1 80.611 Acc@5 97.707 loss 0.750\n",
            "Accuracy of the model on the 3925 test images: 80.6%\n",
            "Max accuracy: 81.20%\n",
            "Test:  [ 0/41]  eta: 0:03:52  loss: 3.9463 (3.9463)  acc1: 11.4583 (11.4583)  acc5: 80.2083 (80.2083)  time: 5.6753  data: 5.1826  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 3.9976 (4.1269)  acc1: 9.3750 (15.7197)  acc5: 85.4167 (83.2386)  time: 0.8891  data: 0.4725  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.5729 (4.7804)  acc1: 7.2917 (11.7560)  acc5: 78.1250 (72.7183)  time: 0.4091  data: 0.0009  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.1220 (4.9234)  acc1: 7.2917 (12.9704)  acc5: 62.5000 (67.7419)  time: 0.4075  data: 0.0002  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3193 (4.4385)  acc1: 28.1250 (22.2166)  acc5: 81.2500 (70.3949)  time: 0.4066  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5450 s / it)\n",
            "* Acc@1 22.217 Acc@5 70.395 loss 4.438\n",
            "Accuracy of the model EMA on 3925 test images: 22.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [68]  [  0/147]  eta: 0:08:34  lr: 0.001383  min_lr: 0.001383  loss: 1.8697 (1.8697)  weight_decay: 0.0500 (0.0500)  time: 3.5008  data: 2.5740  max mem: 7679\n",
            "Epoch: [68]  [ 10/147]  eta: 0:02:30  lr: 0.001378  min_lr: 0.001378  loss: 2.4730 (2.3686)  weight_decay: 0.0500 (0.0500)  time: 1.0966  data: 0.2345  max mem: 7679\n",
            "Epoch: [68]  [ 20/147]  eta: 0:02:04  lr: 0.001372  min_lr: 0.001372  loss: 2.5206 (2.4280)  weight_decay: 0.0500 (0.0500)  time: 0.8571  data: 0.0009  max mem: 7679\n",
            "Epoch: [68]  [ 30/147]  eta: 0:01:50  lr: 0.001368  min_lr: 0.001368  loss: 2.4505 (2.4127)  weight_decay: 0.0500 (0.0500)  time: 0.8549  data: 0.0012  max mem: 7679\n",
            "Epoch: [68]  [ 40/147]  eta: 0:01:38  lr: 0.001362  min_lr: 0.001362  loss: 2.4275 (2.4428)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0009  max mem: 7679\n",
            "Epoch: [68]  [ 50/147]  eta: 0:01:27  lr: 0.001358  min_lr: 0.001358  loss: 2.4653 (2.4244)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0006  max mem: 7679\n",
            "Epoch: [68]  [ 60/147]  eta: 0:01:17  lr: 0.001352  min_lr: 0.001352  loss: 2.4646 (2.4330)  weight_decay: 0.0500 (0.0500)  time: 0.8450  data: 0.0004  max mem: 7679\n",
            "Epoch: [68]  [ 70/147]  eta: 0:01:08  lr: 0.001347  min_lr: 0.001347  loss: 2.4933 (2.4299)  weight_decay: 0.0500 (0.0500)  time: 0.8451  data: 0.0022  max mem: 7679\n",
            "Epoch: [68]  [ 80/147]  eta: 0:00:59  lr: 0.001341  min_lr: 0.001341  loss: 2.4190 (2.4270)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0022  max mem: 7679\n",
            "Epoch: [68]  [ 90/147]  eta: 0:00:50  lr: 0.001337  min_lr: 0.001337  loss: 2.3443 (2.4311)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0010  max mem: 7679\n",
            "Epoch: [68]  [100/147]  eta: 0:00:41  lr: 0.001331  min_lr: 0.001331  loss: 2.4706 (2.4280)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0011  max mem: 7679\n",
            "Epoch: [68]  [110/147]  eta: 0:00:32  lr: 0.001327  min_lr: 0.001327  loss: 2.5942 (2.4380)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0017  max mem: 7679\n",
            "Epoch: [68]  [120/147]  eta: 0:00:23  lr: 0.001321  min_lr: 0.001321  loss: 2.5317 (2.4367)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0016  max mem: 7679\n",
            "Epoch: [68]  [130/147]  eta: 0:00:14  lr: 0.001317  min_lr: 0.001317  loss: 2.4725 (2.4421)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0015  max mem: 7679\n",
            "Epoch: [68]  [140/147]  eta: 0:00:06  lr: 0.001310  min_lr: 0.001310  loss: 2.4706 (2.4431)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0014  max mem: 7679\n",
            "Epoch: [68]  [146/147]  eta: 0:00:00  lr: 0.001310  min_lr: 0.001310  loss: 2.4428 (2.4378)  weight_decay: 0.0500 (0.0500)  time: 0.7236  data: 0.0002  max mem: 7679\n",
            "Epoch: [68] Total time: 0:02:05 (0.8548 s / it)\n",
            "Averaged stats: lr: 0.001310  min_lr: 0.001310  loss: 2.4428 (2.4378)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:36  loss: 0.6721 (0.6721)  acc1: 86.4583 (86.4583)  acc5: 96.8750 (96.8750)  time: 3.8052  data: 3.3601  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.6571 (0.6633)  acc1: 86.4583 (86.3636)  acc5: 97.9167 (97.5379)  time: 0.7117  data: 0.3087  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6456 (0.8187)  acc1: 86.4583 (79.8611)  acc5: 97.9167 (97.2222)  time: 0.4038  data: 0.0044  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6729 (0.7999)  acc1: 85.4167 (80.6116)  acc5: 97.9167 (97.3790)  time: 0.4041  data: 0.0027  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6668 (0.7793)  acc1: 84.7059 (81.0446)  acc5: 97.9167 (97.5541)  time: 0.4029  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4968 s / it)\n",
            "* Acc@1 81.045 Acc@5 97.554 loss 0.779\n",
            "Accuracy of the model on the 3925 test images: 81.0%\n",
            "Max accuracy: 81.20%\n",
            "Test:  [ 0/41]  eta: 0:02:22  loss: 3.9155 (3.9155)  acc1: 11.4583 (11.4583)  acc5: 80.2083 (80.2083)  time: 3.4757  data: 3.0340  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.9675 (4.1079)  acc1: 9.3750 (15.7197)  acc5: 86.4583 (83.9015)  time: 0.6982  data: 0.2877  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.5239 (4.7629)  acc1: 7.2917 (11.7063)  acc5: 79.1667 (73.0655)  time: 0.4188  data: 0.0090  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.1441 (4.9164)  acc1: 7.2917 (12.7352)  acc5: 62.5000 (67.8763)  time: 0.4132  data: 0.0026  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3368 (4.4249)  acc1: 28.1250 (22.0637)  acc5: 81.2500 (70.5987)  time: 0.4073  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4975 s / it)\n",
            "* Acc@1 22.064 Acc@5 70.599 loss 4.425\n",
            "Accuracy of the model EMA on 3925 test images: 22.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [69]  [  0/147]  eta: 0:08:44  lr: 0.001308  min_lr: 0.001308  loss: 2.3079 (2.3079)  weight_decay: 0.0500 (0.0500)  time: 3.5684  data: 2.1511  max mem: 7679\n",
            "Epoch: [69]  [ 10/147]  eta: 0:02:36  lr: 0.001304  min_lr: 0.001304  loss: 2.3118 (2.3856)  weight_decay: 0.0500 (0.0500)  time: 1.1415  data: 0.1962  max mem: 7679\n",
            "Epoch: [69]  [ 20/147]  eta: 0:02:07  lr: 0.001298  min_lr: 0.001298  loss: 2.4713 (2.3804)  weight_decay: 0.0500 (0.0500)  time: 0.8782  data: 0.0006  max mem: 7679\n",
            "Epoch: [69]  [ 30/147]  eta: 0:01:51  lr: 0.001294  min_lr: 0.001294  loss: 2.4426 (2.3843)  weight_decay: 0.0500 (0.0500)  time: 0.8530  data: 0.0005  max mem: 7679\n",
            "Epoch: [69]  [ 40/147]  eta: 0:01:39  lr: 0.001288  min_lr: 0.001288  loss: 2.5092 (2.4207)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0004  max mem: 7679\n",
            "Epoch: [69]  [ 50/147]  eta: 0:01:28  lr: 0.001284  min_lr: 0.001284  loss: 2.5348 (2.4265)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0013  max mem: 7679\n",
            "Epoch: [69]  [ 60/147]  eta: 0:01:18  lr: 0.001278  min_lr: 0.001278  loss: 2.4463 (2.4214)  weight_decay: 0.0500 (0.0500)  time: 0.8472  data: 0.0014  max mem: 7679\n",
            "Epoch: [69]  [ 70/147]  eta: 0:01:08  lr: 0.001274  min_lr: 0.001274  loss: 2.4463 (2.4184)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0012  max mem: 7679\n",
            "Epoch: [69]  [ 80/147]  eta: 0:00:59  lr: 0.001268  min_lr: 0.001268  loss: 2.3955 (2.3990)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0014  max mem: 7679\n",
            "Epoch: [69]  [ 90/147]  eta: 0:00:50  lr: 0.001264  min_lr: 0.001264  loss: 2.4342 (2.4122)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0016  max mem: 7679\n",
            "Epoch: [69]  [100/147]  eta: 0:00:41  lr: 0.001258  min_lr: 0.001258  loss: 2.5524 (2.4191)  weight_decay: 0.0500 (0.0500)  time: 0.8497  data: 0.0013  max mem: 7679\n",
            "Epoch: [69]  [110/147]  eta: 0:00:32  lr: 0.001253  min_lr: 0.001253  loss: 2.5173 (2.4195)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0010  max mem: 7679\n",
            "Epoch: [69]  [120/147]  eta: 0:00:23  lr: 0.001247  min_lr: 0.001247  loss: 2.4829 (2.4259)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0008  max mem: 7679\n",
            "Epoch: [69]  [130/147]  eta: 0:00:14  lr: 0.001243  min_lr: 0.001243  loss: 2.4829 (2.4235)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0015  max mem: 7679\n",
            "Epoch: [69]  [140/147]  eta: 0:00:06  lr: 0.001237  min_lr: 0.001237  loss: 2.3991 (2.4239)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0015  max mem: 7679\n",
            "Epoch: [69]  [146/147]  eta: 0:00:00  lr: 0.001237  min_lr: 0.001237  loss: 2.4885 (2.4231)  weight_decay: 0.0500 (0.0500)  time: 0.7249  data: 0.0002  max mem: 7679\n",
            "Epoch: [69] Total time: 0:02:06 (0.8594 s / it)\n",
            "Averaged stats: lr: 0.001237  min_lr: 0.001237  loss: 2.4885 (2.4231)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:35  loss: 0.5538 (0.5538)  acc1: 88.5417 (88.5417)  acc5: 96.8750 (96.8750)  time: 3.7827  data: 3.3301  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5538 (0.5640)  acc1: 88.5417 (89.6780)  acc5: 97.9167 (98.2008)  time: 0.7119  data: 0.3058  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6149 (0.7363)  acc1: 87.5000 (82.1925)  acc5: 97.9167 (98.0159)  time: 0.4058  data: 0.0029  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7725 (0.7775)  acc1: 81.2500 (80.5780)  acc5: 97.9167 (97.4462)  time: 0.4056  data: 0.0014  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6609 (0.7634)  acc1: 84.3750 (81.2739)  acc5: 97.9167 (97.4268)  time: 0.4047  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4962 s / it)\n",
            "* Acc@1 81.274 Acc@5 97.427 loss 0.763\n",
            "Accuracy of the model on the 3925 test images: 81.3%\n",
            "Max accuracy: 81.27%\n",
            "Test:  [ 0/41]  eta: 0:03:10  loss: 3.8817 (3.8817)  acc1: 11.4583 (11.4583)  acc5: 81.2500 (81.2500)  time: 4.6404  data: 4.1954  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 3.9402 (4.0901)  acc1: 8.3333 (15.6250)  acc5: 86.4583 (84.0909)  time: 0.7992  data: 0.3881  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 4.4745 (4.7464)  acc1: 7.2917 (11.7560)  acc5: 80.2083 (73.2143)  time: 0.4150  data: 0.0041  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.1686 (4.9105)  acc1: 8.3333 (12.6008)  acc5: 61.4583 (67.8763)  time: 0.4112  data: 0.0004  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3561 (4.4123)  acc1: 27.0833 (22.0637)  acc5: 81.2500 (70.7261)  time: 0.4077  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5281 s / it)\n",
            "* Acc@1 22.064 Acc@5 70.726 loss 4.412\n",
            "Accuracy of the model EMA on 3925 test images: 22.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [70]  [  0/147]  eta: 0:11:55  lr: 0.001235  min_lr: 0.001235  loss: 2.7077 (2.7077)  weight_decay: 0.0500 (0.0500)  time: 4.8652  data: 3.9338  max mem: 7679\n",
            "Epoch: [70]  [ 10/147]  eta: 0:02:47  lr: 0.001231  min_lr: 0.001231  loss: 2.3250 (2.4070)  weight_decay: 0.0500 (0.0500)  time: 1.2203  data: 0.3583  max mem: 7679\n",
            "Epoch: [70]  [ 20/147]  eta: 0:02:13  lr: 0.001225  min_lr: 0.001225  loss: 2.3514 (2.4107)  weight_decay: 0.0500 (0.0500)  time: 0.8575  data: 0.0008  max mem: 7679\n",
            "Epoch: [70]  [ 30/147]  eta: 0:01:55  lr: 0.001221  min_lr: 0.001221  loss: 2.2893 (2.3480)  weight_decay: 0.0500 (0.0500)  time: 0.8546  data: 0.0007  max mem: 7679\n",
            "Epoch: [70]  [ 40/147]  eta: 0:01:42  lr: 0.001215  min_lr: 0.001215  loss: 2.2872 (2.3470)  weight_decay: 0.0500 (0.0500)  time: 0.8536  data: 0.0018  max mem: 7679\n",
            "Epoch: [70]  [ 50/147]  eta: 0:01:30  lr: 0.001211  min_lr: 0.001211  loss: 2.3396 (2.3437)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0020  max mem: 7679\n",
            "Epoch: [70]  [ 60/147]  eta: 0:01:19  lr: 0.001205  min_lr: 0.001205  loss: 2.3170 (2.3451)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0013  max mem: 7679\n",
            "Epoch: [70]  [ 70/147]  eta: 0:01:09  lr: 0.001201  min_lr: 0.001201  loss: 2.5230 (2.3651)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0011  max mem: 7679\n",
            "Epoch: [70]  [ 80/147]  eta: 0:01:00  lr: 0.001195  min_lr: 0.001195  loss: 2.4977 (2.3756)  weight_decay: 0.0500 (0.0500)  time: 0.8469  data: 0.0010  max mem: 7679\n",
            "Epoch: [70]  [ 90/147]  eta: 0:00:51  lr: 0.001191  min_lr: 0.001191  loss: 2.4746 (2.3788)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0017  max mem: 7679\n",
            "Epoch: [70]  [100/147]  eta: 0:00:41  lr: 0.001185  min_lr: 0.001185  loss: 2.3756 (2.3803)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0016  max mem: 7679\n",
            "Epoch: [70]  [110/147]  eta: 0:00:32  lr: 0.001181  min_lr: 0.001181  loss: 2.4128 (2.3887)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0020  max mem: 7679\n",
            "Epoch: [70]  [120/147]  eta: 0:00:23  lr: 0.001175  min_lr: 0.001175  loss: 2.5679 (2.3971)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0019  max mem: 7679\n",
            "Epoch: [70]  [130/147]  eta: 0:00:14  lr: 0.001171  min_lr: 0.001171  loss: 2.4801 (2.3938)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0006  max mem: 7679\n",
            "Epoch: [70]  [140/147]  eta: 0:00:06  lr: 0.001165  min_lr: 0.001165  loss: 2.4466 (2.3933)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0004  max mem: 7679\n",
            "Epoch: [70]  [146/147]  eta: 0:00:00  lr: 0.001165  min_lr: 0.001165  loss: 2.5010 (2.3981)  weight_decay: 0.0500 (0.0500)  time: 0.7229  data: 0.0003  max mem: 7679\n",
            "Epoch: [70] Total time: 0:02:07 (0.8656 s / it)\n",
            "Averaged stats: lr: 0.001165  min_lr: 0.001165  loss: 2.5010 (2.3981)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:57  loss: 0.5225 (0.5225)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 4.3406  data: 3.9075  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.5225 (0.5126)  acc1: 89.5833 (90.7197)  acc5: 97.9167 (98.2008)  time: 0.7597  data: 0.3564  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5747 (0.7169)  acc1: 87.5000 (81.9444)  acc5: 97.9167 (97.6190)  time: 0.4017  data: 0.0013  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7140 (0.7475)  acc1: 77.0833 (80.8804)  acc5: 96.8750 (97.5134)  time: 0.4023  data: 0.0008  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6820 (0.7425)  acc1: 82.2917 (81.3248)  acc5: 96.8750 (97.5541)  time: 0.4023  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5073 s / it)\n",
            "* Acc@1 81.325 Acc@5 97.554 loss 0.743\n",
            "Accuracy of the model on the 3925 test images: 81.3%\n",
            "Max accuracy: 81.32%\n",
            "Test:  [ 0/41]  eta: 0:01:29  loss: 3.8482 (3.8482)  acc1: 10.4167 (10.4167)  acc5: 82.2917 (82.2917)  time: 2.1757  data: 1.7477  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 3.9130 (4.0732)  acc1: 8.3333 (15.4356)  acc5: 87.5000 (84.3750)  time: 0.7343  data: 0.3115  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 4.4297 (4.7308)  acc1: 8.3333 (11.5079)  acc5: 81.2500 (73.4623)  time: 0.5022  data: 0.0856  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.1927 (4.9052)  acc1: 7.2917 (12.2984)  acc5: 60.4167 (67.9772)  time: 0.4137  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3749 (4.4008)  acc1: 27.0833 (21.9108)  acc5: 80.2083 (70.8535)  time: 0.4104  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5071 s / it)\n",
            "* Acc@1 21.911 Acc@5 70.854 loss 4.401\n",
            "Accuracy of the model EMA on 3925 test images: 21.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [71]  [  0/147]  eta: 0:09:53  lr: 0.001163  min_lr: 0.001163  loss: 1.9803 (1.9803)  weight_decay: 0.0500 (0.0500)  time: 4.0355  data: 2.9311  max mem: 7679\n",
            "Epoch: [71]  [ 10/147]  eta: 0:02:42  lr: 0.001159  min_lr: 0.001159  loss: 2.2596 (2.3277)  weight_decay: 0.0500 (0.0500)  time: 1.1885  data: 0.2694  max mem: 7679\n",
            "Epoch: [71]  [ 20/147]  eta: 0:02:11  lr: 0.001153  min_lr: 0.001153  loss: 2.3046 (2.3299)  weight_decay: 0.0500 (0.0500)  time: 0.8825  data: 0.0021  max mem: 7679\n",
            "Epoch: [71]  [ 30/147]  eta: 0:01:53  lr: 0.001150  min_lr: 0.001150  loss: 2.4488 (2.3646)  weight_decay: 0.0500 (0.0500)  time: 0.8558  data: 0.0008  max mem: 7679\n",
            "Epoch: [71]  [ 40/147]  eta: 0:01:41  lr: 0.001144  min_lr: 0.001144  loss: 2.4937 (2.3977)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0006  max mem: 7679\n",
            "Epoch: [71]  [ 50/147]  eta: 0:01:29  lr: 0.001140  min_lr: 0.001140  loss: 2.5806 (2.4210)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0013  max mem: 7679\n",
            "Epoch: [71]  [ 60/147]  eta: 0:01:19  lr: 0.001134  min_lr: 0.001134  loss: 2.5137 (2.4287)  weight_decay: 0.0500 (0.0500)  time: 0.8462  data: 0.0017  max mem: 7679\n",
            "Epoch: [71]  [ 70/147]  eta: 0:01:09  lr: 0.001130  min_lr: 0.001130  loss: 2.4762 (2.4166)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0011  max mem: 7679\n",
            "Epoch: [71]  [ 80/147]  eta: 0:01:00  lr: 0.001124  min_lr: 0.001124  loss: 2.4191 (2.4172)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0018  max mem: 7679\n",
            "Epoch: [71]  [ 90/147]  eta: 0:00:50  lr: 0.001120  min_lr: 0.001120  loss: 2.3534 (2.4153)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0016  max mem: 7679\n",
            "Epoch: [71]  [100/147]  eta: 0:00:41  lr: 0.001114  min_lr: 0.001114  loss: 2.4377 (2.4113)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0010  max mem: 7679\n",
            "Epoch: [71]  [110/147]  eta: 0:00:32  lr: 0.001110  min_lr: 0.001110  loss: 2.4758 (2.4112)  weight_decay: 0.0500 (0.0500)  time: 0.8584  data: 0.0019  max mem: 7679\n",
            "Epoch: [71]  [120/147]  eta: 0:00:23  lr: 0.001104  min_lr: 0.001104  loss: 2.4700 (2.4141)  weight_decay: 0.0500 (0.0500)  time: 0.8544  data: 0.0017  max mem: 7679\n",
            "Epoch: [71]  [130/147]  eta: 0:00:14  lr: 0.001101  min_lr: 0.001101  loss: 2.4782 (2.4144)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0010  max mem: 7679\n",
            "Epoch: [71]  [140/147]  eta: 0:00:06  lr: 0.001095  min_lr: 0.001095  loss: 2.3889 (2.4138)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0005  max mem: 7679\n",
            "Epoch: [71]  [146/147]  eta: 0:00:00  lr: 0.001095  min_lr: 0.001095  loss: 2.4782 (2.4171)  weight_decay: 0.0500 (0.0500)  time: 0.7224  data: 0.0002  max mem: 7679\n",
            "Epoch: [71] Total time: 0:02:06 (0.8623 s / it)\n",
            "Averaged stats: lr: 0.001095  min_lr: 0.001095  loss: 2.4782 (2.4171)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:14  loss: 0.6097 (0.6097)  acc1: 89.5833 (89.5833)  acc5: 95.8333 (95.8333)  time: 1.8105  data: 1.3729  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.5830 (0.5842)  acc1: 89.5833 (88.6364)  acc5: 97.9167 (97.8220)  time: 0.7684  data: 0.3512  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5830 (0.7074)  acc1: 86.4583 (82.8373)  acc5: 97.9167 (97.9167)  time: 0.5344  data: 0.1260  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6283 (0.7318)  acc1: 82.2917 (81.4852)  acc5: 97.9167 (98.0847)  time: 0.4039  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7305 (0.7388)  acc1: 81.2500 (81.5287)  acc5: 97.9167 (97.8599)  time: 0.4026  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5103 s / it)\n",
            "* Acc@1 81.529 Acc@5 97.860 loss 0.739\n",
            "Accuracy of the model on the 3925 test images: 81.5%\n",
            "Max accuracy: 81.53%\n",
            "Test:  [ 0/41]  eta: 0:03:02  loss: 3.8121 (3.8121)  acc1: 11.4583 (11.4583)  acc5: 82.2917 (82.2917)  time: 4.4421  data: 3.9830  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 3.8855 (4.0556)  acc1: 9.3750 (15.9091)  acc5: 87.5000 (84.1856)  time: 0.8158  data: 0.4030  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.3847 (4.7150)  acc1: 8.3333 (11.7063)  acc5: 81.2500 (73.1647)  time: 0.4317  data: 0.0246  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2194 (4.8995)  acc1: 7.2917 (12.2984)  acc5: 60.4167 (67.6411)  time: 0.4104  data: 0.0022  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.3926 (4.3892)  acc1: 25.0000 (21.9618)  acc5: 81.2500 (70.6752)  time: 0.4093  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5282 s / it)\n",
            "* Acc@1 21.962 Acc@5 70.675 loss 4.389\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [72]  [  0/147]  eta: 0:08:36  lr: 0.001093  min_lr: 0.001093  loss: 2.6367 (2.6367)  weight_decay: 0.0500 (0.0500)  time: 3.5117  data: 2.5824  max mem: 7679\n",
            "Epoch: [72]  [ 10/147]  eta: 0:02:31  lr: 0.001089  min_lr: 0.001089  loss: 2.6152 (2.4644)  weight_decay: 0.0500 (0.0500)  time: 1.1032  data: 0.2358  max mem: 7679\n",
            "Epoch: [72]  [ 20/147]  eta: 0:02:05  lr: 0.001083  min_lr: 0.001083  loss: 2.5518 (2.4658)  weight_decay: 0.0500 (0.0500)  time: 0.8628  data: 0.0019  max mem: 7679\n",
            "Epoch: [72]  [ 30/147]  eta: 0:01:50  lr: 0.001079  min_lr: 0.001079  loss: 2.4272 (2.4194)  weight_decay: 0.0500 (0.0500)  time: 0.8586  data: 0.0019  max mem: 7679\n",
            "Epoch: [72]  [ 40/147]  eta: 0:01:38  lr: 0.001073  min_lr: 0.001073  loss: 2.2805 (2.3848)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0009  max mem: 7679\n",
            "Epoch: [72]  [ 50/147]  eta: 0:01:27  lr: 0.001070  min_lr: 0.001070  loss: 2.3131 (2.3891)  weight_decay: 0.0500 (0.0500)  time: 0.8465  data: 0.0013  max mem: 7679\n",
            "Epoch: [72]  [ 60/147]  eta: 0:01:18  lr: 0.001064  min_lr: 0.001064  loss: 2.4530 (2.4060)  weight_decay: 0.0500 (0.0500)  time: 0.8444  data: 0.0014  max mem: 7679\n",
            "Epoch: [72]  [ 70/147]  eta: 0:01:08  lr: 0.001060  min_lr: 0.001060  loss: 2.5190 (2.4237)  weight_decay: 0.0500 (0.0500)  time: 0.8458  data: 0.0008  max mem: 7679\n",
            "Epoch: [72]  [ 80/147]  eta: 0:00:59  lr: 0.001054  min_lr: 0.001054  loss: 2.6079 (2.4297)  weight_decay: 0.0500 (0.0500)  time: 0.8460  data: 0.0008  max mem: 7679\n",
            "Epoch: [72]  [ 90/147]  eta: 0:00:50  lr: 0.001050  min_lr: 0.001050  loss: 2.5536 (2.4310)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0020  max mem: 7679\n",
            "Epoch: [72]  [100/147]  eta: 0:00:41  lr: 0.001045  min_lr: 0.001045  loss: 2.4751 (2.4240)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0021  max mem: 7679\n",
            "Epoch: [72]  [110/147]  eta: 0:00:32  lr: 0.001041  min_lr: 0.001041  loss: 2.3389 (2.4193)  weight_decay: 0.0500 (0.0500)  time: 0.8530  data: 0.0015  max mem: 7679\n",
            "Epoch: [72]  [120/147]  eta: 0:00:23  lr: 0.001035  min_lr: 0.001035  loss: 2.4106 (2.4171)  weight_decay: 0.0500 (0.0500)  time: 0.8542  data: 0.0021  max mem: 7679\n",
            "Epoch: [72]  [130/147]  eta: 0:00:14  lr: 0.001031  min_lr: 0.001031  loss: 2.5677 (2.4279)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0026  max mem: 7679\n",
            "Epoch: [72]  [140/147]  eta: 0:00:06  lr: 0.001025  min_lr: 0.001025  loss: 2.5600 (2.4245)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0016  max mem: 7679\n",
            "Epoch: [72]  [146/147]  eta: 0:00:00  lr: 0.001025  min_lr: 0.001025  loss: 2.5600 (2.4272)  weight_decay: 0.0500 (0.0500)  time: 0.7224  data: 0.0002  max mem: 7679\n",
            "Epoch: [72] Total time: 0:02:05 (0.8561 s / it)\n",
            "Averaged stats: lr: 0.001025  min_lr: 0.001025  loss: 2.5600 (2.4272)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:20  loss: 0.5424 (0.5424)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.4291  data: 2.9886  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.6835 (0.6804)  acc1: 87.5000 (86.4583)  acc5: 97.9167 (98.1061)  time: 0.6811  data: 0.2768  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6982 (0.7697)  acc1: 84.3750 (81.8948)  acc5: 97.9167 (98.1151)  time: 0.4090  data: 0.0044  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7597 (0.7722)  acc1: 80.2083 (81.4516)  acc5: 98.9583 (97.9839)  time: 0.4077  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7305 (0.7466)  acc1: 82.2917 (82.3694)  acc5: 97.9167 (97.9108)  time: 0.4026  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4891 s / it)\n",
            "* Acc@1 82.369 Acc@5 97.911 loss 0.747\n",
            "Accuracy of the model on the 3925 test images: 82.4%\n",
            "Max accuracy: 82.37%\n",
            "Test:  [ 0/41]  eta: 0:02:25  loss: 3.7793 (3.7793)  acc1: 11.4583 (11.4583)  acc5: 82.2917 (82.2917)  time: 3.5373  data: 3.0689  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.8599 (4.0393)  acc1: 8.3333 (16.0985)  acc5: 87.5000 (84.5644)  time: 0.7024  data: 0.2815  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.3400 (4.7002)  acc1: 8.3333 (11.8056)  acc5: 82.2917 (73.5615)  time: 0.4183  data: 0.0023  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.2292 (4.8948)  acc1: 6.2500 (12.2648)  acc5: 59.3750 (67.8091)  time: 0.4134  data: 0.0010  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4123 (4.3786)  acc1: 23.9583 (22.1147)  acc5: 81.2500 (70.8535)  time: 0.4077  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4979 s / it)\n",
            "* Acc@1 22.115 Acc@5 70.854 loss 4.379\n",
            "Accuracy of the model EMA on 3925 test images: 22.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [73]  [  0/147]  eta: 0:07:51  lr: 0.001024  min_lr: 0.001024  loss: 2.4422 (2.4422)  weight_decay: 0.0500 (0.0500)  time: 3.2042  data: 2.1282  max mem: 7679\n",
            "Epoch: [73]  [ 10/147]  eta: 0:02:29  lr: 0.001020  min_lr: 0.001020  loss: 2.4422 (2.4777)  weight_decay: 0.0500 (0.0500)  time: 1.0902  data: 0.1952  max mem: 7679\n",
            "Epoch: [73]  [ 20/147]  eta: 0:02:04  lr: 0.001014  min_lr: 0.001014  loss: 2.4030 (2.4201)  weight_decay: 0.0500 (0.0500)  time: 0.8691  data: 0.0012  max mem: 7679\n",
            "Epoch: [73]  [ 30/147]  eta: 0:01:49  lr: 0.001010  min_lr: 0.001010  loss: 2.4042 (2.4019)  weight_decay: 0.0500 (0.0500)  time: 0.8573  data: 0.0008  max mem: 7679\n",
            "Epoch: [73]  [ 40/147]  eta: 0:01:38  lr: 0.001005  min_lr: 0.001005  loss: 2.4414 (2.4209)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0014  max mem: 7679\n",
            "Epoch: [73]  [ 50/147]  eta: 0:01:27  lr: 0.001001  min_lr: 0.001001  loss: 2.5071 (2.4213)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0026  max mem: 7679\n",
            "Epoch: [73]  [ 60/147]  eta: 0:01:17  lr: 0.000995  min_lr: 0.000995  loss: 2.5155 (2.4313)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0025  max mem: 7679\n",
            "Epoch: [73]  [ 70/147]  eta: 0:01:08  lr: 0.000991  min_lr: 0.000991  loss: 2.4871 (2.4319)  weight_decay: 0.0500 (0.0500)  time: 0.8458  data: 0.0017  max mem: 7679\n",
            "Epoch: [73]  [ 80/147]  eta: 0:00:59  lr: 0.000986  min_lr: 0.000986  loss: 2.4853 (2.4399)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0022  max mem: 7679\n",
            "Epoch: [73]  [ 90/147]  eta: 0:00:50  lr: 0.000982  min_lr: 0.000982  loss: 2.3943 (2.4297)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0022  max mem: 7679\n",
            "Epoch: [73]  [100/147]  eta: 0:00:41  lr: 0.000976  min_lr: 0.000976  loss: 2.2754 (2.4238)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0022  max mem: 7679\n",
            "Epoch: [73]  [110/147]  eta: 0:00:32  lr: 0.000973  min_lr: 0.000973  loss: 2.4208 (2.4326)  weight_decay: 0.0500 (0.0500)  time: 0.8518  data: 0.0021  max mem: 7679\n",
            "Epoch: [73]  [120/147]  eta: 0:00:23  lr: 0.000967  min_lr: 0.000967  loss: 2.3415 (2.4144)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0014  max mem: 7679\n",
            "Epoch: [73]  [130/147]  eta: 0:00:14  lr: 0.000963  min_lr: 0.000963  loss: 2.3064 (2.4144)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.0012  max mem: 7679\n",
            "Epoch: [73]  [140/147]  eta: 0:00:06  lr: 0.000958  min_lr: 0.000958  loss: 2.3533 (2.4104)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0008  max mem: 7679\n",
            "Epoch: [73]  [146/147]  eta: 0:00:00  lr: 0.000958  min_lr: 0.000958  loss: 2.3533 (2.4055)  weight_decay: 0.0500 (0.0500)  time: 0.7233  data: 0.0005  max mem: 7679\n",
            "Epoch: [73] Total time: 0:02:05 (0.8540 s / it)\n",
            "Averaged stats: lr: 0.000958  min_lr: 0.000958  loss: 2.3533 (2.4055)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:19  loss: 0.5207 (0.5207)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 4.8564  data: 4.4036  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 0.5341 (0.5557)  acc1: 89.5833 (88.3523)  acc5: 97.9167 (97.9167)  time: 0.8196  data: 0.4110  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.5600 (0.6950)  acc1: 86.4583 (81.8452)  acc5: 97.9167 (97.8175)  time: 0.4097  data: 0.0072  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.6984 (0.7097)  acc1: 81.2500 (81.5524)  acc5: 97.9167 (98.0175)  time: 0.4041  data: 0.0014  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7441 (0.7173)  acc1: 81.2500 (81.4268)  acc5: 97.9167 (97.7580)  time: 0.4043  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5570 s / it)\n",
            "* Acc@1 81.427 Acc@5 97.758 loss 0.717\n",
            "Accuracy of the model on the 3925 test images: 81.4%\n",
            "Max accuracy: 82.37%\n",
            "Test:  [ 0/41]  eta: 0:03:42  loss: 3.7450 (3.7450)  acc1: 11.4583 (11.4583)  acc5: 86.4583 (86.4583)  time: 5.4231  data: 4.9883  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 3.8372 (4.0236)  acc1: 10.4167 (16.0985)  acc5: 88.5417 (84.8485)  time: 0.8674  data: 0.4561  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.2961 (4.6852)  acc1: 8.3333 (11.8056)  acc5: 83.3333 (73.7599)  time: 0.4111  data: 0.0016  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2396 (4.8902)  acc1: 6.2500 (12.0296)  acc5: 58.3333 (67.8763)  time: 0.4102  data: 0.0002  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4326 (4.3683)  acc1: 23.9583 (21.9873)  acc5: 81.2500 (70.9554)  time: 0.4080  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5411 s / it)\n",
            "* Acc@1 21.987 Acc@5 70.955 loss 4.368\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [74]  [  0/147]  eta: 0:06:37  lr: 0.000956  min_lr: 0.000956  loss: 2.2605 (2.2605)  weight_decay: 0.0500 (0.0500)  time: 2.7043  data: 1.7771  max mem: 7679\n",
            "Epoch: [74]  [ 10/147]  eta: 0:02:27  lr: 0.000952  min_lr: 0.000952  loss: 2.5455 (2.4797)  weight_decay: 0.0500 (0.0500)  time: 1.0790  data: 0.2095  max mem: 7679\n",
            "Epoch: [74]  [ 20/147]  eta: 0:02:03  lr: 0.000946  min_lr: 0.000946  loss: 2.5360 (2.4956)  weight_decay: 0.0500 (0.0500)  time: 0.8883  data: 0.0269  max mem: 7679\n",
            "Epoch: [74]  [ 30/147]  eta: 0:01:49  lr: 0.000943  min_lr: 0.000943  loss: 2.5360 (2.5017)  weight_decay: 0.0500 (0.0500)  time: 0.8602  data: 0.0011  max mem: 7679\n",
            "Epoch: [74]  [ 40/147]  eta: 0:01:38  lr: 0.000937  min_lr: 0.000937  loss: 2.4906 (2.4591)  weight_decay: 0.0500 (0.0500)  time: 0.8581  data: 0.0011  max mem: 7679\n",
            "Epoch: [74]  [ 50/147]  eta: 0:01:27  lr: 0.000934  min_lr: 0.000934  loss: 2.3843 (2.4281)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0006  max mem: 7679\n",
            "Epoch: [74]  [ 60/147]  eta: 0:01:17  lr: 0.000928  min_lr: 0.000928  loss: 2.4258 (2.4341)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0011  max mem: 7679\n",
            "Epoch: [74]  [ 70/147]  eta: 0:01:08  lr: 0.000924  min_lr: 0.000924  loss: 2.3999 (2.4089)  weight_decay: 0.0500 (0.0500)  time: 0.8465  data: 0.0012  max mem: 7679\n",
            "Epoch: [74]  [ 80/147]  eta: 0:00:59  lr: 0.000919  min_lr: 0.000919  loss: 2.3340 (2.4083)  weight_decay: 0.0500 (0.0500)  time: 0.8465  data: 0.0006  max mem: 7679\n",
            "Epoch: [74]  [ 90/147]  eta: 0:00:50  lr: 0.000915  min_lr: 0.000915  loss: 2.2670 (2.3925)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0008  max mem: 7679\n",
            "Epoch: [74]  [100/147]  eta: 0:00:41  lr: 0.000910  min_lr: 0.000910  loss: 2.3417 (2.4034)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0007  max mem: 7679\n",
            "Epoch: [74]  [110/147]  eta: 0:00:32  lr: 0.000906  min_lr: 0.000906  loss: 2.5311 (2.4060)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0007  max mem: 7679\n",
            "Epoch: [74]  [120/147]  eta: 0:00:23  lr: 0.000901  min_lr: 0.000901  loss: 2.4713 (2.4098)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0010  max mem: 7679\n",
            "Epoch: [74]  [130/147]  eta: 0:00:14  lr: 0.000897  min_lr: 0.000897  loss: 2.4080 (2.4054)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0010  max mem: 7679\n",
            "Epoch: [74]  [140/147]  eta: 0:00:06  lr: 0.000891  min_lr: 0.000891  loss: 2.3057 (2.4021)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0007  max mem: 7679\n",
            "Epoch: [74]  [146/147]  eta: 0:00:00  lr: 0.000891  min_lr: 0.000891  loss: 2.3377 (2.3996)  weight_decay: 0.0500 (0.0500)  time: 0.7260  data: 0.0004  max mem: 7679\n",
            "Epoch: [74] Total time: 0:02:05 (0.8545 s / it)\n",
            "Averaged stats: lr: 0.000891  min_lr: 0.000891  loss: 2.3377 (2.3996)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:50  loss: 0.4324 (0.4324)  acc1: 90.6250 (90.6250)  acc5: 100.0000 (100.0000)  time: 4.1634  data: 3.7150  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.4874 (0.5137)  acc1: 90.6250 (89.8674)  acc5: 97.9167 (98.3902)  time: 0.7500  data: 0.3403  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6015 (0.7626)  acc1: 87.5000 (80.6052)  acc5: 97.9167 (96.9742)  time: 0.4054  data: 0.0020  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7608 (0.7529)  acc1: 80.2083 (81.2164)  acc5: 97.9167 (97.2110)  time: 0.4036  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7371 (0.7387)  acc1: 80.2083 (81.9363)  acc5: 97.9167 (97.2229)  time: 0.4031  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5050 s / it)\n",
            "* Acc@1 81.936 Acc@5 97.223 loss 0.739\n",
            "Accuracy of the model on the 3925 test images: 81.9%\n",
            "Max accuracy: 82.37%\n",
            "Test:  [ 0/41]  eta: 0:02:12  loss: 3.7101 (3.7101)  acc1: 8.3333 (8.3333)  acc5: 87.5000 (87.5000)  time: 3.2209  data: 2.7289  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.8141 (4.0087)  acc1: 8.3333 (15.4356)  acc5: 90.6250 (85.2273)  time: 0.6685  data: 0.2515  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.2505 (4.6706)  acc1: 8.3333 (11.4583)  acc5: 86.4583 (73.9087)  time: 0.4150  data: 0.0044  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.2491 (4.8863)  acc1: 7.2917 (11.6935)  acc5: 58.3333 (67.8427)  time: 0.4138  data: 0.0026  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4557 (4.3589)  acc1: 23.9583 (21.7580)  acc5: 81.2500 (70.9809)  time: 0.4081  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4892 s / it)\n",
            "* Acc@1 21.758 Acc@5 70.981 loss 4.359\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [75]  [  0/147]  eta: 0:08:36  lr: 0.000890  min_lr: 0.000890  loss: 2.3969 (2.3969)  weight_decay: 0.0500 (0.0500)  time: 3.5124  data: 2.5828  max mem: 7679\n",
            "Epoch: [75]  [ 10/147]  eta: 0:02:30  lr: 0.000886  min_lr: 0.000886  loss: 2.3264 (2.2648)  weight_decay: 0.0500 (0.0500)  time: 1.0976  data: 0.2378  max mem: 7679\n",
            "Epoch: [75]  [ 20/147]  eta: 0:02:04  lr: 0.000881  min_lr: 0.000881  loss: 2.3264 (2.3229)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0018  max mem: 7679\n",
            "Epoch: [75]  [ 30/147]  eta: 0:01:49  lr: 0.000877  min_lr: 0.000877  loss: 2.4914 (2.3517)  weight_decay: 0.0500 (0.0500)  time: 0.8516  data: 0.0014  max mem: 7679\n",
            "Epoch: [75]  [ 40/147]  eta: 0:01:38  lr: 0.000872  min_lr: 0.000872  loss: 2.2569 (2.3318)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0021  max mem: 7679\n",
            "Epoch: [75]  [ 50/147]  eta: 0:01:27  lr: 0.000868  min_lr: 0.000868  loss: 2.3358 (2.3505)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0019  max mem: 7679\n",
            "Epoch: [75]  [ 60/147]  eta: 0:01:17  lr: 0.000863  min_lr: 0.000863  loss: 2.4317 (2.3753)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0015  max mem: 7679\n",
            "Epoch: [75]  [ 70/147]  eta: 0:01:08  lr: 0.000859  min_lr: 0.000859  loss: 2.4497 (2.3790)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0015  max mem: 7679\n",
            "Epoch: [75]  [ 80/147]  eta: 0:00:59  lr: 0.000854  min_lr: 0.000854  loss: 2.4326 (2.3839)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0020  max mem: 7679\n",
            "Epoch: [75]  [ 90/147]  eta: 0:00:50  lr: 0.000850  min_lr: 0.000850  loss: 2.4326 (2.3832)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0019  max mem: 7679\n",
            "Epoch: [75]  [100/147]  eta: 0:00:41  lr: 0.000845  min_lr: 0.000845  loss: 2.4095 (2.3869)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0024  max mem: 7679\n",
            "Epoch: [75]  [110/147]  eta: 0:00:32  lr: 0.000841  min_lr: 0.000841  loss: 2.4095 (2.3864)  weight_decay: 0.0500 (0.0500)  time: 0.8551  data: 0.0043  max mem: 7679\n",
            "Epoch: [75]  [120/147]  eta: 0:00:23  lr: 0.000836  min_lr: 0.000836  loss: 2.4924 (2.3902)  weight_decay: 0.0500 (0.0500)  time: 0.8552  data: 0.0039  max mem: 7679\n",
            "Epoch: [75]  [130/147]  eta: 0:00:14  lr: 0.000832  min_lr: 0.000832  loss: 2.4924 (2.3922)  weight_decay: 0.0500 (0.0500)  time: 0.8521  data: 0.0026  max mem: 7679\n",
            "Epoch: [75]  [140/147]  eta: 0:00:06  lr: 0.000827  min_lr: 0.000827  loss: 2.4499 (2.3943)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0018  max mem: 7679\n",
            "Epoch: [75]  [146/147]  eta: 0:00:00  lr: 0.000827  min_lr: 0.000827  loss: 2.4499 (2.3920)  weight_decay: 0.0500 (0.0500)  time: 0.7249  data: 0.0002  max mem: 7679\n",
            "Epoch: [75] Total time: 0:02:05 (0.8567 s / it)\n",
            "Averaged stats: lr: 0.000827  min_lr: 0.000827  loss: 2.4499 (2.3920)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:57  loss: 0.5683 (0.5683)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 4.3307  data: 3.8961  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 0.5527 (0.5805)  acc1: 89.5833 (89.0152)  acc5: 97.9167 (98.2008)  time: 0.7636  data: 0.3581  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5768 (0.7293)  acc1: 87.5000 (82.3909)  acc5: 97.9167 (98.2639)  time: 0.4063  data: 0.0041  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7280 (0.7456)  acc1: 80.2083 (81.7876)  acc5: 97.9167 (98.1519)  time: 0.4051  data: 0.0021  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6215 (0.7146)  acc1: 85.4167 (82.8280)  acc5: 97.9167 (98.0892)  time: 0.4054  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5106 s / it)\n",
            "* Acc@1 82.828 Acc@5 98.089 loss 0.715\n",
            "Accuracy of the model on the 3925 test images: 82.8%\n",
            "Max accuracy: 82.83%\n",
            "Test:  [ 0/41]  eta: 0:03:54  loss: 3.6792 (3.6792)  acc1: 8.3333 (8.3333)  acc5: 87.5000 (87.5000)  time: 5.7110  data: 5.2702  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 3.7914 (3.9945)  acc1: 8.3333 (15.4356)  acc5: 91.6667 (85.4167)  time: 0.8971  data: 0.4889  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.2056 (4.6558)  acc1: 7.2917 (11.4583)  acc5: 86.4583 (74.0079)  time: 0.4104  data: 0.0066  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2564 (4.8807)  acc1: 7.2917 (11.6599)  acc5: 58.3333 (67.8763)  time: 0.4061  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4733 (4.3485)  acc1: 23.9583 (21.8599)  acc5: 80.2083 (71.0318)  time: 0.4069  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5510 s / it)\n",
            "* Acc@1 21.860 Acc@5 71.032 loss 4.348\n",
            "Accuracy of the model EMA on 3925 test images: 21.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [76]  [  0/147]  eta: 0:12:13  lr: 0.000825  min_lr: 0.000825  loss: 2.5409 (2.5409)  weight_decay: 0.0500 (0.0500)  time: 4.9890  data: 4.0690  max mem: 7679\n",
            "Epoch: [76]  [ 10/147]  eta: 0:02:48  lr: 0.000822  min_lr: 0.000822  loss: 2.1897 (2.2700)  weight_decay: 0.0500 (0.0500)  time: 1.2335  data: 0.3705  max mem: 7679\n",
            "Epoch: [76]  [ 20/147]  eta: 0:02:14  lr: 0.000816  min_lr: 0.000816  loss: 2.3308 (2.3206)  weight_decay: 0.0500 (0.0500)  time: 0.8601  data: 0.0007  max mem: 7679\n",
            "Epoch: [76]  [ 30/147]  eta: 0:01:55  lr: 0.000813  min_lr: 0.000813  loss: 2.4688 (2.3493)  weight_decay: 0.0500 (0.0500)  time: 0.8555  data: 0.0006  max mem: 7679\n",
            "Epoch: [76]  [ 40/147]  eta: 0:01:42  lr: 0.000808  min_lr: 0.000808  loss: 2.5116 (2.3805)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0004  max mem: 7679\n",
            "Epoch: [76]  [ 50/147]  eta: 0:01:30  lr: 0.000804  min_lr: 0.000804  loss: 2.3990 (2.3698)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0014  max mem: 7679\n",
            "Epoch: [76]  [ 60/147]  eta: 0:01:20  lr: 0.000799  min_lr: 0.000799  loss: 2.4959 (2.3953)  weight_decay: 0.0500 (0.0500)  time: 0.8457  data: 0.0016  max mem: 7679\n",
            "Epoch: [76]  [ 70/147]  eta: 0:01:10  lr: 0.000795  min_lr: 0.000795  loss: 2.5689 (2.4138)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0012  max mem: 7679\n",
            "Epoch: [76]  [ 80/147]  eta: 0:01:00  lr: 0.000790  min_lr: 0.000790  loss: 2.4943 (2.4227)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0023  max mem: 7679\n",
            "Epoch: [76]  [ 90/147]  eta: 0:00:51  lr: 0.000787  min_lr: 0.000787  loss: 2.4805 (2.4320)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0021  max mem: 7679\n",
            "Epoch: [76]  [100/147]  eta: 0:00:41  lr: 0.000782  min_lr: 0.000782  loss: 2.4493 (2.4228)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0012  max mem: 7679\n",
            "Epoch: [76]  [110/147]  eta: 0:00:32  lr: 0.000778  min_lr: 0.000778  loss: 2.4235 (2.4265)  weight_decay: 0.0500 (0.0500)  time: 0.8518  data: 0.0013  max mem: 7679\n",
            "Epoch: [76]  [120/147]  eta: 0:00:23  lr: 0.000773  min_lr: 0.000773  loss: 2.4283 (2.4240)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0014  max mem: 7679\n",
            "Epoch: [76]  [130/147]  eta: 0:00:15  lr: 0.000769  min_lr: 0.000769  loss: 2.4047 (2.4196)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0014  max mem: 7679\n",
            "Epoch: [76]  [140/147]  eta: 0:00:06  lr: 0.000764  min_lr: 0.000764  loss: 2.4047 (2.4214)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0007  max mem: 7679\n",
            "Epoch: [76]  [146/147]  eta: 0:00:00  lr: 0.000764  min_lr: 0.000764  loss: 2.3904 (2.4205)  weight_decay: 0.0500 (0.0500)  time: 0.7245  data: 0.0002  max mem: 7679\n",
            "Epoch: [76] Total time: 0:02:07 (0.8662 s / it)\n",
            "Averaged stats: lr: 0.000764  min_lr: 0.000764  loss: 2.3904 (2.4205)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:18  loss: 0.5256 (0.5256)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 3.3685  data: 2.9381  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5917 (0.5918)  acc1: 88.5417 (88.5417)  acc5: 97.9167 (98.2955)  time: 0.6888  data: 0.2742  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.6172 (0.7336)  acc1: 86.4583 (82.1429)  acc5: 97.9167 (97.9167)  time: 0.4123  data: 0.0044  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7812 (0.7358)  acc1: 80.2083 (82.0229)  acc5: 97.9167 (97.9167)  time: 0.4036  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6544 (0.7117)  acc1: 85.8824 (82.9554)  acc5: 97.9167 (97.9108)  time: 0.4026  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4886 s / it)\n",
            "* Acc@1 82.955 Acc@5 97.911 loss 0.712\n",
            "Accuracy of the model on the 3925 test images: 83.0%\n",
            "Max accuracy: 82.96%\n",
            "Test:  [ 0/41]  eta: 0:03:16  loss: 3.6481 (3.6481)  acc1: 9.3750 (9.3750)  acc5: 87.5000 (87.5000)  time: 4.8021  data: 4.3191  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 3.7693 (3.9796)  acc1: 9.3750 (15.7197)  acc5: 91.6667 (85.7008)  time: 0.8655  data: 0.4400  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.1606 (4.6403)  acc1: 7.2917 (11.7063)  acc5: 87.5000 (74.1071)  time: 0.4492  data: 0.0279  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2636 (4.8742)  acc1: 7.2917 (11.8280)  acc5: 57.2917 (67.8427)  time: 0.4156  data: 0.0019  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.4894 (4.3375)  acc1: 23.9583 (21.9618)  acc5: 79.1667 (71.0064)  time: 0.4045  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5438 s / it)\n",
            "* Acc@1 21.962 Acc@5 71.006 loss 4.338\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [77]  [  0/147]  eta: 0:10:38  lr: 0.000763  min_lr: 0.000763  loss: 2.6173 (2.6173)  weight_decay: 0.0500 (0.0500)  time: 4.3445  data: 3.2315  max mem: 7679\n",
            "Epoch: [77]  [ 10/147]  eta: 0:02:48  lr: 0.000759  min_lr: 0.000759  loss: 2.5380 (2.4875)  weight_decay: 0.0500 (0.0500)  time: 1.2302  data: 0.2954  max mem: 7679\n",
            "Epoch: [77]  [ 20/147]  eta: 0:02:14  lr: 0.000754  min_lr: 0.000754  loss: 2.3357 (2.3325)  weight_decay: 0.0500 (0.0500)  time: 0.8920  data: 0.0015  max mem: 7679\n",
            "Epoch: [77]  [ 30/147]  eta: 0:01:55  lr: 0.000751  min_lr: 0.000751  loss: 2.2824 (2.3415)  weight_decay: 0.0500 (0.0500)  time: 0.8579  data: 0.0016  max mem: 7679\n",
            "Epoch: [77]  [ 40/147]  eta: 0:01:42  lr: 0.000746  min_lr: 0.000746  loss: 2.4416 (2.3632)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0014  max mem: 7679\n",
            "Epoch: [77]  [ 50/147]  eta: 0:01:30  lr: 0.000742  min_lr: 0.000742  loss: 2.4332 (2.3665)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0007  max mem: 7679\n",
            "Epoch: [77]  [ 60/147]  eta: 0:01:20  lr: 0.000737  min_lr: 0.000737  loss: 2.2838 (2.3422)  weight_decay: 0.0500 (0.0500)  time: 0.8469  data: 0.0014  max mem: 7679\n",
            "Epoch: [77]  [ 70/147]  eta: 0:01:10  lr: 0.000734  min_lr: 0.000734  loss: 2.3021 (2.3558)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0015  max mem: 7679\n",
            "Epoch: [77]  [ 80/147]  eta: 0:01:00  lr: 0.000729  min_lr: 0.000729  loss: 2.3375 (2.3456)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0018  max mem: 7679\n",
            "Epoch: [77]  [ 90/147]  eta: 0:00:51  lr: 0.000725  min_lr: 0.000725  loss: 2.4515 (2.3570)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0018  max mem: 7679\n",
            "Epoch: [77]  [100/147]  eta: 0:00:41  lr: 0.000720  min_lr: 0.000720  loss: 2.5488 (2.3662)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0028  max mem: 7679\n",
            "Epoch: [77]  [110/147]  eta: 0:00:32  lr: 0.000717  min_lr: 0.000717  loss: 2.4439 (2.3583)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0029  max mem: 7679\n",
            "Epoch: [77]  [120/147]  eta: 0:00:23  lr: 0.000712  min_lr: 0.000712  loss: 2.3726 (2.3609)  weight_decay: 0.0500 (0.0500)  time: 0.8538  data: 0.0025  max mem: 7679\n",
            "Epoch: [77]  [130/147]  eta: 0:00:15  lr: 0.000709  min_lr: 0.000709  loss: 2.4416 (2.3637)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0024  max mem: 7679\n",
            "Epoch: [77]  [140/147]  eta: 0:00:06  lr: 0.000704  min_lr: 0.000704  loss: 2.4464 (2.3612)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0005  max mem: 7679\n",
            "Epoch: [77]  [146/147]  eta: 0:00:00  lr: 0.000704  min_lr: 0.000704  loss: 2.4260 (2.3629)  weight_decay: 0.0500 (0.0500)  time: 0.7225  data: 0.0002  max mem: 7679\n",
            "Epoch: [77] Total time: 0:02:07 (0.8651 s / it)\n",
            "Averaged stats: lr: 0.000704  min_lr: 0.000704  loss: 2.4260 (2.3629)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:37  loss: 0.5003 (0.5003)  acc1: 90.6250 (90.6250)  acc5: 94.7917 (94.7917)  time: 5.3156  data: 4.8462  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 0.5326 (0.5359)  acc1: 90.6250 (90.0568)  acc5: 97.9167 (98.0114)  time: 0.8494  data: 0.4433  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.5785 (0.6770)  acc1: 88.5417 (83.9286)  acc5: 97.9167 (98.4127)  time: 0.4026  data: 0.0026  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.6494 (0.7141)  acc1: 83.3333 (82.7621)  acc5: 98.9583 (98.1183)  time: 0.4035  data: 0.0012  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6890 (0.7032)  acc1: 82.2917 (83.1592)  acc5: 97.6471 (97.9873)  time: 0.4051  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5343 s / it)\n",
            "* Acc@1 83.159 Acc@5 97.987 loss 0.703\n",
            "Accuracy of the model on the 3925 test images: 83.2%\n",
            "Max accuracy: 83.16%\n",
            "Test:  [ 0/41]  eta: 0:02:20  loss: 3.6201 (3.6201)  acc1: 9.3750 (9.3750)  acc5: 88.5417 (88.5417)  time: 3.4378  data: 2.9691  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.7466 (3.9651)  acc1: 9.3750 (15.6250)  acc5: 92.7083 (86.0795)  time: 0.6946  data: 0.2762  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.1154 (4.6247)  acc1: 7.2917 (11.6567)  acc5: 88.5417 (74.2560)  time: 0.4195  data: 0.0054  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.2716 (4.8676)  acc1: 6.2500 (11.5927)  acc5: 57.2917 (67.8091)  time: 0.4150  data: 0.0020  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5050 (4.3267)  acc1: 21.8750 (21.8089)  acc5: 78.1250 (71.0318)  time: 0.4100  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4979 s / it)\n",
            "* Acc@1 21.809 Acc@5 71.032 loss 4.327\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [78]  [  0/147]  eta: 0:08:54  lr: 0.000702  min_lr: 0.000702  loss: 2.4436 (2.4436)  weight_decay: 0.0500 (0.0500)  time: 3.6384  data: 2.7307  max mem: 7679\n",
            "Epoch: [78]  [ 10/147]  eta: 0:02:35  lr: 0.000699  min_lr: 0.000699  loss: 2.4436 (2.3122)  weight_decay: 0.0500 (0.0500)  time: 1.1374  data: 0.2495  max mem: 7679\n",
            "Epoch: [78]  [ 20/147]  eta: 0:02:07  lr: 0.000694  min_lr: 0.000694  loss: 2.4664 (2.3475)  weight_decay: 0.0500 (0.0500)  time: 0.8730  data: 0.0010  max mem: 7679\n",
            "Epoch: [78]  [ 30/147]  eta: 0:01:51  lr: 0.000690  min_lr: 0.000690  loss: 2.4060 (2.3370)  weight_decay: 0.0500 (0.0500)  time: 0.8552  data: 0.0005  max mem: 7679\n",
            "Epoch: [78]  [ 40/147]  eta: 0:01:39  lr: 0.000685  min_lr: 0.000685  loss: 2.3309 (2.3314)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0003  max mem: 7679\n",
            "Epoch: [78]  [ 50/147]  eta: 0:01:28  lr: 0.000682  min_lr: 0.000682  loss: 2.4488 (2.3466)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0007  max mem: 7679\n",
            "Epoch: [78]  [ 60/147]  eta: 0:01:18  lr: 0.000677  min_lr: 0.000677  loss: 2.4959 (2.3660)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0011  max mem: 7679\n",
            "Epoch: [78]  [ 70/147]  eta: 0:01:08  lr: 0.000674  min_lr: 0.000674  loss: 2.4928 (2.3804)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0010  max mem: 7679\n",
            "Epoch: [78]  [ 80/147]  eta: 0:00:59  lr: 0.000669  min_lr: 0.000669  loss: 2.4472 (2.3875)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0013  max mem: 7679\n",
            "Epoch: [78]  [ 90/147]  eta: 0:00:50  lr: 0.000666  min_lr: 0.000666  loss: 2.4028 (2.3868)  weight_decay: 0.0500 (0.0500)  time: 0.8471  data: 0.0016  max mem: 7679\n",
            "Epoch: [78]  [100/147]  eta: 0:00:41  lr: 0.000661  min_lr: 0.000661  loss: 2.5282 (2.3899)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0022  max mem: 7679\n",
            "Epoch: [78]  [110/147]  eta: 0:00:32  lr: 0.000658  min_lr: 0.000658  loss: 2.4140 (2.3922)  weight_decay: 0.0500 (0.0500)  time: 0.8539  data: 0.0020  max mem: 7679\n",
            "Epoch: [78]  [120/147]  eta: 0:00:23  lr: 0.000653  min_lr: 0.000653  loss: 2.4288 (2.3920)  weight_decay: 0.0500 (0.0500)  time: 0.8544  data: 0.0024  max mem: 7679\n",
            "Epoch: [78]  [130/147]  eta: 0:00:14  lr: 0.000650  min_lr: 0.000650  loss: 2.4288 (2.3848)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0019  max mem: 7679\n",
            "Epoch: [78]  [140/147]  eta: 0:00:06  lr: 0.000645  min_lr: 0.000645  loss: 2.3680 (2.3820)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0004  max mem: 7679\n",
            "Epoch: [78]  [146/147]  eta: 0:00:00  lr: 0.000645  min_lr: 0.000645  loss: 2.3721 (2.3834)  weight_decay: 0.0500 (0.0500)  time: 0.7224  data: 0.0003  max mem: 7679\n",
            "Epoch: [78] Total time: 0:02:06 (0.8575 s / it)\n",
            "Averaged stats: lr: 0.000645  min_lr: 0.000645  loss: 2.3721 (2.3834)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:55  loss: 0.5345 (0.5345)  acc1: 90.6250 (90.6250)  acc5: 94.7917 (94.7917)  time: 2.8268  data: 2.3662  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5489 (0.5552)  acc1: 89.5833 (88.2576)  acc5: 97.9167 (98.2955)  time: 0.7351  data: 0.3116  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.6073 (0.6767)  acc1: 85.4167 (83.2837)  acc5: 97.9167 (98.3135)  time: 0.4677  data: 0.0551  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6961 (0.6927)  acc1: 82.2917 (83.0309)  acc5: 97.9167 (98.2863)  time: 0.4069  data: 0.0021  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6589 (0.6911)  acc1: 83.3333 (83.3885)  acc5: 97.9167 (97.9873)  time: 0.4034  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5027 s / it)\n",
            "* Acc@1 83.389 Acc@5 97.987 loss 0.691\n",
            "Accuracy of the model on the 3925 test images: 83.4%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/41]  eta: 0:03:31  loss: 3.5886 (3.5886)  acc1: 9.3750 (9.3750)  acc5: 88.5417 (88.5417)  time: 5.1622  data: 4.7211  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 3.7234 (3.9503)  acc1: 9.3750 (15.3409)  acc5: 93.7500 (86.1742)  time: 0.8390  data: 0.4323  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 4.0718 (4.6094)  acc1: 7.2917 (11.5079)  acc5: 89.5833 (74.5040)  time: 0.4073  data: 0.0042  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2798 (4.8611)  acc1: 5.2083 (11.3575)  acc5: 57.2917 (67.9436)  time: 0.4091  data: 0.0026  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5207 (4.3164)  acc1: 20.8333 (21.7070)  acc5: 78.1250 (71.2357)  time: 0.4090  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5327 s / it)\n",
            "* Acc@1 21.707 Acc@5 71.236 loss 4.316\n",
            "Accuracy of the model EMA on 3925 test images: 21.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [79]  [  0/147]  eta: 0:07:58  lr: 0.000643  min_lr: 0.000643  loss: 2.5540 (2.5540)  weight_decay: 0.0500 (0.0500)  time: 3.2526  data: 2.2873  max mem: 7679\n",
            "Epoch: [79]  [ 10/147]  eta: 0:02:28  lr: 0.000640  min_lr: 0.000640  loss: 2.4445 (2.4519)  weight_decay: 0.0500 (0.0500)  time: 1.0853  data: 0.2089  max mem: 7679\n",
            "Epoch: [79]  [ 20/147]  eta: 0:02:04  lr: 0.000635  min_lr: 0.000635  loss: 2.3940 (2.3864)  weight_decay: 0.0500 (0.0500)  time: 0.8650  data: 0.0007  max mem: 7679\n",
            "Epoch: [79]  [ 30/147]  eta: 0:01:49  lr: 0.000632  min_lr: 0.000632  loss: 2.3208 (2.3757)  weight_decay: 0.0500 (0.0500)  time: 0.8566  data: 0.0003  max mem: 7679\n",
            "Epoch: [79]  [ 40/147]  eta: 0:01:37  lr: 0.000627  min_lr: 0.000627  loss: 2.2283 (2.3472)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0004  max mem: 7679\n",
            "Epoch: [79]  [ 50/147]  eta: 0:01:27  lr: 0.000624  min_lr: 0.000624  loss: 2.4611 (2.3688)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0010  max mem: 7679\n",
            "Epoch: [79]  [ 60/147]  eta: 0:01:17  lr: 0.000619  min_lr: 0.000619  loss: 2.5059 (2.3678)  weight_decay: 0.0500 (0.0500)  time: 0.8451  data: 0.0011  max mem: 7679\n",
            "Epoch: [79]  [ 70/147]  eta: 0:01:08  lr: 0.000616  min_lr: 0.000616  loss: 2.4127 (2.3745)  weight_decay: 0.0500 (0.0500)  time: 0.8416  data: 0.0005  max mem: 7679\n",
            "Epoch: [79]  [ 80/147]  eta: 0:00:58  lr: 0.000612  min_lr: 0.000612  loss: 2.4127 (2.3812)  weight_decay: 0.0500 (0.0500)  time: 0.8430  data: 0.0007  max mem: 7679\n",
            "Epoch: [79]  [ 90/147]  eta: 0:00:50  lr: 0.000608  min_lr: 0.000608  loss: 2.4069 (2.3774)  weight_decay: 0.0500 (0.0500)  time: 0.8484  data: 0.0016  max mem: 7679\n",
            "Epoch: [79]  [100/147]  eta: 0:00:41  lr: 0.000604  min_lr: 0.000604  loss: 2.4590 (2.3840)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0014  max mem: 7679\n",
            "Epoch: [79]  [110/147]  eta: 0:00:32  lr: 0.000601  min_lr: 0.000601  loss: 2.4397 (2.3745)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0016  max mem: 7679\n",
            "Epoch: [79]  [120/147]  eta: 0:00:23  lr: 0.000596  min_lr: 0.000596  loss: 2.3501 (2.3730)  weight_decay: 0.0500 (0.0500)  time: 0.8537  data: 0.0019  max mem: 7679\n",
            "Epoch: [79]  [130/147]  eta: 0:00:14  lr: 0.000593  min_lr: 0.000593  loss: 2.3408 (2.3695)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0011  max mem: 7679\n",
            "Epoch: [79]  [140/147]  eta: 0:00:06  lr: 0.000588  min_lr: 0.000588  loss: 2.3408 (2.3691)  weight_decay: 0.0500 (0.0500)  time: 0.8533  data: 0.0006  max mem: 7679\n",
            "Epoch: [79]  [146/147]  eta: 0:00:00  lr: 0.000588  min_lr: 0.000588  loss: 2.3408 (2.3673)  weight_decay: 0.0500 (0.0500)  time: 0.7264  data: 0.0002  max mem: 7679\n",
            "Epoch: [79] Total time: 0:02:05 (0.8547 s / it)\n",
            "Averaged stats: lr: 0.000588  min_lr: 0.000588  loss: 2.3408 (2.3673)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:08  loss: 0.4698 (0.4698)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 1.6661  data: 1.2082  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.4906 (0.5171)  acc1: 90.6250 (90.7197)  acc5: 97.9167 (98.6742)  time: 0.7353  data: 0.3263  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5269 (0.6631)  acc1: 89.5833 (84.3254)  acc5: 98.9583 (98.7103)  time: 0.5242  data: 0.1201  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6682 (0.7031)  acc1: 85.4167 (83.1317)  acc5: 97.9167 (98.2863)  time: 0.4055  data: 0.0011  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.7270 (0.7080)  acc1: 83.3333 (83.2102)  acc5: 96.8750 (97.9873)  time: 0.4036  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5023 s / it)\n",
            "* Acc@1 83.210 Acc@5 97.987 loss 0.708\n",
            "Accuracy of the model on the 3925 test images: 83.2%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/41]  eta: 0:01:50  loss: 3.5578 (3.5578)  acc1: 10.4167 (10.4167)  acc5: 88.5417 (88.5417)  time: 2.6958  data: 2.2368  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.7022 (3.9366)  acc1: 9.3750 (15.5303)  acc5: 93.7500 (86.1742)  time: 0.6929  data: 0.2715  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 4.0274 (4.5943)  acc1: 7.2917 (11.5575)  acc5: 90.6250 (74.7024)  time: 0.4591  data: 0.0412  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.2872 (4.8542)  acc1: 5.2083 (11.2567)  acc5: 57.2917 (68.0780)  time: 0.4193  data: 0.0038  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5348 (4.3059)  acc1: 19.7917 (21.7070)  acc5: 77.0833 (71.3376)  time: 0.4095  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4988 s / it)\n",
            "* Acc@1 21.707 Acc@5 71.338 loss 4.306\n",
            "Accuracy of the model EMA on 3925 test images: 21.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [80]  [  0/147]  eta: 0:09:58  lr: 0.000587  min_lr: 0.000587  loss: 1.7982 (1.7982)  weight_decay: 0.0500 (0.0500)  time: 4.0714  data: 2.8035  max mem: 7679\n",
            "Epoch: [80]  [ 10/147]  eta: 0:02:44  lr: 0.000584  min_lr: 0.000584  loss: 2.4522 (2.4138)  weight_decay: 0.0500 (0.0500)  time: 1.2027  data: 0.2570  max mem: 7679\n",
            "Epoch: [80]  [ 20/147]  eta: 0:02:11  lr: 0.000579  min_lr: 0.000579  loss: 2.4779 (2.4526)  weight_decay: 0.0500 (0.0500)  time: 0.8852  data: 0.0015  max mem: 7679\n",
            "Epoch: [80]  [ 30/147]  eta: 0:01:54  lr: 0.000576  min_lr: 0.000576  loss: 2.4596 (2.4188)  weight_decay: 0.0500 (0.0500)  time: 0.8518  data: 0.0007  max mem: 7679\n",
            "Epoch: [80]  [ 40/147]  eta: 0:01:41  lr: 0.000571  min_lr: 0.000571  loss: 2.4094 (2.4093)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0005  max mem: 7679\n",
            "Epoch: [80]  [ 50/147]  eta: 0:01:29  lr: 0.000568  min_lr: 0.000568  loss: 2.4818 (2.4282)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0003  max mem: 7679\n",
            "Epoch: [80]  [ 60/147]  eta: 0:01:19  lr: 0.000564  min_lr: 0.000564  loss: 2.4818 (2.4440)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0014  max mem: 7679\n",
            "Epoch: [80]  [ 70/147]  eta: 0:01:09  lr: 0.000561  min_lr: 0.000561  loss: 2.4266 (2.4186)  weight_decay: 0.0500 (0.0500)  time: 0.8470  data: 0.0019  max mem: 7679\n",
            "Epoch: [80]  [ 80/147]  eta: 0:01:00  lr: 0.000556  min_lr: 0.000556  loss: 2.1579 (2.3876)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0011  max mem: 7679\n",
            "Epoch: [80]  [ 90/147]  eta: 0:00:50  lr: 0.000553  min_lr: 0.000553  loss: 2.2078 (2.3822)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0014  max mem: 7679\n",
            "Epoch: [80]  [100/147]  eta: 0:00:41  lr: 0.000549  min_lr: 0.000549  loss: 2.3894 (2.3823)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0022  max mem: 7679\n",
            "Epoch: [80]  [110/147]  eta: 0:00:32  lr: 0.000546  min_lr: 0.000546  loss: 2.3231 (2.3712)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0017  max mem: 7679\n",
            "Epoch: [80]  [120/147]  eta: 0:00:23  lr: 0.000541  min_lr: 0.000541  loss: 2.2389 (2.3657)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0010  max mem: 7679\n",
            "Epoch: [80]  [130/147]  eta: 0:00:14  lr: 0.000538  min_lr: 0.000538  loss: 2.3859 (2.3628)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0012  max mem: 7679\n",
            "Epoch: [80]  [140/147]  eta: 0:00:06  lr: 0.000534  min_lr: 0.000534  loss: 2.3859 (2.3554)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0008  max mem: 7679\n",
            "Epoch: [80]  [146/147]  eta: 0:00:00  lr: 0.000534  min_lr: 0.000534  loss: 2.2230 (2.3525)  weight_decay: 0.0500 (0.0500)  time: 0.7260  data: 0.0002  max mem: 7679\n",
            "Epoch: [80] Total time: 0:02:06 (0.8619 s / it)\n",
            "Averaged stats: lr: 0.000534  min_lr: 0.000534  loss: 2.2230 (2.3525)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:47  loss: 0.4758 (0.4758)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 4.0834  data: 3.5980  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.4758 (0.4973)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.6742)  time: 0.8024  data: 0.3804  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5444 (0.6685)  acc1: 88.5417 (83.8294)  acc5: 97.9167 (98.5615)  time: 0.4445  data: 0.0308  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.7292 (0.6949)  acc1: 79.1667 (82.7957)  acc5: 97.9167 (98.2863)  time: 0.4092  data: 0.0015  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5970 (0.6799)  acc1: 85.8824 (83.3631)  acc5: 97.9167 (98.0892)  time: 0.4042  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5323 s / it)\n",
            "* Acc@1 83.363 Acc@5 98.089 loss 0.680\n",
            "Accuracy of the model on the 3925 test images: 83.4%\n",
            "Max accuracy: 83.39%\n",
            "Test:  [ 0/41]  eta: 0:03:01  loss: 3.5265 (3.5265)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 4.4225  data: 3.9405  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:30  loss: 3.6835 (3.9222)  acc1: 8.3333 (15.4356)  acc5: 93.7500 (86.2689)  time: 0.9995  data: 0.4469  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:15  loss: 3.9836 (4.5787)  acc1: 7.2917 (11.6071)  acc5: 90.6250 (74.8512)  time: 0.5320  data: 0.0500  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.2933 (4.8459)  acc1: 5.2083 (11.2567)  acc5: 57.2917 (68.1116)  time: 0.4072  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5449 (4.2945)  acc1: 19.7917 (21.7325)  acc5: 77.0833 (71.3121)  time: 0.4061  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:23 (0.5818 s / it)\n",
            "* Acc@1 21.732 Acc@5 71.312 loss 4.295\n",
            "Accuracy of the model EMA on 3925 test images: 21.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [81]  [  0/147]  eta: 0:13:10  lr: 0.000532  min_lr: 0.000532  loss: 2.2450 (2.2450)  weight_decay: 0.0500 (0.0500)  time: 5.3800  data: 3.9115  max mem: 7679\n",
            "Epoch: [81]  [ 10/147]  eta: 0:02:53  lr: 0.000529  min_lr: 0.000529  loss: 2.2849 (2.3856)  weight_decay: 0.0500 (0.0500)  time: 1.2630  data: 0.3560  max mem: 7679\n",
            "Epoch: [81]  [ 20/147]  eta: 0:02:16  lr: 0.000525  min_lr: 0.000525  loss: 2.4147 (2.3582)  weight_decay: 0.0500 (0.0500)  time: 0.8590  data: 0.0004  max mem: 7679\n",
            "Epoch: [81]  [ 30/147]  eta: 0:01:57  lr: 0.000522  min_lr: 0.000522  loss: 2.2722 (2.3139)  weight_decay: 0.0500 (0.0500)  time: 0.8590  data: 0.0004  max mem: 7679\n",
            "Epoch: [81]  [ 40/147]  eta: 0:01:43  lr: 0.000518  min_lr: 0.000518  loss: 2.2234 (2.2904)  weight_decay: 0.0500 (0.0500)  time: 0.8552  data: 0.0015  max mem: 7679\n",
            "Epoch: [81]  [ 50/147]  eta: 0:01:31  lr: 0.000515  min_lr: 0.000515  loss: 2.3098 (2.3043)  weight_decay: 0.0500 (0.0500)  time: 0.8529  data: 0.0015  max mem: 7679\n",
            "Epoch: [81]  [ 60/147]  eta: 0:01:20  lr: 0.000510  min_lr: 0.000510  loss: 2.4371 (2.3239)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0016  max mem: 7679\n",
            "Epoch: [81]  [ 70/147]  eta: 0:01:10  lr: 0.000507  min_lr: 0.000507  loss: 2.4517 (2.3296)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0018  max mem: 7679\n",
            "Epoch: [81]  [ 80/147]  eta: 0:01:00  lr: 0.000503  min_lr: 0.000503  loss: 2.3301 (2.3316)  weight_decay: 0.0500 (0.0500)  time: 0.8457  data: 0.0016  max mem: 7679\n",
            "Epoch: [81]  [ 90/147]  eta: 0:00:51  lr: 0.000500  min_lr: 0.000500  loss: 2.3658 (2.3407)  weight_decay: 0.0500 (0.0500)  time: 0.8459  data: 0.0014  max mem: 7679\n",
            "Epoch: [81]  [100/147]  eta: 0:00:42  lr: 0.000496  min_lr: 0.000496  loss: 2.4337 (2.3527)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0025  max mem: 7679\n",
            "Epoch: [81]  [110/147]  eta: 0:00:33  lr: 0.000493  min_lr: 0.000493  loss: 2.4887 (2.3627)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0029  max mem: 7679\n",
            "Epoch: [81]  [120/147]  eta: 0:00:24  lr: 0.000489  min_lr: 0.000489  loss: 2.4887 (2.3646)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0012  max mem: 7679\n",
            "Epoch: [81]  [130/147]  eta: 0:00:15  lr: 0.000486  min_lr: 0.000486  loss: 2.3581 (2.3613)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0008  max mem: 7679\n",
            "Epoch: [81]  [140/147]  eta: 0:00:06  lr: 0.000481  min_lr: 0.000481  loss: 2.2912 (2.3648)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0002  max mem: 7679\n",
            "Epoch: [81]  [146/147]  eta: 0:00:00  lr: 0.000481  min_lr: 0.000481  loss: 2.4597 (2.3682)  weight_decay: 0.0500 (0.0500)  time: 0.7235  data: 0.0002  max mem: 7679\n",
            "Epoch: [81] Total time: 0:02:07 (0.8674 s / it)\n",
            "Averaged stats: lr: 0.000481  min_lr: 0.000481  loss: 2.4597 (2.3682)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:04:01  loss: 0.5106 (0.5106)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 5.8870  data: 5.4180  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 0.5414 (0.5515)  acc1: 89.5833 (89.6780)  acc5: 97.9167 (98.2955)  time: 0.8999  data: 0.4962  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.5425 (0.6933)  acc1: 88.5417 (84.0774)  acc5: 97.9167 (98.3631)  time: 0.4016  data: 0.0021  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.6415 (0.7054)  acc1: 85.4167 (83.5013)  acc5: 98.9583 (98.4879)  time: 0.4032  data: 0.0002  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6350 (0.6983)  acc1: 85.4167 (83.7962)  acc5: 97.9167 (98.3440)  time: 0.4040  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5464 s / it)\n",
            "* Acc@1 83.796 Acc@5 98.344 loss 0.698\n",
            "Accuracy of the model on the 3925 test images: 83.8%\n",
            "Max accuracy: 83.80%\n",
            "Test:  [ 0/41]  eta: 0:02:40  loss: 3.4953 (3.4953)  acc1: 11.4583 (11.4583)  acc5: 89.5833 (89.5833)  time: 3.9198  data: 3.4601  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 3.6621 (3.9076)  acc1: 8.3333 (15.5303)  acc5: 93.7500 (86.2689)  time: 0.7317  data: 0.3169  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 3.9389 (4.5628)  acc1: 7.2917 (11.6071)  acc5: 90.6250 (74.7024)  time: 0.4165  data: 0.0038  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3005 (4.8379)  acc1: 5.2083 (11.2567)  acc5: 56.2500 (67.9772)  time: 0.4153  data: 0.0026  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5568 (4.2835)  acc1: 19.7917 (21.7325)  acc5: 77.0833 (71.2611)  time: 0.4085  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5084 s / it)\n",
            "* Acc@1 21.732 Acc@5 71.261 loss 4.283\n",
            "Accuracy of the model EMA on 3925 test images: 21.7%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [82]  [  0/147]  eta: 0:09:59  lr: 0.000480  min_lr: 0.000480  loss: 2.6227 (2.6227)  weight_decay: 0.0500 (0.0500)  time: 4.0811  data: 3.0961  max mem: 7679\n",
            "Epoch: [82]  [ 10/147]  eta: 0:02:38  lr: 0.000477  min_lr: 0.000477  loss: 2.4513 (2.3728)  weight_decay: 0.0500 (0.0500)  time: 1.1573  data: 0.2860  max mem: 7679\n",
            "Epoch: [82]  [ 20/147]  eta: 0:02:08  lr: 0.000473  min_lr: 0.000473  loss: 2.2581 (2.2663)  weight_decay: 0.0500 (0.0500)  time: 0.8622  data: 0.0032  max mem: 7679\n",
            "Epoch: [82]  [ 30/147]  eta: 0:01:52  lr: 0.000470  min_lr: 0.000470  loss: 2.3211 (2.3094)  weight_decay: 0.0500 (0.0500)  time: 0.8566  data: 0.0011  max mem: 7679\n",
            "Epoch: [82]  [ 40/147]  eta: 0:01:40  lr: 0.000466  min_lr: 0.000466  loss: 2.3700 (2.2895)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0007  max mem: 7679\n",
            "Epoch: [82]  [ 50/147]  eta: 0:01:29  lr: 0.000463  min_lr: 0.000463  loss: 2.2753 (2.3075)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0010  max mem: 7679\n",
            "Epoch: [82]  [ 60/147]  eta: 0:01:18  lr: 0.000459  min_lr: 0.000459  loss: 2.3159 (2.3040)  weight_decay: 0.0500 (0.0500)  time: 0.8474  data: 0.0010  max mem: 7679\n",
            "Epoch: [82]  [ 70/147]  eta: 0:01:09  lr: 0.000456  min_lr: 0.000456  loss: 2.3220 (2.3144)  weight_decay: 0.0500 (0.0500)  time: 0.8444  data: 0.0008  max mem: 7679\n",
            "Epoch: [82]  [ 80/147]  eta: 0:00:59  lr: 0.000452  min_lr: 0.000452  loss: 2.3368 (2.3108)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0018  max mem: 7679\n",
            "Epoch: [82]  [ 90/147]  eta: 0:00:50  lr: 0.000449  min_lr: 0.000449  loss: 2.3938 (2.3261)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0018  max mem: 7679\n",
            "Epoch: [82]  [100/147]  eta: 0:00:41  lr: 0.000445  min_lr: 0.000445  loss: 2.4307 (2.3134)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0015  max mem: 7679\n",
            "Epoch: [82]  [110/147]  eta: 0:00:32  lr: 0.000442  min_lr: 0.000442  loss: 2.3978 (2.3251)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0025  max mem: 7679\n",
            "Epoch: [82]  [120/147]  eta: 0:00:23  lr: 0.000438  min_lr: 0.000438  loss: 2.4074 (2.3267)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0023  max mem: 7679\n",
            "Epoch: [82]  [130/147]  eta: 0:00:14  lr: 0.000436  min_lr: 0.000436  loss: 2.3931 (2.3273)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0013  max mem: 7679\n",
            "Epoch: [82]  [140/147]  eta: 0:00:06  lr: 0.000432  min_lr: 0.000432  loss: 2.2594 (2.3211)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0006  max mem: 7679\n",
            "Epoch: [82]  [146/147]  eta: 0:00:00  lr: 0.000432  min_lr: 0.000432  loss: 2.2594 (2.3267)  weight_decay: 0.0500 (0.0500)  time: 0.7257  data: 0.0002  max mem: 7679\n",
            "Epoch: [82] Total time: 0:02:06 (0.8595 s / it)\n",
            "Averaged stats: lr: 0.000432  min_lr: 0.000432  loss: 2.2594 (2.3267)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:35  loss: 0.4882 (0.4882)  acc1: 90.6250 (90.6250)  acc5: 96.8750 (96.8750)  time: 3.7869  data: 3.3230  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5152 (0.5212)  acc1: 90.6250 (89.8674)  acc5: 97.9167 (98.4849)  time: 0.7162  data: 0.3028  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5762 (0.6727)  acc1: 87.5000 (83.8790)  acc5: 98.9583 (98.5119)  time: 0.4193  data: 0.0020  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6728 (0.6900)  acc1: 80.2083 (83.0309)  acc5: 98.9583 (98.3199)  time: 0.4168  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6242 (0.6744)  acc1: 83.3333 (83.7452)  acc5: 97.9167 (98.2420)  time: 0.4037  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5029 s / it)\n",
            "* Acc@1 83.745 Acc@5 98.242 loss 0.674\n",
            "Accuracy of the model on the 3925 test images: 83.7%\n",
            "Max accuracy: 83.80%\n",
            "Test:  [ 0/41]  eta: 0:01:49  loss: 3.4651 (3.4651)  acc1: 11.4583 (11.4583)  acc5: 89.5833 (89.5833)  time: 2.6680  data: 2.2210  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.6362 (3.8933)  acc1: 8.3333 (15.6250)  acc5: 94.7917 (86.3636)  time: 0.6896  data: 0.2687  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.8972 (4.5474)  acc1: 6.2500 (11.8056)  acc5: 90.6250 (74.7024)  time: 0.4585  data: 0.0373  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3075 (4.8304)  acc1: 5.2083 (11.3575)  acc5: 56.2500 (67.7755)  time: 0.4188  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5701 (4.2730)  acc1: 19.7917 (21.8089)  acc5: 76.0417 (71.1847)  time: 0.4075  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5004 s / it)\n",
            "* Acc@1 21.809 Acc@5 71.185 loss 4.273\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [83]  [  0/147]  eta: 0:12:41  lr: 0.000430  min_lr: 0.000430  loss: 2.8083 (2.8083)  weight_decay: 0.0500 (0.0500)  time: 5.1790  data: 3.9178  max mem: 7679\n",
            "Epoch: [83]  [ 10/147]  eta: 0:02:52  lr: 0.000428  min_lr: 0.000428  loss: 2.6272 (2.5271)  weight_decay: 0.0500 (0.0500)  time: 1.2578  data: 0.3565  max mem: 7679\n",
            "Epoch: [83]  [ 20/147]  eta: 0:02:15  lr: 0.000424  min_lr: 0.000424  loss: 2.3734 (2.3848)  weight_decay: 0.0500 (0.0500)  time: 0.8620  data: 0.0006  max mem: 7679\n",
            "Epoch: [83]  [ 30/147]  eta: 0:01:56  lr: 0.000421  min_lr: 0.000421  loss: 2.1695 (2.3415)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0009  max mem: 7679\n",
            "Epoch: [83]  [ 40/147]  eta: 0:01:42  lr: 0.000417  min_lr: 0.000417  loss: 2.3479 (2.3492)  weight_decay: 0.0500 (0.0500)  time: 0.8521  data: 0.0015  max mem: 7679\n",
            "Epoch: [83]  [ 50/147]  eta: 0:01:31  lr: 0.000414  min_lr: 0.000414  loss: 2.3519 (2.3535)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0014  max mem: 7679\n",
            "Epoch: [83]  [ 60/147]  eta: 0:01:20  lr: 0.000410  min_lr: 0.000410  loss: 2.3838 (2.3647)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0006  max mem: 7679\n",
            "Epoch: [83]  [ 70/147]  eta: 0:01:10  lr: 0.000408  min_lr: 0.000408  loss: 2.3867 (2.3503)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0007  max mem: 7679\n",
            "Epoch: [83]  [ 80/147]  eta: 0:01:00  lr: 0.000404  min_lr: 0.000404  loss: 2.3867 (2.3617)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0017  max mem: 7679\n",
            "Epoch: [83]  [ 90/147]  eta: 0:00:51  lr: 0.000401  min_lr: 0.000401  loss: 2.4040 (2.3627)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0014  max mem: 7679\n",
            "Epoch: [83]  [100/147]  eta: 0:00:42  lr: 0.000397  min_lr: 0.000397  loss: 2.3388 (2.3575)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0015  max mem: 7679\n",
            "Epoch: [83]  [110/147]  eta: 0:00:32  lr: 0.000394  min_lr: 0.000394  loss: 2.4720 (2.3654)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0023  max mem: 7679\n",
            "Epoch: [83]  [120/147]  eta: 0:00:23  lr: 0.000391  min_lr: 0.000391  loss: 2.5036 (2.3742)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0022  max mem: 7679\n",
            "Epoch: [83]  [130/147]  eta: 0:00:15  lr: 0.000388  min_lr: 0.000388  loss: 2.5124 (2.3834)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0014  max mem: 7679\n",
            "Epoch: [83]  [140/147]  eta: 0:00:06  lr: 0.000384  min_lr: 0.000384  loss: 2.4602 (2.3808)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0003  max mem: 7679\n",
            "Epoch: [83]  [146/147]  eta: 0:00:00  lr: 0.000384  min_lr: 0.000384  loss: 2.4143 (2.3757)  weight_decay: 0.0500 (0.0500)  time: 0.7231  data: 0.0002  max mem: 7679\n",
            "Epoch: [83] Total time: 0:02:07 (0.8660 s / it)\n",
            "Averaged stats: lr: 0.000384  min_lr: 0.000384  loss: 2.4143 (2.3757)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:03  loss: 0.4964 (0.4964)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 4.4861  data: 4.0277  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5487 (0.5615)  acc1: 89.5833 (89.3939)  acc5: 97.9167 (98.6742)  time: 0.7903  data: 0.3830  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5840 (0.6743)  acc1: 88.5417 (84.2758)  acc5: 97.9167 (98.5615)  time: 0.4100  data: 0.0104  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7205 (0.7021)  acc1: 80.2083 (83.3333)  acc5: 97.9167 (98.3871)  time: 0.4014  data: 0.0012  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6537 (0.6887)  acc1: 83.3333 (84.0510)  acc5: 97.9167 (98.1911)  time: 0.4036  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5160 s / it)\n",
            "* Acc@1 84.051 Acc@5 98.191 loss 0.689\n",
            "Accuracy of the model on the 3925 test images: 84.1%\n",
            "Max accuracy: 84.05%\n",
            "Test:  [ 0/41]  eta: 0:02:30  loss: 3.4358 (3.4358)  acc1: 10.4167 (10.4167)  acc5: 89.5833 (89.5833)  time: 3.6718  data: 3.2236  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 3.6109 (3.8787)  acc1: 8.3333 (15.2462)  acc5: 94.7917 (86.1742)  time: 0.7242  data: 0.2955  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 3.8545 (4.5311)  acc1: 5.2083 (11.6567)  acc5: 90.6250 (74.5536)  time: 0.4267  data: 0.0022  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3141 (4.8220)  acc1: 4.1667 (11.2231)  acc5: 55.2083 (67.6747)  time: 0.4183  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5823 (4.2619)  acc1: 19.7917 (21.7580)  acc5: 76.0417 (71.1592)  time: 0.4106  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5119 s / it)\n",
            "* Acc@1 21.758 Acc@5 71.159 loss 4.262\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [84]  [  0/147]  eta: 0:14:01  lr: 0.000383  min_lr: 0.000383  loss: 2.3755 (2.3755)  weight_decay: 0.0500 (0.0500)  time: 5.7255  data: 3.5635  max mem: 7679\n",
            "Epoch: [84]  [ 10/147]  eta: 0:02:59  lr: 0.000380  min_lr: 0.000380  loss: 2.5726 (2.4719)  weight_decay: 0.0500 (0.0500)  time: 1.3108  data: 0.3274  max mem: 7679\n",
            "Epoch: [84]  [ 20/147]  eta: 0:02:18  lr: 0.000376  min_lr: 0.000376  loss: 2.5383 (2.4760)  weight_decay: 0.0500 (0.0500)  time: 0.8612  data: 0.0021  max mem: 7679\n",
            "Epoch: [84]  [ 30/147]  eta: 0:01:58  lr: 0.000374  min_lr: 0.000374  loss: 2.4896 (2.4292)  weight_decay: 0.0500 (0.0500)  time: 0.8536  data: 0.0003  max mem: 7679\n",
            "Epoch: [84]  [ 40/147]  eta: 0:01:44  lr: 0.000370  min_lr: 0.000370  loss: 2.3893 (2.3988)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0006  max mem: 7679\n",
            "Epoch: [84]  [ 50/147]  eta: 0:01:32  lr: 0.000368  min_lr: 0.000368  loss: 2.3893 (2.3919)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0013  max mem: 7679\n",
            "Epoch: [84]  [ 60/147]  eta: 0:01:21  lr: 0.000364  min_lr: 0.000364  loss: 2.3909 (2.3743)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0012  max mem: 7679\n",
            "Epoch: [84]  [ 70/147]  eta: 0:01:11  lr: 0.000361  min_lr: 0.000361  loss: 2.3107 (2.3590)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0007  max mem: 7679\n",
            "Epoch: [84]  [ 80/147]  eta: 0:01:01  lr: 0.000358  min_lr: 0.000358  loss: 2.3304 (2.3639)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0005  max mem: 7679\n",
            "Epoch: [84]  [ 90/147]  eta: 0:00:51  lr: 0.000355  min_lr: 0.000355  loss: 2.3732 (2.3498)  weight_decay: 0.0500 (0.0500)  time: 0.8489  data: 0.0009  max mem: 7679\n",
            "Epoch: [84]  [100/147]  eta: 0:00:42  lr: 0.000351  min_lr: 0.000351  loss: 2.1724 (2.3424)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0010  max mem: 7679\n",
            "Epoch: [84]  [110/147]  eta: 0:00:33  lr: 0.000349  min_lr: 0.000349  loss: 2.3422 (2.3493)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0009  max mem: 7679\n",
            "Epoch: [84]  [120/147]  eta: 0:00:24  lr: 0.000345  min_lr: 0.000345  loss: 2.4224 (2.3504)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0019  max mem: 7679\n",
            "Epoch: [84]  [130/147]  eta: 0:00:15  lr: 0.000343  min_lr: 0.000343  loss: 2.4400 (2.3501)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0026  max mem: 7679\n",
            "Epoch: [84]  [140/147]  eta: 0:00:06  lr: 0.000339  min_lr: 0.000339  loss: 2.5251 (2.3620)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0013  max mem: 7679\n",
            "Epoch: [84]  [146/147]  eta: 0:00:00  lr: 0.000339  min_lr: 0.000339  loss: 2.5251 (2.3600)  weight_decay: 0.0500 (0.0500)  time: 0.7228  data: 0.0002  max mem: 7679\n",
            "Epoch: [84] Total time: 0:02:08 (0.8711 s / it)\n",
            "Averaged stats: lr: 0.000339  min_lr: 0.000339  loss: 2.5251 (2.3600)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:09  loss: 0.5688 (0.5688)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.1545  data: 2.7144  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5357 (0.5319)  acc1: 90.6250 (90.5303)  acc5: 97.9167 (98.3902)  time: 0.6653  data: 0.2480  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5357 (0.6538)  acc1: 88.5417 (85.3671)  acc5: 97.9167 (98.5119)  time: 0.4146  data: 0.0027  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6453 (0.6811)  acc1: 82.2917 (83.9718)  acc5: 98.9583 (98.5215)  time: 0.4086  data: 0.0021  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6310 (0.6780)  acc1: 84.3750 (84.0510)  acc5: 97.9167 (98.2420)  time: 0.4038  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4874 s / it)\n",
            "* Acc@1 84.051 Acc@5 98.242 loss 0.678\n",
            "Accuracy of the model on the 3925 test images: 84.1%\n",
            "Max accuracy: 84.05%\n",
            "Test:  [ 0/41]  eta: 0:03:56  loss: 3.4039 (3.4039)  acc1: 10.4167 (10.4167)  acc5: 90.6250 (90.6250)  time: 5.7599  data: 5.3096  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 3.5829 (3.8633)  acc1: 9.3750 (15.5303)  acc5: 94.7917 (86.2689)  time: 0.8997  data: 0.4874  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 3.8130 (4.5146)  acc1: 7.2917 (11.9048)  acc5: 90.6250 (74.6032)  time: 0.4102  data: 0.0031  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3186 (4.8128)  acc1: 4.1667 (11.3239)  acc5: 55.2083 (67.5403)  time: 0.4087  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.5927 (4.2503)  acc1: 19.7917 (21.8599)  acc5: 76.0417 (71.1338)  time: 0.4091  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5524 s / it)\n",
            "* Acc@1 21.860 Acc@5 71.134 loss 4.250\n",
            "Accuracy of the model EMA on 3925 test images: 21.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [85]  [  0/147]  eta: 0:08:39  lr: 0.000338  min_lr: 0.000338  loss: 2.6752 (2.6752)  weight_decay: 0.0500 (0.0500)  time: 3.5322  data: 2.6190  max mem: 7679\n",
            "Epoch: [85]  [ 10/147]  eta: 0:02:31  lr: 0.000336  min_lr: 0.000336  loss: 2.4950 (2.4360)  weight_decay: 0.0500 (0.0500)  time: 1.1070  data: 0.2390  max mem: 7679\n",
            "Epoch: [85]  [ 20/147]  eta: 0:02:05  lr: 0.000332  min_lr: 0.000332  loss: 2.4839 (2.4477)  weight_decay: 0.0500 (0.0500)  time: 0.8624  data: 0.0006  max mem: 7679\n",
            "Epoch: [85]  [ 30/147]  eta: 0:01:50  lr: 0.000330  min_lr: 0.000330  loss: 2.4299 (2.3731)  weight_decay: 0.0500 (0.0500)  time: 0.8535  data: 0.0004  max mem: 7679\n",
            "Epoch: [85]  [ 40/147]  eta: 0:01:38  lr: 0.000326  min_lr: 0.000326  loss: 2.4088 (2.3820)  weight_decay: 0.0500 (0.0500)  time: 0.8486  data: 0.0005  max mem: 7679\n",
            "Epoch: [85]  [ 50/147]  eta: 0:01:27  lr: 0.000324  min_lr: 0.000324  loss: 2.4246 (2.3891)  weight_decay: 0.0500 (0.0500)  time: 0.8472  data: 0.0009  max mem: 7679\n",
            "Epoch: [85]  [ 60/147]  eta: 0:01:17  lr: 0.000320  min_lr: 0.000320  loss: 2.3736 (2.3656)  weight_decay: 0.0500 (0.0500)  time: 0.8452  data: 0.0014  max mem: 7679\n",
            "Epoch: [85]  [ 70/147]  eta: 0:01:08  lr: 0.000318  min_lr: 0.000318  loss: 2.0945 (2.3300)  weight_decay: 0.0500 (0.0500)  time: 0.8451  data: 0.0011  max mem: 7679\n",
            "Epoch: [85]  [ 80/147]  eta: 0:00:59  lr: 0.000314  min_lr: 0.000314  loss: 2.1688 (2.3295)  weight_decay: 0.0500 (0.0500)  time: 0.8456  data: 0.0012  max mem: 7679\n",
            "Epoch: [85]  [ 90/147]  eta: 0:00:50  lr: 0.000312  min_lr: 0.000312  loss: 2.4155 (2.3379)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0024  max mem: 7679\n",
            "Epoch: [85]  [100/147]  eta: 0:00:41  lr: 0.000308  min_lr: 0.000308  loss: 2.4155 (2.3355)  weight_decay: 0.0500 (0.0500)  time: 0.8573  data: 0.0029  max mem: 7679\n",
            "Epoch: [85]  [110/147]  eta: 0:00:32  lr: 0.000306  min_lr: 0.000306  loss: 2.3816 (2.3386)  weight_decay: 0.0500 (0.0500)  time: 0.8546  data: 0.0021  max mem: 7679\n",
            "Epoch: [85]  [120/147]  eta: 0:00:23  lr: 0.000303  min_lr: 0.000303  loss: 2.5012 (2.3498)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0017  max mem: 7679\n",
            "Epoch: [85]  [130/147]  eta: 0:00:14  lr: 0.000300  min_lr: 0.000300  loss: 2.4865 (2.3419)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0015  max mem: 7679\n",
            "Epoch: [85]  [140/147]  eta: 0:00:06  lr: 0.000297  min_lr: 0.000297  loss: 2.3190 (2.3398)  weight_decay: 0.0500 (0.0500)  time: 0.8477  data: 0.0004  max mem: 7679\n",
            "Epoch: [85]  [146/147]  eta: 0:00:00  lr: 0.000297  min_lr: 0.000297  loss: 2.3190 (2.3355)  weight_decay: 0.0500 (0.0500)  time: 0.7222  data: 0.0002  max mem: 7679\n",
            "Epoch: [85] Total time: 0:02:05 (0.8550 s / it)\n",
            "Averaged stats: lr: 0.000297  min_lr: 0.000297  loss: 2.3190 (2.3355)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:27  loss: 0.4885 (0.4885)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 5.0610  data: 4.5927  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 0.5108 (0.5247)  acc1: 90.6250 (89.6780)  acc5: 97.9167 (98.3902)  time: 0.8246  data: 0.4209  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.5314 (0.6800)  acc1: 87.5000 (83.5814)  acc5: 98.9583 (98.3135)  time: 0.4004  data: 0.0031  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.6511 (0.6863)  acc1: 82.2917 (83.2661)  acc5: 98.9583 (98.3871)  time: 0.4011  data: 0.0013  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5870 (0.6726)  acc1: 84.3750 (83.8726)  acc5: 97.9167 (98.2166)  time: 0.4022  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5239 s / it)\n",
            "* Acc@1 83.873 Acc@5 98.217 loss 0.673\n",
            "Accuracy of the model on the 3925 test images: 83.9%\n",
            "Max accuracy: 84.05%\n",
            "Test:  [ 0/41]  eta: 0:02:44  loss: 3.3731 (3.3731)  acc1: 10.4167 (10.4167)  acc5: 90.6250 (90.6250)  time: 4.0045  data: 3.5516  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 3.5557 (3.8494)  acc1: 9.3750 (15.5303)  acc5: 94.7917 (86.1742)  time: 0.7379  data: 0.3262  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 3.7723 (4.4993)  acc1: 8.3333 (12.0040)  acc5: 90.6250 (74.6528)  time: 0.4155  data: 0.0043  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3232 (4.8049)  acc1: 4.1667 (11.1895)  acc5: 55.2083 (67.4731)  time: 0.4175  data: 0.0025  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6053 (4.2400)  acc1: 19.7917 (21.8089)  acc5: 76.0417 (71.1083)  time: 0.4121  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5101 s / it)\n",
            "* Acc@1 21.809 Acc@5 71.108 loss 4.240\n",
            "Accuracy of the model EMA on 3925 test images: 21.8%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [86]  [  0/147]  eta: 0:05:52  lr: 0.000296  min_lr: 0.000296  loss: 2.1476 (2.1476)  weight_decay: 0.0500 (0.0500)  time: 2.3989  data: 1.4114  max mem: 7679\n",
            "Epoch: [86]  [ 10/147]  eta: 0:02:26  lr: 0.000293  min_lr: 0.000293  loss: 2.5568 (2.3806)  weight_decay: 0.0500 (0.0500)  time: 1.0723  data: 0.1913  max mem: 7679\n",
            "Epoch: [86]  [ 20/147]  eta: 0:02:02  lr: 0.000290  min_lr: 0.000290  loss: 2.3588 (2.3218)  weight_decay: 0.0500 (0.0500)  time: 0.8969  data: 0.0349  max mem: 7679\n",
            "Epoch: [86]  [ 30/147]  eta: 0:01:48  lr: 0.000288  min_lr: 0.000288  loss: 2.3548 (2.3269)  weight_decay: 0.0500 (0.0500)  time: 0.8540  data: 0.0010  max mem: 7679\n",
            "Epoch: [86]  [ 40/147]  eta: 0:01:37  lr: 0.000284  min_lr: 0.000284  loss: 2.3902 (2.3149)  weight_decay: 0.0500 (0.0500)  time: 0.8538  data: 0.0009  max mem: 7679\n",
            "Epoch: [86]  [ 50/147]  eta: 0:01:27  lr: 0.000282  min_lr: 0.000282  loss: 2.1778 (2.2807)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0005  max mem: 7679\n",
            "Epoch: [86]  [ 60/147]  eta: 0:01:17  lr: 0.000279  min_lr: 0.000279  loss: 2.2204 (2.2852)  weight_decay: 0.0500 (0.0500)  time: 0.8469  data: 0.0006  max mem: 7679\n",
            "Epoch: [86]  [ 70/147]  eta: 0:01:08  lr: 0.000277  min_lr: 0.000277  loss: 2.3194 (2.2808)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0010  max mem: 7679\n",
            "Epoch: [86]  [ 80/147]  eta: 0:00:59  lr: 0.000273  min_lr: 0.000273  loss: 2.3030 (2.2823)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0009  max mem: 7679\n",
            "Epoch: [86]  [ 90/147]  eta: 0:00:50  lr: 0.000271  min_lr: 0.000271  loss: 2.4446 (2.3087)  weight_decay: 0.0500 (0.0500)  time: 0.8548  data: 0.0011  max mem: 7679\n",
            "Epoch: [86]  [100/147]  eta: 0:00:41  lr: 0.000268  min_lr: 0.000268  loss: 2.4663 (2.3079)  weight_decay: 0.0500 (0.0500)  time: 0.8811  data: 0.0016  max mem: 7679\n",
            "Epoch: [86]  [110/147]  eta: 0:00:32  lr: 0.000266  min_lr: 0.000266  loss: 2.3538 (2.3129)  weight_decay: 0.0500 (0.0500)  time: 0.8752  data: 0.0009  max mem: 7679\n",
            "Epoch: [86]  [120/147]  eta: 0:00:23  lr: 0.000262  min_lr: 0.000262  loss: 2.4331 (2.3239)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0005  max mem: 7679\n",
            "Epoch: [86]  [130/147]  eta: 0:00:14  lr: 0.000260  min_lr: 0.000260  loss: 2.5207 (2.3373)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0005  max mem: 7679\n",
            "Epoch: [86]  [140/147]  eta: 0:00:06  lr: 0.000257  min_lr: 0.000257  loss: 2.3951 (2.3350)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0004  max mem: 7679\n",
            "Epoch: [86]  [146/147]  eta: 0:00:00  lr: 0.000257  min_lr: 0.000257  loss: 2.3712 (2.3289)  weight_decay: 0.0500 (0.0500)  time: 0.7244  data: 0.0002  max mem: 7679\n",
            "Epoch: [86] Total time: 0:02:06 (0.8592 s / it)\n",
            "Averaged stats: lr: 0.000257  min_lr: 0.000257  loss: 2.3712 (2.3289)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:55  loss: 0.5486 (0.5486)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 2.8165  data: 2.3710  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:19  loss: 0.5486 (0.5429)  acc1: 89.5833 (90.2462)  acc5: 97.9167 (98.4849)  time: 0.6315  data: 0.2281  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:10  loss: 0.5626 (0.6670)  acc1: 88.5417 (84.4246)  acc5: 98.9583 (98.5615)  time: 0.4082  data: 0.0075  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6759 (0.6788)  acc1: 82.2917 (84.0054)  acc5: 98.9583 (98.5887)  time: 0.4039  data: 0.0007  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6044 (0.6681)  acc1: 85.4167 (84.4076)  acc5: 97.9167 (98.3694)  time: 0.4034  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4751 s / it)\n",
            "* Acc@1 84.408 Acc@5 98.369 loss 0.668\n",
            "Accuracy of the model on the 3925 test images: 84.4%\n",
            "Max accuracy: 84.41%\n",
            "Test:  [ 0/41]  eta: 0:02:19  loss: 3.3426 (3.3426)  acc1: 10.4167 (10.4167)  acc5: 90.6250 (90.6250)  time: 3.4112  data: 2.9407  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.5287 (3.8354)  acc1: 9.3750 (15.7197)  acc5: 94.7917 (86.1742)  time: 0.7013  data: 0.2695  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.7313 (4.4837)  acc1: 8.3333 (12.0536)  acc5: 90.6250 (74.5536)  time: 0.4290  data: 0.0040  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3279 (4.7966)  acc1: 4.1667 (11.2231)  acc5: 53.1250 (67.3051)  time: 0.4198  data: 0.0029  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6169 (4.2294)  acc1: 19.7917 (21.9873)  acc5: 76.0417 (70.9554)  time: 0.4094  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5020 s / it)\n",
            "* Acc@1 21.987 Acc@5 70.955 loss 4.229\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [87]  [  0/147]  eta: 0:11:16  lr: 0.000256  min_lr: 0.000256  loss: 1.9434 (1.9434)  weight_decay: 0.0500 (0.0500)  time: 4.6011  data: 2.6605  max mem: 7679\n",
            "Epoch: [87]  [ 10/147]  eta: 0:02:44  lr: 0.000254  min_lr: 0.000254  loss: 2.2851 (2.1692)  weight_decay: 0.0500 (0.0500)  time: 1.2042  data: 0.2423  max mem: 7679\n",
            "Epoch: [87]  [ 20/147]  eta: 0:02:12  lr: 0.000251  min_lr: 0.000251  loss: 2.3273 (2.2210)  weight_decay: 0.0500 (0.0500)  time: 0.8614  data: 0.0005  max mem: 7679\n",
            "Epoch: [87]  [ 30/147]  eta: 0:01:54  lr: 0.000249  min_lr: 0.000249  loss: 2.3404 (2.2138)  weight_decay: 0.0500 (0.0500)  time: 0.8568  data: 0.0006  max mem: 7679\n",
            "Epoch: [87]  [ 40/147]  eta: 0:01:41  lr: 0.000245  min_lr: 0.000245  loss: 2.2434 (2.2237)  weight_decay: 0.0500 (0.0500)  time: 0.8550  data: 0.0007  max mem: 7679\n",
            "Epoch: [87]  [ 50/147]  eta: 0:01:30  lr: 0.000243  min_lr: 0.000243  loss: 2.2579 (2.2394)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0010  max mem: 7679\n",
            "Epoch: [87]  [ 60/147]  eta: 0:01:19  lr: 0.000240  min_lr: 0.000240  loss: 2.4541 (2.2756)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0015  max mem: 7679\n",
            "Epoch: [87]  [ 70/147]  eta: 0:01:09  lr: 0.000238  min_lr: 0.000238  loss: 2.4456 (2.2807)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0013  max mem: 7679\n",
            "Epoch: [87]  [ 80/147]  eta: 0:01:00  lr: 0.000235  min_lr: 0.000235  loss: 2.4267 (2.2862)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0026  max mem: 7679\n",
            "Epoch: [87]  [ 90/147]  eta: 0:00:50  lr: 0.000233  min_lr: 0.000233  loss: 2.4647 (2.2956)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0027  max mem: 7679\n",
            "Epoch: [87]  [100/147]  eta: 0:00:41  lr: 0.000230  min_lr: 0.000230  loss: 2.3574 (2.2960)  weight_decay: 0.0500 (0.0500)  time: 0.8497  data: 0.0024  max mem: 7679\n",
            "Epoch: [87]  [110/147]  eta: 0:00:32  lr: 0.000228  min_lr: 0.000228  loss: 2.3574 (2.3078)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0022  max mem: 7679\n",
            "Epoch: [87]  [120/147]  eta: 0:00:23  lr: 0.000225  min_lr: 0.000225  loss: 2.4911 (2.3246)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0018  max mem: 7679\n",
            "Epoch: [87]  [130/147]  eta: 0:00:14  lr: 0.000223  min_lr: 0.000223  loss: 2.5288 (2.3366)  weight_decay: 0.0500 (0.0500)  time: 0.8507  data: 0.0017  max mem: 7679\n",
            "Epoch: [87]  [140/147]  eta: 0:00:06  lr: 0.000220  min_lr: 0.000220  loss: 2.2828 (2.3228)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0005  max mem: 7679\n",
            "Epoch: [87]  [146/147]  eta: 0:00:00  lr: 0.000220  min_lr: 0.000220  loss: 2.2828 (2.3214)  weight_decay: 0.0500 (0.0500)  time: 0.7272  data: 0.0003  max mem: 7679\n",
            "Epoch: [87] Total time: 0:02:06 (0.8633 s / it)\n",
            "Averaged stats: lr: 0.000220  min_lr: 0.000220  loss: 2.2828 (2.3214)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:52  loss: 0.5612 (0.5612)  acc1: 89.5833 (89.5833)  acc5: 97.9167 (97.9167)  time: 5.6678  data: 5.2077  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 0.5940 (0.5763)  acc1: 88.5417 (88.6364)  acc5: 97.9167 (98.2008)  time: 0.8946  data: 0.4810  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 0.5940 (0.6757)  acc1: 87.5000 (84.1270)  acc5: 97.9167 (98.5119)  time: 0.4101  data: 0.0057  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 0.6482 (0.6682)  acc1: 85.4167 (84.3078)  acc5: 98.9583 (98.4879)  time: 0.4035  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6147 (0.6618)  acc1: 85.8824 (84.6624)  acc5: 97.9167 (98.2930)  time: 0.4051  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5496 s / it)\n",
            "* Acc@1 84.662 Acc@5 98.293 loss 0.662\n",
            "Accuracy of the model on the 3925 test images: 84.7%\n",
            "Max accuracy: 84.66%\n",
            "Test:  [ 0/41]  eta: 0:02:16  loss: 3.3139 (3.3139)  acc1: 10.4167 (10.4167)  acc5: 91.6667 (91.6667)  time: 3.3369  data: 2.8859  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.5032 (3.8213)  acc1: 10.4167 (15.8144)  acc5: 94.7917 (86.0795)  time: 0.6832  data: 0.2690  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.6913 (4.4682)  acc1: 8.3333 (12.2024)  acc5: 89.5833 (74.1567)  time: 0.4165  data: 0.0055  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3346 (4.7881)  acc1: 4.1667 (11.2231)  acc5: 51.0417 (67.0363)  time: 0.4133  data: 0.0026  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6272 (4.2187)  acc1: 19.7917 (22.0382)  acc5: 76.0417 (70.7771)  time: 0.4102  data: 0.0008  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4934 s / it)\n",
            "* Acc@1 22.038 Acc@5 70.777 loss 4.219\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [88]  [  0/147]  eta: 0:07:34  lr: 0.000219  min_lr: 0.000219  loss: 2.2709 (2.2709)  weight_decay: 0.0500 (0.0500)  time: 3.0934  data: 2.1437  max mem: 7679\n",
            "Epoch: [88]  [ 10/147]  eta: 0:02:27  lr: 0.000217  min_lr: 0.000217  loss: 2.2709 (2.3373)  weight_decay: 0.0500 (0.0500)  time: 1.0731  data: 0.1960  max mem: 7679\n",
            "Epoch: [88]  [ 20/147]  eta: 0:02:03  lr: 0.000214  min_lr: 0.000214  loss: 2.3170 (2.3137)  weight_decay: 0.0500 (0.0500)  time: 0.8641  data: 0.0010  max mem: 7679\n",
            "Epoch: [88]  [ 30/147]  eta: 0:01:49  lr: 0.000212  min_lr: 0.000212  loss: 2.3170 (2.2895)  weight_decay: 0.0500 (0.0500)  time: 0.8551  data: 0.0006  max mem: 7679\n",
            "Epoch: [88]  [ 40/147]  eta: 0:01:37  lr: 0.000209  min_lr: 0.000209  loss: 2.3481 (2.3184)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0006  max mem: 7679\n",
            "Epoch: [88]  [ 50/147]  eta: 0:01:27  lr: 0.000207  min_lr: 0.000207  loss: 2.3621 (2.3124)  weight_decay: 0.0500 (0.0500)  time: 0.8474  data: 0.0007  max mem: 7679\n",
            "Epoch: [88]  [ 60/147]  eta: 0:01:17  lr: 0.000204  min_lr: 0.000204  loss: 2.4332 (2.3289)  weight_decay: 0.0500 (0.0500)  time: 0.8468  data: 0.0011  max mem: 7679\n",
            "Epoch: [88]  [ 70/147]  eta: 0:01:08  lr: 0.000202  min_lr: 0.000202  loss: 2.4304 (2.3337)  weight_decay: 0.0500 (0.0500)  time: 0.8466  data: 0.0015  max mem: 7679\n",
            "Epoch: [88]  [ 80/147]  eta: 0:00:58  lr: 0.000200  min_lr: 0.000200  loss: 2.4184 (2.3325)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0012  max mem: 7679\n",
            "Epoch: [88]  [ 90/147]  eta: 0:00:49  lr: 0.000198  min_lr: 0.000198  loss: 2.4114 (2.3410)  weight_decay: 0.0500 (0.0500)  time: 0.8513  data: 0.0019  max mem: 7679\n",
            "Epoch: [88]  [100/147]  eta: 0:00:41  lr: 0.000195  min_lr: 0.000195  loss: 2.4114 (2.3450)  weight_decay: 0.0500 (0.0500)  time: 0.8541  data: 0.0018  max mem: 7679\n",
            "Epoch: [88]  [110/147]  eta: 0:00:32  lr: 0.000193  min_lr: 0.000193  loss: 2.3920 (2.3468)  weight_decay: 0.0500 (0.0500)  time: 0.8541  data: 0.0007  max mem: 7679\n",
            "Epoch: [88]  [120/147]  eta: 0:00:23  lr: 0.000190  min_lr: 0.000190  loss: 2.4940 (2.3550)  weight_decay: 0.0500 (0.0500)  time: 0.8543  data: 0.0013  max mem: 7679\n",
            "Epoch: [88]  [130/147]  eta: 0:00:14  lr: 0.000188  min_lr: 0.000188  loss: 2.4941 (2.3542)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0012  max mem: 7679\n",
            "Epoch: [88]  [140/147]  eta: 0:00:06  lr: 0.000186  min_lr: 0.000186  loss: 2.3187 (2.3552)  weight_decay: 0.0500 (0.0500)  time: 0.8489  data: 0.0003  max mem: 7679\n",
            "Epoch: [88]  [146/147]  eta: 0:00:00  lr: 0.000186  min_lr: 0.000186  loss: 2.3187 (2.3581)  weight_decay: 0.0500 (0.0500)  time: 0.7234  data: 0.0002  max mem: 7679\n",
            "Epoch: [88] Total time: 0:02:05 (0.8530 s / it)\n",
            "Averaged stats: lr: 0.000186  min_lr: 0.000186  loss: 2.3187 (2.3581)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:30  loss: 0.5003 (0.5003)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 3.6792  data: 3.2092  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5256 (0.5203)  acc1: 89.5833 (90.5303)  acc5: 98.9583 (98.6742)  time: 0.7148  data: 0.2943  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5629 (0.6690)  acc1: 88.5417 (84.2758)  acc5: 97.9167 (98.5119)  time: 0.4164  data: 0.0040  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6902 (0.6917)  acc1: 81.2500 (83.8710)  acc5: 98.9583 (98.5215)  time: 0.4084  data: 0.0027  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6086 (0.6713)  acc1: 87.0588 (84.4841)  acc5: 97.9167 (98.3694)  time: 0.4022  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4985 s / it)\n",
            "* Acc@1 84.484 Acc@5 98.369 loss 0.671\n",
            "Accuracy of the model on the 3925 test images: 84.5%\n",
            "Max accuracy: 84.66%\n",
            "Test:  [ 0/41]  eta: 0:03:14  loss: 3.2854 (3.2854)  acc1: 10.4167 (10.4167)  acc5: 92.7083 (92.7083)  time: 4.7534  data: 4.3184  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 3.4776 (3.8071)  acc1: 10.4167 (15.8144)  acc5: 94.7917 (85.9849)  time: 0.8166  data: 0.3992  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 3.6519 (4.4526)  acc1: 8.3333 (12.1528)  acc5: 89.5833 (74.1567)  time: 0.4195  data: 0.0053  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3407 (4.7790)  acc1: 3.1250 (10.9879)  acc5: 51.0417 (67.1035)  time: 0.4117  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6352 (4.2077)  acc1: 19.7917 (21.9873)  acc5: 76.0417 (70.8535)  time: 0.4058  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5346 s / it)\n",
            "* Acc@1 21.987 Acc@5 70.854 loss 4.208\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [89]  [  0/147]  eta: 0:10:58  lr: 0.000185  min_lr: 0.000185  loss: 2.5636 (2.5636)  weight_decay: 0.0500 (0.0500)  time: 4.4804  data: 3.0438  max mem: 7679\n",
            "Epoch: [89]  [ 10/147]  eta: 0:02:42  lr: 0.000183  min_lr: 0.000183  loss: 2.4150 (2.3130)  weight_decay: 0.0500 (0.0500)  time: 1.1883  data: 0.2842  max mem: 7679\n",
            "Epoch: [89]  [ 20/147]  eta: 0:02:11  lr: 0.000180  min_lr: 0.000180  loss: 2.3959 (2.2907)  weight_decay: 0.0500 (0.0500)  time: 0.8600  data: 0.0047  max mem: 7679\n",
            "Epoch: [89]  [ 30/147]  eta: 0:01:53  lr: 0.000178  min_lr: 0.000178  loss: 2.4294 (2.3196)  weight_decay: 0.0500 (0.0500)  time: 0.8567  data: 0.0007  max mem: 7679\n",
            "Epoch: [89]  [ 40/147]  eta: 0:01:41  lr: 0.000176  min_lr: 0.000176  loss: 2.4294 (2.3156)  weight_decay: 0.0500 (0.0500)  time: 0.8560  data: 0.0004  max mem: 7679\n",
            "Epoch: [89]  [ 50/147]  eta: 0:01:29  lr: 0.000174  min_lr: 0.000174  loss: 2.2139 (2.3032)  weight_decay: 0.0500 (0.0500)  time: 0.8524  data: 0.0005  max mem: 7679\n",
            "Epoch: [89]  [ 60/147]  eta: 0:01:19  lr: 0.000171  min_lr: 0.000171  loss: 2.2552 (2.2996)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0010  max mem: 7679\n",
            "Epoch: [89]  [ 70/147]  eta: 0:01:10  lr: 0.000169  min_lr: 0.000169  loss: 2.3816 (2.3072)  weight_decay: 0.0500 (0.0500)  time: 0.9087  data: 0.0010  max mem: 7679\n",
            "Epoch: [89]  [ 80/147]  eta: 0:01:01  lr: 0.000167  min_lr: 0.000167  loss: 2.3400 (2.2971)  weight_decay: 0.0500 (0.0500)  time: 0.9052  data: 0.0005  max mem: 7679\n",
            "Epoch: [89]  [ 90/147]  eta: 0:00:51  lr: 0.000165  min_lr: 0.000165  loss: 2.3856 (2.3058)  weight_decay: 0.0500 (0.0500)  time: 0.8467  data: 0.0005  max mem: 7679\n",
            "Epoch: [89]  [100/147]  eta: 0:00:42  lr: 0.000163  min_lr: 0.000163  loss: 2.4654 (2.3180)  weight_decay: 0.0500 (0.0500)  time: 0.8491  data: 0.0005  max mem: 7679\n",
            "Epoch: [89]  [110/147]  eta: 0:00:33  lr: 0.000161  min_lr: 0.000161  loss: 2.5545 (2.3278)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0007  max mem: 7679\n",
            "Epoch: [89]  [120/147]  eta: 0:00:24  lr: 0.000158  min_lr: 0.000158  loss: 2.3625 (2.3252)  weight_decay: 0.0500 (0.0500)  time: 0.8516  data: 0.0007  max mem: 7679\n",
            "Epoch: [89]  [130/147]  eta: 0:00:15  lr: 0.000157  min_lr: 0.000157  loss: 2.3625 (2.3258)  weight_decay: 0.0500 (0.0500)  time: 0.8505  data: 0.0010  max mem: 7679\n",
            "Epoch: [89]  [140/147]  eta: 0:00:06  lr: 0.000154  min_lr: 0.000154  loss: 2.1909 (2.3107)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0009  max mem: 7679\n",
            "Epoch: [89]  [146/147]  eta: 0:00:00  lr: 0.000154  min_lr: 0.000154  loss: 2.1909 (2.3103)  weight_decay: 0.0500 (0.0500)  time: 0.7248  data: 0.0002  max mem: 7679\n",
            "Epoch: [89] Total time: 0:02:08 (0.8719 s / it)\n",
            "Averaged stats: lr: 0.000154  min_lr: 0.000154  loss: 2.1909 (2.3103)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:24  loss: 0.4953 (0.4953)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.5198  data: 3.0492  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.4974 (0.5260)  acc1: 89.5833 (90.2462)  acc5: 97.9167 (98.3902)  time: 0.6863  data: 0.2794  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5335 (0.6416)  acc1: 89.5833 (85.5655)  acc5: 97.9167 (98.5119)  time: 0.4059  data: 0.0032  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6794 (0.6546)  acc1: 82.2917 (85.0134)  acc5: 98.9583 (98.6223)  time: 0.4062  data: 0.0021  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6154 (0.6478)  acc1: 85.8824 (85.1720)  acc5: 97.9167 (98.3694)  time: 0.4023  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4889 s / it)\n",
            "* Acc@1 85.172 Acc@5 98.369 loss 0.648\n",
            "Accuracy of the model on the 3925 test images: 85.2%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:03:03  loss: 3.2572 (3.2572)  acc1: 11.4583 (11.4583)  acc5: 92.7083 (92.7083)  time: 4.4842  data: 4.0345  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 3.4524 (3.7937)  acc1: 10.4167 (15.7197)  acc5: 94.7917 (85.7955)  time: 0.8293  data: 0.3956  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 3.6127 (4.4375)  acc1: 8.3333 (12.1528)  acc5: 89.5833 (74.1071)  time: 0.4358  data: 0.0174  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3462 (4.7703)  acc1: 3.1250 (10.9879)  acc5: 52.0833 (66.9691)  time: 0.4059  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6442 (4.1971)  acc1: 19.7917 (22.0382)  acc5: 76.0417 (70.7516)  time: 0.4052  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5345 s / it)\n",
            "* Acc@1 22.038 Acc@5 70.752 loss 4.197\n",
            "Accuracy of the model EMA on 3925 test images: 22.0%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [90]  [  0/147]  eta: 0:11:47  lr: 0.000153  min_lr: 0.000153  loss: 2.1742 (2.1742)  weight_decay: 0.0500 (0.0500)  time: 4.8107  data: 3.8764  max mem: 7679\n",
            "Epoch: [90]  [ 10/147]  eta: 0:02:46  lr: 0.000152  min_lr: 0.000152  loss: 2.4722 (2.3234)  weight_decay: 0.0500 (0.0500)  time: 1.2163  data: 0.3533  max mem: 7679\n",
            "Epoch: [90]  [ 20/147]  eta: 0:02:13  lr: 0.000149  min_lr: 0.000149  loss: 2.3875 (2.3344)  weight_decay: 0.0500 (0.0500)  time: 0.8631  data: 0.0009  max mem: 7679\n",
            "Epoch: [90]  [ 30/147]  eta: 0:01:55  lr: 0.000147  min_lr: 0.000147  loss: 2.3301 (2.3102)  weight_decay: 0.0500 (0.0500)  time: 0.8612  data: 0.0007  max mem: 7679\n",
            "Epoch: [90]  [ 40/147]  eta: 0:01:42  lr: 0.000145  min_lr: 0.000145  loss: 2.4806 (2.3411)  weight_decay: 0.0500 (0.0500)  time: 0.8542  data: 0.0005  max mem: 7679\n",
            "Epoch: [90]  [ 50/147]  eta: 0:01:30  lr: 0.000143  min_lr: 0.000143  loss: 2.4652 (2.3469)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0009  max mem: 7679\n",
            "Epoch: [90]  [ 60/147]  eta: 0:01:20  lr: 0.000141  min_lr: 0.000141  loss: 2.4244 (2.3351)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0013  max mem: 7679\n",
            "Epoch: [90]  [ 70/147]  eta: 0:01:09  lr: 0.000139  min_lr: 0.000139  loss: 2.4244 (2.3541)  weight_decay: 0.0500 (0.0500)  time: 0.8461  data: 0.0012  max mem: 7679\n",
            "Epoch: [90]  [ 80/147]  eta: 0:01:00  lr: 0.000137  min_lr: 0.000137  loss: 2.3930 (2.3548)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0021  max mem: 7679\n",
            "Epoch: [90]  [ 90/147]  eta: 0:00:51  lr: 0.000135  min_lr: 0.000135  loss: 2.3712 (2.3465)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0027  max mem: 7679\n",
            "Epoch: [90]  [100/147]  eta: 0:00:41  lr: 0.000133  min_lr: 0.000133  loss: 2.4045 (2.3411)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0027  max mem: 7679\n",
            "Epoch: [90]  [110/147]  eta: 0:00:32  lr: 0.000131  min_lr: 0.000131  loss: 2.5067 (2.3508)  weight_decay: 0.0500 (0.0500)  time: 0.8536  data: 0.0029  max mem: 7679\n",
            "Epoch: [90]  [120/147]  eta: 0:00:23  lr: 0.000129  min_lr: 0.000129  loss: 2.5497 (2.3673)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0020  max mem: 7679\n",
            "Epoch: [90]  [130/147]  eta: 0:00:15  lr: 0.000128  min_lr: 0.000128  loss: 2.3993 (2.3599)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0012  max mem: 7679\n",
            "Epoch: [90]  [140/147]  eta: 0:00:06  lr: 0.000125  min_lr: 0.000125  loss: 2.2820 (2.3599)  weight_decay: 0.0500 (0.0500)  time: 0.8510  data: 0.0004  max mem: 7679\n",
            "Epoch: [90]  [146/147]  eta: 0:00:00  lr: 0.000125  min_lr: 0.000125  loss: 2.3715 (2.3605)  weight_decay: 0.0500 (0.0500)  time: 0.7255  data: 0.0002  max mem: 7679\n",
            "Epoch: [90] Total time: 0:02:07 (0.8649 s / it)\n",
            "Averaged stats: lr: 0.000125  min_lr: 0.000125  loss: 2.3715 (2.3605)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:09  loss: 0.5425 (0.5425)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 4.6159  data: 4.1506  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5072 (0.5105)  acc1: 91.6667 (91.2879)  acc5: 97.9167 (98.4849)  time: 0.7899  data: 0.3840  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5197 (0.6423)  acc1: 89.5833 (85.5655)  acc5: 98.9583 (98.7103)  time: 0.4049  data: 0.0046  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6976 (0.6695)  acc1: 83.3333 (84.4758)  acc5: 98.9583 (98.6559)  time: 0.4044  data: 0.0011  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6217 (0.6679)  acc1: 85.4167 (84.6624)  acc5: 97.9167 (98.3949)  time: 0.4062  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5182 s / it)\n",
            "* Acc@1 84.662 Acc@5 98.395 loss 0.668\n",
            "Accuracy of the model on the 3925 test images: 84.7%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:03:01  loss: 3.2290 (3.2290)  acc1: 11.4583 (11.4583)  acc5: 92.7083 (92.7083)  time: 4.4304  data: 3.9798  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 3.4269 (3.7798)  acc1: 10.4167 (15.3409)  acc5: 94.7917 (85.5114)  time: 0.7739  data: 0.3645  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 3.5726 (4.4217)  acc1: 8.3333 (11.9048)  acc5: 89.5833 (73.8591)  time: 0.4133  data: 0.0030  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3522 (4.7610)  acc1: 3.1250 (10.7191)  acc5: 51.0417 (66.7675)  time: 0.4148  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6522 (4.1861)  acc1: 17.7083 (21.8854)  acc5: 76.0417 (70.6242)  time: 0.4087  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5180 s / it)\n",
            "* Acc@1 21.885 Acc@5 70.624 loss 4.186\n",
            "Accuracy of the model EMA on 3925 test images: 21.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [91]  [  0/147]  eta: 0:08:12  lr: 0.000125  min_lr: 0.000125  loss: 2.0088 (2.0088)  weight_decay: 0.0500 (0.0500)  time: 3.3477  data: 2.3922  max mem: 7679\n",
            "Epoch: [91]  [ 10/147]  eta: 0:02:50  lr: 0.000123  min_lr: 0.000123  loss: 2.2001 (2.1448)  weight_decay: 0.0500 (0.0500)  time: 1.2428  data: 0.2196  max mem: 7679\n",
            "Epoch: [91]  [ 20/147]  eta: 0:02:16  lr: 0.000121  min_lr: 0.000121  loss: 2.3103 (2.2148)  weight_decay: 0.0500 (0.0500)  time: 0.9615  data: 0.0021  max mem: 7679\n",
            "Epoch: [91]  [ 30/147]  eta: 0:01:57  lr: 0.000119  min_lr: 0.000119  loss: 2.2204 (2.1966)  weight_decay: 0.0500 (0.0500)  time: 0.8706  data: 0.0012  max mem: 7679\n",
            "Epoch: [91]  [ 40/147]  eta: 0:01:43  lr: 0.000117  min_lr: 0.000117  loss: 2.2204 (2.2335)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0006  max mem: 7679\n",
            "Epoch: [91]  [ 50/147]  eta: 0:01:31  lr: 0.000116  min_lr: 0.000116  loss: 2.4435 (2.2546)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0006  max mem: 7679\n",
            "Epoch: [91]  [ 60/147]  eta: 0:01:20  lr: 0.000114  min_lr: 0.000114  loss: 2.4955 (2.2933)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0006  max mem: 7679\n",
            "Epoch: [91]  [ 70/147]  eta: 0:01:10  lr: 0.000112  min_lr: 0.000112  loss: 2.4955 (2.3186)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0008  max mem: 7679\n",
            "Epoch: [91]  [ 80/147]  eta: 0:01:00  lr: 0.000110  min_lr: 0.000110  loss: 2.4612 (2.3340)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0008  max mem: 7679\n",
            "Epoch: [91]  [ 90/147]  eta: 0:00:51  lr: 0.000109  min_lr: 0.000109  loss: 2.3895 (2.3333)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0009  max mem: 7679\n",
            "Epoch: [91]  [100/147]  eta: 0:00:42  lr: 0.000106  min_lr: 0.000106  loss: 2.2903 (2.3216)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0008  max mem: 7679\n",
            "Epoch: [91]  [110/147]  eta: 0:00:33  lr: 0.000105  min_lr: 0.000105  loss: 2.3521 (2.3298)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0010  max mem: 7679\n",
            "Epoch: [91]  [120/147]  eta: 0:00:23  lr: 0.000103  min_lr: 0.000103  loss: 2.4562 (2.3335)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0010  max mem: 7679\n",
            "Epoch: [91]  [130/147]  eta: 0:00:15  lr: 0.000102  min_lr: 0.000102  loss: 2.3353 (2.3255)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0016  max mem: 7679\n",
            "Epoch: [91]  [140/147]  eta: 0:00:06  lr: 0.000100  min_lr: 0.000100  loss: 2.3310 (2.3263)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0015  max mem: 7679\n",
            "Epoch: [91]  [146/147]  eta: 0:00:00  lr: 0.000100  min_lr: 0.000100  loss: 2.3671 (2.3235)  weight_decay: 0.0500 (0.0500)  time: 0.7231  data: 0.0002  max mem: 7679\n",
            "Epoch: [91] Total time: 0:02:07 (0.8693 s / it)\n",
            "Averaged stats: lr: 0.000100  min_lr: 0.000100  loss: 2.3671 (2.3235)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:22  loss: 0.5241 (0.5241)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.4765  data: 3.0323  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5245 (0.5424)  acc1: 89.5833 (89.6780)  acc5: 97.9167 (98.2955)  time: 0.6889  data: 0.2788  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5781 (0.6497)  acc1: 88.5417 (85.1687)  acc5: 98.9583 (98.5615)  time: 0.4090  data: 0.0026  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6543 (0.6593)  acc1: 83.3333 (84.6438)  acc5: 98.9583 (98.6223)  time: 0.4073  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5992 (0.6516)  acc1: 87.5000 (85.0955)  acc5: 97.9167 (98.3694)  time: 0.4048  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4906 s / it)\n",
            "* Acc@1 85.096 Acc@5 98.369 loss 0.652\n",
            "Accuracy of the model on the 3925 test images: 85.1%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:02:04  loss: 3.2012 (3.2012)  acc1: 11.4583 (11.4583)  acc5: 91.6667 (91.6667)  time: 3.0293  data: 2.5760  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.4017 (3.7656)  acc1: 11.4583 (15.2462)  acc5: 94.7917 (85.2273)  time: 0.6589  data: 0.2400  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.5337 (4.4055)  acc1: 8.3333 (11.7560)  acc5: 89.5833 (73.7103)  time: 0.4221  data: 0.0053  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3571 (4.7510)  acc1: 3.1250 (10.6183)  acc5: 51.0417 (66.5995)  time: 0.4169  data: 0.0022  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6590 (4.1747)  acc1: 17.7083 (21.8854)  acc5: 77.0833 (70.5223)  time: 0.4085  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4882 s / it)\n",
            "* Acc@1 21.885 Acc@5 70.522 loss 4.175\n",
            "Accuracy of the model EMA on 3925 test images: 21.9%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [92]  [  0/147]  eta: 0:07:00  lr: 0.000099  min_lr: 0.000099  loss: 2.4248 (2.4248)  weight_decay: 0.0500 (0.0500)  time: 2.8631  data: 1.9171  max mem: 7679\n",
            "Epoch: [92]  [ 10/147]  eta: 0:02:30  lr: 0.000098  min_lr: 0.000098  loss: 2.3617 (2.2932)  weight_decay: 0.0500 (0.0500)  time: 1.0989  data: 0.1773  max mem: 7679\n",
            "Epoch: [92]  [ 20/147]  eta: 0:02:04  lr: 0.000096  min_lr: 0.000096  loss: 2.3605 (2.3281)  weight_decay: 0.0500 (0.0500)  time: 0.8881  data: 0.0019  max mem: 7679\n",
            "Epoch: [92]  [ 30/147]  eta: 0:01:49  lr: 0.000094  min_lr: 0.000094  loss: 2.3949 (2.3561)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0013  max mem: 7679\n",
            "Epoch: [92]  [ 40/147]  eta: 0:01:38  lr: 0.000092  min_lr: 0.000092  loss: 2.3926 (2.3378)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0017  max mem: 7679\n",
            "Epoch: [92]  [ 50/147]  eta: 0:01:27  lr: 0.000091  min_lr: 0.000091  loss: 2.2872 (2.3057)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0013  max mem: 7679\n",
            "Epoch: [92]  [ 60/147]  eta: 0:01:17  lr: 0.000089  min_lr: 0.000089  loss: 2.4532 (2.3249)  weight_decay: 0.0500 (0.0500)  time: 0.8475  data: 0.0012  max mem: 7679\n",
            "Epoch: [92]  [ 70/147]  eta: 0:01:08  lr: 0.000088  min_lr: 0.000088  loss: 2.4193 (2.3124)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0018  max mem: 7679\n",
            "Epoch: [92]  [ 80/147]  eta: 0:00:59  lr: 0.000086  min_lr: 0.000086  loss: 2.4125 (2.3203)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0030  max mem: 7679\n",
            "Epoch: [92]  [ 90/147]  eta: 0:00:50  lr: 0.000085  min_lr: 0.000085  loss: 2.4125 (2.3217)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0028  max mem: 7679\n",
            "Epoch: [92]  [100/147]  eta: 0:00:41  lr: 0.000083  min_lr: 0.000083  loss: 2.4532 (2.3337)  weight_decay: 0.0500 (0.0500)  time: 0.8518  data: 0.0024  max mem: 7679\n",
            "Epoch: [92]  [110/147]  eta: 0:00:32  lr: 0.000081  min_lr: 0.000081  loss: 2.3599 (2.3276)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0019  max mem: 7679\n",
            "Epoch: [92]  [120/147]  eta: 0:00:23  lr: 0.000080  min_lr: 0.000080  loss: 2.2944 (2.3193)  weight_decay: 0.0500 (0.0500)  time: 0.8531  data: 0.0020  max mem: 7679\n",
            "Epoch: [92]  [130/147]  eta: 0:00:14  lr: 0.000078  min_lr: 0.000078  loss: 2.3970 (2.3333)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0022  max mem: 7679\n",
            "Epoch: [92]  [140/147]  eta: 0:00:06  lr: 0.000077  min_lr: 0.000077  loss: 2.4374 (2.3340)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0008  max mem: 7679\n",
            "Epoch: [92]  [146/147]  eta: 0:00:00  lr: 0.000077  min_lr: 0.000077  loss: 2.3839 (2.3311)  weight_decay: 0.0500 (0.0500)  time: 0.7231  data: 0.0002  max mem: 7679\n",
            "Epoch: [92] Total time: 0:02:05 (0.8547 s / it)\n",
            "Averaged stats: lr: 0.000077  min_lr: 0.000077  loss: 2.3839 (2.3311)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:41  loss: 0.5090 (0.5090)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.9320  data: 3.4693  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5090 (0.5194)  acc1: 90.6250 (90.5303)  acc5: 97.9167 (98.3902)  time: 0.7417  data: 0.3184  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5504 (0.6393)  acc1: 88.5417 (85.2679)  acc5: 98.9583 (98.6607)  time: 0.4208  data: 0.0062  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.7056 (0.6545)  acc1: 81.2500 (84.6438)  acc5: 98.9583 (98.6559)  time: 0.4115  data: 0.0046  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5947 (0.6444)  acc1: 86.4583 (85.0701)  acc5: 97.9167 (98.4459)  time: 0.4029  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5078 s / it)\n",
            "* Acc@1 85.070 Acc@5 98.446 loss 0.644\n",
            "Accuracy of the model on the 3925 test images: 85.1%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:03:32  loss: 3.1732 (3.1732)  acc1: 12.5000 (12.5000)  acc5: 92.7083 (92.7083)  time: 5.1711  data: 4.7074  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:26  loss: 3.3763 (3.7515)  acc1: 12.5000 (15.6250)  acc5: 94.7917 (85.0379)  time: 0.8502  data: 0.4288  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 3.4950 (4.3892)  acc1: 8.3333 (12.0040)  acc5: 90.6250 (73.5119)  time: 0.4142  data: 0.0010  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3614 (4.7408)  acc1: 3.1250 (10.7527)  acc5: 50.0000 (66.4315)  time: 0.4110  data: 0.0005  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6649 (4.1632)  acc1: 17.7083 (22.0637)  acc5: 76.0417 (70.4459)  time: 0.4078  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5421 s / it)\n",
            "* Acc@1 22.064 Acc@5 70.446 loss 4.163\n",
            "Accuracy of the model EMA on 3925 test images: 22.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [93]  [  0/147]  eta: 0:07:29  lr: 0.000076  min_lr: 0.000076  loss: 2.4929 (2.4929)  weight_decay: 0.0500 (0.0500)  time: 3.0586  data: 2.1246  max mem: 7679\n",
            "Epoch: [93]  [ 10/147]  eta: 0:02:24  lr: 0.000075  min_lr: 0.000075  loss: 2.4950 (2.4998)  weight_decay: 0.0500 (0.0500)  time: 1.0565  data: 0.1966  max mem: 7679\n",
            "Epoch: [93]  [ 20/147]  eta: 0:02:02  lr: 0.000073  min_lr: 0.000073  loss: 2.4912 (2.4689)  weight_decay: 0.0500 (0.0500)  time: 0.8575  data: 0.0021  max mem: 7679\n",
            "Epoch: [93]  [ 30/147]  eta: 0:01:48  lr: 0.000072  min_lr: 0.000072  loss: 2.4207 (2.4226)  weight_decay: 0.0500 (0.0500)  time: 0.8552  data: 0.0008  max mem: 7679\n",
            "Epoch: [93]  [ 40/147]  eta: 0:01:37  lr: 0.000070  min_lr: 0.000070  loss: 2.3260 (2.3841)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0012  max mem: 7679\n",
            "Epoch: [93]  [ 50/147]  eta: 0:01:26  lr: 0.000069  min_lr: 0.000069  loss: 2.3212 (2.3646)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0020  max mem: 7679\n",
            "Epoch: [93]  [ 60/147]  eta: 0:01:17  lr: 0.000067  min_lr: 0.000067  loss: 2.3921 (2.3707)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0018  max mem: 7679\n",
            "Epoch: [93]  [ 70/147]  eta: 0:01:07  lr: 0.000066  min_lr: 0.000066  loss: 2.3921 (2.3583)  weight_decay: 0.0500 (0.0500)  time: 0.8483  data: 0.0010  max mem: 7679\n",
            "Epoch: [93]  [ 80/147]  eta: 0:00:58  lr: 0.000065  min_lr: 0.000065  loss: 2.3128 (2.3612)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0010  max mem: 7679\n",
            "Epoch: [93]  [ 90/147]  eta: 0:00:49  lr: 0.000064  min_lr: 0.000064  loss: 2.4206 (2.3524)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0020  max mem: 7679\n",
            "Epoch: [93]  [100/147]  eta: 0:00:41  lr: 0.000062  min_lr: 0.000062  loss: 2.4206 (2.3467)  weight_decay: 0.0500 (0.0500)  time: 0.8517  data: 0.0020  max mem: 7679\n",
            "Epoch: [93]  [110/147]  eta: 0:00:32  lr: 0.000061  min_lr: 0.000061  loss: 2.4225 (2.3580)  weight_decay: 0.0500 (0.0500)  time: 0.8524  data: 0.0019  max mem: 7679\n",
            "Epoch: [93]  [120/147]  eta: 0:00:23  lr: 0.000059  min_lr: 0.000059  loss: 2.3669 (2.3549)  weight_decay: 0.0500 (0.0500)  time: 0.8533  data: 0.0019  max mem: 7679\n",
            "Epoch: [93]  [130/147]  eta: 0:00:14  lr: 0.000058  min_lr: 0.000058  loss: 2.2677 (2.3445)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0016  max mem: 7679\n",
            "Epoch: [93]  [140/147]  eta: 0:00:06  lr: 0.000057  min_lr: 0.000057  loss: 2.3051 (2.3543)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0015  max mem: 7679\n",
            "Epoch: [93]  [146/147]  eta: 0:00:00  lr: 0.000057  min_lr: 0.000057  loss: 2.3051 (2.3524)  weight_decay: 0.0500 (0.0500)  time: 0.7235  data: 0.0003  max mem: 7679\n",
            "Epoch: [93] Total time: 0:02:05 (0.8534 s / it)\n",
            "Averaged stats: lr: 0.000057  min_lr: 0.000057  loss: 2.3051 (2.3524)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:53  loss: 0.5028 (0.5028)  acc1: 90.6250 (90.6250)  acc5: 98.9583 (98.9583)  time: 2.7696  data: 2.3205  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5028 (0.5191)  acc1: 90.6250 (90.3409)  acc5: 97.9167 (98.5795)  time: 0.7307  data: 0.3296  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5490 (0.6413)  acc1: 88.5417 (84.9206)  acc5: 98.9583 (98.7103)  time: 0.4671  data: 0.0675  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6524 (0.6568)  acc1: 82.2917 (84.4422)  acc5: 98.9583 (98.6559)  time: 0.4057  data: 0.0023  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6207 (0.6494)  acc1: 85.4167 (84.7643)  acc5: 97.9167 (98.3949)  time: 0.4046  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5037 s / it)\n",
            "* Acc@1 84.764 Acc@5 98.395 loss 0.649\n",
            "Accuracy of the model on the 3925 test images: 84.8%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:01:58  loss: 3.1446 (3.1446)  acc1: 12.5000 (12.5000)  acc5: 92.7083 (92.7083)  time: 2.8961  data: 2.4204  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.3502 (3.7370)  acc1: 12.5000 (15.7197)  acc5: 94.7917 (84.7538)  time: 0.6893  data: 0.2727  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.4569 (4.3725)  acc1: 9.3750 (12.0536)  acc5: 90.6250 (73.1151)  time: 0.4415  data: 0.0295  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3652 (4.7299)  acc1: 2.0833 (10.7191)  acc5: 48.9583 (66.1962)  time: 0.4141  data: 0.0006  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6697 (4.1513)  acc1: 17.7083 (22.0892)  acc5: 76.0417 (70.2930)  time: 0.4103  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4959 s / it)\n",
            "* Acc@1 22.089 Acc@5 70.293 loss 4.151\n",
            "Accuracy of the model EMA on 3925 test images: 22.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [94]  [  0/147]  eta: 0:09:20  lr: 0.000056  min_lr: 0.000056  loss: 2.5063 (2.5063)  weight_decay: 0.0500 (0.0500)  time: 3.8152  data: 2.9051  max mem: 7679\n",
            "Epoch: [94]  [ 10/147]  eta: 0:02:33  lr: 0.000055  min_lr: 0.000055  loss: 2.3659 (2.3611)  weight_decay: 0.0500 (0.0500)  time: 1.1218  data: 0.2652  max mem: 7679\n",
            "Epoch: [94]  [ 20/147]  eta: 0:02:06  lr: 0.000054  min_lr: 0.000054  loss: 2.3731 (2.3818)  weight_decay: 0.0500 (0.0500)  time: 0.8519  data: 0.0009  max mem: 7679\n",
            "Epoch: [94]  [ 30/147]  eta: 0:01:50  lr: 0.000053  min_lr: 0.000053  loss: 2.4196 (2.3933)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0015  max mem: 7679\n",
            "Epoch: [94]  [ 40/147]  eta: 0:01:38  lr: 0.000051  min_lr: 0.000051  loss: 2.3026 (2.3664)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0016  max mem: 7679\n",
            "Epoch: [94]  [ 50/147]  eta: 0:01:28  lr: 0.000050  min_lr: 0.000050  loss: 2.3026 (2.3693)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0018  max mem: 7679\n",
            "Epoch: [94]  [ 60/147]  eta: 0:01:18  lr: 0.000049  min_lr: 0.000049  loss: 2.4642 (2.3908)  weight_decay: 0.0500 (0.0500)  time: 0.8498  data: 0.0021  max mem: 7679\n",
            "Epoch: [94]  [ 70/147]  eta: 0:01:08  lr: 0.000048  min_lr: 0.000048  loss: 2.4167 (2.3782)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0018  max mem: 7679\n",
            "Epoch: [94]  [ 80/147]  eta: 0:00:59  lr: 0.000047  min_lr: 0.000047  loss: 2.2970 (2.3730)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0015  max mem: 7679\n",
            "Epoch: [94]  [ 90/147]  eta: 0:00:50  lr: 0.000046  min_lr: 0.000046  loss: 2.4838 (2.3736)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0016  max mem: 7679\n",
            "Epoch: [94]  [100/147]  eta: 0:00:41  lr: 0.000044  min_lr: 0.000044  loss: 2.5095 (2.3673)  weight_decay: 0.0500 (0.0500)  time: 0.8492  data: 0.0016  max mem: 7679\n",
            "Epoch: [94]  [110/147]  eta: 0:00:32  lr: 0.000043  min_lr: 0.000043  loss: 2.4464 (2.3745)  weight_decay: 0.0500 (0.0500)  time: 0.8478  data: 0.0017  max mem: 7679\n",
            "Epoch: [94]  [120/147]  eta: 0:00:23  lr: 0.000042  min_lr: 0.000042  loss: 2.4068 (2.3654)  weight_decay: 0.0500 (0.0500)  time: 0.8485  data: 0.0019  max mem: 7679\n",
            "Epoch: [94]  [130/147]  eta: 0:00:14  lr: 0.000041  min_lr: 0.000041  loss: 2.2926 (2.3600)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0015  max mem: 7679\n",
            "Epoch: [94]  [140/147]  eta: 0:00:06  lr: 0.000040  min_lr: 0.000040  loss: 2.2404 (2.3453)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0009  max mem: 7679\n",
            "Epoch: [94]  [146/147]  eta: 0:00:00  lr: 0.000040  min_lr: 0.000040  loss: 2.2191 (2.3431)  weight_decay: 0.0500 (0.0500)  time: 0.7221  data: 0.0003  max mem: 7679\n",
            "Epoch: [94] Total time: 0:02:05 (0.8554 s / it)\n",
            "Averaged stats: lr: 0.000040  min_lr: 0.000040  loss: 2.2191 (2.3431)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:05  loss: 0.5254 (0.5254)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 4.5139  data: 4.0308  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5254 (0.5305)  acc1: 90.6250 (90.2462)  acc5: 97.9167 (98.2955)  time: 0.7832  data: 0.3716  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5510 (0.6475)  acc1: 88.5417 (84.9206)  acc5: 98.9583 (98.5615)  time: 0.4138  data: 0.0049  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6631 (0.6557)  acc1: 82.2917 (84.6438)  acc5: 98.9583 (98.6559)  time: 0.4106  data: 0.0021  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5947 (0.6470)  acc1: 85.8824 (85.0446)  acc5: 97.9167 (98.4459)  time: 0.4034  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5182 s / it)\n",
            "* Acc@1 85.045 Acc@5 98.446 loss 0.647\n",
            "Accuracy of the model on the 3925 test images: 85.0%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:02:58  loss: 3.1157 (3.1157)  acc1: 13.5417 (13.5417)  acc5: 92.7083 (92.7083)  time: 4.3596  data: 3.8593  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:25  loss: 3.3235 (3.7221)  acc1: 12.5000 (15.9091)  acc5: 94.7917 (84.4697)  time: 0.8222  data: 0.3935  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 3.4227 (4.3556)  acc1: 9.3750 (12.2520)  acc5: 90.6250 (73.0159)  time: 0.4421  data: 0.0243  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3690 (4.7187)  acc1: 2.0833 (10.7191)  acc5: 48.9583 (65.9946)  time: 0.4165  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6737 (4.1393)  acc1: 17.7083 (22.0892)  acc5: 76.0417 (70.1656)  time: 0.4136  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5382 s / it)\n",
            "* Acc@1 22.089 Acc@5 70.166 loss 4.139\n",
            "Accuracy of the model EMA on 3925 test images: 22.1%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [95]  [  0/147]  eta: 0:11:27  lr: 0.000039  min_lr: 0.000039  loss: 2.4024 (2.4024)  weight_decay: 0.0500 (0.0500)  time: 4.6749  data: 3.7375  max mem: 7679\n",
            "Epoch: [95]  [ 10/147]  eta: 0:02:43  lr: 0.000039  min_lr: 0.000039  loss: 2.4132 (2.3703)  weight_decay: 0.0500 (0.0500)  time: 1.1970  data: 0.3403  max mem: 7679\n",
            "Epoch: [95]  [ 20/147]  eta: 0:02:11  lr: 0.000037  min_lr: 0.000037  loss: 2.3342 (2.2930)  weight_decay: 0.0500 (0.0500)  time: 0.8534  data: 0.0008  max mem: 7679\n",
            "Epoch: [95]  [ 30/147]  eta: 0:01:54  lr: 0.000036  min_lr: 0.000036  loss: 2.1459 (2.2818)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0008  max mem: 7679\n",
            "Epoch: [95]  [ 40/147]  eta: 0:01:41  lr: 0.000035  min_lr: 0.000035  loss: 2.1459 (2.2766)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0015  max mem: 7679\n",
            "Epoch: [95]  [ 50/147]  eta: 0:01:29  lr: 0.000034  min_lr: 0.000034  loss: 2.2821 (2.2846)  weight_decay: 0.0500 (0.0500)  time: 0.8499  data: 0.0015  max mem: 7679\n",
            "Epoch: [95]  [ 60/147]  eta: 0:01:19  lr: 0.000033  min_lr: 0.000033  loss: 2.3588 (2.2850)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0012  max mem: 7679\n",
            "Epoch: [95]  [ 70/147]  eta: 0:01:09  lr: 0.000033  min_lr: 0.000033  loss: 2.3952 (2.2754)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0019  max mem: 7679\n",
            "Epoch: [95]  [ 80/147]  eta: 0:01:00  lr: 0.000031  min_lr: 0.000031  loss: 2.3654 (2.2743)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0024  max mem: 7679\n",
            "Epoch: [95]  [ 90/147]  eta: 0:00:50  lr: 0.000031  min_lr: 0.000031  loss: 2.3738 (2.2820)  weight_decay: 0.0500 (0.0500)  time: 0.8497  data: 0.0024  max mem: 7679\n",
            "Epoch: [95]  [100/147]  eta: 0:00:41  lr: 0.000030  min_lr: 0.000030  loss: 2.3488 (2.2847)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0018  max mem: 7679\n",
            "Epoch: [95]  [110/147]  eta: 0:00:32  lr: 0.000029  min_lr: 0.000029  loss: 2.4088 (2.3023)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0018  max mem: 7679\n",
            "Epoch: [95]  [120/147]  eta: 0:00:23  lr: 0.000028  min_lr: 0.000028  loss: 2.5381 (2.3209)  weight_decay: 0.0500 (0.0500)  time: 0.8494  data: 0.0017  max mem: 7679\n",
            "Epoch: [95]  [130/147]  eta: 0:00:14  lr: 0.000027  min_lr: 0.000027  loss: 2.4522 (2.3070)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0008  max mem: 7679\n",
            "Epoch: [95]  [140/147]  eta: 0:00:06  lr: 0.000026  min_lr: 0.000026  loss: 2.3809 (2.3169)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0002  max mem: 7679\n",
            "Epoch: [95]  [146/147]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 2.3852 (2.3176)  weight_decay: 0.0500 (0.0500)  time: 0.7229  data: 0.0002  max mem: 7679\n",
            "Epoch: [95] Total time: 0:02:06 (0.8627 s / it)\n",
            "Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 2.3852 (2.3176)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:13  loss: 0.5130 (0.5130)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.2441  data: 2.7782  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 0.5130 (0.5163)  acc1: 90.6250 (90.4356)  acc5: 97.9167 (98.2955)  time: 0.6817  data: 0.2737  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5475 (0.6407)  acc1: 88.5417 (85.0694)  acc5: 98.9583 (98.6111)  time: 0.4152  data: 0.0132  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6577 (0.6538)  acc1: 82.2917 (84.5766)  acc5: 98.9583 (98.6223)  time: 0.4034  data: 0.0017  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5934 (0.6436)  acc1: 86.4583 (84.9427)  acc5: 97.9167 (98.4204)  time: 0.4027  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4876 s / it)\n",
            "* Acc@1 84.943 Acc@5 98.420 loss 0.644\n",
            "Accuracy of the model on the 3925 test images: 84.9%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:02:40  loss: 3.0867 (3.0867)  acc1: 13.5417 (13.5417)  acc5: 93.7500 (93.7500)  time: 3.9181  data: 3.4750  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 3.2968 (3.7071)  acc1: 13.5417 (15.9091)  acc5: 95.8333 (84.4697)  time: 0.7313  data: 0.3196  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 3.4035 (4.3387)  acc1: 9.3750 (12.4008)  acc5: 90.6250 (72.9167)  time: 0.4152  data: 0.0035  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3728 (4.7075)  acc1: 2.0833 (10.7863)  acc5: 48.9583 (65.8938)  time: 0.4159  data: 0.0016  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6775 (4.1273)  acc1: 17.7083 (22.1911)  acc5: 76.0417 (70.0892)  time: 0.4098  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5083 s / it)\n",
            "* Acc@1 22.191 Acc@5 70.089 loss 4.127\n",
            "Accuracy of the model EMA on 3925 test images: 22.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [96]  [  0/147]  eta: 0:09:19  lr: 0.000026  min_lr: 0.000026  loss: 2.2535 (2.2535)  weight_decay: 0.0500 (0.0500)  time: 3.8054  data: 2.5866  max mem: 7679\n",
            "Epoch: [96]  [ 10/147]  eta: 0:02:34  lr: 0.000025  min_lr: 0.000025  loss: 2.3316 (2.2881)  weight_decay: 0.0500 (0.0500)  time: 1.1252  data: 0.2360  max mem: 7679\n",
            "Epoch: [96]  [ 20/147]  eta: 0:02:06  lr: 0.000024  min_lr: 0.000024  loss: 2.3542 (2.3480)  weight_decay: 0.0500 (0.0500)  time: 0.8579  data: 0.0008  max mem: 7679\n",
            "Epoch: [96]  [ 30/147]  eta: 0:01:51  lr: 0.000023  min_lr: 0.000023  loss: 2.3412 (2.3350)  weight_decay: 0.0500 (0.0500)  time: 0.8550  data: 0.0006  max mem: 7679\n",
            "Epoch: [96]  [ 40/147]  eta: 0:01:39  lr: 0.000022  min_lr: 0.000022  loss: 2.5065 (2.3953)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0008  max mem: 7679\n",
            "Epoch: [96]  [ 50/147]  eta: 0:01:28  lr: 0.000022  min_lr: 0.000022  loss: 2.4999 (2.3882)  weight_decay: 0.0500 (0.0500)  time: 0.8490  data: 0.0012  max mem: 7679\n",
            "Epoch: [96]  [ 60/147]  eta: 0:01:18  lr: 0.000021  min_lr: 0.000021  loss: 2.3896 (2.3764)  weight_decay: 0.0500 (0.0500)  time: 0.8476  data: 0.0009  max mem: 7679\n",
            "Epoch: [96]  [ 70/147]  eta: 0:01:08  lr: 0.000020  min_lr: 0.000020  loss: 2.3931 (2.3754)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0010  max mem: 7679\n",
            "Epoch: [96]  [ 80/147]  eta: 0:00:59  lr: 0.000019  min_lr: 0.000019  loss: 2.3794 (2.3727)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0017  max mem: 7679\n",
            "Epoch: [96]  [ 90/147]  eta: 0:00:50  lr: 0.000019  min_lr: 0.000019  loss: 2.2831 (2.3667)  weight_decay: 0.0500 (0.0500)  time: 0.8509  data: 0.0017  max mem: 7679\n",
            "Epoch: [96]  [100/147]  eta: 0:00:41  lr: 0.000018  min_lr: 0.000018  loss: 2.2971 (2.3646)  weight_decay: 0.0500 (0.0500)  time: 0.8523  data: 0.0018  max mem: 7679\n",
            "Epoch: [96]  [110/147]  eta: 0:00:32  lr: 0.000017  min_lr: 0.000017  loss: 2.2971 (2.3627)  weight_decay: 0.0500 (0.0500)  time: 0.8532  data: 0.0023  max mem: 7679\n",
            "Epoch: [96]  [120/147]  eta: 0:00:23  lr: 0.000016  min_lr: 0.000016  loss: 2.3207 (2.3572)  weight_decay: 0.0500 (0.0500)  time: 0.8521  data: 0.0021  max mem: 7679\n",
            "Epoch: [96]  [130/147]  eta: 0:00:14  lr: 0.000016  min_lr: 0.000016  loss: 2.2962 (2.3458)  weight_decay: 0.0500 (0.0500)  time: 0.8525  data: 0.0013  max mem: 7679\n",
            "Epoch: [96]  [140/147]  eta: 0:00:06  lr: 0.000015  min_lr: 0.000015  loss: 2.4657 (2.3553)  weight_decay: 0.0500 (0.0500)  time: 0.8506  data: 0.0006  max mem: 7679\n",
            "Epoch: [96]  [146/147]  eta: 0:00:00  lr: 0.000015  min_lr: 0.000015  loss: 2.4747 (2.3573)  weight_decay: 0.0500 (0.0500)  time: 0.7242  data: 0.0004  max mem: 7679\n",
            "Epoch: [96] Total time: 0:02:06 (0.8592 s / it)\n",
            "Averaged stats: lr: 0.000015  min_lr: 0.000015  loss: 2.4747 (2.3573)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:01:56  loss: 0.5031 (0.5031)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 2.8480  data: 2.4166  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5162 (0.5206)  acc1: 90.6250 (90.1515)  acc5: 97.9167 (98.3902)  time: 0.6593  data: 0.2523  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5479 (0.6461)  acc1: 88.5417 (84.9702)  acc5: 98.9583 (98.6111)  time: 0.4223  data: 0.0182  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6597 (0.6555)  acc1: 82.2917 (84.6102)  acc5: 98.9583 (98.6895)  time: 0.4036  data: 0.0004  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5920 (0.6451)  acc1: 85.4167 (85.0446)  acc5: 98.9583 (98.4968)  time: 0.4030  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4813 s / it)\n",
            "* Acc@1 85.045 Acc@5 98.497 loss 0.645\n",
            "Accuracy of the model on the 3925 test images: 85.0%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:02:07  loss: 3.0572 (3.0572)  acc1: 13.5417 (13.5417)  acc5: 93.7500 (93.7500)  time: 3.1075  data: 2.6050  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:21  loss: 3.2695 (3.6921)  acc1: 13.5417 (15.7197)  acc5: 95.8333 (84.0909)  time: 0.6890  data: 0.2672  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.3863 (4.3218)  acc1: 10.4167 (12.5000)  acc5: 91.6667 (72.9167)  time: 0.4331  data: 0.0198  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3767 (4.6962)  acc1: 2.0833 (10.8199)  acc5: 48.9583 (65.7594)  time: 0.4153  data: 0.0032  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6809 (4.1153)  acc1: 17.7083 (22.2420)  acc5: 76.0417 (69.9618)  time: 0.4085  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4959 s / it)\n",
            "* Acc@1 22.242 Acc@5 69.962 loss 4.115\n",
            "Accuracy of the model EMA on 3925 test images: 22.2%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [97]  [  0/147]  eta: 0:08:44  lr: 0.000015  min_lr: 0.000015  loss: 2.4924 (2.4924)  weight_decay: 0.0500 (0.0500)  time: 3.5685  data: 2.5491  max mem: 7679\n",
            "Epoch: [97]  [ 10/147]  eta: 0:02:31  lr: 0.000014  min_lr: 0.000014  loss: 2.3982 (2.3343)  weight_decay: 0.0500 (0.0500)  time: 1.1090  data: 0.2332  max mem: 7679\n",
            "Epoch: [97]  [ 20/147]  eta: 0:02:05  lr: 0.000014  min_lr: 0.000014  loss: 2.4207 (2.4342)  weight_decay: 0.0500 (0.0500)  time: 0.8594  data: 0.0017  max mem: 7679\n",
            "Epoch: [97]  [ 30/147]  eta: 0:01:50  lr: 0.000013  min_lr: 0.000013  loss: 2.4789 (2.3906)  weight_decay: 0.0500 (0.0500)  time: 0.8538  data: 0.0023  max mem: 7679\n",
            "Epoch: [97]  [ 40/147]  eta: 0:01:38  lr: 0.000012  min_lr: 0.000012  loss: 2.3419 (2.3781)  weight_decay: 0.0500 (0.0500)  time: 0.8514  data: 0.0018  max mem: 7679\n",
            "Epoch: [97]  [ 50/147]  eta: 0:01:28  lr: 0.000012  min_lr: 0.000012  loss: 2.3419 (2.3554)  weight_decay: 0.0500 (0.0500)  time: 0.8497  data: 0.0015  max mem: 7679\n",
            "Epoch: [97]  [ 60/147]  eta: 0:01:18  lr: 0.000011  min_lr: 0.000011  loss: 2.3833 (2.3502)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0018  max mem: 7679\n",
            "Epoch: [97]  [ 70/147]  eta: 0:01:08  lr: 0.000011  min_lr: 0.000011  loss: 2.4189 (2.3599)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0017  max mem: 7679\n",
            "Epoch: [97]  [ 80/147]  eta: 0:00:59  lr: 0.000010  min_lr: 0.000010  loss: 2.4187 (2.3531)  weight_decay: 0.0500 (0.0500)  time: 0.8488  data: 0.0021  max mem: 7679\n",
            "Epoch: [97]  [ 90/147]  eta: 0:00:50  lr: 0.000010  min_lr: 0.000010  loss: 2.3414 (2.3551)  weight_decay: 0.0500 (0.0500)  time: 0.8481  data: 0.0019  max mem: 7679\n",
            "Epoch: [97]  [100/147]  eta: 0:00:41  lr: 0.000009  min_lr: 0.000009  loss: 2.4383 (2.3555)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0025  max mem: 7679\n",
            "Epoch: [97]  [110/147]  eta: 0:00:32  lr: 0.000009  min_lr: 0.000009  loss: 2.3096 (2.3332)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0033  max mem: 7679\n",
            "Epoch: [97]  [120/147]  eta: 0:00:23  lr: 0.000008  min_lr: 0.000008  loss: 2.2828 (2.3364)  weight_decay: 0.0500 (0.0500)  time: 0.8522  data: 0.0034  max mem: 7679\n",
            "Epoch: [97]  [130/147]  eta: 0:00:14  lr: 0.000008  min_lr: 0.000008  loss: 2.3852 (2.3347)  weight_decay: 0.0500 (0.0500)  time: 0.8515  data: 0.0021  max mem: 7679\n",
            "Epoch: [97]  [140/147]  eta: 0:00:06  lr: 0.000007  min_lr: 0.000007  loss: 2.3475 (2.3267)  weight_decay: 0.0500 (0.0500)  time: 0.8487  data: 0.0005  max mem: 7679\n",
            "Epoch: [97]  [146/147]  eta: 0:00:00  lr: 0.000007  min_lr: 0.000007  loss: 2.3504 (2.3269)  weight_decay: 0.0500 (0.0500)  time: 0.7234  data: 0.0002  max mem: 7679\n",
            "Epoch: [97] Total time: 0:02:05 (0.8555 s / it)\n",
            "Averaged stats: lr: 0.000007  min_lr: 0.000007  loss: 2.3504 (2.3269)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:03:10  loss: 0.5067 (0.5067)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 4.6498  data: 4.1859  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:24  loss: 0.5079 (0.5182)  acc1: 90.6250 (90.2462)  acc5: 97.9167 (98.3902)  time: 0.7945  data: 0.3849  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5530 (0.6440)  acc1: 88.5417 (84.9702)  acc5: 98.9583 (98.6111)  time: 0.4094  data: 0.0055  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6663 (0.6552)  acc1: 83.3333 (84.6102)  acc5: 98.9583 (98.6559)  time: 0.4072  data: 0.0031  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5908 (0.6451)  acc1: 85.8824 (85.0191)  acc5: 97.9167 (98.4459)  time: 0.4042  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:21 (0.5204 s / it)\n",
            "* Acc@1 85.019 Acc@5 98.446 loss 0.645\n",
            "Accuracy of the model on the 3925 test images: 85.0%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:03:46  loss: 3.0277 (3.0277)  acc1: 13.5417 (13.5417)  acc5: 94.7917 (94.7917)  time: 5.5348  data: 5.1040  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:27  loss: 3.2421 (3.6769)  acc1: 13.5417 (15.8144)  acc5: 95.8333 (84.3750)  time: 0.8797  data: 0.4655  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:13  loss: 3.3693 (4.3047)  acc1: 10.4167 (12.6488)  acc5: 92.7083 (73.1647)  time: 0.4138  data: 0.0017  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:06  loss: 5.3800 (4.6846)  acc1: 2.0833 (10.8535)  acc5: 48.9583 (65.9610)  time: 0.4131  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6839 (4.1032)  acc1: 17.7083 (22.2930)  acc5: 77.0833 (70.1401)  time: 0.4103  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:22 (0.5491 s / it)\n",
            "* Acc@1 22.293 Acc@5 70.140 loss 4.103\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [98]  [  0/147]  eta: 0:09:30  lr: 0.000007  min_lr: 0.000007  loss: 2.6620 (2.6620)  weight_decay: 0.0500 (0.0500)  time: 3.8782  data: 2.9523  max mem: 7679\n",
            "Epoch: [98]  [ 10/147]  eta: 0:02:34  lr: 0.000007  min_lr: 0.000007  loss: 2.5271 (2.4059)  weight_decay: 0.0500 (0.0500)  time: 1.1282  data: 0.2689  max mem: 7679\n",
            "Epoch: [98]  [ 20/147]  eta: 0:02:07  lr: 0.000006  min_lr: 0.000006  loss: 2.4077 (2.3768)  weight_decay: 0.0500 (0.0500)  time: 0.8602  data: 0.0020  max mem: 7679\n",
            "Epoch: [98]  [ 30/147]  eta: 0:01:51  lr: 0.000006  min_lr: 0.000006  loss: 2.4373 (2.3896)  weight_decay: 0.0500 (0.0500)  time: 0.8619  data: 0.0024  max mem: 7679\n",
            "Epoch: [98]  [ 40/147]  eta: 0:01:39  lr: 0.000006  min_lr: 0.000006  loss: 2.2235 (2.3202)  weight_decay: 0.0500 (0.0500)  time: 0.8549  data: 0.0015  max mem: 7679\n",
            "Epoch: [98]  [ 50/147]  eta: 0:01:28  lr: 0.000005  min_lr: 0.000005  loss: 2.1156 (2.3182)  weight_decay: 0.0500 (0.0500)  time: 0.8496  data: 0.0016  max mem: 7679\n",
            "Epoch: [98]  [ 60/147]  eta: 0:01:18  lr: 0.000005  min_lr: 0.000005  loss: 2.4260 (2.3291)  weight_decay: 0.0500 (0.0500)  time: 0.8474  data: 0.0014  max mem: 7679\n",
            "Epoch: [98]  [ 70/147]  eta: 0:01:08  lr: 0.000005  min_lr: 0.000005  loss: 2.2193 (2.3062)  weight_decay: 0.0500 (0.0500)  time: 0.8473  data: 0.0014  max mem: 7679\n",
            "Epoch: [98]  [ 80/147]  eta: 0:00:59  lr: 0.000004  min_lr: 0.000004  loss: 2.2426 (2.3089)  weight_decay: 0.0500 (0.0500)  time: 0.8480  data: 0.0021  max mem: 7679\n",
            "Epoch: [98]  [ 90/147]  eta: 0:00:50  lr: 0.000004  min_lr: 0.000004  loss: 2.3536 (2.3054)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0018  max mem: 7679\n",
            "Epoch: [98]  [100/147]  eta: 0:00:41  lr: 0.000004  min_lr: 0.000004  loss: 2.3161 (2.3083)  weight_decay: 0.0500 (0.0500)  time: 0.8503  data: 0.0012  max mem: 7679\n",
            "Epoch: [98]  [110/147]  eta: 0:00:32  lr: 0.000003  min_lr: 0.000003  loss: 2.4509 (2.3180)  weight_decay: 0.0500 (0.0500)  time: 0.8528  data: 0.0030  max mem: 7679\n",
            "Epoch: [98]  [120/147]  eta: 0:00:23  lr: 0.000003  min_lr: 0.000003  loss: 2.4509 (2.3222)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0031  max mem: 7679\n",
            "Epoch: [98]  [130/147]  eta: 0:00:14  lr: 0.000003  min_lr: 0.000003  loss: 2.4486 (2.3223)  weight_decay: 0.0500 (0.0500)  time: 0.8526  data: 0.0013  max mem: 7679\n",
            "Epoch: [98]  [140/147]  eta: 0:00:06  lr: 0.000003  min_lr: 0.000003  loss: 2.3521 (2.3209)  weight_decay: 0.0500 (0.0500)  time: 0.8520  data: 0.0006  max mem: 7679\n",
            "Epoch: [98]  [146/147]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000003  loss: 2.3807 (2.3211)  weight_decay: 0.0500 (0.0500)  time: 0.7256  data: 0.0002  max mem: 7679\n",
            "Epoch: [98] Total time: 0:02:06 (0.8596 s / it)\n",
            "Averaged stats: lr: 0.000003  min_lr: 0.000003  loss: 2.3807 (2.3211)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:43  loss: 0.5062 (0.5062)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.9909  data: 3.4828  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:22  loss: 0.5076 (0.5177)  acc1: 90.6250 (90.4356)  acc5: 97.9167 (98.2955)  time: 0.7293  data: 0.3212  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 0.5521 (0.6421)  acc1: 88.5417 (85.1190)  acc5: 98.9583 (98.5615)  time: 0.4040  data: 0.0030  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6638 (0.6534)  acc1: 83.3333 (84.7782)  acc5: 98.9583 (98.6223)  time: 0.4047  data: 0.0005  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5891 (0.6437)  acc1: 85.4167 (85.1210)  acc5: 97.9167 (98.4204)  time: 0.4043  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5013 s / it)\n",
            "* Acc@1 85.121 Acc@5 98.420 loss 0.644\n",
            "Accuracy of the model on the 3925 test images: 85.1%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:02:45  loss: 2.9984 (2.9984)  acc1: 13.5417 (13.5417)  acc5: 95.8333 (95.8333)  time: 4.0443  data: 3.6042  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:23  loss: 3.2148 (3.6617)  acc1: 13.5417 (15.9091)  acc5: 95.8333 (84.4697)  time: 0.7440  data: 0.3309  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:12  loss: 3.3523 (4.2876)  acc1: 11.4583 (12.7976)  acc5: 92.7083 (73.2639)  time: 0.4157  data: 0.0028  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3829 (4.6728)  acc1: 2.0833 (10.8535)  acc5: 48.9583 (66.0282)  time: 0.4136  data: 0.0011  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6863 (4.0910)  acc1: 16.6667 (22.3185)  acc5: 76.0417 (70.1911)  time: 0.4074  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.5098 s / it)\n",
            "* Acc@1 22.318 Acc@5 70.191 loss 4.091\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [99]  [  0/147]  eta: 0:09:44  lr: 0.000003  min_lr: 0.000003  loss: 2.5216 (2.5216)  weight_decay: 0.0500 (0.0500)  time: 3.9759  data: 2.3400  max mem: 7679\n",
            "Epoch: [99]  [ 10/147]  eta: 0:02:42  lr: 0.000002  min_lr: 0.000002  loss: 2.5216 (2.4140)  weight_decay: 0.0500 (0.0500)  time: 1.1840  data: 0.2134  max mem: 7679\n",
            "Epoch: [99]  [ 20/147]  eta: 0:02:10  lr: 0.000002  min_lr: 0.000002  loss: 2.4010 (2.3271)  weight_decay: 0.0500 (0.0500)  time: 0.8788  data: 0.0006  max mem: 7679\n",
            "Epoch: [99]  [ 30/147]  eta: 0:01:53  lr: 0.000002  min_lr: 0.000002  loss: 2.4661 (2.3495)  weight_decay: 0.0500 (0.0500)  time: 0.8527  data: 0.0006  max mem: 7679\n",
            "Epoch: [99]  [ 40/147]  eta: 0:01:40  lr: 0.000002  min_lr: 0.000002  loss: 2.4830 (2.3713)  weight_decay: 0.0500 (0.0500)  time: 0.8504  data: 0.0006  max mem: 7679\n",
            "Epoch: [99]  [ 50/147]  eta: 0:01:29  lr: 0.000002  min_lr: 0.000002  loss: 2.4506 (2.3626)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0007  max mem: 7679\n",
            "Epoch: [99]  [ 60/147]  eta: 0:01:19  lr: 0.000002  min_lr: 0.000002  loss: 2.3965 (2.3555)  weight_decay: 0.0500 (0.0500)  time: 0.8479  data: 0.0006  max mem: 7679\n",
            "Epoch: [99]  [ 70/147]  eta: 0:01:09  lr: 0.000001  min_lr: 0.000001  loss: 2.3960 (2.3364)  weight_decay: 0.0500 (0.0500)  time: 0.8493  data: 0.0011  max mem: 7679\n",
            "Epoch: [99]  [ 80/147]  eta: 0:00:59  lr: 0.000001  min_lr: 0.000001  loss: 2.1933 (2.3367)  weight_decay: 0.0500 (0.0500)  time: 0.8501  data: 0.0014  max mem: 7679\n",
            "Epoch: [99]  [ 90/147]  eta: 0:00:50  lr: 0.000001  min_lr: 0.000001  loss: 2.3271 (2.3408)  weight_decay: 0.0500 (0.0500)  time: 0.8482  data: 0.0017  max mem: 7679\n",
            "Epoch: [99]  [100/147]  eta: 0:00:41  lr: 0.000001  min_lr: 0.000001  loss: 2.3398 (2.3421)  weight_decay: 0.0500 (0.0500)  time: 0.8495  data: 0.0017  max mem: 7679\n",
            "Epoch: [99]  [110/147]  eta: 0:00:32  lr: 0.000001  min_lr: 0.000001  loss: 2.3568 (2.3384)  weight_decay: 0.0500 (0.0500)  time: 0.8502  data: 0.0009  max mem: 7679\n",
            "Epoch: [99]  [120/147]  eta: 0:00:23  lr: 0.000001  min_lr: 0.000001  loss: 2.3664 (2.3372)  weight_decay: 0.0500 (0.0500)  time: 0.8511  data: 0.0012  max mem: 7679\n",
            "Epoch: [99]  [130/147]  eta: 0:00:14  lr: 0.000001  min_lr: 0.000001  loss: 2.3664 (2.3388)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0013  max mem: 7679\n",
            "Epoch: [99]  [140/147]  eta: 0:00:06  lr: 0.000001  min_lr: 0.000001  loss: 2.2824 (2.3281)  weight_decay: 0.0500 (0.0500)  time: 0.8508  data: 0.0007  max mem: 7679\n",
            "Epoch: [99]  [146/147]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 2.2824 (2.3281)  weight_decay: 0.0500 (0.0500)  time: 0.7235  data: 0.0002  max mem: 7679\n",
            "Epoch: [99] Total time: 0:02:06 (0.8610 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 2.2824 (2.3281)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/41]  eta: 0:02:06  loss: 0.5051 (0.5051)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 3.0837  data: 2.6218  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 0.5052 (0.5174)  acc1: 90.6250 (90.4356)  acc5: 97.9167 (98.2955)  time: 0.6651  data: 0.2433  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 0.5506 (0.6421)  acc1: 88.5417 (85.0694)  acc5: 98.9583 (98.5615)  time: 0.4185  data: 0.0032  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 0.6630 (0.6533)  acc1: 83.3333 (84.7446)  acc5: 98.9583 (98.6223)  time: 0.4093  data: 0.0005  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.5875 (0.6438)  acc1: 85.8824 (85.0955)  acc5: 97.9167 (98.4204)  time: 0.4045  data: 0.0002  max mem: 7679\n",
            "Test: Total time: 0:00:19 (0.4867 s / it)\n",
            "* Acc@1 85.096 Acc@5 98.420 loss 0.644\n",
            "Accuracy of the model on the 3925 test images: 85.1%\n",
            "Max accuracy: 85.17%\n",
            "Test:  [ 0/41]  eta: 0:02:10  loss: 2.9692 (2.9692)  acc1: 13.5417 (13.5417)  acc5: 95.8333 (95.8333)  time: 3.1862  data: 2.7545  max mem: 7679\n",
            "Test:  [10/41]  eta: 0:00:20  loss: 3.1875 (3.6465)  acc1: 13.5417 (15.9091)  acc5: 95.8333 (84.5644)  time: 0.6659  data: 0.2522  max mem: 7679\n",
            "Test:  [20/41]  eta: 0:00:11  loss: 3.3356 (4.2705)  acc1: 11.4583 (12.9464)  acc5: 92.7083 (73.2639)  time: 0.4145  data: 0.0018  max mem: 7679\n",
            "Test:  [30/41]  eta: 0:00:05  loss: 5.3854 (4.6608)  acc1: 2.0833 (10.8199)  acc5: 47.9167 (66.0618)  time: 0.4122  data: 0.0009  max mem: 7679\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 4.6883 (4.0787)  acc1: 16.6667 (22.3185)  acc5: 76.0417 (70.2675)  time: 0.4062  data: 0.0001  max mem: 7679\n",
            "Test: Total time: 0:00:20 (0.4880 s / it)\n",
            "* Acc@1 22.318 Acc@5 70.268 loss 4.079\n",
            "Accuracy of the model EMA on 3925 test images: 22.3%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/result_small_1)... Done. 28.7s\n",
            "Training time 4:52:37\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▂▂▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema ▁▁▁▁▁▁▂▃▄▄▅▅▆▇▇▇████████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▁▃▅▅▆▆▇▇▇▇▇▇▇▇██████████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema ▁▁▁▁▁▁▂▃▃▄▄▅▅▆▆▆▇▇▇▇▇▇██████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss █▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema ████▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss █▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr ▁▂▃▄▅▅▆▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr ▁▂▃▄▅▅▆▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss █▅▅▅▄▅▄▄▅▃▄▄▅▄▄▄▃▄▄▂▃▃▃▃▃▃▃▂▁▄▃▃▃▄▁▃▃▂▃▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ▁▂▃▄▅▆▇▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ▁▂▃▄▅▆▇▇██████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 85.09554\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc1_ema 22.31847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 98.42038\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_acc5_ema 70.26752\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.64379\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Test/test_loss_ema 4.07868\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 2.32808\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 3599\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 1.8603\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 50223688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpolished-resonance-22\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/lolikgiovi/convnext/runs/bmkjhrkc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230305_100114-bmkjhrkc/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "!python main.py --model convnext_small --eval true \\\n",
        "                --resume /content/result_small_1/checkpoint-best.pth \\\n",
        "                --input_size 160 --drop_path 0.1 \\\n",
        "                --data_path /content/imagenette2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgiPPQ4aOePB",
        "outputId": "a60834d3-96e9-48bd-d0c7-9e8b8904181f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/imagenette2-160', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=160, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_small', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='/content/result_small_1/checkpoint-best.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(160, 160), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7f45ea057bb0>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7f45ea057670>\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Transform = \n",
            "Resize(size=182, interpolation=bicubic)\n",
            "CenterCrop(size=(160, 160))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "reading from datapath /content/imagenette2-160\n",
            "Number of the class = 1000\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f45ea060250>\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Mixup is activated!\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (9): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (10): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (11): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (12): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (13): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (14): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (15): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (16): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (17): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (18): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (19): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (20): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (21): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (22): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (23): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (24): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (25): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (26): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): DropPath()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            ")\n",
            "number of params: 50223688\n",
            "LR = 0.00400000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 9469\n",
            "Number of training training per epoch = 147\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.2.9.dwconv.weight\",\n",
            "      \"stages.2.9.pwconv1.weight\",\n",
            "      \"stages.2.9.pwconv2.weight\",\n",
            "      \"stages.2.10.dwconv.weight\",\n",
            "      \"stages.2.10.pwconv1.weight\",\n",
            "      \"stages.2.10.pwconv2.weight\",\n",
            "      \"stages.2.11.dwconv.weight\",\n",
            "      \"stages.2.11.pwconv1.weight\",\n",
            "      \"stages.2.11.pwconv2.weight\",\n",
            "      \"stages.2.12.dwconv.weight\",\n",
            "      \"stages.2.12.pwconv1.weight\",\n",
            "      \"stages.2.12.pwconv2.weight\",\n",
            "      \"stages.2.13.dwconv.weight\",\n",
            "      \"stages.2.13.pwconv1.weight\",\n",
            "      \"stages.2.13.pwconv2.weight\",\n",
            "      \"stages.2.14.dwconv.weight\",\n",
            "      \"stages.2.14.pwconv1.weight\",\n",
            "      \"stages.2.14.pwconv2.weight\",\n",
            "      \"stages.2.15.dwconv.weight\",\n",
            "      \"stages.2.15.pwconv1.weight\",\n",
            "      \"stages.2.15.pwconv2.weight\",\n",
            "      \"stages.2.16.dwconv.weight\",\n",
            "      \"stages.2.16.pwconv1.weight\",\n",
            "      \"stages.2.16.pwconv2.weight\",\n",
            "      \"stages.2.17.dwconv.weight\",\n",
            "      \"stages.2.17.pwconv1.weight\",\n",
            "      \"stages.2.17.pwconv2.weight\",\n",
            "      \"stages.2.18.dwconv.weight\",\n",
            "      \"stages.2.18.pwconv1.weight\",\n",
            "      \"stages.2.18.pwconv2.weight\",\n",
            "      \"stages.2.19.dwconv.weight\",\n",
            "      \"stages.2.19.pwconv1.weight\",\n",
            "      \"stages.2.19.pwconv2.weight\",\n",
            "      \"stages.2.20.dwconv.weight\",\n",
            "      \"stages.2.20.pwconv1.weight\",\n",
            "      \"stages.2.20.pwconv2.weight\",\n",
            "      \"stages.2.21.dwconv.weight\",\n",
            "      \"stages.2.21.pwconv1.weight\",\n",
            "      \"stages.2.21.pwconv2.weight\",\n",
            "      \"stages.2.22.dwconv.weight\",\n",
            "      \"stages.2.22.pwconv1.weight\",\n",
            "      \"stages.2.22.pwconv2.weight\",\n",
            "      \"stages.2.23.dwconv.weight\",\n",
            "      \"stages.2.23.pwconv1.weight\",\n",
            "      \"stages.2.23.pwconv2.weight\",\n",
            "      \"stages.2.24.dwconv.weight\",\n",
            "      \"stages.2.24.pwconv1.weight\",\n",
            "      \"stages.2.24.pwconv2.weight\",\n",
            "      \"stages.2.25.dwconv.weight\",\n",
            "      \"stages.2.25.pwconv1.weight\",\n",
            "      \"stages.2.25.pwconv2.weight\",\n",
            "      \"stages.2.26.dwconv.weight\",\n",
            "      \"stages.2.26.pwconv1.weight\",\n",
            "      \"stages.2.26.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.2.9.gamma\",\n",
            "      \"stages.2.9.dwconv.bias\",\n",
            "      \"stages.2.9.norm.weight\",\n",
            "      \"stages.2.9.norm.bias\",\n",
            "      \"stages.2.9.pwconv1.bias\",\n",
            "      \"stages.2.9.pwconv2.bias\",\n",
            "      \"stages.2.10.gamma\",\n",
            "      \"stages.2.10.dwconv.bias\",\n",
            "      \"stages.2.10.norm.weight\",\n",
            "      \"stages.2.10.norm.bias\",\n",
            "      \"stages.2.10.pwconv1.bias\",\n",
            "      \"stages.2.10.pwconv2.bias\",\n",
            "      \"stages.2.11.gamma\",\n",
            "      \"stages.2.11.dwconv.bias\",\n",
            "      \"stages.2.11.norm.weight\",\n",
            "      \"stages.2.11.norm.bias\",\n",
            "      \"stages.2.11.pwconv1.bias\",\n",
            "      \"stages.2.11.pwconv2.bias\",\n",
            "      \"stages.2.12.gamma\",\n",
            "      \"stages.2.12.dwconv.bias\",\n",
            "      \"stages.2.12.norm.weight\",\n",
            "      \"stages.2.12.norm.bias\",\n",
            "      \"stages.2.12.pwconv1.bias\",\n",
            "      \"stages.2.12.pwconv2.bias\",\n",
            "      \"stages.2.13.gamma\",\n",
            "      \"stages.2.13.dwconv.bias\",\n",
            "      \"stages.2.13.norm.weight\",\n",
            "      \"stages.2.13.norm.bias\",\n",
            "      \"stages.2.13.pwconv1.bias\",\n",
            "      \"stages.2.13.pwconv2.bias\",\n",
            "      \"stages.2.14.gamma\",\n",
            "      \"stages.2.14.dwconv.bias\",\n",
            "      \"stages.2.14.norm.weight\",\n",
            "      \"stages.2.14.norm.bias\",\n",
            "      \"stages.2.14.pwconv1.bias\",\n",
            "      \"stages.2.14.pwconv2.bias\",\n",
            "      \"stages.2.15.gamma\",\n",
            "      \"stages.2.15.dwconv.bias\",\n",
            "      \"stages.2.15.norm.weight\",\n",
            "      \"stages.2.15.norm.bias\",\n",
            "      \"stages.2.15.pwconv1.bias\",\n",
            "      \"stages.2.15.pwconv2.bias\",\n",
            "      \"stages.2.16.gamma\",\n",
            "      \"stages.2.16.dwconv.bias\",\n",
            "      \"stages.2.16.norm.weight\",\n",
            "      \"stages.2.16.norm.bias\",\n",
            "      \"stages.2.16.pwconv1.bias\",\n",
            "      \"stages.2.16.pwconv2.bias\",\n",
            "      \"stages.2.17.gamma\",\n",
            "      \"stages.2.17.dwconv.bias\",\n",
            "      \"stages.2.17.norm.weight\",\n",
            "      \"stages.2.17.norm.bias\",\n",
            "      \"stages.2.17.pwconv1.bias\",\n",
            "      \"stages.2.17.pwconv2.bias\",\n",
            "      \"stages.2.18.gamma\",\n",
            "      \"stages.2.18.dwconv.bias\",\n",
            "      \"stages.2.18.norm.weight\",\n",
            "      \"stages.2.18.norm.bias\",\n",
            "      \"stages.2.18.pwconv1.bias\",\n",
            "      \"stages.2.18.pwconv2.bias\",\n",
            "      \"stages.2.19.gamma\",\n",
            "      \"stages.2.19.dwconv.bias\",\n",
            "      \"stages.2.19.norm.weight\",\n",
            "      \"stages.2.19.norm.bias\",\n",
            "      \"stages.2.19.pwconv1.bias\",\n",
            "      \"stages.2.19.pwconv2.bias\",\n",
            "      \"stages.2.20.gamma\",\n",
            "      \"stages.2.20.dwconv.bias\",\n",
            "      \"stages.2.20.norm.weight\",\n",
            "      \"stages.2.20.norm.bias\",\n",
            "      \"stages.2.20.pwconv1.bias\",\n",
            "      \"stages.2.20.pwconv2.bias\",\n",
            "      \"stages.2.21.gamma\",\n",
            "      \"stages.2.21.dwconv.bias\",\n",
            "      \"stages.2.21.norm.weight\",\n",
            "      \"stages.2.21.norm.bias\",\n",
            "      \"stages.2.21.pwconv1.bias\",\n",
            "      \"stages.2.21.pwconv2.bias\",\n",
            "      \"stages.2.22.gamma\",\n",
            "      \"stages.2.22.dwconv.bias\",\n",
            "      \"stages.2.22.norm.weight\",\n",
            "      \"stages.2.22.norm.bias\",\n",
            "      \"stages.2.22.pwconv1.bias\",\n",
            "      \"stages.2.22.pwconv2.bias\",\n",
            "      \"stages.2.23.gamma\",\n",
            "      \"stages.2.23.dwconv.bias\",\n",
            "      \"stages.2.23.norm.weight\",\n",
            "      \"stages.2.23.norm.bias\",\n",
            "      \"stages.2.23.pwconv1.bias\",\n",
            "      \"stages.2.23.pwconv2.bias\",\n",
            "      \"stages.2.24.gamma\",\n",
            "      \"stages.2.24.dwconv.bias\",\n",
            "      \"stages.2.24.norm.weight\",\n",
            "      \"stages.2.24.norm.bias\",\n",
            "      \"stages.2.24.pwconv1.bias\",\n",
            "      \"stages.2.24.pwconv2.bias\",\n",
            "      \"stages.2.25.gamma\",\n",
            "      \"stages.2.25.dwconv.bias\",\n",
            "      \"stages.2.25.norm.weight\",\n",
            "      \"stages.2.25.norm.bias\",\n",
            "      \"stages.2.25.pwconv1.bias\",\n",
            "      \"stages.2.25.pwconv2.bias\",\n",
            "      \"stages.2.26.gamma\",\n",
            "      \"stages.2.26.dwconv.bias\",\n",
            "      \"stages.2.26.norm.weight\",\n",
            "      \"stages.2.26.norm.bias\",\n",
            "      \"stages.2.26.pwconv1.bias\",\n",
            "      \"stages.2.26.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 2940\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = SoftTargetCrossEntropy()\n",
            "Resume checkpoint /content/result_small_1/checkpoint-best.pth\n",
            "With optim & sched!\n",
            "Eval only mode\n",
            "Test:  [ 0/41]  eta: 0:06:14  loss: 0.4953 (0.4953)  acc1: 90.6250 (90.6250)  acc5: 97.9167 (97.9167)  time: 9.1338  data: 6.6816  max mem: 2325\n",
            "Test:  [10/41]  eta: 0:00:37  loss: 0.4974 (0.5260)  acc1: 89.5833 (90.2462)  acc5: 97.9167 (98.3902)  time: 1.1964  data: 0.6083  max mem: 2325\n",
            "Test:  [20/41]  eta: 0:00:17  loss: 0.5335 (0.6416)  acc1: 89.5833 (85.5655)  acc5: 97.9167 (98.5119)  time: 0.4088  data: 0.0007  max mem: 2325\n",
            "Test:  [30/41]  eta: 0:00:07  loss: 0.6794 (0.6546)  acc1: 82.2917 (85.0134)  acc5: 98.9583 (98.6223)  time: 0.4158  data: 0.0002  max mem: 2325\n",
            "Test:  [40/41]  eta: 0:00:00  loss: 0.6154 (0.6478)  acc1: 85.8824 (85.1720)  acc5: 97.9167 (98.3694)  time: 0.4222  data: 0.0002  max mem: 2325\n",
            "Test: Total time: 0:00:26 (0.6389 s / it)\n",
            "* Acc@1 85.172 Acc@5 98.369 loss 0.648\n",
            "Accuracy of the network on 3925 test images: 85.17198%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is higher than the paper's result which is 83%.\n",
        "\n",
        "It took longer training time compared to Tiny Architecture, almost 5 hours."
      ],
      "metadata": {
        "id": "B9sYCM8_ZigU"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6tCqILVtanjC",
        "YneHUU_BaVwf"
      ],
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1TVH81eu5rXYt4lHGUgylNyCTU6q0a5s0",
      "authorship_tag": "ABX9TyNytZmVBbg4oxaTR3UvAaDA",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}